const data_for_modality_monolingual = 
[
	{"name":"CUADCovenantNotToSueLegalBenchClassification","keyword":"monolingual","description":"\n  CUADCovenantNotToSueLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party is restricted from contesting the validity of the counterparty's ownership of intellectual property or otherwise bringing a claim against the counterparty for matters unrelated to the contract.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"autogkb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAutoGKB Annotation Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AutoGKB Annotation Benchmark is a comprehensive dataset designed to evaluate models' ability to extract pharmacogenomic variant-drug associations from scientific literature. This ground truth values for this data were compiled by reviewers from PharmGKB. This benchmark addresses the critical need for automated systems that can identify genetic variants, associated drugs, and their clinical relationships from biomedicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shlokn/autogkb.","url":"https://huggingface.co/datasets/shlokn/autogkb","creator_name":"Shlok Natarajan","creator_url":"https://huggingface.co/shlokn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"STAIR-Captions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for STAIR-Captions\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSTAIR Captions is a large-scale dataset containing 820,310 Japanese captions. This dataset can be used for caption generation, multimodal retrieval, and image generation.\n\n\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\n\n\n\n\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language data in JDocQA is in Japanese (BCP-47 ja-JP).\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shunk031/STAIR-Captions.","url":"https://huggingface.co/datasets/shunk031/STAIR-Captions","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-cinema-image-animee","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du cinÃ©ma et de l'image animÃ©e, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackMT","keyword":"monolingual","description":"\n  CodeFeedbackMT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2402.14658\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CodeFeedbackMT\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackMT.","url":"https://huggingface.co/datasets/mteb/CodeFeedbackMT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"lccc","keyword":"monolingual","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\nThis pipeline involves a set of rules and several classifier-based filters.\nNoises such as offensive or sensitive words, special symbols, emojis,\ngrammatically incorrect sentences, and incoherent conversations are filtered.","url":"https://huggingface.co/datasets/silver/lccc","creator_name":"Silver","creator_url":"https://huggingface.co/silver","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"qg_annotation","keyword":"monolingual","description":"Human-annotated question generated by models.","url":"https://huggingface.co/datasets/lmqg/qg_annotation","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","1K - 10K","Tabular"],"keywords_longer_than_N":true},
	{"name":"go_emotions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GoEmotions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\nThe raw data is included as well as the smaller, simplified version of the dataset with predefined train/val/test\nsplits.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class, multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is in English.\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/go_emotions.","url":"https://huggingface.co/datasets/google-research-datasets/go_emotions","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v3","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n400000/50000/50000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"beer_reviews_label_drift_neutral","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/beer_reviews_label_drift_neutral","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FaceMask","keyword":"monolingual","description":"MaskFace es un conjunto de datos de imÃ¡genes de personas con y sin mascarillas Consta de 3 clases: 1 clase de si la persona estÃ¡ puesta la mascarilla, \notra clase si la persona no esta puesta la mascarilla y una clase donde la persona estÃ¡ puesta la mascarilla incorrectamente.","url":"https://huggingface.co/datasets/poolrf2001/FaceMask","creator_name":"Paul Rivera","creator_url":"https://huggingface.co/poolrf2001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"BBNLI","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BBNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBBNLI (Bias Benchmark for Natural Language Inference) is bias measurement benchmark for the tasks of both natural language inference and question answering. BBNLI consists of 16 subtopics each tailored to measure a specific stereotype that is negatively impacting certain classes. Each subtopic includes a set of 3 to 11 premises,  5 to 11 stereotypical hypotheses that are geared towards measuring biases and 3 to 5 test hypotheses.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/feyzaakyurek/BBNLI.","url":"https://huggingface.co/datasets/feyzaakyurek/BBNLI","creator_name":"Afra Feyza Akyurek","creator_url":"https://huggingface.co/feyzaakyurek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","natural-language-inference","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"gov_report_qs","keyword":"monolingual","description":"GovReport-QS hierarchical question-summary generation dataset.\n\nThere are two configs:\n  - paragraph: paragraph-level annotated data\n  - document: aggregated paragraph-level annotated data for the same document","url":"https://huggingface.co/datasets/launch/gov_report_qs","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","launch/gov_report"],"keywords_longer_than_N":true},
	{"name":"bigscience-lama","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\n\t\n\n@inproceedings{petroni2020how,\n  title={How Context Affects Language Models' Factual Predictions},\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\n  booktitle={Automated Knowledge Base Construction},\n  year={2020}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama.","url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"spanish_imdb_synopsis","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Spanish IMDb Synopsis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n4969 movie synopsis from IMDb in spanish.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll descriptions are in spanish, the other fields have some mix of spanish and english.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ndescription: IMDb description for the movie (string), should be spanish\nkeywords: IMDb keywords for the movie (string), mix of spanish and english\ngenre: The genres of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis.","url":"https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis","creator_name":"Mathias Gatti","creator_url":"https://huggingface.co/mathigatti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"kpwr_and_cen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tKPWr & CEN\n\t\n\n","url":"https://huggingface.co/datasets/clarin-knext/kpwr_and_cen","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"polstance","keyword":"monolingual","description":"Political stance in Danish. Examples represent statements by \npoliticians and are annotated for, against, or neutral to a given topic/article.","url":"https://huggingface.co/datasets/strombergnlp/polstance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"qg_ruquad","keyword":"monolingual","description":"[SberSQuAD](https://huggingface.co/datasets/sberquad) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_ruquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","deepset/germanquad","Russian"],"keywords_longer_than_N":true},
	{"name":"kptimes","keyword":"monolingual","description":"KPTimes benchmark dataset for keyphrase extraction an generation.","url":"https://huggingface.co/datasets/taln-ls2n/kptimes","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","unknown","unknown","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"qg_itquad","keyword":"monolingual","description":"[SQuAD-it](https://huggingface.co/datasets/squad_it) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_itquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Italian"],"keywords_longer_than_N":true},
	{"name":"amz20","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/kuroneko5943/amz20","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"big_patent_100k_characters","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSampled Big Patent Dataset\n\t\n\nThis is a sampled Trelis/big_patent_sample dataset containing rows of data with descriptions shorter than or equal to 100,000 characters in length.\n--- Sampled from Trelis/big_patent_sampled ---\n\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million charactersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_100k_characters.","url":"https://huggingface.co/datasets/Trelis/big_patent_100k_characters","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"samromur_children_test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_children\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe SamrÃ³mur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with AlmannarÃ³mur, Center for Language Technology. The recording process hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test.","url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"probability_words_nli","keyword":"monolingual","description":"Probing neural language models for understanding of words of estimative probability","url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"distributed-computing-complex","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDistributed Systems Q&A Dataset\n\t\n\nThis dataset is collection of question-and-answer pairs related to distributed systems, compiled from a list of commonly asked questions in a college-level class. \nThis dataset is designed to assist educators, researchers, and developers working on tuning AI models, chatbots, or educational tools in the field of distributed systems.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nQuestions: A variety of questions covering fundamental distributed systems concepts.\nAnswers:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jeffreyszhou/distributed-computing-complex.","url":"https://huggingface.co/datasets/jeffreyszhou/distributed-computing-complex","creator_name":"Jeffrey Zhou","creator_url":"https://huggingface.co/jeffreyszhou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"OpenCodeReasoningRubrics","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOpenCodeReasoningRubrics\n\t\n\nThis dataset contains questions and rubric annotations intended for evaluating reasoning quality in open-ended coding or logical tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset has the following fields:\n\nindex (int): A unique identifier.\nquestion (str): A natural language question or prompt.\nrubric (str): An explanation or rubric detailing expectations or evaluation criteria.\n\nThe data is stored in split .parquet files for efficient loadingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danikhan632/OpenCodeReasoningRubrics.","url":"https://huggingface.co/datasets/danikhan632/OpenCodeReasoningRubrics","creator_name":"Daniyal M Khan","creator_url":"https://huggingface.co/danikhan632","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_oracle","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_oracle.","url":"https://huggingface.co/datasets/allenai/ms2_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","description":"Lorem ipsum","url":"https://huggingface.co/datasets/albertvillanova/test","creator_name":"Albert Villanova del Moral","creator_url":"https://huggingface.co/albertvillanova","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"CaSERa-catalan-stance-emotions-raco","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CaSERa, the Catalan Stance and Emotions Dataset from RacÃ³ CatalÃ \n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CaSERa dataset is a Catalan corpus from the forum RacÃ³ CatalÃ  annotated with Emotions and Dynamic Stance. The dataset contains 15.782 unique sentences grouped in 10.745 pairs of sentences, paired as parent messages and replies to these messages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to train models for emotion detection and dynamic stanceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco.","url":"https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Barcelona Supercomputing Center","RacÃ³ CatalÃ ","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"spiced","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SPICED\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Scientific Paraphrase and Information ChangE Dataset (SPICED) is a dataset of paired scientific findings from scientific papers, news media, and Twitter. The types of pairs are between <paper, news> and <paper, tweet>. Each pair is labeled for the degree of information similarity in the findings described by each sentence, on a scale from 1-5. This is called the Information Matching Score (IMS). The data was curated from S2ORCâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spiced.","url":"https://huggingface.co/datasets/copenlu/spiced","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"CaSET-catalan-stance-emotions-twitter","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CaSET, the Catalan Stance and Emotions Dataset from Twitter\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CaSET dataset is a Catalan corpus of Tweets annotated with Emotions, Static Stance, and Dynamic Stance. The dataset contains 11k unique sentences on five controversial topics, grouped in 6k pairs of sentences, paired as parent messages and replies to these messages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to train models for emotion detectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter.","url":"https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Barcelona Supercomputing Center","Twitter","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"medmcqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MedMCQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.\nEach sample contains a question, correct answer(s), and other options which requireâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openlifescienceai/medmcqa.","url":"https://huggingface.co/datasets/openlifescienceai/medmcqa","creator_name":"Open Life Science AI","creator_url":"https://huggingface.co/openlifescienceai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","multiple-choice-qa","open-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_max","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_max.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ViHOS","keyword":"monolingual","description":"This is a dataset of Vietnamese Hate and Offensive Spans dataset from social media texts.","url":"https://huggingface.co/datasets/phusroyal/ViHOS","creator_name":"Phu Gia Hoang","creator_url":"https://huggingface.co/phusroyal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","hate-speech-detection","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-summarisation-preferences","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman feedback data\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nSee https://github.com/openai/summarize-from-feedback for original details of the dataset.\nHere the data is formatted to enable huggingface transformers sequence classification models to be trained as reward functions.\n","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"naab-raw","keyword":"monolingual","description":"Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word Ù†Ø§Ø¨ which means pure and high-grade. This corpus contains the raw (uncleaned) version of it.","url":"https://huggingface.co/datasets/SLPL/naab-raw","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_unique","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/unpredictable/unpredictable_unique","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"google-play-review","keyword":"monolingual","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","url":"https://huggingface.co/datasets/jakartaresearch/google-play-review","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"human_actions_quality_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/human_actions_quality_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"humaneval_infilling","keyword":"monolingual","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation.","url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"nlprepl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for NLPre-PL â€“ fairly divided version of NKJP1M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the official NLPre-PL dataset - a uniformly paragraph-level divided version of NKJP1M corpus â€“ the 1-million token balanced subcorpus of the National Corpus of Polish (Narodowy Korpus JÄ™zyka Polskiego)\nThe NLPre dataset aims at fairly dividing the paragraphs length-wise and topic-wise into train, development, and test sets. Thus, we ensure a similar number of segments\ndistribution perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ipipan/nlprepl.","url":"https://huggingface.co/datasets/ipipan/nlprepl","creator_name":"IPI PAN","creator_url":"https://huggingface.co/ipipan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","lemmatization","parsing","expert-generated"],"keywords_longer_than_N":true},
	{"name":"tamil_stories","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\ntamil_stories is an open source dataset of instruct-style records generated by scraping publicly available short stories on the following websites.\n\nSiruvarmalar\nTamilsurangam\n\nApart from scraping and automated cleaning, the data was also tagged manually by a group of volunteers. \nThis dataset created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/tamil_stories.","url":"https://huggingface.co/datasets/aitamilnadu/tamil_stories","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tsl_news","keyword":"monolingual","description":"This new dataset is designed to solve this great NLP task and is crafted with a lot of care.","url":"https://huggingface.co/datasets/Tidrael/tsl_news","creator_name":"Trieu Nguyen","creator_url":"https://huggingface.co/Tidrael","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-relations-public-administration","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the developmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-penal","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode pÃ©nal, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"openwebtext","keyword":"monolingual","description":"An open-source replication of the WebText dataset from OpenAI.","url":"https://huggingface.co/datasets/Skylion007/openwebtext","creator_name":"Aaron Gokaslan","creator_url":"https://huggingface.co/Skylion007","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"czi_drsm","keyword":"monolingual","description":"Research Article document classification dataset based on aspects of disease research. Currently, the dataset consists of three subsets: \n\n(A) classifies title/abstracts of papers into most popular subtypes of clinical, basic, and translational papers (~20k papers); \n\n    - Clinical Characteristics, Disease Pathology, and Diagnosis - \n        Text that describes (A) symptoms, signs, or â€˜phenotypeâ€™ of a disease; \n        (B) the effects of the disease on patient organs, tissues, or cells; \n        (C) the results of clinical tests that reveal pathology (including\n        biomarkers); (D) research that use this information to figure out\n        a diagnosis.\n    - Therapeutics in the clinic - \n        Text describing how treatments work in the clinic (but not in a clinical trial).\n    - Disease mechanism - \n        Text that describes either (A) mechanistic involvement of specific genes in disease \n        (deletions, gain of function, etc); (B) how molecular signalling or metabolism \n        binding, activating, phosphorylation, concentration increase, etc.) \n        are involved in the mechanism of a disease; or (C) the physiological \n        mechanism of disease at the level of tissues, organs, and body systems.\n    - Patient-Based Therapeutics - \n        Text describing (A) Clinical trials (studies of therapeutic measures being \n        used on patients in a clinical trial); (B) Post Marketing Drug Surveillance \n        (effects of a drug after approval in the general population or as part of \n        â€˜standard healthcareâ€™); (C) Drug repurposing (how a drug that has been \n        approved for one use is being applied to a new disease).\n\n(B) identifies whether a title/abstract of a paper describes substantive research into Quality of Life (~10k papers); \n    \n    - -1 - the paper is not a primary experimental study in rare disease\n    - 0 - the study does not directly investigate quality of life\n    - 1 - the study investigates qol but not as its primary contribution\n    - 2 - the study's primary contribution centers on quality of life measures\n\n(C) identifies if a paper is a natural history study (~10k papers). \n`   \n    - -1 - the paper is not a primary experimental study in rare disease\n    - 0 - the study is not directly investigating the natural history of a disease\n    - 1 - the study includes some elements a natural history but not as its primary contribution\n    - 2 - the study's primary contribution centers on observing the time course of a rare disease\n    \nThese classifications are particularly relevant in rare disease research, a field that is generally understudied.","url":"https://huggingface.co/datasets/bigbio/czi_drsm","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"wiki_toxic","keyword":"monolingual","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw","url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"TACO","keyword":"monolingual","description":"TACO is a benchmark for Python code generation, it includes 25443 problems and 1000 problems for train and test splits.","url":"https://huggingface.co/datasets/BAAI/TACO","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-vabb-mlcls-pr","keyword":"monolingual","description":"\n  VABBMultiLabelClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains the fourteenth edition of the Flemish Academic Bibliography for the Social Sciences and Humanities (VABB-SHW), a database of academic publications from the social sciences and humanities authored by researchers affiliated to Flemish universities (more information). Publications in the database are used as one of the parameters of the Flemish performance-based research funding systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-vabb-mlcls-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-vabb-mlcls-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","clips/mteb-nl-vabb","Dutch"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-opentender-cls-pr","keyword":"monolingual","description":"\n  OpenTenderClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains Belgian and Dutch tender calls from OpenTender in Dutch\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://arxiv.org/abs/2509.12340\n\n\n\t\n\nSource datasets:\n\nclips/mteb-nl-opentender-cls\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-opentender-cls-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-opentender-cls-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","clips/mteb-nl-opentender-cls","Dutch"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_mc","keyword":"monolingual","description":"TruthfulQA-MC is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.","url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_mc","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"cord","keyword":"monolingual","description":"CORD (Consolidated Receipt Dataset) with normalized bounding boxes.","url":"https://huggingface.co/datasets/wkrl/cord","creator_name":"Karl Brendel","creator_url":"https://huggingface.co/wkrl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","parsing","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"lccc","keyword":"monolingual","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\nThis pipeline involves a set of rules and several classifier-based filters.\nNoises such as offensive or sensitive words, special symbols, emojis,\ngrammatically incorrect sentences, and incoherent conversations are filtered.","url":"https://huggingface.co/datasets/thu-coai/lccc","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["dialogue-generation","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-propriete-intellectuelle","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la propriÃ©tÃ© intellectuelle, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cgi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode GÃ©nÃ©ral des ImpÃ´ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/cgi.","url":"https://huggingface.co/datasets/louisbrulenaudet/cgi","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"difraud","keyword":"monolingual","description":"DIFrauD -- (Domain Independent Fraud Detection) is a corpus of deceptive and truthful texts from 7 domains:\n\n\"fake_news\",\n\"job_scams\",\n\"phishing\",\n\"political_statements\",\n\"product_reviews\",\n\"sms\",\n\"twitter_rumours\"\n\nTo load a specific domain, pass it as the \"name\" parameter to load_dataset()","url":"https://huggingface.co/datasets/redasers/difraud","creator_name":"ReDAS Lab at the University of Houston","creator_url":"https://huggingface.co/redasers","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"code-procedure-civile","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de procÃ©dure civile, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"lpf","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLivre des procÃ©dures fiscales, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervisedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lpf.","url":"https://huggingface.co/datasets/louisbrulenaudet/lpf","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"discourse_marker_qa","keyword":"monolingual","description":"Discourse marker/connective prediction as multiple choice questions based on the Discovery dataset","url":"https://huggingface.co/datasets/sileod/discourse_marker_qa","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","open-domain-qa","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"ro-paraphrase-bible","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Romanian Bible Paraphrase Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \nversions is straighforward. \nWe compiled aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible.","url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-scoring","semantic-similarity-scoring","semantic-similarity-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_mean","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrievedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_mean.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"internal-datasets","keyword":"monolingual","description":"SynQA is a Reading Comprehension dataset created in the work \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\" (https://aclanthology.org/2021.emnlp-main.696/).\nIt consists of 314,811 synthetically generated questions on the passages in the SQuAD v1.1 (https://arxiv.org/abs/1606.05250) training set.\n\nIn this work, we use a synthetic adversarial data generation to make QA models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA (https://adversarialqa.github.io/) dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation to show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8% of the time on average, compared to 17.6% for a model trained without synthetic data.\n\nFor full details on how the dataset was created, kindly refer to the paper.","url":"https://huggingface.co/datasets/Marbyun/internal-datasets","creator_name":"Ivan Rivaldo Marbun","creator_url":"https://huggingface.co/Marbyun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","generated","found"],"keywords_longer_than_N":true},
	{"name":"pubhealth","keyword":"monolingual","description":"A dataset of 11,832 claims for fact- checking, which are related a range of health topics\nincluding biomedical subjects (e.g., infectious diseases, stem cell research), government healthcare policy\n(e.g., abortion, mental health, womenâ€™s health), and other public health-related stories","url":"https://huggingface.co/datasets/bigbio/pubhealth","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"model-written-evals","keyword":"monolingual","description":"This new dataset is designed to solve this great NLP task and is crafted with a lot of care.","url":"https://huggingface.co/datasets/khalidalt/model-written-evals","creator_name":"Khalid Almubarak","creator_url":"https://huggingface.co/khalidalt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","zero-shot-classification","question-answering","multiple-choice-qa","multiple-choice-coreference-resolution"],"keywords_longer_than_N":true},
	{"name":"inferes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for InferES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNatural Language Inference dataset for European Spanish\nPaper accepted and (to be) presented at COLING 2022\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\n\n\t\n\t\t\n\t\tData Instances\n\t\n\ntrain size = 6444 \ntest size = 1612\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes.","url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"comps","keyword":"monolingual","description":"COMPS is a dataset of minimal pair sentences in English that enables the \ntesting knowledge of concepts and their properties in language models (LMs).\nSpecifically, it tests the ability of LMs to attribute properties to everyday \nconcepts, and demonstrate reasoning compatible with property inheritance, where\nsubordinate concepts inherit the properties of their superordinate (hypernyms).","url":"https://huggingface.co/datasets/kanishka/comps","creator_name":"Kanishka Misra","creator_url":"https://huggingface.co/kanishka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"winogavil","keyword":"monolingual","description":"WinoGAViL is a challenging dataset for evaluating vision-and-language commonsense reasoning abilities. Given a set of images, a cue, and a number K, the task is to select the K images that best fits the association. This dataset was collected via the WinoGAViL online game to collect vision-and-language associations, (e.g., werewolves to a full moon). Inspired by the popular card game Codenames, a spymaster gives a textual cue related to several visual candidates, and another player has to identify them. Human players are rewarded for creating associations that are challenging for a rival AI model but still solvable by other human players. We evaluate several state-of-the-art vision-and-language models, finding that they are intuitive for humans (>90% Jaccard index) but challenging for state-of-the-art AI models, where the best model (ViLT) achieves a score of 52%, succeeding mostly where the cue is visually salient. Our analysis as well as the feedback we collect from players indicate that the collected associations require diverse reasoning skills, including general knowledge, common sense, abstraction, and more.","url":"https://huggingface.co/datasets/severo/winogavil","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"winogavil","keyword":"monolingual","description":"WinoGAViL is a challenging dataset for evaluating vision-and-language commonsense reasoning abilities. Given a set of images, a cue, and a number K, the task is to select the K images that best fits the association. This dataset was collected via the WinoGAViL online game to collect vision-and-language associations, (e.g., werewolves to a full moon). Inspired by the popular card game Codenames, a spymaster gives a textual cue related to several visual candidates, and another player has to identify them. Human players are rewarded for creating associations that are challenging for a rival AI model but still solvable by other human players. We evaluate several state-of-the-art vision-and-language models, finding that they are intuitive for humans (>90% Jaccard index) but challenging for state-of-the-art AI models, where the best model (ViLT) achieves a score of 52%, succeeding mostly where the cue is visually salient. Our analysis as well as the feedback we collect from players indicate that the collected associations require diverse reasoning skills, including general knowledge, common sense, abstraction, and more.","url":"https://huggingface.co/datasets/nlphuji/winogavil","creator_name":"nlphuji","creator_url":"https://huggingface.co/nlphuji","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"code-postes-communications-electroniques","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des postes et des communications Ã©lectroniques, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail.","url":"https://huggingface.co/datasets/abisee/cnn_dailymail","creator_name":"Abigail See","creator_url":"https://huggingface.co/abisee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"skateboarding-tricks","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Skateboarding tricks\n\t\n\nDataset used to train Text to skateboarding image model.\nFor each row the dataset contains image and text keys.\nimage is a varying size PIL jpeg, and text is the accompanying text caption.\n","url":"https://huggingface.co/datasets/vogloblinsky/skateboarding-tricks","creator_name":"Ogloblinsky","creator_url":"https://huggingface.co/vogloblinsky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/gsm8k.","url":"https://huggingface.co/datasets/openai/gsm8k","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"sd-character-level-ner","keyword":"monolingual","description":"    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.","url":"https://huggingface.co/datasets/EMBO/sd-character-level-ner","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","named-entity-recognition","parsing","expert-generated"],"keywords_longer_than_N":true},
	{"name":"PubMedQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe official leaderboard is available at: https://pubmedqa.github.io/.\n500 questions in the pqa_labeled are used as the test set. They can be found atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qiaojin/PubMedQA.","url":"https://huggingface.co/datasets/qiaojin/PubMedQA","creator_name":"Qiao Jin","creator_url":"https://huggingface.co/qiaojin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"turkish-constitutional-court","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is extracted from the following Github repo, which was created for the journal paper with URL https://www.sciencedirect.com/science/article/abs/pii/S0306457321001692.\nhttps://github.com/koc-lab/law-turk\nThe dataset includes 1290 court case decision texts from the Turkish Court of Cassation. Each sample has one label, which is the ruling of the court. The possible rulings are \"Violation\" and \"No violation\". There are 1290 samples. 1141 of these samplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court.","url":"https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court","creator_name":"Aykut KoÃ§ Lab","creator_url":"https://huggingface.co/KocLab-Bilkent","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"truthful_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for truthful_qa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/truthfulqa/truthful_qa.","url":"https://huggingface.co/datasets/truthfulqa/truthful_qa","creator_name":"TruthfulQA","creator_url":"https://huggingface.co/truthfulqa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"cloth","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tcloth\n\t\n\nCLOTH is a dataset which is a collection of nearly 100,000 cloze questions from middle school and high school English exams. The detail of CLOTH dataset is shown below.\n\n\t\n\t\t\nNumber of questions\nTrain\nValid\nTest\n\n\n\t\t\nMiddle school\n22056\n3273\n3198\n\n\nHigh school\n54794\n7794\n8318\n\n\nTotal\n76850\n11067\n11516\n\n\n\t\n\nSource: https://www.cs.cmu.edu/~glai1/data/cloth/\n","url":"https://huggingface.co/datasets/AndyChiang/cloth","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","monolingual","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"autoregressive-paraphrase-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"naacl2022","keyword":"monolingual","description":"NACL22 is a dataset labelled for Science Entity Recognition task, which is a subtask of NER task. \nThe text is from 2022 conference papers collected from ACL anthology. \nThe dataset is collected by Haotian Teng and Xiaoyue Cui. \nAnnotation standard can be found here https://github.com/neubig/nlp-from-scratch-assignment-2022/blob/main/annotation_standard.md","url":"https://huggingface.co/datasets/havens2/naacl2022","creator_name":"Haotian Teng","creator_url":"https://huggingface.co/havens2","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"peoples_speech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLCommons/peoples_speech.","url":"https://huggingface.co/datasets/MLCommons/peoples_speech","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"P3","keyword":"monolingual","description":"This is a repreprocessed version of P3 with any updates that have been made to the P3 datasets since the release of the original P3. It is used for the finetuning of bloomz-p3 & mt0-xxl-p3. The script is available here.\n","url":"https://huggingface.co/datasets/Muennighoff/P3","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"monolingual","description":"ï·½\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"clintox","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for clintox\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nclintox is a dataset included in MoleculeNet. Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons. This uses the CT_TOX task.\nNote, there was one molecule in the training set that could not be converted to SELFIES (*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a moleculeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clintox.","url":"https://huggingface.co/datasets/zpn/clintox","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"icelandic-error-corpus-IceEC","keyword":"monolingual","description":"The Icelandic Error Corpus (IceEC) is a collection of texts in modern Icelandic annotated for mistakes related to spelling, grammar, and other issues. The texts are organized by genre. The current version includes sentences from student essays, online news texts and Wikipedia articles.\nSentences within texts in the student essays had to be shuffled due to the license which they were originally published under, but neither the online news texts nor the Wikipedia articles needed to be shuffled.","url":"https://huggingface.co/datasets/mideind/icelandic-error-corpus-IceEC","creator_name":"MiÃ°eind ehf.","creator_url":"https://huggingface.co/mideind","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","Icelandic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"alsqa","keyword":"monolingual","description":"To test the lexical overlap heuristic utilization in Reading Comprehension models, we create a new test set: Analyzing Lexically Similar QA (ALSQA).\nWe augment the SQuAD 2.0 dataset (Rajpurkar et al., 2018) by asking crowdworkers to generate questions with high context-overlap from questions with low overlap (These questions are paraphrases of the original questions).\nIn the case of un-answerable questions, annotators were asked to re-write the question without changing its meaning and maintain the unanswerability reason.3 ALSQA contains 365 questions pairs, 190 with an- swer and 174 without answer.","url":"https://huggingface.co/datasets/biu-nlp/alsqa","creator_name":"Bar-Ilan University NLP Lab","creator_url":"https://huggingface.co/biu-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","open-domain-qa","extractive-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"SLF5K","keyword":"monolingual","description":"The Summarization with Language Feedback (SLF5K) dataset is an English-language dataset containing 5K unique samples that can be used for the task of abstraction summarization. Each sample consists of a Reddit title and post, a model-generated (FeedME) summary, and human-written language feedback on that summary. Additionally, each sample has a high-quality, human-written (gold) summary that should be ideal for the Reddit post. Lastly, each sample has two additional model-generated summaries with binary human preference labels, on which summary is preferred by a human. The dataset can be used to train language models with language feedback on abstractive summarization. It can also be used to train a reward model on binary preferences.","url":"https://huggingface.co/datasets/JeremyAlain/SLF5K","creator_name":"JÃ©rÃ©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ner","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"wnut_17\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWNUT 17: Emerging and Rare entity recognition\nThis shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\nNamed entities form the basis of many modern approaches to other tasks (like event clustering and summarisation),\nbut recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms.\nTake for exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kriyans/ner.","url":"https://huggingface.co/datasets/Kriyans/ner","creator_name":"parsana","creator_url":"https://huggingface.co/Kriyans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tathagata","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for tathagata\n\t\n\n\n\t\n\t\t\n\t\tI-Dataset Summary\n\t\n\ntathagata.txt is a dataset based on summaries of major Buddhist, Hindu and Advaita texts such as:\n\nDiamond Sutra\nLankavatara Sutra\nSri Nisargadatta Maharaj quotes\nQuotes from the Bhagavad Gita\n\nThis dataset was used to train this model https://huggingface.co/radm/rugpt3medium-tathagata\n\n\t\n\t\t\n\t\n\t\n\t\tII-Languages\n\t\n\nThe texts in the dataset are in Russian (ru).\n","url":"https://huggingface.co/datasets/radm/tathagata","creator_name":"r4dm","creator_url":"https://huggingface.co/radm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Lipogram-e","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Lipogram-e\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\n\nThis is a dataset of 3 English books which do not contain the letter \"e\" in them. This dataset includes all of \"Gadsby\" by Ernest Vincent Wright, all of \"A Void\" by Georges Perec, and almost all of \"Eunoia\" by Christian Bok (except for the single chapter that uses the letter \"e\" in it) This dataset is contributed as part of a paper titled \"Most Language Models can be Poets too: An AI Writing Assistant and Constrained Textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e.","url":"https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"msmarco-nlgen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MSMARCO - Natural Language Generation Task\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe original focus of MSMARCO was to provide a corpus for training and testing systems which given a real domain user query systems would then provide the most likley candidate answer and do so in language which was natural and conversational. All questions have been generated from real anonymized Bing user queries which grounds the dataset in a real world problem and can provide researchers realâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/din0s/msmarco-nlgen.","url":"https://huggingface.co/datasets/din0s/msmarco-nlgen","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"pierogue","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPierogue\n\t\n\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\n\nTopics: cosmos, nature, music, technology, fashion\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\n\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue.","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","text-generation","document-retrieval","language-modeling"],"keywords_longer_than_N":true},
	{"name":"IRIS_sts","keyword":"monolingual","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de JustiÃ§a\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for Semantic Textual Similarity\n\nValues from 0-1: random sentences across documents\nValues from 2-4: sentences from the same summary (implying some level of entailment)\nValues from 4-5: sentences pairs generated through OpenAi'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts.","url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"SumarizaÃ§Ã£o e InformaÃ§Ã£o de decisÃµes: AplicaÃ§Ã£o de TÃ©cnicas de InteligÃªncia Artificial no Supremo Tribunal de JustiÃ§a (IRIS)","creator_url":"https://huggingface.co/stjiris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","automated","found"],"keywords_longer_than_N":true},
	{"name":"ru_goemotions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GoEmotions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe RuGoEmotions dataset contains 34k Reddit comments labeled for 9 emotion categories (joy, interest, surprice, sadness, anger, disgust, fear, guilt and neutral).\nThe dataset already with predefined train/val/test splits\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class, multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Djacon/ru_goemotions.","url":"https://huggingface.co/datasets/Djacon/ru_goemotions","creator_name":"Daniel","creator_url":"https://huggingface.co/Djacon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"clean_mc4_it","keyword":"monolingual","description":"A thoroughly cleaned version of the Italian portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.","url":"https://huggingface.co/datasets/gsarti/clean_mc4_it","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tr_rte","keyword":"monolingual","description":"nlpyeditepe/tr_rte dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nlpyeditepe/tr_rte","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","found","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"EpiSet4BinaryClassification","keyword":"monolingual","description":"INSERT DESCRIPTION","url":"https://huggingface.co/datasets/ncats/EpiSet4BinaryClassification","creator_name":"National Center for Advancing Translational Sciences","creator_url":"https://huggingface.co/ncats","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["unknown","unknown","monolingual","unknown","English"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-questions-2016","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Stackoverflow Post Questions]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \nthe other hand, every software developerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016.","url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ManyTypes4TypeScript","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tModels Trained On ManyTypes4TypeScript\n\t\n\n\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task similarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript.","url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"casum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CaSum\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (AgÃ¨ncia Catalana de NotÃ­cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rouge score. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum.","url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","machine-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"telugu_asr_corpus","keyword":"monolingual","description":"The corpus contains roughly 360 hours of audio and transcripts in Telugu language. The transcripts have beed de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/telugu_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"germandpr","keyword":"monolingual","description":"We take GermanQuAD as a starting point and add hard negatives from a dump of the full German Wikipedia following the approach of the DPR authors (Karpukhin et al., 2020). The format of the dataset also resembles the one of DPR. GermanDPR comprises 9275 question/answer pairs in the training set and 1025 pairs in the test set. For each pair, there are one positive context and three hard negative contexts.","url":"https://huggingface.co/datasets/deepset/germandpr","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"id_newspapers_2018","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset of Indonesian Online Newspaper\n\t\n\nThis is a copy of dataset created by Feryandi Nurdiantoro (https://github.com/feryandi/Dataset-Artikel). The original dataset in json format is stored uncompressed in Google Drive in more than 500K files, one file per article. Unfortunately, due to its size, it is impossible to download the whole dataset as one big compressed file (it takes forever to compress it online). Therefore I provide here a copy and its cleaned version as compressedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/indonesian-nlp/id_newspapers_2018.","url":"https://huggingface.co/datasets/indonesian-nlp/id_newspapers_2018","creator_name":"Indonesian NLP","creator_url":"https://huggingface.co/indonesian-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"catalan_general_crawling","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Catalan General Crawling\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Catalan General Crawling Corpus is a 435-million-token web corpus of Catalan built from the web. It has been obtained by crawling the 500 most popular .cat and .ad domains during July 2020. It consists of 434,817,705 tokens, 19,451,691 sentences and 1,016,114 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.\nThis work is licensed under a Creative Commonsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_general_crawling.","url":"https://huggingface.co/datasets/projecte-aina/catalan_general_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"java-cmpx","keyword":"monolingual","description":"giganticode/java-cmpx dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/giganticode/java-cmpx","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"socialdisner","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSocialDisNER\n\t\n\nThis is a third party reupload of the SocialDisNER dataset.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {GarcÃ­a Subies, Guillem and Barbero JimÃ©nez, Ãlvaro and MartÃ­nez FernÃ¡ndez, Paloma},\n    title = {A comparative analysis of Spanish Clinical encoder-based models on NER and classificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IIC/socialdisner.","url":"https://huggingface.co/datasets/IIC/socialdisner","creator_name":"Instituto de IngenierÃ­a del Conocimiento","creator_url":"https://huggingface.co/IIC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_nl","keyword":"monolingual","description":"    This dataset is the CNN/Dailymail dataset translated to Dutch.\n    This is the original dataset:\n    ```\n    load_dataset(\"cnn_dailymail\", '3.0.0')\n    ```\n    And this is the HuggingFace translation pipeline:\n    ```\n    pipeline(\n        task='translation_en_to_nl',\n        model='Helsinki-NLP/opus-mt-en-nl',\n        tokenizer='Helsinki-NLP/opus-mt-en-nl')\n    ```","url":"https://huggingface.co/datasets/ml6team/cnn_dailymail_nl","creator_name":"ML6 Team","creator_url":"https://huggingface.co/ml6team","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["no-annotation","found","monolingual","https://github.com/huggingface/datasets/tree/master/datasets/cnn_dailymail","Dutch"],"keywords_longer_than_N":true},
	{"name":"aspectemo","keyword":"monolingual","description":"AspectEmo dataset: Multi-Domain Corpus of Consumer Reviews for Aspect-Based \n                Sentiment Analysis","url":"https://huggingface.co/datasets/clarin-pl/aspectemo","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-accent","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent.","url":"https://huggingface.co/datasets/DTU54DL/common-accent","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"my-awesome-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewtun/my-awesome-dataset.","url":"https://huggingface.co/datasets/lewtun/my-awesome-dataset","creator_name":"Lewis Tunstall","creator_url":"https://huggingface.co/lewtun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"dialogsum_reformat","keyword":"monolingual","description":"DialogSUM Corpus contains 13460 chat dialogues with manually annotated\nsummaries.\nThere are two features:\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - topic: one liner summary of the dialogue.\n  - id: id of a example.","url":"https://huggingface.co/datasets/knkarthick/dialogsum_reformat","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"livingner1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLivingNER\n\t\n\nThis is a third party reupload of the LivingNER task 1 dataset.\nIt only contains the task 1 for the Spanish language. It does not include the multilingual data nor the background data.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {GarcÃ­a Subies, Guillem and Barbero JimÃ©nez, Ãlvaro and MartÃ­nezâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner1.","url":"https://huggingface.co/datasets/IIC/livingner1","creator_name":"Instituto de IngenierÃ­a del Conocimiento","creator_url":"https://huggingface.co/IIC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"nkjp1m","keyword":"monolingual","description":"This is the official dataset for NKJP1M â€“ the 1-million token subcorpus of the\nNational Corpus of Polish (Narodowy Korpus JÄ™zyka Polskiego)\n\nBesides the text (divided into paragraphs/samples and sentences) the\nset contains lemmas and morpho-syntactic tags for all tokens in the corpus.\n\nThis release corresponds to the version 1.2 of the corpus with\nfollowing corrections and improvements. In particular the\nmorpho-syntactic annotation has been aligned with the present version\nof Morfeusz2 morphological analyser.","url":"https://huggingface.co/datasets/ipipan/nkjp1m","creator_name":"IPI PAN","creator_url":"https://huggingface.co/ipipan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","part-of-speech","lemmatization","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"core-2020-05-10-deduplication","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CORE Deduplication\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCORE 2020 Deduplication dataset (https://core.ac.uk/documentation/dataset) contains 100K scholarly documents labeled as duplicates/non-duplicates.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset language is English (BCP-47 en)\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{dedup2020,\n  title={Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings},\n  author={Gyawali, Bikash and Anastasiou, Lucas andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication.","url":"https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication","creator_name":"Pinecone","creator_url":"https://huggingface.co/pinecone","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","natural-language-inference","semantic-similarity-scoring","text-scoring","unknown"],"keywords_longer_than_N":true},
	{"name":"123_test","keyword":"monolingual","description":"The Fewshot Table dataset consists of tables that naturally occur on the web, that are formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. The dataset consists of approximately 413K tables that are extracted from the WDC Web Table Corpora 2015, which is released under the Apache-2.0 license. The WDC Web Table Corpora \"contains vast amounts of HTML tables. [...] The Web Data Commons project extracts relational Web tables from the Common Crawl, the largest and most up-to-date Web corpus that is currently available to the public.\"","url":"https://huggingface.co/datasets/JeremyAlain/123_test","creator_name":"JÃ©rÃ©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"dialogs_from_jokes","keyword":"monolingual","description":"Converted to json version of dataset from Koziev/NLP_Datasets\n","url":"https://huggingface.co/datasets/artemsnegirev/dialogs_from_jokes","creator_name":"Artem Snegirev","creator_url":"https://huggingface.co/artemsnegirev","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","monolingual","Russian","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"openwebtext_20p","keyword":"monolingual","description":"\n\t\n\t\t\n\t\topenwebtext_20p\n\t\n\nfirst 20% of openwebtext\n","url":"https://huggingface.co/datasets/Bingsu/openwebtext_20p","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"jomleh","keyword":"monolingual","description":"Jomleh is a Farsi (Persian) monolingual dataset composed of one sentence per sample. It's focused on quality over quantity and it's curated mostly based on the OSCAR project (https://oscar-project.com) among other data sources.\\","url":"https://huggingface.co/datasets/mlengineer-ai/jomleh","creator_name":"ML Engineer","creator_url":"https://huggingface.co/mlengineer-ai","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"araina-text-corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAraina Text Corpus\n\t\n\nText corpus in Aranese variety of Gascon dialect of Occitan.\n\n\t\n\t\t\n\t\tCorpora\n\t\n\n\n_nogues: Literary texts translated by AntÃ²ni NoguÃ©s. Sourced from institutestudisaranesi.cat\n_suils: Language educational material by Jordi SuÃ¯ls SubirÃ \n_conselh: Administrative proceedings from Conselh Generau d'Aran\n\n\n\t\n\t\t\n\t\tProject Araina\n\t\n\nThis corpus was prepared as part of Project Araina with support from Culture Department of the Catalan autonomous government.\nAquest corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/araina-text-corpus.","url":"https://huggingface.co/datasets/collectivat/araina-text-corpus","creator_name":"ColÂ·lectivaT","creator_url":"https://huggingface.co/collectivat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"knesset_meetings_corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAn example of a sample:\n{\n    \"text\": <text content of given document>,\n    \"path\": <file path to docx>\n}\n\nDataset usage\nAvailable \"kneset16\",\"kneset17\",\"knesset_tagged\" configurations\nAnd only train set.\ntrain_ds = load_dataset(\"imvladikon/knesset_meetings_corpus\", \"kneset16\", split=\"train\")\n\nThe Knesset Meetings Corpus 2004-2005 is made up of two components:\n\nRaw texts - 282 files made up of 867,725 lines together. These can be downloaded inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/knesset_meetings_corpus.","url":"https://huggingface.co/datasets/imvladikon/knesset_meetings_corpus","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"telugu-dataset","keyword":"monolingual","description":"Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008).","url":"https://huggingface.co/datasets/varox34/telugu-dataset","creator_name":"Varun Shah","creator_url":"https://huggingface.co/varox34","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"squad-augmented-v2","keyword":"monolingual","description":"christti/squad-augmented-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/christti/squad-augmented-v2","creator_name":"Christoph Timmermann","creator_url":"https://huggingface.co/christti","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"unpredictable_sporcle-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_sporcle-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_mmo-champion-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_mmo-champion-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_bulbapedia-bulbagarden-net","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_bulbapedia-bulbagarden-net","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"news-data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for news-data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe News Dataset is an English-language dataset containing just over 4k unique news articles scrapped from AriseTv- One of the most popular news television in Nigeria. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIt supports news article classification into different categories.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n'''\n{'Title': 'Nigeria: APC Yet to Zone Party Positions Ahead ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/okite97/news-data.","url":"https://huggingface.co/datasets/okite97/news-data","creator_name":"Okite Chimaobi Samuel","creator_url":"https://huggingface.co/okite97","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","other","found"],"keywords_longer_than_N":true},
	{"name":"contentious_contexts","keyword":"monolingual","description":"This dataset contains extracts from historical Dutch newspapers which have been containing keywords of potentially contentious words (according to present-day sensibilities). \nThe dataset contains multiple annotations per instance, given the option to quantify agreement scores for annotations. This dataset can be used to track how words and their meanings have changed over time","url":"https://huggingface.co/datasets/biglam/contentious_contexts","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-scoring","multi-label-classification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ctebmsp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCT-EBM-SP (Clinical Trials for Evidence-based Medicine in Spanish)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Clinical Trials for Evidence-Based-Medicine in Spanish corpus is a collection of 1200 texts about clinical trials studies and clinical trials announcements:\n\n500 abstracts from journals published under a Creative Commons license, e.g. available in PubMed or the Scientific Electronic Library Online (SciELO)\n700 clinical trials announcements published in the European Clinical Trialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lcampillos/ctebmsp.","url":"https://huggingface.co/datasets/lcampillos/ctebmsp","creator_name":"Leonardo Campillos-Llanos","creator_url":"https://huggingface.co/lcampillos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tm1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Taskmaster-1\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-1-2019\nPaper: https://arxiv.org/pdf/1909.05358.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm1')\nontology = load_ontology('tm1')\ndatabase =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm1.","url":"https://huggingface.co/datasets/ConvLab/tm1","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","arxiv:1909.05358"],"keywords_longer_than_N":true},
	{"name":"hl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for the High-Level Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe High-Level (HL) dataset aligns object-centric descriptions from COCO \nwith high-level descriptions crowdsourced along 3 axes: scene, action, rationale\nThe HL dataset contains 14997 images from COCO and a total of 134973 crowdsourced captions (3 captions for each axis) aligned with ~749984 object-centric captions from COCO.\nEach axis is collected by asking the following 3 questions:\n\nWhere is the pictureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl.","url":"https://huggingface.co/datasets/michelecafagna26/hl","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","question-answering","zero-shot-classification","text-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"spellcheck_benchmark","keyword":"monolingual","description":"Russian Spellcheck Benchmark is a new benchmark for spelling correction in Russian language.\n                It includes four datasets, each of which consists of pairs of sentences in Russian language. \n                Each pair embodies sentence, which may contain spelling errors, and its corresponding correction. \n                Datasets were gathered from various sources and domains including social networks, internet blogs, github commits, \n                medical anamnesis, literature, news, reviews and more.","url":"https://huggingface.co/datasets/ai-forever/spellcheck_benchmark","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"fake_railroad_company","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tfake_railroad_company\n\t\n\nThis is toy data I created about an imaginary railroad company.\n\n\t\n\t\t\n\t\tV1\n\t\n\nThis is the first version of the data that I generated.\n\n\t\n\t\t\n\t\tV2\n\t\n\nI tweaked some of the weights I used to calculate the satisfaction score.\n\n\t\n\t\t\n\t\tV3\n\t\n\nSome customers are now power users who ride more often than other users.\n\n\t\n\t\t\n\t\tV4\n\t\n\nCustomers with children are more likely to be members\n","url":"https://huggingface.co/datasets/davidwisdom/fake_railroad_company","creator_name":"David Wisdom","creator_url":"https://huggingface.co/davidwisdom","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"topicsum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TopicSum Corpus [Single Dataset Comprising of XSUM & DialogSUM for One Liner Summarization/ Topic Generation of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nDialogSUM: https://github.com/cylnlp/dialogsum\nXSUM: https://huggingface.co/datasets/knkarthick/xsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTopicSUM is collection of large-scale dialogue summarization dataset from XSUM & DialogSUM, consisting of 241,171â€¦ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/topicsum.","url":"https://huggingface.co/datasets/knkarthick/topicsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"peewee-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Peewee Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPeewee Issues is a dataset containing all the issues in the Peewee github repository up to the last date of extraction (5/3/2023). It has been made for educational purposes in mind (especifically, to get me used to using Hugging Face's datasets), but can be used for multi-label classification or semantic search. The contents are all in English and concern SQL databases and ORM libraries.\n","url":"https://huggingface.co/datasets/akumoth/peewee-issues","creator_name":"Rainer Palm","creator_url":"https://huggingface.co/akumoth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","topic-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"fig-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Fig-QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for the paper Testing the Ability of Language Models to Interpret Figurative Language. Fig-QA consists of 10256 examples of human-written creative metaphors that are paired as a Winograd schema. It can be used to evaluate the commonsense reasoning of models. The metaphors themselves can also be used as training data for other tasks, such as metaphor detection or generation. \n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nightingal3/fig-qa.","url":"https://huggingface.co/datasets/nightingal3/fig-qa","creator_name":"Emmy Liu","creator_url":"https://huggingface.co/nightingal3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bengali_asr_corpus","keyword":"monolingual","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples","url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"LeCaRDv2","keyword":"monolingual","description":"\n  LeCaRDv2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the case document that best matches or is most relevant to the scenario described in each of the provided queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/THUIR/LeCaRDv2\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LeCaRDv2.","url":"https://huggingface.co/datasets/mteb/LeCaRDv2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"commonsense_qa-ID","keyword":"monolingual","description":"CommonsenseQA-ID is Indonesian translation version of CommonsenseQA, a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.","url":"https://huggingface.co/datasets/rizquuula/commonsense_qa-ID","creator_name":"Muhammad Razif Rizqullah","creator_url":"https://huggingface.co/rizquuula","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Writing-style-classification","keyword":"monolingual","description":"This file contains news texts (sentences) belonging to different writing styles. The original dataset created by {Upeksha, D., Wijayarathna, C., Siriwardena, M.,\nLasandun, L., Wimalasuriya, C., de Silva, N., and Dias, G. (2015). Implementing a corpus for Sinhala language. 01}is processed and cleaned.\nIf you use this dataset, please cite {Dhananjaya et al. BERTifying Sinhala - A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification, 2022} and the above mentionedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"WANLI","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for WANLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWANLI (Worker-AI Collaboration for NLI) is a collection of 108K English sentence pairs for the task of natural language inference (NLI).\nEach example is created by first identifying a \"pocket\" of examples in MultiNLI (Williams et al., 2018) that share a challenging reasoning pattern, then instructing GPT-3 to write a new example with the same pattern.\nThe set of generated examples are automatically filtered to contain those mostâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alisawuffles/WANLI.","url":"https://huggingface.co/datasets/alisawuffles/WANLI","creator_name":"Alisa Liu","creator_url":"https://huggingface.co/alisawuffles","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","crowdsourced","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki-edits-uk","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUkrainian Wikipedia Edits\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nA collection of over 5M sentence edits extracted from Ukrainian Wikipedia history revisions.\nEdits were filtered by edit distance and sentence length. This makes them usable for grammatical error correction (GEC) or spellchecker models pre-training.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nUkrainian grammatical error correction (GEC) - see UA-GEC\nUkrainian spelling correction\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nUkrainian\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/osyvokon/wiki-edits-uk.","url":"https://huggingface.co/datasets/osyvokon/wiki-edits-uk","creator_name":"Oleksiy Syvokon","creator_url":"https://huggingface.co/osyvokon","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","crowdsourced","monolingual","translation"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_self_contained","keyword":"monolingual","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/patrickvonplaten/librispeech_asr_self_contained","creator_name":"Patrick von Platen","creator_url":"https://huggingface.co/patrickvonplaten","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"id_recipe","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for id_recipe\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIndonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food. \nid_recipe is an Indonesian Food Recipe dataset. The dataset contains >10000 Indonesian Recipe.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIndonesian\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nHere are the number of examples\n\n\t\n\t\t\nnameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sultannn/id_recipe.","url":"https://huggingface.co/datasets/Sultannn/id_recipe","creator_name":"Sultan","creator_url":"https://huggingface.co/Sultannn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ecommerce_reviews_with_language_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/ecommerce_reviews_with_language_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"broad_twitter_corpus","keyword":"monolingual","description":"This is the Broad Twitter corpus, a dataset of tweets collected over stratified times, places and social uses. \nThe goal is to represent a broad range of activities, giving a dataset more representative of the language used \nin this hardest of social media formats to process. Further, the BTC is annotated for named entities.\n\nFor more details see [https://aclanthology.org/C16-1111/](https://aclanthology.org/C16-1111/)","url":"https://huggingface.co/datasets/strombergnlp/broad_twitter_corpus","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"twitter_pos","keyword":"monolingual","description":"Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis dataset contains two datasets for English PoS tagging for tweets:\n\n* Ritter, with train/dev/test\n* Foster, with dev/test\n\nSplits defined in the Derczynski paper, but the data is from Ritter and Foster.\n\nFor more details see:\n\n* https://gate.ac.uk/wiki/twitter-postagger.html\n* https://aclanthology.org/D11-1141.pdf\n* https://www.aaai.org/ocs/index.php/ws/aaaiw11/paper/download/3912/4191","url":"https://huggingface.co/datasets/strombergnlp/twitter_pos","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ans-stance","keyword":"monolingual","description":"The dataset is a collection of news titles in arabic along with paraphrased and corrupted titles. The stance prediction version is a 3-class classification task. Data contains three columns: s1, s2, stance.","url":"https://huggingface.co/datasets/strombergnlp/ans-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enriched","keyword":"monolingual","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\nThis version is not yet supported.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"rustance","keyword":"monolingual","description":"This is a stance prediction dataset in Russian. The dataset contains comments on news articles,\nand rows are a comment, the title of the news article it responds to, and the stance of the comment\ntowards the article.","url":"https://huggingface.co/datasets/strombergnlp/rustance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","sentiment-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"sen1floods11","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSen1Floods11\n\t\n\nSen1Floods11: a georeferenced dataset to train and test deep learning flood algorithms for Sentinel-1 (Example). This data was generated by Cloud to Street, a Public Benefit Corporation: https://www.cloudtostreet.info/. For questions about this dataset or code please email support@cloudtostreet.info. Please cite this data as:\nBonafilia, D., Tellman, B., Anderson, T., Issenberg, E. 2020. Sen1Floods11: a georeferenced dataset to train and test deep learning floodâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/harshinde/sen1floods11.","url":"https://huggingface.co/datasets/harshinde/sen1floods11","creator_name":"Harsh","creator_url":"https://huggingface.co/harshinde","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bioscope","keyword":"monolingual","description":"The BioScope corpus consists of medical and biological texts annotated for\nnegation, speculation and their linguistic scope. This was done to allow a\ncomparison between the development of systems for negation/hedge detection and\nscope resolution. The BioScope corpus was annotated by two independent linguists\nfollowing the guidelines written by our linguist expert before the annotation of\nthe corpus was initiated.","url":"https://huggingface.co/datasets/bigbio/bioscope","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc-by-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"amazon_polarity","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Amazon Review Polarity\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Amazon reviews dataset consists of reviews from amazon.\nThe data span a period of 18 years, including ~35 million reviews up to March 2013.\nReviews include product and user information, ratings, and a plaintext review.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset is mainly used for text classification: given the content and the title, predict the correctâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fancyzhx/amazon_polarity.","url":"https://huggingface.co/datasets/fancyzhx/amazon_polarity","creator_name":"Xiang Zhang","creator_url":"https://huggingface.co/fancyzhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"nyt_ingredients","keyword":"monolingual","description":"New York Times Ingredient Phrase Tagger Dataset\nWe use a conditional random field model (CRF) to extract tags from labelled training data, which was tagged by human news assistants. \ne wrote about our approach on the [New York Times Open blog](http://open.blogs.nytimes.com/2015/04/09/extracting-structured-data-from-recipes-using-conditional-random-fields/).\nThis repo contains scripts to extract the Quantity, Unit, Name, and Comments from unstructured ingredient phrases. \nWe use it on Cooking to format incoming recipes. Given the following input:\n\n```\n1 pound carrots, young ones if possible\nKosher salt, to taste\n2 tablespoons sherry vinegar\n2 tablespoons honey\n2 tablespoons extra-virgin olive oil\n1 medium-size shallot, peeled and finely diced\n1/2 teaspoon fresh thyme leaves, finely chopped\nBlack pepper, to taste\n```","url":"https://huggingface.co/datasets/napsternxg/nyt_ingredients","creator_name":"SHUBHANSHU MISHRA","creator_url":"https://huggingface.co/napsternxg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"numer_sense","keyword":"monolingual","description":"NumerSense is a new numerical commonsense reasoning probing task, with a diagnostic dataset consisting of 3,145 masked-word-prediction probes.\n\nWe propose to study whether numerical commonsense knowledge can be induced from pre-trained language models like BERT, and to what extent this access to knowledge robust against adversarial examples is. We hope this will be beneficial for tasks such as knowledge base completion and open-domain question answering.","url":"https://huggingface.co/datasets/INK-USC/numer_sense","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","slot-filling","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"md_gender_bias","keyword":"monolingual","description":"Machine learning models are trained to find patterns in data.\nNLP models can inadvertently learn socially undesirable patterns when training on gender biased text.\nIn this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions:\nbias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker.\nUsing this fine-grained framework, we automatically annotate eight large scale datasets with gender information.\nIn addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites.\nDistinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers.\nWe show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models,\ndetecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.","url":"https://huggingface.co/datasets/facebook/md_gender_bias","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","crowdsourced","found","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"youtube_caption_corrections","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for YouTube Caption Corrections\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is built from pairs of YouTube captions where both an auto-generated and a manually-corrected caption are available for a single specified language. It currently only in English, but scripts at repo support other languages. The motivation for creating it was from viewing errors in auto-generated captions at a recent virtual conference, with the hope that there could be some way to help correct thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/youtube_caption_corrections.","url":"https://huggingface.co/datasets/community-datasets/youtube_caption_corrections","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","text-generation","fill-mask","slot-filling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"lex_glue","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"LexGLUE\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nInspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018), the subsequent more difficult SuperGLUE (Wang et al., 2019), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018; McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a benchmark dataset to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/lex_glue.","url":"https://huggingface.co/datasets/coastalcph/lex_glue","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","multi-class-classification","multi-label-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"sede","keyword":"monolingual","description":"SEDE (Stack Exchange Data Explorer) is new dataset for Text-to-SQL tasks with more than 12,000 SQL queries and their\nnatural language description. It's based on a real usage of users from the Stack Exchange Data Explorer platform,\nwhich brings complexities and challenges never seen before in any other semantic parsing dataset like\nincluding complex nesting, dates manipulation, numeric and text manipulation, parameters, and most\nimportantly: under-specification and hidden-assumptions.\n\nPaper (NLP4Prog workshop at ACL2021): https://arxiv.org/abs/2106.05006","url":"https://huggingface.co/datasets/hirupert/sede","creator_name":"hirupert","creator_url":"https://huggingface.co/hirupert","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","parsing","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mnist","keyword":"monolingual","description":"The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\nimages per class. There are 60,000 training images and 10,000 test images.","url":"https://huggingface.co/datasets/severo/mnist","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit_tifu","keyword":"monolingual","description":"Reddit dataset, where TIFU denotes the name of subbreddit /r/tifu.\nAs defined in the publication, styel \"short\" uses title as summary and\n\"long\" uses tldr as summary.\n\nFeatures includes:\n  - document: post text without tldr.\n  - tldr: tldr line.\n  - title: trimmed title without tldr.\n  - ups: upvotes.\n  - score: score.\n  - num_comments: number of comments.\n  - upvote_ratio: upvote ratio.","url":"https://huggingface.co/datasets/ctr4si/reddit_tifu","creator_name":"Center for SuperIntelligence","creator_url":"https://huggingface.co/ctr4si","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hope_edi","keyword":"monolingual","description":"A Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not.","url":"https://huggingface.co/datasets/dravidianlangtech/hope_edi","creator_name":"dravidianlangtech","creator_url":"https://huggingface.co/dravidianlangtech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","expert-generated","crowdsourced","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"finer","keyword":"monolingual","description":"The directory data contains a corpus of Finnish technology related news articles with a manually prepared\nnamed entity annotation (digitoday.2014.csv). The text material was extracted from the archives of Digitoday,\na Finnish online technology news source (www.digitoday.fi). The corpus consists of 953 articles\n(193,742 word tokens) with six named entity classes (organization, location, person, product, event, and date).\nThe corpus is available for research purposes and can be readily used for development of NER systems for Finnish.","url":"https://huggingface.co/datasets/mpsilfve/finer","creator_name":"Miikka Silfverberg","creator_url":"https://huggingface.co/mpsilfve","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"twadrl","keyword":"monolingual","description":"The TwADR-L dataset contains medical concepts written on social media (Twitter) mapped to how they are formally written in medical ontologies (SIDER 4). \\","url":"https://huggingface.co/datasets/bigbio/twadrl","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"simple_questions_v2","keyword":"monolingual","description":"SimpleQuestions is a dataset for simple QA, which consists\nof a total of 108,442 questions written in natural language by human\nEnglish-speaking annotators each paired with a corresponding fact,\nformatted as (subject, relationship, object), that provides the answer\nbut also a complete explanation.  Fast have been extracted from the\nKnowledge Base Freebase (freebase.com).  We randomly shuffle these\nquestions and use 70% of them (75910) as training set, 10% as\nvalidation set (10845), and the remaining 20% as test set.","url":"https://huggingface.co/datasets/fbougares/simple_questions_v2","creator_name":"Fethi BOUGARES","creator_url":"https://huggingface.co/fbougares","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"parla_text_corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tParlaTextCorpus\n\t\n\nSpoken text corpus for Catalan. Derived and cleaned from three sources. OpenSubtitles, Tv3Parla and Festcat.\n","url":"https://huggingface.co/datasets/Baybars/parla_text_corpus","creator_name":"Baybars KÃ¼lebi","creator_url":"https://huggingface.co/Baybars","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["language-modeling","no-annotation","various","monolingual","found"],"keywords_longer_than_N":true},
	{"name":"ilpost","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ilpost\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIlPost dataset, containing news articles taken from IlPost.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n IlPost text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federiciâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/ilpost.","url":"https://huggingface.co/datasets/ARTeLab/ilpost","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","Italian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ask_a_patient","keyword":"monolingual","description":"The AskAPatient dataset contains medical concepts written on social media mapped to how they are formally written in medical ontologies (SNOMED-CT and AMT).","url":"https://huggingface.co/datasets/bigbio/ask_a_patient","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"demo-common-whisper","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/demo-common-whisper.","url":"https://huggingface.co/datasets/DTU54DL/demo-common-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kinnews_kirnews","keyword":"monolingual","description":"Kinyarwanda and Kirundi news classification datasets","url":"https://huggingface.co/datasets/andreniyongabo/kinnews_kirnews","creator_name":"Andre Niyongabo Rubungo","creator_url":"https://huggingface.co/andreniyongabo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","topic-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"meddocan","keyword":"monolingual","description":"MEDDOCAN: Medical Document Anonymization Track\n\nThis dataset is designed for the MEDDOCAN task, sponsored by Plan de Impulso de las TecnologÃ­as del Lenguaje.\n\nIt is a manually classified collection of 1,000 clinical case reports derived from the Spanish Clinical Case Corpus (SPACCC), enriched with PHI expressions.\n\nThe annotation of the entire set of entity mentions was carried out by experts annotatorsand it includes 29 entity types relevant for the annonymiation of medical documents.22 of these annotation types are actually present in the corpus: TERRITORIO, FECHAS, EDAD_SUJETO_ASISTENCIA, NOMBRE_SUJETO_ASISTENCIA, NOMBRE_PERSONAL_SANITARIO, SEXO_SUJETO_ASISTENCIA, CALLE, PAIS, ID_SUJETO_ASISTENCIA, CORREO, ID_TITULACION_PERSONAL_SANITARIO,ID_ASEGURAMIENTO, HOSPITAL, FAMILIARES_SUJETO_ASISTENCIA, INSTITUCION, ID_CONTACTO ASISTENCIAL,NUMERO_TELEFONO, PROFESION, NUMERO_FAX, OTROS_SUJETO_ASISTENCIA, CENTRO_SALUD, ID_EMPLEO_PERSONAL_SANITARIO\n    \nFor further information, please visit https://temu.bsc.es/meddocan/ or send an email to encargo-pln-life@bsc.es","url":"https://huggingface.co/datasets/bigbio/meddocan","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"numeric_fused_head","keyword":"monolingual","description":"Fused Head constructions are noun phrases in which the head noun is missing and is said to be \"fused\" with its dependent modifier. This missing information is implicit and is important for sentence understanding.The missing heads are easily filled in by humans,  but pose a challenge for computational models.\n\nFor example, in the sentence: \"I bought 5 apples but got only 4.\", 4 is a Fused-Head, and the missing head is apples, which appear earlier in the sentence.\n\nThis is a crowd-sourced dataset of 10k numerical fused head examples (1M tokens).","url":"https://huggingface.co/datasets/yanaiela/numeric_fused_head","creator_name":"Yanai Elazar","creator_url":"https://huggingface.co/yanaiela","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"doc2dial","keyword":"monolingual","description":"Doc2dial is dataset of goal-oriented dialogues that are grounded in the associated documents. It includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets this dataset covers a variety of dialogue scenes in information-seeking conversations.","url":"https://huggingface.co/datasets/IBM/doc2dial","creator_name":"IBM","creator_url":"https://huggingface.co/ibm","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"proto_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is for studying computational models trained to reason about prototypical situations. It is anticipated that still would not lead to usage in a downstream task, but as a way of studying the knowledge (and biases) of prototypical situations already contained in pre-trained models. The data it is partially based on (Family Feud).\nUsing deterministic filtering a sampling from a larger set of all transcriptions wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/proto_qa.","url":"https://huggingface.co/datasets/community-datasets/proto_qa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xsum_factuality","keyword":"monolingual","description":"Neural abstractive summarization models are highly prone to hallucinate content that is unfaithful to the input\ndocument. The popular metric such as ROUGE fails to show the severity of the problem. The dataset consists of\nfaithfulness and factuality annotations of abstractive summaries for the XSum dataset. We have crowdsourced 3 judgements\n for each of 500 x 5 document-system pairs. This will be a valuable resource to the abstractive summarization community.","url":"https://huggingface.co/datasets/google-research-datasets/xsum_factuality","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","monolingual","extended|other-xsum"],"keywords_longer_than_N":true},
	{"name":"biolang","keyword":"monolingual","description":"This dataset is based on abstracts from the open access section of EuropePubMed Central to train language models in the domain of biology.","url":"https://huggingface.co/datasets/EMBO/biolang","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"nli_tr","keyword":"monolingual","description":"The Natural Language Inference in Turkish (NLI-TR) is a set of two large scale datasets that were obtained by translating the foundational NLI corpora (SNLI and MNLI) using Amazon Translate.","url":"https://huggingface.co/datasets/boun-tabi/nli_tr","creator_name":"BOUN Text Analytics and BIoInformatics Lab","creator_url":"https://huggingface.co/boun-tabi","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","expert-generated"],"keywords_longer_than_N":true},
	{"name":"persian_ner","keyword":"monolingual","description":"The dataset includes 250,015 tokens and 7,682 Persian sentences in total. It is available in 3 folds to be used in turn as training and test sets. The NER tags are in IOB format.","url":"https://huggingface.co/datasets/HaniehPoostchi/persian_ner","creator_name":"Hanieh Poostchi","creator_url":"https://huggingface.co/HaniehPoostchi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"msr_sqa","keyword":"monolingual","description":"Recent work in semantic parsing for question answering has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but inter-related questions. We created SQA by asking crowdsourced workers to decompose 2,022 questions from WikiTableQuestions (WTQ), which contains highly-compositional questions about tables from Wikipedia. We had three workers decompose each WTQ question, resulting in a dataset of 6,066 sequences that contain 17,553 questions in total. Each question is also associated with answers in the form of cell locations in the tables.","url":"https://huggingface.co/datasets/microsoft/msr_sqa","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"lcc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LCC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of Danish data from the Leipzig Collection that has been annotated for sentiment analysis by Finn Ã…rup Nielsen.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for sentiment analysis.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset has a document and an associated label.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nAn entry in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/lcc.","url":"https://huggingface.co/datasets/DDSC/lcc","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"turkish_ner","keyword":"monolingual","description":"Turkish Wikipedia Named-Entity Recognition and Text Categorization\n(TWNERTC) dataset is a collection of automatically categorized and annotated\nsentences obtained from Wikipedia. The authors constructed large-scale\ngazetteers by using a graph crawler algorithm to extract\nrelevant entity and domain information\nfrom a semantic knowledge base, Freebase.\nThe constructed gazetteers contains approximately\n300K entities with thousands of fine-grained entity types\nunder 77 different domains.","url":"https://huggingface.co/datasets/erayyildiz/turkish_ner","creator_name":"Eray Yildiz","creator_url":"https://huggingface.co/erayyildiz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mac_morpho","keyword":"monolingual","description":"Mac-Morpho is a corpus of Brazilian Portuguese texts annotated with part-of-speech tags.\nIts first version was released in 2003 [1], and since then, two revisions have been made in order\nto improve the quality of the resource [2, 3].\nThe corpus is available for download split into train, development and test sections.\nThese are 76%, 4% and 20% of the corpus total, respectively (the reason for the unusual numbers\nis that the corpus was first split into 80%/20% train/test, and then 5% of the train section was\nset aside for development). This split was used in [3], and new POS tagging research with Mac-Morpho\nis encouraged to follow it in order to make consistent comparisons possible.\n\n\n[1] AluÃ­sio, S., Pelizzoni, J., Marchi, A.R., de Oliveira, L., Manenti, R., MarquiafÃ¡vel, V. 2003.\nAn account of the challenge of tagging a reference corpus for brazilian portuguese.\nIn: Proceedings of the 6th International Conference on Computational Processing of the Portuguese Language. PROPOR 2003\n\n[2] Fonseca, E.R., Rosa, J.L.G. 2013. Mac-morpho revisited: Towards robust part-of-speech.\nIn: Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology â€“ STIL\n\n[3] Fonseca, E.R., AluÃ­sio, Sandra Maria, Rosa, J.L.G. 2015.\nEvaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese.\nJournal of the Brazilian Computer Society.","url":"https://huggingface.co/datasets/nilc-nlp/mac_morpho","creator_name":"NILC NLP","creator_url":"https://huggingface.co/nilc-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"taskmaster2","keyword":"monolingual","description":"Taskmaster is dataset for goal oriented conversations. The Taskmaster-2 dataset consists of 17,289 dialogs in the seven domains which include restaurants, food ordering, movies, hotels, flights, music and sports. Unlike Taskmaster-1, which includes both written \"self-dialogs\" and spoken two-person dialogs, Taskmaster-2 consists entirely of spoken two-person dialogs. In addition, while Taskmaster-1 is almost exclusively task-based, Taskmaster-2 contains a good number of search- and recommendation-oriented dialogs. All dialogs in this release were created using a Wizard of Oz (WOz) methodology in which crowdsourced workers played the role of a 'user' and trained call center operators played the role of the 'assistant'. In this way, users were led to believe they were interacting with an automated system that â€œspokeâ€ using text-to-speech (TTS) even though it was in fact a human behind the scenes. As a result, users could express themselves however they chose in the context of an automated interface.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster2","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"polarity","keyword":"monolingual","description":"The Amazon reviews dataset consists of reviews from amazon.\nThe data span a period of 18 years, including ~35 million reviews up to March 2013.\nReviews include product and user information, ratings, and a plaintext review.","url":"https://huggingface.co/datasets/CyranoB/polarity","creator_name":"Eddie Pick","creator_url":"https://huggingface.co/CyranoB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-confessions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-confessions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts from the following subreddits:\n\n/r/trueoffmychest\n/r/confession\n/r/confessions\n/r/offmychest\n\nPosts are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions.","url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"ILUR-news-text-classification-corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNews Texts Dataset\n\t\n\nWe release a dataset of over 12000 news articles from iLur.am, categorized into 7 classes: sport, politics, weather, economy, accidents, art, society. The articles are split into train (2242k tokens) and test sets (425k tokens).\nFor more details, refer to the paper.\n","url":"https://huggingface.co/datasets/Karavet/ILUR-news-text-classification-corpus","creator_name":"Karen Avetisyan","creator_url":"https://huggingface.co/Karavet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","Armenian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"re_dial","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ReDial (Recommendation Dialogues)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReDial (Recommendation Dialogues) is an annotated dataset of dialogues, where users\nrecommend movies to each other. The dataset was collected by a team of researchers working at\nPolytechnique MontrÃ©al, MILA â€“ Quebec AI Institute, Microsoft Research MontrÃ©al, HEC Montreal, and Element AI.\nThe dataset allows research at the intersection of goal-directed dialogue systems\n(such as restaurant recommendation)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/re_dial.","url":"https://huggingface.co/datasets/community-datasets/re_dial","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","text-classification","sentiment-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"saf_legal_domain_german","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_legal_domain_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Short Answer Feedback (SAF) dataset contains 19 German questions in the domain of the German social law (with reference answers). The idea of constructing a bilingual (English and German) short answer dataset as a way to remedy the lack of content-focused feedback datasets was introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Shortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german.","url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"cedr_v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [cedr]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Corpus for Emotions Detecting in Russian-language text sentences of different social sources (CEDR) contains 9410  comments labeled for 5 emotion categories (joy, sadness, surprise, fear, and anger). \nHere are 2 dataset configurations:\n\n\"main\" - contains \"text\", \"labels\", and \"source\" features;\n\"enriched\" - includes all \"main\" features and \"sentences\".\n\nDataset with predefined train/test splits.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sagteam/cedr_v1.","url":"https://huggingface.co/datasets/sagteam/cedr_v1","creator_name":"AI technology lab at NRC \"Kurchatov Institute\"","creator_url":"https://huggingface.co/sagteam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"health_fact","keyword":"monolingual","description":"PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of\npublic health claims. Each instance in the PUBHEALTH dataset has an associated\nveracity label (true, false, unproven, mixture). Furthermore each instance in the\ndataset has an explanation text field. The explanation is a justification for which\nthe claim has been assigned a particular veracity label.\n\nThe dataset was created to explore fact-checking of difficult to verify claims i.e.,\nthose which require expertise from outside of the journalistics domain, in this case\nbiomedical and public health expertise.\n\nIt was also created in response to the lack of fact-checking datasets which provide\ngold standard natural language explanations for verdicts/labels.\n\nNOTE: There are missing labels in the dataset and we have replaced them with -1.","url":"https://huggingface.co/datasets/ImperialCollegeLondon/health_fact","creator_name":"Imperial College London","creator_url":"https://huggingface.co/ImperialCollegeLondon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","multi-class-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"wiki-entity-similarity","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWiki Entity Similarity\n\t\n\nUsage:\nfrom datasets import load_dataset\n\ncorpus = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20corpus', split='train')\nassert corpus[0] == {'article': 'A1000 road', 'link_text': 'A1000', 'is_same': 1}\n\npairs = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20pairs', split='train')\nassert corpus[0] == {'article': 'Rhinobatos', 'link_text': 'Ehinobatos beurleni', 'is_same': 1}\nassert len(corpus) == 4_793_180\n\n\n\t\n\t\t\n\t\tCorpus (name=*corpus)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Exr0n/wiki-entity-similarity.","url":"https://huggingface.co/datasets/Exr0n/wiki-entity-similarity","creator_name":"exr0n","creator_url":"https://huggingface.co/Exr0n","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["found","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"coarse_discourse","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"coarse_discourse\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA large corpus of discourse annotations and relations on ~10K forum threads.\nWe collect and release a corpus of over 9,000 threads comprising over 100,000 comments manually annotated via paid crowdsourcing with discourse acts and randomly sampled from the site Reddit.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/coarse_discourse.","url":"https://huggingface.co/datasets/google-research-datasets/coarse_discourse","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"curation-corpus-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tcuration-corpus-ru\n\t\n\nTranslated version of d0rj/curation-corpus into Russian.\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translated","monolingual","d0rj/curation-corpus","Russian"],"keywords_longer_than_N":true},
	{"name":"ten-million-reddit-answers","keyword":"monolingual","description":"A spiritual successor to our One Million Questions, this NLP dataset contains an outstanding ten million of /r/AskReddit answers, going back from the end of November of 2020.","url":"https://huggingface.co/datasets/SocialGrep/ten-million-reddit-answers","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"hyperpartisan_news_detection","keyword":"monolingual","description":"Hyperpartisan News Detection was a dataset created for PAN @ SemEval 2019 Task 4.\nGiven a news article text, decide whether it follows a hyperpartisan argumentation, i.e., whether it exhibits blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person.\n\nThere are 2 parts:\n- byarticle: Labeled through crowdsourcing on an article basis. The data contains only articles for which a consensus among the crowdsourcing workers existed.\n- bypublisher: Labeled by the overall bias of the publisher as provided by BuzzFeed journalists or MediaBiasFactCheck.com.","url":"https://huggingface.co/datasets/SemEvalWorkshop/hyperpartisan_news_detection","creator_name":"SemEval","creator_url":"https://huggingface.co/SemEvalWorkshop","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"quartz","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"quartz\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each\nquestion is paired with one of 405 different background sentences (sometimes short paragraphs).\nThe QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with\none of 405 different background sentences (sometimes short paragraphs).\nThe dataset is split intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/quartz.","url":"https://huggingface.co/datasets/allenai/quartz","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"swahili_news","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Swahili : News Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSwahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\nNews contributes to education, technology, and the economic growth of a country, and news in local languages plays an important culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swahili_news.","url":"https://huggingface.co/datasets/community-datasets/swahili_news","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"id_newspapers_2018","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Indonesian Newspapers 2018\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains around 500K articles (136M of words) from 7 Indonesian newspapers: Detik, Kompas, Tempo,\nCNN Indonesia, Sindo, Republika and Poskota. The articles are dated between 1st January 2018 and 20th August 2018\n(with few exceptions dated earlier). The size of uncompressed 500K json files (newspapers-json.tgz) is around 2.2GB,\nand the cleaned uncompressed in a big text file (newspapers.txt.gz) isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/id_newspapers_2018.","url":"https://huggingface.co/datasets/community-datasets/id_newspapers_2018","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"turkish_shrinked_ner","keyword":"monolingual","description":"Shrinked version (48 entity type) of the turkish_ner.\n\nOriginal turkish_ner dataset: Automatically annotated Turkish corpus for named entity recognition and text categorization using large-scale gazetteers. The constructed gazetteers contains approximately 300K entities with thousands of fine-grained entity types under 25 different domains.\n\nShrinked entity types are: academic, academic_person, aircraft, album_person, anatomy, animal, architect_person, capital, chemical, clothes, country, culture, currency, date, food, genre, government, government_person, language, location, material, measure, medical, military, military_person, nation, newspaper, organization, organization_person, person, production_art_music, production_art_music_person, quantity, religion, science, shape, ship, software, space, space_person, sport, sport_name, sport_person, structure, subject, tech, train, vehicle","url":"https://huggingface.co/datasets/community-datasets/turkish_shrinked_ner","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"starter","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Langame/starter.","url":"https://huggingface.co/datasets/Langame/starter","creator_name":"Langa","creator_url":"https://huggingface.co/Langame","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"id_puisi","keyword":"monolingual","description":"Puisi (poem) is an Indonesian poetic form. The dataset contains 7223 Indonesian puisi with its title and author.","url":"https://huggingface.co/datasets/ilhamfp/id_puisi","creator_name":"Ilham Firdausi Putra","creator_url":"https://huggingface.co/ilhamfp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"This-is-not-a-dataset","keyword":"monolingual","description":"\n    \n\n\n\"A Large Negation Benchmark to Challenge Large Language Models\"\n\n\nWe introduce a large semi-automatically generated dataset of ~400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms that we use to evaluate LLMs.\n\n\n\nðŸ“– Paper: This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models (EMNLP'23)\nðŸ’» Baseline Code and the Official Scorer:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset.","url":"https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ChessQA-Benchmark","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChessQA-Benchmark\n\t\n\nCSSLab, Department of Computer Science, University of Toronto  \n\nCode: GitHub\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nChess provides an ideal testbed for evaluating the reasoning, modeling, and abstraction capabilities of large language models (LLMs), as it has well-defined structure and objective ground truth while admitting a wide spectrum of skill levels. However, existing evaluations of LLM ability in chess are ad hoc and narrow in scope, making it difficult to accuratelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wieeii/ChessQA-Benchmark.","url":"https://huggingface.co/datasets/wieeii/ChessQA-Benchmark","creator_name":"Qianfeng Wen","creator_url":"https://huggingface.co/wieeii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-ports-maritimes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des ports maritimes, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedure-penale","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de procÃ©dure pÃ©nale, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-recherche","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la recherche, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"args_me","keyword":"monolingual","description":"The args.me corpus (version 1.0, cleaned) comprises 382 545 arguments crawled from four debate portals in the middle of 2019. The debate portals are Debatewise, IDebate.org, Debatepedia, and Debate.org. The arguments are extracted using heuristics that are designed for each debate portal.","url":"https://huggingface.co/datasets/webis/args_me","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"VoxDIY-RusNews","keyword":"monolingual","description":"VoxDIY:  Benchmark Dataset for Russian Crowdsourced Audio Transcription.","url":"https://huggingface.co/datasets/toloka/VoxDIY-RusNews","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"sloTS","keyword":"monolingual","description":"To increase the accessibility and diversity of easy reading in Slovenian and to create a prototype system that automatically simplifies texts in Slovenian, we prepared a dataset for the Slovenian language that contains aligned simple and complex sentences, which can be used for further development of models for simplifying texts in Slovenian.\n\nDataset is a .json file that usually contains one complex (\"kompleksni\") and one simplified sentence (\"enostavni\") per row. However, if a complex sentence contains a lot of information we translated this sentence into more than one simplified sentences. Vice versa, more complex sentences can be translated into one simplified sentence if some information is given through more than one complex sentences but we summarised them into one simplified one.","url":"https://huggingface.co/datasets/cjvt/sloTS","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","monolingual","Slovenian","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"metashift","keyword":"monolingual","description":"The MetaShift is a dataset of datasets for evaluating distribution shifts and training conflicts.\nThe MetaShift dataset is a collection of 12,868 sets of natural images across 410 classes.\nIt was created for understanding the performance of a machine learning model across diverse data distributions.","url":"https://huggingface.co/datasets/jameszou707/metashift","creator_name":"zou","creator_url":"https://huggingface.co/jameszou707","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","other","multi-label-image-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"diffusiondb_ner","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tDescription\n\t\n\nExtended dataset infered by the name entity recognition model en_ner_prompting. This model has been trained on hand-annotated prompts from poloclub/diffusiondb.\nThis dataset is hence infered by this model and can comprise mistakes, especially on certain categories (cf. model card).\n  The entities comprise 7 main categories and 11 subcategories for a total of 16 categories, extracted from a topic analysis made with BERTopic.\n  The topic analysis can be explored theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/teo-sanchez/diffusiondb_ner.","url":"https://huggingface.co/datasets/teo-sanchez/diffusiondb_ner","creator_name":"TÃ©o Sanchez","creator_url":"https://huggingface.co/teo-sanchez","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["found","monolingual","poloclub/diffusiondb","English","cc-by-3.0"],"keywords_longer_than_N":true},
	{"name":"the-antiwork-subreddit-dataset","keyword":"monolingual","description":"This dataset follows the notorious subreddit /r/Antiwork, a place for many Redditors to share resources and discuss grievances with the current labour market.","url":"https://huggingface.co/datasets/SocialGrep/the-antiwork-subreddit-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"tripclick-training","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTripClick Baselines with Improved Training Data\n\t\n\nEstablishing Strong Baselines for TripClick Health Retrieval Sebastian HofstÃ¤tter, Sophia Althammer, Mete Sertkan and Allan Hanbury\nhttps://arxiv.org/abs/2201.00365\ntl;dr We create strong re-ranking and dense retrieval baselines (BERTCAT, BERTDOT, ColBERT, and TK) for TripClick (health ad-hoc retrieval). We improve the â€“ originally too noisy â€“ training data with a simple negative sampling policy. We achieve large gains over BM25 in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training.","url":"https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training","creator_name":"Sebastian HofstÃ¤tter","creator_url":"https://huggingface.co/sebastian-hofstaetter","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","other","clicks","other"],"keywords_longer_than_N":true},
	{"name":"pesp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPages of Early Soviet Performance (PESP)\n\t\n\nThis dataset was created as part of the Pages of Early Soviet Performance project at Princeton and provides text and image research data from a previously scanned collection of illustrated periodicals held by Princeton University's Slavic Collections. The project was a partnership with ITMO University in Saint Petersburg. Our work focused on document segmentation and the prediction of image, text, title, and mixedtext regions in the documentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/apjanco/pesp.","url":"https://huggingface.co/datasets/apjanco/pesp","creator_name":"Andy Janco","creator_url":"https://huggingface.co/apjanco","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unam_tesis","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card of \"unam_tesis\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl dataset unam_tesis cuenta con 1000 tesis de 5 carreras de la Universidad Nacional AutÃ³noma de MÃ©xico (UNAM), 200 por carrera. Se pretende seguir incrementando este dataset con las demÃ¡s carreras y mÃ¡s tesis.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\ntext-classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEspaÃ±ol (es)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nLas instancias del dataset son de la siguiente forma: \nEl objetivoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis.","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis","creator_name":"I Hackathon Somos NLP: PLN en EspaÃ±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-modeling","MajorIsaiah","Ximyer","clavel"],"keywords_longer_than_N":true},
	{"name":"sufficient_facts","keyword":"monolingual","description":"SufficientFacts is a diagnostic test dataset for fact checking with insufficient evidence.","url":"https://huggingface.co/datasets/copenlu/sufficient_facts","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"peoples_speech_v1.0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLCommons/peoples_speech_v1.0.","url":"https://huggingface.co/datasets/MLCommons/peoples_speech_v1.0","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"psycholinguistic_eval","keyword":"monolingual","description":"Psycholinguistic dataset from 'What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models'\nby Allyson Ettinger","url":"https://huggingface.co/datasets/KevinZ/psycholinguistic_eval","creator_name":"Kevin Zhao","creator_url":"https://huggingface.co/KevinZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","fill-mask","question-answering","zero-shot-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"the-reddit-place-dataset","keyword":"monolingual","description":"The written history or /r/Place, in posts and comments.","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-place-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"financial-reports-sec","keyword":"monolingual","description":"The dataset contains the annual report of US public firms filing with the SEC EDGAR system.\nEach annual report (10K filing) is broken into 20 sections. Each section is split into individual sentences.\nSentiment labels are provided on a per filing basis from the market reaction around the filing data.\nAdditional metadata for each filing is included in the dataset.","url":"https://huggingface.co/datasets/JanosAudran/financial-reports-sec","creator_name":"Aman Khan","creator_url":"https://huggingface.co/JanosAudran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-classification","masked-language-modeling","multi-class-classification","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"Ukr-Synth","keyword":"monolingual","description":"Large silver standard Ukrainian corpus annotated with morphology tags, syntax trees and PER, LOC, ORG NER-tags.","url":"https://huggingface.co/datasets/ukr-models/Ukr-Synth","creator_name":"Volodymyr Kurnosov","creator_url":"https://huggingface.co/ukr-models","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","parsing","part-of-speech","machine-generated"],"keywords_longer_than_N":true},
	{"name":"GRIT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGRIT: Large-Scale Training Corpus of Grounded Image-Text Pairs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce GRIT, a large-scale dataset of Grounded Image-Text pairs, which is created based on image-text pairs from COYO-700M and LAION-2B. We construct a pipeline to extract and link text spans (i.e., noun phrases, and referring expressions) in the caption to their corresponding image regions. More details can be found in the paper.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nDuring the construction, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zzliang/GRIT.","url":"https://huggingface.co/datasets/zzliang/GRIT","creator_name":"zhiliang","creator_url":"https://huggingface.co/zzliang","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","object-detection","zero-shot-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_full_doc","keyword":"monolingual","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"CrowdSpeech","keyword":"monolingual","description":"CrowdSpeech is a publicly available large-scale dataset of crowdsourced audio transcriptions. It contains annotations for more than 50 hours of English speech transcriptions from more than 1,000 crowd workers.","url":"https://huggingface.co/datasets/toloka/CrowdSpeech","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus consists of a single speaker, with 4515 segments extracted\nfrom a single LibriVox audiobook.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Hungarian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Splitsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"monolingual","description":"A Persian multispeaker dataset for text-to-speech purposes.","url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"jigsaw_toxicity_pred","keyword":"monolingual","description":"This dataset consists of a large number of Wikipedia comments which have been labeled by human raters for toxic behavior.","url":"https://huggingface.co/datasets/google/jigsaw_toxicity_pred","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"umnsrs","keyword":"monolingual","description":"UMNSRS, developed by Pakhomov, et al., consists of 725 clinical term pairs whose semantic similarity and relatedness.\nThe similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch\na bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness.\nThe following subsets are available:\n- similarity: A set of 566 UMLS concept pairs manually rated for semantic similarity (e.g. whale-dolphin) using a\n  continuous response scale.\n- relatedness: A set of 588 UMLS concept pairs manually rated for semantic relatedness (e.g. needle-thread) using a\n  continuous response scale.\n- similarity_mod: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not\n  match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper (Corpus\n  Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley, Reed McEwan,\n  Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644). The resulting dataset contains 449 pairs.\n- relatedness_mod: Modification of the UMNSRS-Relatedness dataset to exclude control samples and those pairs that did\n  not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper\n  (Corpus Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley,\n  Reed McEwan, Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644).\n  The resulting dataset contains 458 pairs.","url":"https://huggingface.co/datasets/bigbio/umnsrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","Tabular"],"keywords_longer_than_N":true},
	{"name":"jigsaw_unintended_bias","keyword":"monolingual","description":"A collection of comments from the defunct Civil Comments platform that have been annotated for their toxicity.","url":"https://huggingface.co/datasets/google/jigsaw_unintended_bias","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-scoring","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"smithsonian_butterflies","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Smithsonian Butterflies]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHigh-res images from Smithsonian \"Education and Outreach\" & \"NMNH - Entomology Dept.\" collections. Crawled\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIncludes metadata about the scientific name of butterflies, but there maybe missing values. Might be good for classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tExample data\n\t\n\n{'image_url':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ceyda/smithsonian_butterflies.","url":"https://huggingface.co/datasets/ceyda/smithsonian_butterflies","creator_name":"Ceyda Cinarel","creator_url":"https://huggingface.co/ceyda","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FakeNewsSet","keyword":"monolingual","description":"\\","url":"https://huggingface.co/datasets/fake-news-UFG/FakeNewsSet","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"4catac","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 4catac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the accent.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac.","url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","expert-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"Graptoloidea-Specimens-Imaging","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Graptoloidea Specimens Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset offers a detailed examination of Graptoloidea specimens, featuring attributes like image file paths, suborder, infraorder, family (including subfamily), tagged species names, geological stages, mean age values, and locality details (with coordinates and horizon information), complemented by original reference citations for each specimen. It serves as a comprehensive resource for paleontologicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging.","url":"https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging","creator_name":"Zaolin Zhang","creator_url":"https://huggingface.co/LeoZhangzaolin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"observation_or_evaluation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Observation or evaluation\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains statements classified into observations and evaluations categories, based on the principles of Nonviolent Communication (NVC) teached by Marshall Rosenberg. It includes a synthetic dataset generated and augmented through various language models to classify statements reflecting either pure observations (noticing) or evaluations (judgments), aimed at understanding and practicing effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation.","url":"https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation","creator_name":"Thomas Gauthier-Caron","creator_url":"https://huggingface.co/thomasgauthier","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","machine-generated","book","tv_script","monolingual"],"keywords_longer_than_N":true},
	{"name":"poquad-imp","keyword":"monolingual","description":"PoQuaD dataset\n","url":"https://huggingface.co/datasets/arduwa/poquad-imp","creator_name":"Jakub","creator_url":"https://huggingface.co/arduwa","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"bofip","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBulletin officiel des finances publiques - impÃ´ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/bofip.","url":"https://huggingface.co/datasets/louisbrulenaudet/bofip","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_benchmark","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP_M3_mcqa_benchmark\n\t\n\nThis benchmark is a filtered subset of the MMLU test set (cais/mmlu) focused on 21 STEM subjects. It is formatted for Multiple Choice Question Answering (MCQA) tasks.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nEach entry includes:\n\nquestion: A multiple-choice question in plain text.\nchoices: A list of four possible answers (A, B, C, D).\nanswer: The correct answer, represented by a single letter (A, B, C, or D).\n\n\n\t\n\t\t\n\t\tIncluded Subjects\n\t\n\n\nabstract_algebraâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_benchmark.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_benchmark","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mseformula","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tARQMath-Task-2\n\t\n\nMathematics Stack Exchange Formula Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"code-justice-penale-mineurs","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la justice pÃ©nale des mineurs, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CAPP","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFrench Court of Judicial jurisprudence decisions (CAPP) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CAPP Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/CAPP.\nThis comprehensive collection includes appellate court decisions, providing valuable insights into French jurisprudence and legal reasoning at the appeal level.\nIt serves as a rich resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CAPP.","url":"https://huggingface.co/datasets/Tricoteuses/CAPP","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"trilemma-of-truth","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“š Dataset Card for Trilemma of Truth (ToT) Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§¾ Dataset Summary\n\t\n\nThe Trilemma of Truth dataset is a benchmark for evaluating model performance across three types of statements:\n\nFactually true statements\nFactually false statements\nNeither-valued statements\n\nIt includes three configurations:\n\ncity_locations: statements about city-country relationsmed_indications: drug-indication associations\nword_definitions: synonym, type, and instance relationships fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlomarxx/trilemma-of-truth.","url":"https://huggingface.co/datasets/carlomarxx/trilemma-of-truth","creator_name":"Germans Savcisens","creator_url":"https://huggingface.co/carlomarxx","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","fact-checking","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"Train_data","keyword":"monolingual","description":"AI-Mock-Interviewer/Train_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AI-Mock-Interviewer/Train_data","creator_name":"AI-Mock-Interviewer","creator_url":"https://huggingface.co/AI-Mock-Interviewer","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","dialogue-modeling","human-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JPCharRecog_v1.1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tJPCharRecog_v1.1\n\t\n\nJPCharRecog v1.1 ã¯ã€æ—¥æœ¬èªžã®å˜æ–‡å­—ï¼ˆCJK ã‚’å«ã‚€ï¼‰èªè­˜ã‚’ç›®çš„ã¨ã—ãŸã€åˆæˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç”»åƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚ç´”è¦–è¦šè¦å› ï¼ˆãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ãƒŸãƒª/ã‚¦ã‚§ã‚¤ãƒˆ/æ–‡å­—ã‚µã‚¤ã‚º/åŠ£åŒ–ï¼‰ã‚’æ“ä½œå¯èƒ½ãªè¨­è¨ˆã§ã€è¾žæ›¸ã‚„æ–‡è„ˆã®å¯„ä¸Žã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ç”¨é€”ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚\n\nTask: Single-character recognition (JPCharRecog-like)\nLanguage: Japanese (CJK)\nFamilies: NotoSansJP, NotoSerifJP\nWeights: ExtraLight, Regular, Black\nSizes(px): 12, 64, 96\nEffects: none (PNG)\n\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nèªžå½™ã‚„æ–‡è„ˆã«ã‚ˆã‚‹è£œæ­£ã‚’æŽ’ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ç´”ç²‹ãªã€Œèª­å–ã‚Šã€èƒ½åŠ›ã‚’å˜æ–‡å­—ã§æ¸¬ã‚‹ãŸã‚ã®åŸºç¤Žãƒ™ãƒ³ãƒã§ã™ã€‚\nãƒ•ã‚©ãƒ³ãƒˆè¨­è¨ˆã‚„æœ€å°ç·šå¹…ã€ã‚¨ã‚¤ãƒªã‚¢ã‚·ãƒ³ã‚°ã®å½±éŸ¿ã‚’ã€ã‚¦ã‚§ã‚¤ãƒˆã‚„ã‚µã‚¤ã‚ºã®ç³»çµ±æ“ä½œã§å®šé‡åŒ–ã—ã¾ã™ã€‚\nOCRâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JPCharRecog_v1.1.","url":"https://huggingface.co/datasets/Silviase/JPCharRecog_v1.1","creator_name":"Koki Maeda","creator_url":"https://huggingface.co/Silviase","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","monolingual","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"comprehensive-car-damage","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCar Front and Rear Damage Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating machine learning models for car damage detection, specifically focusing on front and rear vehicle damages.\nIt includes high-quality labeled images categorized into six distinct classes:\n\nR_Normal: Rear view of undamaged cars  \nR_Crushed: Rear view of cars with crushed damage  \nR_Breakage: Rear view of cars with visible breakage  \nF_Normal: Front view ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DrBimmer/comprehensive-car-damage.","url":"https://huggingface.co/datasets/DrBimmer/comprehensive-car-damage","creator_name":"Dr. Bimmer","creator_url":"https://huggingface.co/DrBimmer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"T5_german_summaries_filtered_convos","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset T5 German\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tInformation on model\n\t\n\n\nT-Systems-onsite/mt5-small-sum-de-en-v2\nsource_prefix: \"summarize: \"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos.","url":"https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicenseeLegalBenchClassification","keyword":"monolingual","description":"\n  CUADAffiliateLicenseLicenseeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a clause describes a license grant to a licensee (incl. sublicensor) and the affiliates of such licensee/sublicensor.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-sport","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du sport, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"GujaratiNewsClassification","keyword":"monolingual","description":"\n  GujaratiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Gujarati dataset for 3-class classification of Gujarati news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-gujarati\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GujaratiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GujaratiNewsClassification.","url":"https://huggingface.co/datasets/mteb/GujaratiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Gujarati"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-english","keyword":"monolingual","description":"\n  CQADupstackEnglishRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackEnglishRetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-english.","url":"https://huggingface.co/datasets/mteb/cqadupstack-english","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"truthful-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 790 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rahmanidashti/truthful-qa.","url":"https://huggingface.co/datasets/rahmanidashti/truthful-qa","creator_name":"Hossein A. (Saeed) Rahmani","creator_url":"https://huggingface.co/rahmanidashti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"afrimmlu-translate-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for afrimmlu-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"NanoNQRetrieval","keyword":"monolingual","description":"\n  NanoNQRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNQ is a smaller subset of a dataset which contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web\n\n\nReference\nhttps://ai.google.com/research/NaturalQuestions\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNQRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoNQRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Panjabi"],"keywords_longer_than_N":true},
	{"name":"deepseek-svg-description","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSVG Reasoning and Generation Dataset\n\t\n\nA rich dataset containing SVG graphics, structured reasoning, and generated descriptions.Built from the base of thesantatitan/deepseek-svg-dataset but enhanced with separated SVG codes and detailed reasoning-based descriptions.\n\n\t\n\t\t\n\t\n\t\n\t\tDescription Generation Process\n\t\n\nThe dataset has been enhanced by using the reasoning part from the original completion to generate longer, detailed descriptions. The SVG code part of the completion is ignoredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShahzebKhoso/deepseek-svg-description.","url":"https://huggingface.co/datasets/ShahzebKhoso/deepseek-svg-description","creator_name":"Shahzeb Khoso","creator_url":"https://huggingface.co/ShahzebKhoso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-securite-interieure","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la sÃ©curitÃ© intÃ©rieure, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P","keyword":"monolingual","description":"\n  AlloProfClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.","url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"CUADSourceCodeEscrowLegalBenchClassification","keyword":"monolingual","description":"\n  CUADSourceCodeEscrowLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires one party to deposit its source code into escrow with a third party, which can be released to the counterparty upon the occurrence of certain events (bankruptcy, insolvency, etc.).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P.v2","keyword":"monolingual","description":"\n  AlloProfClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2.","url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"legalbench_corporate_lobbying","keyword":"monolingual","description":"\n  LegalBenchCorporateLobbying\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset includes bill titles and bill summaries related to corporate lobbying.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench/viewer/corporate_lobbying\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying.","url":"https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"wb-products","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace Wildberries. It includes all information from the product card and metadata from the API, excluding image URLs. The dataset was collected by processing approximately 160 million products out of a potential 230 million, starting from the first product. Data collection had to be stopped due to serious rate limits that prevented further progress. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-products.","url":"https://huggingface.co/datasets/nyuuzyou/wb-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"CQs-Gen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCritical Questions Generation Dataset: CQs-Gen\n\t\n\nThis dataset is designed to benchmark the ability of language models to generate critical questions (CQs) for argumentative texts. Each instance consists of a naturally occurring argumentative intervention paired with multiple reference questions, annotated for their usefulness in challenging the arguments.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nNumber of interventions: 220  \n\nAverage intervention length: 738.4 characters  \n\nAverage number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/CQs-Gen.","url":"https://huggingface.co/datasets/HiTZ/CQs-Gen","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","cc-by-3.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LoquaciousSet","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLargeScaleASR: 25,000 hours of transcribed and heterogeneous English speech recognition data for research and commercial use.\n\t\n\nThe full details are available in the paper.\nMade of 6 subsets:\n\nlarge contains 25,000 hours of read / spontaneous and clean / noisy transcribed speech.\nmedium contains 2,500 hours of read / spontaneous and clean / noisy transcribed speech.\nsmall contains 250 hours of read / spontaneous and clean / noisy transcribed speech.\nclean contains 13,000 hours of readâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/speechbrain/LoquaciousSet.","url":"https://huggingface.co/datasets/speechbrain/LoquaciousSet","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Magahi"],"keywords_longer_than_N":true},
	{"name":"ChemBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChemBench\n\t\n\n\n\n\n\n\n\n\n\n\nA manually curated benchmark for evaluating chemistry and materials capabilities of Large Language Models\n\n\n\n\n\t\n\t\t\n\t\tâš ï¸ IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tðŸš« THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY ðŸš«\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/ChemBench.","url":"https://huggingface.co/datasets/jablonkagroup/ChemBench","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","language-modeling","natural-language-inference","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Oriya"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-stats","keyword":"monolingual","description":"\n  CQADupstackStatsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackStatsRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-stats.","url":"https://huggingface.co/datasets/mteb/cqadupstack-stats","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"mcqa_greek_asep","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multiple Choice QA Greek ASEP\n\t\n\nThe Multiple Choice QA Greek ASEP dataset is a set of 1200 multiple choice questions in Greek. The questions were extracted and converted from questions available at the website of the Greek Supreme Council for Civil Personnel Selection (Î‘Î½ÏŽÏ„Î±Ï„Î¿ Î£Ï…Î¼Î²Î¿ÏÎ»Î¹Î¿ Î•Ï€Î¹Î»Î¿Î³Î®Ï‚ Î ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ¿Ï, Î‘Î£Î•Î -ASEP) (1Î“/2025).\nThe dataset includes questions in the following domains:\n\nÎ£Ï…Î½Ï„Î±Î³Î¼Î±Ï„Î¹ÎºÏŒ Î”Î¯ÎºÎ±Î¹Î¿ (Constitutional Law): 187 questions\n\nÎ”Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÏŒ Î”Î¯ÎºÎ±Î¹Î¿â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/mcqa_greek_asep.","url":"https://huggingface.co/datasets/ilsp/mcqa_greek_asep","creator_name":"Athena Research Center | Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","monolingual","Greek","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Oriya"],"keywords_longer_than_N":true},
	{"name":"InstructIR-mteb","keyword":"monolingual","description":"\n  InstructIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA benchmark specifically designed to evaluate the instruction following ability in information retrieval models. Our approach focuses on user-aligned instructions tailored to each query instance, reflecting the diverse characteristics inherent in real-world search scenarios. NOTE: scores on this may differ unless you include instruction first, then \"[SEP]\" and then the query via redefining combine_query_and_instruction inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InstructIR-mteb.","url":"https://huggingface.co/datasets/mteb/InstructIR-mteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"JSICK","keyword":"monolingual","description":"\n  JSICK\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JSICK\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSICK.","url":"https://huggingface.co/datasets/mteb/JSICK","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"MultiPL-E","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MultiPL-E\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPL-E is a dataset for evaluating large language models for code\ngeneration that supports 22 programming languages. It takes the OpenAI \nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\ntranslate them  to other languages. It is easy to add support for new languages \nand benchmarks.\nThe dataset is divided into several configurations named SRCDATA-LANG, where\nSRCDATA is eitherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/MultiPL-E.","url":"https://huggingface.co/datasets/nuprl/MultiPL-E","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","machine-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"monolingual","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/bigbench.","url":"https://huggingface.co/datasets/tasksource/bigbench","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"LearningPaper24","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLearningPaper24 Dataset\n\t\n\n\n\nThis dataset contains video recordings and metadata from ICLR and NeurIPS 2024 conference talks. It includes both poster and oral presentations, along with their associated metadata such as titles, abstracts, keywords, and primary areas.\nThe paper list is originally sourced from Paperlists.\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nlearningpaper24/\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ metadata/\nâ”‚   â””â”€â”€ catalog.json\nâ””â”€â”€ video/\n    â”œâ”€â”€ {openreview_id}_{slideslive_id}.mp4\n    â””â”€â”€ ...â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivianchen98/LearningPaper24.","url":"https://huggingface.co/datasets/vivianchen98/LearningPaper24","creator_name":"Shenghui Chen","creator_url":"https://huggingface.co/vivianchen98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","video-text-to-text","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"MMBench-DEV-RU","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMMBench-DEV-RU\n\t\n\nÐ­Ñ‚Ð¾ Ð¿ÐµÑ€ÐµÐ²ÐµÐ´ÐµÐ½Ð½Ñ‹Ð¹ Dev ÑÐ¿Ð»Ð¸Ñ‚ mmbench Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… LLM.\nÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ð» Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸ gpt-4, Ñ‡Ð°ÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð±Ñ‹Ð»Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð° Ð°ÑÑÐµÑÐ¾Ñ€Ð°Ð¼Ð¸.\nÐ’ Ð´Ð°Ð½Ð½Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¼Ð°Ð»Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°. \nÐ¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº: https://huggingface.co/spaces/opencompass/MMBench\n\n\t\n\t\t\n\t\n\t\n\t\tÐ¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°\n\t\n\nhttps://github.com/Natyren/mmbench-ru-eval\nÐ¤Ð°Ð¹Ð», ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²Ñ‹ ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ÐµÑÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð°Ñ‚ÑŒ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ gtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU.","url":"https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","monolingual","original","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"tt-crawl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release TatarCrawl dataset, a web news corpus consisting of materials from nearly 15 unique sources in the Tatar Language.\nTo load and use dataset, run this script:\nfrom datasets import load_dataset\n\ntt_crawl=load_dataset(\"neurotatarlar/tt-crawl\")\n\n","url":"https://huggingface.co/datasets/yasalma/tt-crawl","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"code-deontologie-architectes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de dÃ©ontologie des architectes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"MPCC","keyword":"monolingual","description":"\n MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models\n\n\n\n      \n    [Github repository] \n    \n    \n\n\nðŸŒŸ The official repository of MPCC.\n\n\t\n\t\t\n\t\tðŸ”¥News\n\t\n\n\nðŸ”¥ Our work is accepted by ACM MM 2025.\nðŸ”¥ We have release benchmark on [ðŸ¤—HuggingFace].\n\n\n\t\n\t\t\n\t\tðŸ’¡ Motivation\n\t\n\nMultimodal Planning with Complex Constraints (MPCC) presents a novel benchmark targeting real-world planning scenarios that require models to jointly reason over visualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jyyyyy67/MPCC.","url":"https://huggingface.co/datasets/jyyyyy67/MPCC","creator_name":"jyyyyy","creator_url":"https://huggingface.co/jyyyyy67","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","visual-question-answering","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"CUADRenewalTermLegalBenchClassification","keyword":"monolingual","description":"\n  CUADRenewalTermLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a renewal term.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code_contests","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CodeContests\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCodeContests is a competitive programming dataset for machine-learning. This\ndataset was used when training AlphaCode.\nIt consists of programming problems, from a variety of sources:\n\n\t\n\t\t\nSite\nURL\nSource\n\n\n\t\t\nAizu\nhttps://judge.u-aizu.ac.jp\nCodeNet\n\n\nAtCoder\nhttps://atcoder.jp\nCodeNet\n\n\nCodeChef\nhttps://www.codechef.com\ndescription2code\n\n\nCodeforces\nhttps://codeforces.com\ndescription2code and Codeforces\n\n\nHackerEarthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Imandra/code_contests.","url":"https://huggingface.co/datasets/Imandra/code_contests","creator_name":"Imandra Inc","creator_url":"https://huggingface.co/Imandra","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"usa-corn-belt-crop-yield","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUSA County Level Crop Yield Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains county level crop yield across 763 counties from 1984 till 2018 in the US Corn Belt. The data was originally collected in Khaki et al. 2020, then further processed, augmented dedup-ed in Hasan et al. 2024.\nHere are the 9 unique states in the dataset:\n\nIllinois\nIndiana\nIowa\nKansas\nMinnesota\nMissouri\nNebraska\nNorth Dakota\nSouth Dakota\n\nEach row of the CSV includes:\n\nWeather: 6 weekly mean weatherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/notadib/usa-corn-belt-crop-yield.","url":"https://huggingface.co/datasets/notadib/usa-corn-belt-crop-yield","creator_name":"Adib H","creator_url":"https://huggingface.co/notadib","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-commerce","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de commerce, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"VieStudentFeedbackClassification","keyword":"monolingual","description":"\n  VieStudentFeedbackClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for classification of student feedback\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://ieeexplore.ieee.org/document/8573337\n\n\n\t\n\nSource datasets:\n\nuitnlp/vietnamese_students_feedback\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification.","url":"https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"code-disciplinaire-penal-marine-marchande","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode disciplinaire et pÃ©nal de la marine marchande, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-sante-publique","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la santÃ© publique, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"French-reviews-with-prediction-of-their-feelings","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ‡«ðŸ‡· French Sentiment Dataset - Multisource (Auto-labeled)\n\t\n\nThis dataset contains 960,000 French-language text reviews, automatically labeled with sentiment classes: positive, neutral, or negative, using the TextBlob-FR library.\nIt is suitable for training or evaluating sentiment classification models in French, as well as general-purpose NLP research on French texts.\n\n\n\t\n\t\t\n\t\n\t\n\t\tâš™ï¸ Labeling method\n\t\n\nSentiment labels were automatically generated based on polarity scores using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gaouehalim/French-reviews-with-prediction-of-their-feelings.","url":"https://huggingface.co/datasets/gaouehalim/French-reviews-with-prediction-of-their-feelings","creator_name":"GAOUE Halim","creator_url":"https://huggingface.co/gaouehalim","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","extended|other"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Urdu"],"keywords_longer_than_N":true},
	{"name":"code-rural-ancien","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode rural (ancien), non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"InternationalCitizenshipQuestionsLegalBenchClassification","keyword":"monolingual","description":"\n  InternationalCitizenshipQuestionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions about citizenship law from across the world. Dataset was made using the GLOBALCIT citizenship law dataset, by constructing questions about citizenship law as Yes or No questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Schemaorg","keyword":"monolingual","description":"This dataset is a collection of Mixed-hop Prediction datasets created from Schema.org's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/Schemaorg","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-commande-publique","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la commande publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus","keyword":"monolingual","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NFCorpus","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"CodeCompass","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCodeCompass: A Benchmark for Code Generation\n\t\n\nPaper: Rethinking Verification for LLM Code Generation: From Generation to Testing\n\n\t\n\t\t\n\t\tDescription\n\t\n\nCodeCompass is a rigorous benchmark designed to evaluate the code generation capabilities of Large Language Models (LLMs). It comprises a comprehensive collection of programming problems sourced from competitive platforms, offering a standardized framework for assessing algorithmic reasoning, problem-solving, and code synthesis in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/CodeCompass.","url":"https://huggingface.co/datasets/opencompass/CodeCompass","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","monolingual","English","apache-2.0","arxiv:2507.06920"],"keywords_longer_than_N":true},
	{"name":"bangla-health-related-paraphrased-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"BanglaHealthParaphrase\"\n\t\n\n\n\nBanglaHealthParaphrase is a Bengali paraphrasing dataset specifically curated for the health domain. It contains over 200,000 sentence pairs, where each pair consists of an original Bengali sentence and its paraphrased version. The dataset was created through a multi-step pipeline involving extraction of health-related content from Bengali news sources, English pivot-based paraphrasing, and back-translation to ensure linguistic diversityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset.","url":"https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset","creator_name":"Faisal MIST","creator_url":"https://huggingface.co/faisal4590aziz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","original","Bengali","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DataNote","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“˜ DataNote Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Giá»›i thiá»‡u\n\t\n\nDataNote lÃ  má»™t dataset chá»©a cÃ¡c Ä‘oáº¡n code snippet vÃ  vÃ­ dá»¥ láº­p trÃ¬nh cho nhiá»u ngÃ´n ngá»¯ khÃ¡c nhau.Dataset nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ phá»¥c vá»¥ cho viá»‡c há»c táº­p, quáº£n lÃ½ snippet vÃ  sÆ°u táº§m code máº«u.\n\n\n\t\n\t\t\n\t\tðŸ“‚ Cáº¥u trÃºc dá»¯ liá»‡u\n\t\n\nMá»—i báº£n ghi trong dataset bao gá»“m cÃ¡c trÆ°á»ng:\n\ntitle: TÃªn hoáº·c tiÃªu Ä‘á» cá»§a snippet\ncontent: Ná»™i dung code thá»±c táº¿\nlanguage: NgÃ´n ngá»¯ láº­p trÃ¬nh (javascript, python, html, css, sql, â€¦)\ndescription: MÃ´ táº£ ngáº¯n gá»n vá» chá»©câ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TwanAPI/DataNote.","url":"https://huggingface.co/datasets/TwanAPI/DataNote","creator_name":"Thanh Tuáº¥n ","creator_url":"https://huggingface.co/TwanAPI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","natural-language-inference","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"HagridRetrieval","keyword":"monolingual","description":"\n  HagridRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset)is a dataset for generative information-seeking scenarios. It consists of queriesalong with a set of manually labelled relevant passages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/project-miracl/hagrid\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HagridRetrieval.","url":"https://huggingface.co/datasets/mteb/HagridRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mseqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tARQMath-Task-1\n\t\n\nMathematics Stack Exchange Answer Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"mb-crater_binary_seg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-crater_binary_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Crater\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-crater_binary_seg.","url":"https://huggingface.co/datasets/Mirali33/mb-crater_binary_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"TTI-Set","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tText-to-Image Model Attribution Dataset\n\t\n\nThis dataset is distilled from two comprehensive sources:\n\nA 2-year snapshot of the CivitAI SFW (Safe-for-Work) image dataset, containing metadata for generated images.\nA complete export of all models published on CivitAI, including metadata such as model names, types, and version identifiers.\n\nBy matching image-level resourceIDs (used to generate each image) with the corresponding model version IDs from the model dataset, we identified andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pointofnoreturn/TTI-Set.","url":"https://huggingface.co/datasets/pointofnoreturn/TTI-Set","creator_name":"laura wagner","creator_url":"https://huggingface.co/pointofnoreturn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NoticIA","keyword":"monolingual","description":"\n    \n\n\n\"A Clickbait Article Summarization Dataset in Spanish.\"\n\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\n\nðŸ“– Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\nðŸ’» Baseline Code: https://github.com/ikergarcia1996/NoticIA\nðŸ¤– Pre Trained Modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA.","url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker GarcÃ­a-Ferrero","creator_url":"https://huggingface.co/Iker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"monolingual","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"OverrulingLegalBenchClassification","keyword":"monolingual","description":"\n  OverrulingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task consists of classifying whether or not a particular sentence of case law overturns the decision of a previous case.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSciFact.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSciFact-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSciFact","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Gujarati"],"keywords_longer_than_N":true},
	{"name":"code-rural-peche-maritime","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode rural et de la pÃªche maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"crello","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Crello\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Crello dataset is a collection of raster graphic designs originally compiled for the study of vector graphic documents. It contains document meta-data such as canvas size and pre-rendered elements such as images or text boxes. The original templates were collected from crello.com (now create.vista.com) and converted to a low-resolution format suitable for machine learning analysis. More recently, it has been used forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/crello.","url":"https://huggingface.co/datasets/cyberagent/crello","creator_name":"CyberAgent","creator_url":"https://huggingface.co/cyberagent","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["image-segmentation","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S.v2","keyword":"monolingual","description":"\n  AlloProfClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S.v2\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2.","url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"monolingual","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"textureninja","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Texture Ninja\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,540 texture images from texture.ninja. It includes high-resolution textures of brick, concrete, rock, wood, metal, paint, plaster, ground materials, and other surfaces. The original images were downloaded, processed, and compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while maintaining good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/textureninja.","url":"https://huggingface.co/datasets/nyuuzyou/textureninja","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"amazon-food-reviews-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Food Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset.","url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cantemist","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CANTEMIST\n\t\n\nCollection of 1301 oncological clinical case reports written in Spanish, with tumor morphology mentions manually annotated and mapped by clinical experts to a controlled terminology. Every tumor morphology mention is linked to an eCIE-O code (the Spanish equivalent of ICD-O).\nThe original dataset is distributed in Brat format, and was randomly sampled into 3 subsets. The training, development and test sets contain 501, 500 and 300 documents eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/masaenger/cantemist.","url":"https://huggingface.co/datasets/masaenger/cantemist","creator_name":"Mario SÃ¤nger","creator_url":"https://huggingface.co/masaenger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"boulder_segmentation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tboulder_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Boulder\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/boulder_segmentation.","url":"https://huggingface.co/datasets/gremlin97/boulder_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","description":"\n  Banking77Classification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset composed of online banking queries annotated with their corresponding intents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten\n\n\nReference\nhttps://arxiv.org/abs/2003.04807\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Banking77Classification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/banking77.","url":"https://huggingface.co/datasets/mteb/banking77","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"fungi_diagnostic_chars_comparison_japanese","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tfungi_diagnostic_chars_comparison_japaneseå¤§èŒè¼ªã€Œè­˜åˆ¥å½¢è³ªã¾ã¨ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœ€çµ‚æ›´æ–°æ—¥ / Last updated: 2025/5/2ï¼ˆup to R3-12744ï¼‰\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\tæ¦‚è¦ / Overview\n\t\n\nAtsushi Nakajimaï¼ˆä¸­å³¶æ·³å¿—ï¼‰ãŒå€‹äººã§é‹å–¶ã—ã¦ã„ã‚‹Webã‚µã‚¤ãƒˆå¤§èŒè¼ªã§ã¯ã€æ•°åƒä»¶ä»¥ä¸Šã®èŒé¡žåˆ†é¡žå­¦è«–æ–‡ã‚’ã€Œè«–æ–‡3è¡Œã¾ã¨ã‚ã€ã¨ã„ã†å½¢ã§è¦ç´„ãŠã‚ˆã³ç´¢å¼•ä»˜ã‘ï¼ˆã‚¤ãƒ³ãƒ‡ã‚­ã‚·ãƒ³ã‚°ï¼‰ã—ãŸæƒ…å ±ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ãã®ä¸€ç’°ã¨ã—ã¦ã€ã‚ã‚‹èŒã¨åˆ¥ã®èŒã®ã€Œå…±é€šã™ã‚‹ã€ã‚ã‚‹ã„ã¯ã€Œç•°ãªã‚‹ã€è­˜åˆ¥å½¢è³ª (diagnostic characters) ã«é–¢ã™ã‚‹è¨˜è¿°ã‚’äººæ‰‹ã§æŠ½å‡ºã—ã¦ã„ã¾ã™ã€‚\nDaikinrin, a website personally operated by Atsushi Nakajima, provides summaries and indexingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese.","url":"https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MC-III-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfEmployeesLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNoSolicitOfEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party's soliciting or hiring employees and/or contractors from the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"YinYang-Text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for YinYang-Text\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nYinYang-Text is a Direct Preference Optimization (DPO) dataset for training AI models to navigate ethical tradeoffs. The dataset contains 56,268 preference pairs across 10 fundamental AI alignment dimensions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nprompt (string): Input scenario requiring ethical decision-making\nchosen (string): Preferred response\nrejected (string): Dispreferredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arena/YinYang-Text.","url":"https://huggingface.co/datasets/Arena/YinYang-Text","creator_name":"Mahsa Kh","creator_url":"https://huggingface.co/Arena","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"all-nli-tr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AllNLITR\n\t\n\nThis dataset is a formatted version of NLI-TR datasets, sharing the same licenses. The format is intended to be in line with AllNLI by Sentence Transformers for ease of training.\nDespite originally being intended for Natural Language Inference (NLI), this dataset can be used for training/finetuning an embedding model for semantic textual similarity.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Subsets\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tpair-class subset\n\t\n\n\nColumns: \"premise\", \"hypothesis\", \"label\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emrecan/all-nli-tr.","url":"https://huggingface.co/datasets/emrecan/all-nli-tr","creator_name":"Emrecan Ã‡elik","creator_url":"https://huggingface.co/emrecan","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","Turkish","cc-by-3.0"],"keywords_longer_than_N":true},
	{"name":"snli-zh","keyword":"monolingual","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English\nsentence pairs manually labeled for balanced classification with the labels\nentailment, contradiction, and neutral, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).","url":"https://huggingface.co/datasets/shibing624/snli-zh","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"sen1floods11","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSen1Floods11\n\t\n\nSen1Floods11: a georeferenced dataset to train and test deep learning flood algorithms for Sentinel-1 (Example). This data was generated by Cloud to Street, a Public Benefit Corporation: https://www.cloudtostreet.info/. For questions about this dataset or code please email support@cloudtostreet.info. Please cite this data as:\nBonafilia, D., Tellman, B., Anderson, T., Issenberg, E. 2020. Sen1Floods11: a georeferenced dataset to train and test deep learning floodâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/harshinde/sen1floods11.","url":"https://huggingface.co/datasets/harshinde/sen1floods11","creator_name":"Harsh","creator_url":"https://huggingface.co/harshinde","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test.","url":"https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test","creator_name":"Marco Palumbo","creator_url":"https://huggingface.co/MarcPal08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"UnSafeChain","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUnsafeChain Dataset\n\t\n\nUnsafeChain is a correction-based alignment dataset designed to improve the safety of large language models (LLMs) through exposure to unsafe completions and their corrected responses.\nIt contains three distinct subsets:\n\ntrain_full.csv: Complete dataset with all examples.\ntrain_random.csv: Randomly selected examples for baseline comparisons.\ntrain_selected.csv: Carefully curated hard unsafe examples, emphasizing safety recovery.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/raj-tomar001/UnSafeChain.","url":"https://huggingface.co/datasets/raj-tomar001/UnSafeChain","creator_name":"Raj Tomar","creator_url":"https://huggingface.co/raj-tomar001","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["machine-generated","monolingual","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Awadhi"],"keywords_longer_than_N":true},
	{"name":"children-stories-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChildren's Stories Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a collection of children's stories designed to teach positive values, problem-solving skills, and emotional intelligence. The stories feature diverse characters and settings, making them suitable for children aged 3-8.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach story record contains:\n\nid: Unique story identifier\ntitle: Story title\ntext: Full story text\ntype: Story type (e.g., \"daily_adventure\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/garethpaul/children-stories-dataset.","url":"https://huggingface.co/datasets/garethpaul/children-stories-dataset","creator_name":"Gareth","creator_url":"https://huggingface.co/garethpaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","text2text-generation","no-annotation","machine-generated"],"keywords_longer_than_N":true},
	{"name":"so-arm101","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSO-101 Roboter Dataset\n\t\n\nDieses Dataset enthÃ¤lt Teleoperationsdaten fÃ¼r den SO-101 Roboter, aufgenommen mit Phosphobot.\n\n\t\n\t\t\n\t\tBeschreibung\n\t\n\n\nRoboter: SO-101\nKamera: Logitech HD Webcam eMeet C980 Pro (4 Kameras)\nSoftware: Phosphobot\nAufnahme: Teleoperation mit visueller RÃ¼ckmeldung\n\n\n\t\n\t\t\n\t\tStruktur\n\t\n\nso-arm101/\nâ”œâ”€â”€ meta/\nâ”‚   â””â”€â”€ info.json          # Dataset-Metadaten\nâ”œâ”€â”€ sessions/              # Aufnahme-Sessions\nâ”‚   â””â”€â”€ [session_id]/      # Einzelne Sessions\nâ”‚       â”œâ”€â”€ videos/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MaxFridge/so-arm101.","url":"https://huggingface.co/datasets/MaxFridge/so-arm101","creator_name":"Max Fritsch","creator_url":"https://huggingface.co/MaxFridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"afrimgsm-translate-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimgsm","Amharic"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de MÃ©canique des Structures et des SystÃ¨mes CouplÃ©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"SpartQA","keyword":"monolingual","description":"\n  SpartQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on SpartQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/HLR/SpartQA_generation\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SpartQA\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SpartQA.","url":"https://huggingface.co/datasets/mteb/SpartQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/spartqa","English"],"keywords_longer_than_N":true},
	{"name":"WordNetNoun","keyword":"monolingual","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from WordNet's subsumption (hypernym) hierarchy of noun entities for training and evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/WordNetNoun","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSCIDOCS.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSCIDOCS-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSCIDOCS","French"],"keywords_longer_than_N":true},
	{"name":"math_hard_fr","keyword":"monolingual","description":"tktung/math_hard_fr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tktung/math_hard_fr","creator_name":"Tung Tran","creator_url":"https://huggingface.co/tktung","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","French"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithThirdPartiesLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLISharingWithThirdPartiesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some third-parties (including consultants, agents and professional advisors).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"omgevingswet_participatie_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOmgevingswet & Participatie Q&A\n\t\n\n1000 NL conversaties in ShareGPT-formaat met:\n\nid\nconversations: lijst van beurtwisselingen {from: \"human\"/\"gpt\", value: \"...\"}\n\nSplits: train (900), test (100).\n\n\t\n\t\t\n\t\tVoorbeeld\n\t\n\n{\n    \"id\": \"q0001\",\n    \"conversations\": [\n        { \"from\": \"human\", \"value\": \"Wat is ...?\" },\n        { \"from\": \"gpt\", \"value\": \"Antwoord ...\" }\n    ]\n}\n\n","url":"https://huggingface.co/datasets/mamersfo/omgevingswet_participatie_qa","creator_name":"Martin van Amersfoorth","creator_url":"https://huggingface.co/mamersfo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","monolingual","original","Dutch"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"MaCBench-Prompt-Ablations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMaCBench-Prompt-Ablations\n\t\n\n\n\n\n\n\n\n\n\n\nA Chemistry and Materials Benchmark for evaluating Vision Large Language Models\n\n\n\n\n\t\n\t\t\n\t\tâš ï¸ IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tðŸš« THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY ðŸš«\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/MaCBench-Prompt-Ablations.","url":"https://huggingface.co/datasets/jablonkagroup/MaCBench-Prompt-Ablations","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multiple-choice","image-to-text","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"human-eval","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAiravata HumanEval Prompts\n\t\n\nThis benchmark contains a set of prompts written by real-users to evaluate LLMs on real-world tasks and test it for different abilities. We collect prompts for 5 abilities listed below:\n\nLong: Ability to generate long-form text like writing essays, speeches, reports, etc.\nFact-Ops: Ability to give factual opinions and explanations like seeking recommendations, seeking advice, opinions, explanations, etc.\nContent: Ability to make content accessible likeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/human-eval.","url":"https://huggingface.co/datasets/ai4bharat/human-eval","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"BC-I-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"eli-why-perceived-background-match","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tELI-Why Perceived Background Match\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  Dataset Summary\n\t\n\nThis split contains human judgments on whether an LLM-generated explanation was perceived to match the intended educational background of the audience (e.g., elementary, high school, graduate school).\nEach example in this dataset includes:\n\nThe original question\nThe intended education level (based on prompting)\nThe explanation generated according to the intended education level\nThe perceived education level (based onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match.","url":"https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["human-annotated","machine-generated","monolingual","eli-why","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Manipuri"],"keywords_longer_than_N":true},
	{"name":"eli-why","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“˜ ELI-Why\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  Dataset Summary\n\t\n\nELI-Why is a benchmark for evaluating how well large language models (LLMs) explain \"Why\" questions to people across different educational levels.This full release contains over 13,000 diverse â€œWhyâ€ questions with:\n\nðŸ“š Domain and Discipline metadata\nðŸŒ A web-retrieved explanation\nðŸ¤– 16 model-generated explanations from 4 LLMs:\nGPT-4\nLLaMA 3.2\nQwen 2.5\nR1-Distilled LLaMA\n\n\n\nEach model responds at four educational levels: ðŸ§’ elementary schoolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why.","url":"https://huggingface.co/datasets/INK-USC/eli-why","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wb-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset of questions and answers scraped from product pages from the Russian marketplace Wildberries. Dataset contains all questions and answers, as well as all metadata from the API. However, the \"productName\" field may be empty in some cases because the API does not return the name for old products.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-questions.","url":"https://huggingface.co/datasets/nyuuzyou/wb-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","open-domain-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"clker-svg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Clker.com SVG Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 255,758 public domain SVG vector clipart images collected from Clker.com. Clker.com hosts user-shared vector clip art that is explicitly released into the public domain (CC0). The dataset includes the SVG content itself along with metadata such as titles and tags associated with each image. The SVG files in this dataset have been minified using tdewolff/minify to reduce file size while preservingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/clker-svg.","url":"https://huggingface.co/datasets/nyuuzyou/clker-svg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"taln-archives_fr_prompt_keywords_extraction","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttaln-archives_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntaln-archives_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 24,507 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction.","url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/taln-archives"],"keywords_longer_than_N":true},
	{"name":"text_meme","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttext_meme\n\t\n\nÐ¡Ð¾ÑÐºÑ€Ð°Ð¿ÐµÐ½Ð¾ Ñ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Telegram ÐºÐ°Ð½Ð°Ð»Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÐ¼Ñ‹.\n","url":"https://huggingface.co/datasets/d0rj/text_meme","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","monolingual","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"LLaVA-OneVision-Data-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLLaVA-OneVision-Data-ru\n\t\n\nTranslated lmms-lab/LLaVA-OneVision-Data dataset into Russian language using Google translate.\n\nAlmost all datasets have been translated, except for the following:\n[\"tallyqa(cauldron,llava_format)\", \"clevr(cauldron,llava_format)\", \"VisualWebInstruct(filtered)\", \"figureqa(cauldron,llava_format)\", \"magpie_pro(l3_80b_mt)\", \"magpie_pro(qwen2_72b_st)\", \"rendered_text(cauldron)\", \"ureader_ie\"]\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nimport datasets\n\n\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru.","url":"https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","visual-question-answering","image-to-text","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"prost","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPROST: Physical Reasoning about Objects Through Space and Time\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPhysical Reasoning about Objects Through Space and Time (PROST) is a probing dataset to evaluate the ability of pretrained LMs to understand and reason about the physical world. PROST consists of 18,736 cloze-style multiple choice questions from 14 manually curated templates, covering 10 physical reasoning concepts:  direction, mass, height, circumference, stackable, rollable, graspableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lighteval/prost.","url":"https://huggingface.co/datasets/lighteval/prost","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","open-domain-qa","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"UrduRomanSentimentClassification","keyword":"monolingual","description":"\n  UrduRomanSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Roman Urdu dataset is a data corpus comprising of more than 20000 records tagged for sentiment (Positive, Negative, Neutral)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://archive.ics.uci.edu/dataset/458/roman+urdu+data+set\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification.","url":"https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GreekLegalCodeClassification","keyword":"monolingual","description":"\n  GreekLegalCodeClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreek Legal Code Dataset for Classification. (subset = chapter)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://arxiv.org/abs/2109.15298\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreekLegalCodeClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreekLegalCodeClassification.","url":"https://huggingface.co/datasets/mteb/GreekLegalCodeClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Modern Greek (1453-)"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personake amministrativo e famiglie di rispondere ad alcune domande\nsul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali an indicatori di gradimento.\nIl dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelliggenza artificiale.\nGrazie aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test","creator_name":"giovanni de santis","creator_url":"https://huggingface.co/Giova-tech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 13284\nFiltered size: 13240\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"code-douanes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des douanes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"soda-audio","keyword":"monolingual","description":"Parent dataset: SODA\nThe dataset was created based on SODA by first subsetting it and then adding two synthetic columns for training the Ultravox model:\n\nalt_last_turn: is an alternative for the last turn of the dialogue (dialogue[-1]) and was (re-)generated by Llama-3-8B Instruct;\naudio_one_but_last: is the TTS'd speech for the turn before the last one (dialogue[-2]) using the Eleven Labs voice API using a set of random voices.\n\n","url":"https://huggingface.co/datasets/fixie-ai/soda-audio","creator_name":"Fixie.ai","creator_url":"https://huggingface.co/fixie-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["machine-generated","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NewsClassification","keyword":"monolingual","description":"\n  NewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/1509.01626\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NewsClassification.","url":"https://huggingface.co/datasets/mteb/NewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 37133\nFiltered size: 37133\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Perros_gatos","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ¶ðŸ± Dogs vs Cats Dataset\n\t\n\nEste conjunto de datos contiene imÃ¡genes de perros y gatos, utilizadas comÃºnmente para tareas de clasificaciÃ³n binaria en visiÃ³n por computadora.\n\n\t\n\t\t\n\t\tDescripciÃ³n\n\t\n\nEl conjunto de datos fue originalmente parte de una competencia de Kaggle organizada por Microsoft, con el objetivo de construir un modelo capaz de distinguir entre imÃ¡genes de perros y gatos.\nCada imagen estÃ¡ etiquetada como dog o cat en el nombre del archivo, por ejemplo:\n\ncat.0.jpgâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IABD12/Perros_gatos.","url":"https://huggingface.co/datasets/IABD12/Perros_gatos","creator_name":"Alejandro Cruz Aguilar","creator_url":"https://huggingface.co/IABD12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"COVID-19_qa_pairs","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-19_qa_pairs dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis datasets includes 604 question-answer pairs related to COVID-19 pandemic machine translated in Greek language. \nThe data is extracted from the official website of WHO.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nquestion: Query question\ndocument: Answer to the question\n\n\n\t\n\t\t\n\t\tBias, Risks, and Limitations\n\t\n\nThis dataset is the result of machine translation.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe dataset is licensed under theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs.","url":"https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","monolingual","original","Greek"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/flunardelli/mmlu.","url":"https://huggingface.co/datasets/flunardelli/mmlu","creator_name":"Fernando Lunardelli","creator_url":"https://huggingface.co/flunardelli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adaptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"new_real_datasets","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","url":"https://huggingface.co/datasets/hongin9812/new_real_datasets","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"agxqa_v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AgXQA 1.1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Agricultural eXtension Question Answering Dataset (AgXQA 1.1) is a small-scale, SQuAD-like QA dataset targeting the Agriculture Extension domain. \nVersion 1.1 currently contains 2.1K+ questions related to irrigation topics across the US, focusing on the Midwest since our crops of interest were mainly soybean and corn.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion Answering.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/msu-ceco/agxqa_v1.","url":"https://huggingface.co/datasets/msu-ceco/agxqa_v1","creator_name":"The Computational Ecohydrology Group at MSU","creator_url":"https://huggingface.co/msu-ceco","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"PersonalJurisdictionLegalBenchClassification","keyword":"monolingual","description":"\n  PersonalJurisdictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a fact pattern describing the set of contacts between a plaintiff, defendant, and forum, determine if a court in that forum could excercise personal jurisdiction over the defendant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-s2s","keyword":"monolingual","description":"\n  ArXivHierarchicalClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArXivHierarchicalClusteringS2S\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-s2s.","url":"https://huggingface.co/datasets/mteb/arxiv-clustering-s2s","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"Il dataset Ã¨ stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tutti per la collaborazione â¤ï¸\n","url":"https://huggingface.co/datasets/qwertychri/sentiment-analysis-test","creator_name":"Christian Scimenes","creator_url":"https://huggingface.co/qwertychri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-news-articles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"RuReviewsClassification","keyword":"monolingual","description":"\n  RuReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nProduct review classification (3-point scale) based on RuRevies dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/sismetanin/rureviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RuReviewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuReviewsClassification.","url":"https://huggingface.co/datasets/mteb/RuReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ga-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corruptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"termith-eval_fr_prompt_keywords_extraction","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttermith-eval_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntermith-eval_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 8,295 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPromptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction.","url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/termith-eval"],"keywords_longer_than_N":true},
	{"name":"NanoDBPediaRetrieval","keyword":"monolingual","description":"\n  NanoDBPediaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoDBPediaRetrieval is a small version of the standard test collection for entity search over the DBpedia knowledge base.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic\n\nReference\nhttps://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","topic-classification","expert-annotated","monolingual","mteb/dbpedia"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"mb-s5mars","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-s5mars\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Hole\n3: Ridge\n4: Rock\n5: Rover\n6: Sand / Soil\n7: Sky\n8: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-s5mars.","url":"https://huggingface.co/datasets/Mirali33/mb-s5mars","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 113\nNumber of unique topics: 9\nNumber of unique subtopics: 46\nLast updated: 2025-05-28\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-test.","url":"https://huggingface.co/datasets/magichampz/medical-cyber-test","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"R2MEDBioinformaticsRetrieval","keyword":"monolingual","description":"\n  R2MEDBioinformaticsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBioinformatics retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Bioinformatics\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBioinformaticsRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Bioinformatics"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Oriya"],"keywords_longer_than_N":true},
	{"name":"IMDB_Sentiment","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"imdb\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 84.13 MB\nSize of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kwaai/IMDB_Sentiment.","url":"https://huggingface.co/datasets/Kwaai/IMDB_Sentiment","creator_name":"Kwaai","creator_url":"https://huggingface.co/Kwaai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","sentiment-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations_cleaned","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset (cleaned)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"next.js-15.4-with-reasoning","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Next.js Documentation Dataset based on next.js 15.4 version is a high-quality, code-centric dataset created from Next.js documentation for fine-tuning language models. It contains 1,172 question-answer pairs derived from 178 markdown documentation files, focusing on practical code examples and real-world development scenarios.\nThis dataset is designed for:\n\nQuestion Answering: Natural language questions about Next.js development\nCode Generation: Generating practicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Slava32/next.js-15.4-with-reasoning.","url":"https://huggingface.co/datasets/Slava32/next.js-15.4-with-reasoning","creator_name":"Slava","creator_url":"https://huggingface.co/Slava32","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","extractive-qa","text2text-generation","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Oriya"],"keywords_longer_than_N":true},
	{"name":"BC-IV-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-IV-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mouse-glioblastoma-snRNAseq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMouse Glioblastoma Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data from the brain (glioblastoma tumors and their microenvironment) of both young and aged mice. It provides a high-resolution cellular and molecular census of glioblastoma, a highly aggressive brain tumor, with crucial insights into its age-related characteristics.\nThe original data was sourced from a CELLxGENE Discover collection titledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/mouse-glioblastoma-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/mouse-glioblastoma-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dust_devil_detection","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdust_devil_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: dustdevil\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/dust_devil_detection.","url":"https://huggingface.co/datasets/gremlin97/dust_devil_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"libri-in-italiano","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLibri\n\t\n\nIl dataset dei libri consiste in una raccolta diversificata di 18 libri organizzati in 4 categorie.\nQuesto dataset Ã¨ ben pulito e progettato per supportare diversi compiti di elaborazione del linguaggio naturale (NLP), inclusi generazione di testo, traduzione e modellazione del linguaggio mascherato.\n\n\t\n\t\t\n\t\tDettagli\n\t\n\nIl dataset contiene 4 colonne:\n\ntitolo: Il titolo del libro.\nautore: L'autore del libro.\ncategoria: Il genere/categoria del libro.\ncontenuto: Il contenutoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano.","url":"https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","fill-mask","IsmaelMousa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Manipuri"],"keywords_longer_than_N":true},
	{"name":"SynWOZ","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynWOZ\n\t\n\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ.","url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"RARbMath","keyword":"monolingual","description":"\n  RARbMath\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on RAR-b math-pooled dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.06347\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RARbMath\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RARbMath.","url":"https://huggingface.co/datasets/mteb/RARbMath","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/math-pooled","English"],"keywords_longer_than_N":true},
	{"name":"escher-vismin-dev","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-vismin-dev\n\t\n\nVismin dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/mair-lab/escher-vismin-dev","creator_name":"MAIR Lab","creator_url":"https://huggingface.co/mair-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Manipuri"],"keywords_longer_than_N":true},
	{"name":"GreenNodeTableMarkdownRetrieval","keyword":"monolingual","description":"\n  GreenNodeTableMarkdownRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreenNodeTable documents\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFinancial, Encyclopaedic, Non-fiction\n\n\nReference\nhttps://huggingface.co/GreenNode\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreenNodeTableMarkdownRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval.","url":"https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"Diversity6LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity6LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 6).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"conequest","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tconequest\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Cone\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masks\n  â”œâ”€â”€ val/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/conequest.","url":"https://huggingface.co/datasets/gremlin97/conequest","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"monolingual","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues (base)Â \n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"real-toxicity-prompts-lite","keyword":"monolingual","description":"This is a fork of the original RealToxicityPrompts dataset that contains a much smaller subset of the 100k prompts.\nSubsets:\n\n50_pct: This subset contains all the challenging prompts + 50% of the full RealToxicityPrompts size sampled from the other prompts.\n10_pct: This subset contains all the challenging prompts + 10% of the full RealToxicityPrompts size sampled from the other prompts.\n\nPlease refer to the original dataset for the Dataset Card.\n","url":"https://huggingface.co/datasets/oskarvanderwal/real-toxicity-prompts-lite","creator_name":"Oskar van der Wal","creator_url":"https://huggingface.co/oskarvanderwal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","allenai/real-toxicity-prompts","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TrCOLA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTrCOLA - Corpus of Linguistic Acceptability for Turkish Language\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for TrCOLA\n\t\n\nTrCOLA is the Turkish version of CoLA dataset, The Corpus of Linguistic Acceptability.\nThis dataset introduces linguistic acceptability task for Turkish. The total dataset size is 9.9K instances.\nEach instance of the dataset is an original and correct sentence, variation of sentence that is produced in a specific way, the variation type and a binary label stating the sentence is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA.","url":"https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","monolingual","original","Turkish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"begemot","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Begemot.ai\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 2,728,999 educational project descriptions in Russian language generated with neural networks from begemot.ai website. The content includes project titles, descriptions, chapters and chapter content across various educational topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nid: Uniqueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/begemot.","url":"https://huggingface.co/datasets/nyuuzyou/begemot","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","topic-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"plvideo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Platforma Video Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from video pages on the Russian video-sharing platform Platforma, a Russian YouTube alternative. It includes information about 181,876 videos across 12,341 channels. The dataset contains detailed information about each video and its associated channel, providing a comprehensive view of the content available on the platform.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, but thereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/plvideo.","url":"https://huggingface.co/datasets/nyuuzyou/plvideo","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"PROALegalBenchClassification","keyword":"monolingual","description":"\n  PROALegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a statute, determine if the text contains an explicit private right of action. Given a privacy policy clause and a description of the clause, determine if the description is correct. A private right of action (PROA) exists when a statute empowers an ordinary individual (i.e., a private person) to legally enforce their rights by bringing an action in court. In short, a PROA creates the ability for anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PROALegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/PROALegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mb-surface_cls","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-surface_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: apx\n1: act\n2: arm\n3: art\n4: cct\n5: cio\n6: clr\n7: dls\n8: dri\n9: drh\n10: drp\n11: drt\n12: flr\n13: gro\n14: hor\n15: inl\n16: lar\n17: ltv\n18: mah\n19: mct\n20: mas\n21: mca\n22: nsk\n23: obt\n24:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-surface_cls.","url":"https://huggingface.co/datasets/Mirali33/mb-surface_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFU-C","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C.","url":"https://huggingface.co/datasets/annnli/TOFU-C","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MixBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Awadhi"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cf","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cf.","url":"https://huggingface.co/datasets/annnli/TOFU-Cf","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CUADNoticePeriodToTerminateRenewalLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNoticePeriodToTerminateRenewalLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a notice period required to terminate renewal.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"xlam-function-calling-60k-raw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tXLAM Function Calling 60k Raw Dataset\n\t\n\nThis dataset includes train and test splits derived from Salesforce/xlam-function-calling-60k.\n\nTrain split size: 95% of the original dataset\nTest split size: 5% of the original dataset\n\n","url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","language-modeling","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/IRRISIGHT.","url":"https://huggingface.co/datasets/Nibir/IRRISIGHT","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"twinviews-13k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TwinViews-13k\n\t\n\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k.","url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"CVC","keyword":"monolingual","description":"\nThis repository contains all the data associated with the paper \"CVC: A Large-Scale Chinese Value Rule Corpus for Cultural Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. Weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/CVC.","url":"https://huggingface.co/datasets/Beijing-AISI/CVC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wmdp_bio_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWMDP-Bio Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-bio.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split is preserved.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_bio_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_bio_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-III-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TOFUCrP","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCrP.","url":"https://huggingface.co/datasets/kimperyang/TOFUCrP","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"monolingual","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"code-douanes-mayotte","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des douanes de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Gujarati"],"keywords_longer_than_N":true},
	{"name":"boolq_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBoolQ Bangla (BN) is a question-answering dataset for yes/no questions, generated using GPT-4. The dataset contains 15,942 examples, with each entry consisting of a triplet: (question, passage, answer). The questions are naturally occurring, generated from unprompted and unconstrained settings. Input passages were sourced from Bangla Wikipedia, Banglapedia, and News Articles, and GPT-4 was used to generate corresponding yes/no questions with answers.\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/boolq_bn.","url":"https://huggingface.co/datasets/hishab/boolq_bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsClassification","keyword":"monolingual","description":"\n  SinhalaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsClassification.","url":"https://huggingface.co/datasets/mteb/SinhalaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Category-classification"],"keywords_longer_than_N":true},
	{"name":"EnglishHealthcare1Retrieval-sample","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEnglishHealthcare1Retrieval-sample\n\t\n\nA sample dataset for medical research retrieval evaluation.\n\n\t\n\t\t\n\t\tTask category\n\t\n\nRetrieval\n\n\t\n\t\t\n\t\tDomains\n\t\n\nMedical, Academic\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the standard MTEB retrieval format:\n\ncorpus/corpus-00000-of-00001.parquet: 10 documents with fields _id, title, text\nqueries/queries-00000-of-00001.parquet: 6 queries with fields _id, text  \ndata/test-00000-of-00001.parquet: 6 relevance judgments with fields query-idâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample.","url":"https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample","creator_name":"MTEB Private","creator_url":"https://huggingface.co/mteb-private","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-juridictions-financieres","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des juridictions financiÃ¨res, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"HellaSwag","keyword":"monolingual","description":"\n  HellaSwag\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on HellaSwag.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://rowanzellers.com/hellaswag/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"HellaSwag\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HellaSwag.","url":"https://huggingface.co/datasets/mteb/HellaSwag","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/hellaswag","English"],"keywords_longer_than_N":true},
	{"name":"HW1_Text_Dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TextDataHW1\n\t\n\nThis dataset contains text descriptors of National Collegiate Athletics Association (NCAA) schools and labels for their athletic conference.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original split contains text descriptions of 101 different National Collegiate Athletics Association (NCAA) schools, and are labeled by their athletic conference.\nThe data was augmented, using 303 rows of EDA, 202 rows of character level noise, 303 rowsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emkessle/HW1_Text_Dataset.","url":"https://huggingface.co/datasets/emkessle/HW1_Text_Dataset","creator_name":"Ethan Kessler","creator_url":"https://huggingface.co/emkessle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"escher-ss2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-ss2\n\t\n\nSomethingSomethingv2 dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-ss2","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la LÃ©gion d'honneur, de la MÃ©daille militaire et de l'ordre national du MÃ©rite, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corruptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"copyright_unlearning","keyword":"monolingual","description":"boyiwei/copyright_unlearning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/boyiwei/copyright_unlearning","creator_name":"Boyi Wei","creator_url":"https://huggingface.co/boyiwei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"medium-articles-posts-with-content","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedium Articles Dataset Generator\n\t\n\nThis project combines multiple datasets from Kaggle and Hugging Face to create a comprehensive collection of Medium articles. The combined dataset is available on Hugging Face Hub.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a unique compilation that not only combines multiple sources but also ensures data quality through normalization and deduplication. A key feature is that all entries in the text column are unique - there are no duplicateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content.","url":"https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content","creator_name":"The First","creator_url":"https://huggingface.co/Alaamer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"melange_visual_bbq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMelange Visual Bias Benchmark\n\t\n\nA visual multiple-choice benchmark for evaluating social bias and reasoning in vision-language models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMelange Visual Bias Benchmark is a multimodal extension of the BBQ (Bias Benchmark for Question Answering) dataset, designed to probe social bias and fairness in VLMs (Vision-Language Models). Instead of relying on textual context, this dataset grounds each multiple-choice question in one or more scene images that depict theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDfree/melange_visual_bbq.","url":"https://huggingface.co/datasets/IDfree/melange_visual_bbq","creator_name":"no_ID","creator_url":"https://huggingface.co/IDfree","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","visual-question-answering","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"EstonianValenceClassification","keyword":"monolingual","description":"\n  EstonianValenceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset containing annotated Estonian news data from the Postimees and Ã•htuleht newspapers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferencehttps://figshare.com/articles/dataset/Estonian_Valence_Corpus_Eesti_valentsikorpus/24517054\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EstonianValenceClassification.","url":"https://huggingface.co/datasets/mteb/EstonianValenceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLINoticeOnCompelledDisclosureLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall notify Disclosing Party in case Receiving Party is required by law, regulation or judicial process to disclose any Confidential Information.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PIQA","keyword":"monolingual","description":"\n  PIQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on PIQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/1911.11641\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"PIQA\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PIQA.","url":"https://huggingface.co/datasets/mteb/PIQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/piqa","English"],"keywords_longer_than_N":true},
	{"name":"medotvet-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for medotvet.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,319 medical questions and answers from the Russian website medotvet.ru. It includes questions posed by users seeking medical advice, along with responses provided by doctors across various specialties. The dataset can be analyzed to understand common health concerns among the Russian-speaking population and the types of medical advice provided online.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/medotvet-questions.","url":"https://huggingface.co/datasets/nyuuzyou/medotvet-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"medical_qa","keyword":"monolingual","description":"\n  MedicalQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists 2048 medical question and answer pairs.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MedicalQARetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/medical_qa.","url":"https://huggingface.co/datasets/mteb/medical_qa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"publicdomainfiles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PublicDomainFiles.com Collection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains various public domain media files collected from PublicDomainFiles.com. The website hosts a diverse collection of user-shared content explicitly released into the public domain, including images, fonts, clip art, artwork, video clips, TV shows, and pictures. While images are the predominant file type, the dataset encompasses a wide range of multimedia formats. Each item includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/publicdomainfiles.","url":"https://huggingface.co/datasets/nyuuzyou/publicdomainfiles","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fastfine","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Fastfine.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 13,248 pages of educational content in Russian language extracted from fastfine.ru website. The content includes academic papers, essays and educational materials across various subjects.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fastfine.","url":"https://huggingface.co/datasets/nyuuzyou/fastfine","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"LitSearchRetrieval","keyword":"monolingual","description":"\n  LitSearchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The dataset contains the query set and retrieval corpus for the paper LitSearch: A Retrieval Benchmark for\n    Scientific Literature Search. It introduces LitSearch, a retrieval benchmark comprising 597 realistic literature\n    search queries about recent ML and NLP papers. LitSearch is constructed using a combination of (1) questions\n    generated by GPT-4 based on paragraphs containing inline citations fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LitSearchRetrieval.","url":"https://huggingface.co/datasets/mteb/LitSearchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"ContractNLIReturnOfConfidentialInformationLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIReturnOfConfidentialInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall destroy or return some Confidential Information upon the termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity1LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity1LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 1).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"indonesian-islamic-story-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset 100 Cerita Pendek Islami Bahasa Indonesia\n\t\n\nDataset ini berisi 100 cerita pendek Islami yang ditulis dalam Bahasa Indonesia, dalam format CSV yang terstruktur. Setiap entri mencakup:\n\nJudul cerita\nIsi ringkas cerita\nKategori nilai moral\nPesan moral dari cerita\nPanjang estimasi cerita (jumlah kata)\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“š Kegunaan Dataset\n\t\n\nðŸ•Œ Cocok digunakan untuk:\n\nPengembangan AI berbahasa Indonesia (story generator, chatbot edukasi)\nContent creator (TikTok, YouTube Shortsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ilonks/indonesian-islamic-story-dataset.","url":"https://huggingface.co/datasets/Ilonks/indonesian-islamic-story-dataset","creator_name":"Ilonksrcc","creator_url":"https://huggingface.co/Ilonks","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"monolingual","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","QuoraRetrieval","English"],"keywords_longer_than_N":true},
	{"name":"cybersecurity_alarm_analysis","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Security Alert Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nè¯¥æ•°æ®é›†åŒ…å«å®‰å…¨å‘Šè­¦æ—¥å¿—æ•°æ®ï¼Œç”¨äºŽè®­ç»ƒå¤§æ¨¡åž‹åˆ¤æ–­å®‰å…¨å‘Šè­¦æ˜¯çœŸå®žæ”»å‡»è¿˜æ˜¯è¯¯æŠ¥ã€‚æ•°æ®é›†é‡‡ç”¨Alpacaæ ¼å¼ï¼ŒåŒ…å«instructionã€inputå’Œoutputä¸‰ä¸ªå­—æ®µã€‚\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTask: å®‰å…¨å‘Šè­¦åˆ†ç±»\nTask Type: æ–‡æœ¬åˆ†ç±»\nLanguages: ä¸­æ–‡\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\næ•°æ®é›†ä¸­çš„æ–‡æœ¬ä¸ºä¸­æ–‡ã€‚\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\næ¯ä¸ªæ ·æœ¬åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\ninstruction: ä»»åŠ¡è¯´æ˜Žï¼ŒæŒ‡å¯¼æ¨¡åž‹ä½œä¸ºç½‘ç»œå®‰å…¨å‘Šè­¦åˆ†æžä¸“å®¶åˆ†æžå®‰å…¨å‘Šè­¦æ—¥å¿—\ninput: å‘Šè­¦æ—¥å¿—æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼ŒåŒ…å«å¤šç§å®‰å…¨å‘Šè­¦çš„è¯¦ç»†ä¿¡æ¯\noutput: æ ‡ç­¾ï¼ˆ\"æ”»å‡»\"æˆ–\"è¯¯æŠ¥\"ï¼‰\n\n\n\t\n\t\t\n\t\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis.","url":"https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis","creator_name":"zheng tian","creator_url":"https://huggingface.co/tiangler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DCLM_German","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDCLM German Dataset\n\t\n\nThis dataset contains German language data processed for LLM pretraining, filtered using FastText language detection.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the entire dataset\ndataset = load_dataset(\"faidrap/DCLM_German\")\n\n# Stream for large datasets (recommended)\ndataset = load_dataset(\"faidrap/DCLM_German\", streaming=True)\n\n# Access the data\nfor example in dataset['train']:\n    print(example['text'][:100])  # Print first 100 charsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faidrap/DCLM_German.","url":"https://huggingface.co/datasets/faidrap/DCLM_German","creator_name":"Faidra Patsatzi","creator_url":"https://huggingface.co/faidrap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Assamese"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA","keyword":"monolingual","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HotpotQA","English"],"keywords_longer_than_N":true},
	{"name":"DramaCV","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DramaCV\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DramaCV Dataset is an English-language dataset containing utterances of fictional characters in drama plays collected from Project Gutenberg. The dataset was automatically created by parsing 499 drama plays from the 15th to 20th century on Project Gutenberg, that are then parsed to attribute each character line to its speaker.\n\n\t\n\t\t\n\t\tTask\n\t\n\nThis dataset was developed for Authorship Verification of literary characters. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gasmichel/DramaCV.","url":"https://huggingface.co/datasets/gasmichel/DramaCV","creator_name":"Gaspard Michel","creator_url":"https://huggingface.co/gasmichel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Urdu"],"keywords_longer_than_N":true},
	{"name":"IITU_Safety-Helmet_Dataset_v1.0_Demo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIITU Safety-Helmet Dataset v1.0 Demo\n\t\n\n\n\t\n\t\t\n\t\tOverview:\n\t\n\nThis dataset contains annotated images of safety helmets captured both by drone and at ground level, designed for helmet detection and color classification tasks in computer vision.\nThis is the DEMO version of the dataset, now it contains only 14 images and annotations.\n\n\n\t\n\t\t\n\t\tðŸ“– Dataset Summary\n\t\n\nThis dataset contains 1,664 images annotated for safety-helmet detection and color classification.  \n\n6,473 helmet instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ersace/IITU_Safety-Helmet_Dataset_v1.0_Demo.","url":"https://huggingface.co/datasets/ersace/IITU_Safety-Helmet_Dataset_v1.0_Demo","creator_name":"Ersaiyn","creator_url":"https://huggingface.co/ersace","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","crowdsourced","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"dataset_111-220","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","url":"https://huggingface.co/datasets/hongin9812/dataset_111-220","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"AI_Generated_Ghibli","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAI-Generated Ghibli Images Dataset\n\t\n\nThis repository contains a collection of AI-generated images in the style of Studio Ghibli. These images showcase various subjects, characters, and landscapes rendered in the distinctive artistic style associated with Studio Ghibli animation films.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nNumber of Images: 368 high-quality images\nImage Format: Primarily PNG and JPG files\nResolution: Various resolutions (primarily high resolution)\nGeneration Tools: Createdâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/filberthamijoyo/AI_Generated_Ghibli.","url":"https://huggingface.co/datasets/filberthamijoyo/AI_Generated_Ghibli","creator_name":"Filbert Hamijoyo","creator_url":"https://huggingface.co/filberthamijoyo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","other","multi-class-image-classification","image-captioning","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ravnursson_asr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ravnursson_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus \"RAVNURSSON FAROESE SPEECH AND TRANSCRIPTS\" (or RAVNURSSON Corpus for short) is a collection of speech recordings with transcriptions intended for Automatic Speech Recognition (ASR) applications in the language that is spoken at the Faroe Islands (Faroese). It was curated at the ReykjavÃ­k University (RU) in 2022.\nThe RAVNURSSON Corpus is an extract of the \"Basic Language Resource Kit 1.0\" (BLARK 1.0) [1] developedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr.","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr","creator_name":"Carlos Daniel HernÃ¡ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"GR-I-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"CHARP","keyword":"monolingual","description":"CHARP is a testbed, designed for evaluating supposedly non-hallucinatory models abilities to reason over the conversational history of knowledge-grounded dialogue systems.","url":"https://huggingface.co/datasets/huawei-noah/CHARP","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","dialogue-generation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"eli-why-manually-web-retrieved","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“š ELI-Why Manually Web-Retrieved Explanations\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  Dataset Summary\n\t\n\nThis dataset contains high-quality, manually curated explanations for \"Why\" questions, retrieved from the web to serve as educationally appropriate references.Each explanation is annotated with:\n\nA corresponding question\nA fine-grained topic and domain label (e.g., STEM / Physics)\nThe intended educational level (Elementary, High School, Graduate)\nThe original source URL from which the explanation wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved.","url":"https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-verified","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFEVER","French"],"keywords_longer_than_N":true},
	{"name":"dbpedia","keyword":"monolingual","description":"\n  DBPedia\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/dbpedia.","url":"https://huggingface.co/datasets/mteb/dbpedia","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"medra-medical","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedra Medical Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, provisionally named the \"Medra Medical Reasoning Dataset,\" is a curated and processed collection of various medical question answering, dialogue, and reasoning datasets. It has been specifically formatted to facilitate the training of large language models, such as Gemma 3 (code-named Medra in this project), to improve their medical knowledge, enhance their reasoning capabilities, and enable them toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicoboss/medra-medical.","url":"https://huggingface.co/datasets/nicoboss/medra-medical","creator_name":"Nico Bosshard","creator_url":"https://huggingface.co/nicoboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"code-environnement","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'environnement, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Gujarati"],"keywords_longer_than_N":true},
	{"name":"arxiv_nlp_intstruct","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"arxiv_nlp_intstruct\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"AlgorithmicResearchGroup/arxiv_nlp_intstruct\" dataset consists of question-answer pairs derived from ArXiv abstracts from the cs.CL category\". \nQuestions and answers are generated using GPT-3.5-turbo model\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\ttrain\n\t\n\n\nSize of downloaded dataset files: 38.4 MB\n\nAn example of 'train' looks as follows.\n{\n    \"question\": \"Whatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct.","url":"https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct","creator_name":"Algorithmic Research Group","creator_url":"https://huggingface.co/AlgorithmicResearchGroup","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","masked-language-modeling","no-annotation","monolingual"],"keywords_longer_than_N":true},
	{"name":"clker-images","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Clker.com Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 140,313 public domain clipart images collected from Clker.com. Clker.com hosts user-shared vector clip art that is explicitly released into the public domain (CC0). The dataset includes the images themselves along with metadata such as titles and tags associated with each image.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All image titles and tags are in English.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/clker-images.","url":"https://huggingface.co/datasets/nyuuzyou/clker-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"soloby","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Soloby.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 744,131 question-answer pairs in Russian language extracted from soloby.ru website. The content includes educational questions and answers across various subjects and categories.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\npage_url: URL of the question page (string)\nquestion_title: The questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/soloby.","url":"https://huggingface.co/datasets/nyuuzyou/soloby","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","open-domain-qa","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"monolingual","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"chatgpt-in-russia-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Ñ‡Ð°Ñ‚Ð³Ð¿Ñ‚-Ð²-Ñ€Ð¾ÑÑÐ¸Ð¸.Ñ€Ñ„\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains question-answer pairs collected from Ñ‡Ð°Ñ‚Ð³Ð¿Ñ‚-Ð²-Ñ€Ð¾ÑÑÐ¸Ð¸.Ñ€Ñ„ (meaning in English would be something like chatgpt-in-russia[.]rf), a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 704,208 unique question-answer pairs covering various topics.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa.","url":"https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"jokemachine","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tJokeMachine Dataset\n\t\n\nThe JokeMachine dataset contains short-form comedic responses generated in a stand-up comedy style. Each row consists of a prompt and a response, intended for training language models in humorous text generation.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFields:\n\nprompt: Always \"write a joke\" â€” used as a standard prompt for consistency.\nresponse: The generated joke or humorous response (1+ sentences).\n\n\nSplit:\n\ntrain: All available rows are in the training set.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pawneeranger/jokemachine.","url":"https://huggingface.co/datasets/pawneeranger/jokemachine","creator_name":"pawneeranger","creator_url":"https://huggingface.co/pawneeranger","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","human","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Maithili"],"keywords_longer_than_N":true},
	{"name":"VieQuADRetrieval","keyword":"monolingual","description":"\n  VieQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for evaluating Machine Reading Comprehension from Wikipedia articles.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReferencehttps://aclanthology.org/2020.coling-main.233.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VieQuADRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieQuADRetrieval.","url":"https://huggingface.co/datasets/mteb/VieQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tContextual Text Anonymizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\n\n\t\n\t\t\n\t\tDocument Types\n\t\n\nThe dataset includes examples from the following categories:\n\nMedical records\nBanking documents\nBusiness correspondence\nRecruitment documents\nSocial media content\nLegal documents\nEducationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset.","url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"MichaÅ‚ Kurkowski","creator_url":"https://huggingface.co/kurkowski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","token-classification","named-entity-recognition","text-simplification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-civil","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode civil, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"PHYBench_preprocess_OnlyQuestion","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPHYBench Preprocessed Dataset (Questions Only)\n\t\n\nThis dataset is a preprocessed version of Eureka-Lab/PHYBench, containing only the samples where the final answer was missing in the original data.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original physics problem statement (from the content column).\nanswer: An empty (null) field.\n\nThis dataset can be used for inference or for problems where only the question is required.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\nds =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/daichira/PHYBench_preprocess_OnlyQuestion.","url":"https://huggingface.co/datasets/daichira/PHYBench_preprocess_OnlyQuestion","creator_name":"Tsuji Daichi","creator_url":"https://huggingface.co/daichira","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BACE-V-SMILES-2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBACE Dataset\n\t\n\nThis dataset contains BACE molecule images generated from SMILES strings.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nQuestion: The question associated with the molecule\nAnswer: The answer associated with the molecule\nTargetMolecule: SMILES representation of the molecule\nSampleMethod: Method used for sampling\nSampleNum: Sample number\nSampleRep: Sample representation\nfile_name: The file path to the molecule image\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChemVision/BACE-V-SMILES-2.","url":"https://huggingface.co/datasets/ChemVision/BACE-V-SMILES-2","creator_name":"ChemVisionLanguage","creator_url":"https://huggingface.co/ChemVision","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","monolingual","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Gujarati"],"keywords_longer_than_N":true},
	{"name":"TextQuantificationDatasets","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tAutomated Nonparametric Content Analysis Datasets\n\t\n\nThis repository provides the four benchmark datasets used in:\n\nConnor T. Jerzak, Gary King, and Anton Strezhnev. An Improved Method of Automated Nonparametric Content Analysis for Social Science. Political Analysis, 31(1): 42â€“58, 2023.\n\nEach dataset is formatted for easy loading in Python and R (CSV). Labels are integer-coded from 1,...,K; text is provided as raw strings.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasets\n\t\n\n\n\t\n\t\t\nName\nDocuments\nCategoriesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/TextQuantificationDatasets.","url":"https://huggingface.co/datasets/cjerzak/TextQuantificationDatasets","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"monolingual","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"TriggerIR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“š TriggerIR\n\t\n\nTriggerIR is a synthetic benchmark for testing conceptâ€‘erasure in informationâ€‘retrieval (IR) systems. It contains paired movieâ€‘synopsis documents with and without a sensitive \"trigger\" concept, plus two queries (neutralÂ & explicit) designed to differentiate them. The corpus is entirely machineâ€‘generated so that debiasing experiments can be shared without disclosing real copyrighted text.\n\n\t\n\t\t\n\t\n\t\n\t\tâœ¨ Dataset at a glance\n\t\n\n\n\t\n\t\t\nsplit\ndocuments\npairs\nconcepts\navgâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cwestnedge/TriggerIR.","url":"https://huggingface.co/datasets/cwestnedge/TriggerIR","creator_name":"collins","creator_url":"https://huggingface.co/cwestnedge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"openspaces-depth-aware-32-samples","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOpenSpaces Depth-Aware Visual QA Dataset\n\t\n\nThis is a 32-sample visual question answering (VQA) dataset that includes:\n\nRGB images from the OpenSpaces dataset\nPredicted depth maps generated using Depth Anything\n3 depth-aware QA pairs per image:\nYes/No question (e.g., â€œIs there a person near the door?â€)\nShort answer question (e.g., â€œWhat color is the manâ€™s coat?â€)\nSpatial sorting question (e.g., â€œSort the objects from closest to farthestâ€)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Use\n\t\n\nThis dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/srimoyee12/openspaces-depth-aware-32-samples.","url":"https://huggingface.co/datasets/srimoyee12/openspaces-depth-aware-32-samples","creator_name":"Srimoyee Mukhopadhyay","creator_url":"https://huggingface.co/srimoyee12","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","visual-question-answering","human-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018","keyword":"monolingual","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FiQA2018","English"],"keywords_longer_than_N":true},
	{"name":"GR-I-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent_fr_prompt_intent_classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tamazon_massive_intent_fr_prompt_intent_classification\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\namazon_massive_intent_fr_prompt_intent_classification is a subset of the Dataset of French Prompts (DFP).It contains 555,000 rows that can be used for an intent text classification task.The original data (without prompts) comes from the dataset amazon_massive_intent_fr-FR by FitzGerald et al..\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the sameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification.","url":"https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","amazon_massive_intent"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"HebrewSentimentAnalysis","keyword":"monolingual","description":"\n  HebrewSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israelâ€™s president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder, 2013) to scrape all the comments to all of the presidentâ€™s posts in the period of June â€“ August 2014, the first three months of Rivlinâ€™s presidency.2 While the presidentâ€™s posts aimed at reconcilingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis.","url":"https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCSRetrieval","keyword":"monolingual","description":"\n  NanoSCIDOCSRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/scidocs","English"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-All","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-All.","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-All","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-impositions-biens-services","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des impositions sur les biens et services, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Assamese"],"keywords_longer_than_N":true},
	{"name":"HindiDiscourseClassification","keyword":"monolingual","description":"\n  HindiDiscourseClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Hindi Discourse dataset in Hindi with values for coherence.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nFiction, Social, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.149/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HindiDiscourseClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HindiDiscourseClassification.","url":"https://huggingface.co/datasets/mteb/HindiDiscourseClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"filtered-coyo-700M-beta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for filterred-coyo-700M-beta\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe texts in the COYO-700M dataset consist of English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance in COYO-700M represents single image-text pair information with meta-attributes:\n{\n  'id': 841814333321,\n  'url': 'https://blog.dogsof.com/wp-content/uploads/2021/03/Image-from-iOS-5-e1614711641382.jpg',\n  'text': 'A Pomsky dogâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta.","url":"https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"MaCBench-Ablations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMaCBench-Ablations\n\t\n\n\n\n\n\n\n\n\n\n\nA Chemistry and Materials Benchmark for evaluating Vision Large Language Models\n\n\n\n\n\t\n\t\t\n\t\tâš ï¸ IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tðŸš« THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY ðŸš«\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidate evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/MaCBench-Ablations.","url":"https://huggingface.co/datasets/jablonkagroup/MaCBench-Ablations","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multiple-choice","image-to-text","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"KAIROS_EVAL","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tKAIROS_EVAL Dataset\n\t\n\nPaper: LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions | Code (GitHub)\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKAIROS is a benchmark dataset designed to evaluate the robustness of large language models (LLMs) in multi-agent, socially interactive scenarios. Unlike static QA datasets, KAIROS dynamically constructs evaluation settings for each model by capturing its original belief (answer + confidence) and then simulating peer influence throughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/KAIROS_EVAL.","url":"https://huggingface.co/datasets/declare-lab/KAIROS_EVAL","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","reinforcement-learning","multiple-choice","multiple-choice-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"gretel-financial-risk-analysis-v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated by fine-tuning Phi-3-mini-128k-instruct on 14,306 SEC filings (10-K, 10-Q, and 8-K) from 2023-2024, utilizing differential privacy. It is designed for training models to extract key risk factors and generate structured summaries from financial documents while demonstrating the application of differential privacy to safeguard sensitive information.\nThis dataset showcasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-atmospheric_dust_cls_rdr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-atmospheric_dust_cls_rdr_upd\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-22\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: dusty\n1: not_dusty\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 9817 images\ntest: 5214 images\nval: 4969 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_rdr.","url":"https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_rdr","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PathPal","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Name: Descriptive and Categorized Travel Snippets\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset is a synthetic collection created from 160 different travel-related categories, providing detailed descriptions of accessible adventures and activities. It aims to inspire and inform individuals about opportunities accommodating diverse needs, each entry pairing a detailed description with a category label reflecting the nature of the activity.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nDescriptions:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alternativerealitystudio/PathPal.","url":"https://huggingface.co/datasets/alternativerealitystudio/PathPal","creator_name":"Alternative Reality Studio","creator_url":"https://huggingface.co/alternativerealitystudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"code-collectivites-territoriales","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des collectivitÃ©s territoriales, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Urdu"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iv","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des impÃ´ts, annexe IV, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_det","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-boulder_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 8 splits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mb-boulder_det.","url":"https://huggingface.co/datasets/gremlin97/mb-boulder_det","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-forestier-nouveau","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode forestier (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"texturecan","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TextureCan Textures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,037 texture images from texturecan.com. It includes textures of various materials such as brick, paper, fabric, metal, wood, stone, and other surfaces. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while maintaining good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/texturecan.","url":"https://huggingface.co/datasets/nyuuzyou/texturecan","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"cc0-textures","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CC0 Textures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 18,785 texture images from cc0-textures.com. It includes textures of wood, metal, concrete, fabric, stone, ceramic, and other materials. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while keeping good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): Texture titles and tagsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cc0-textures.","url":"https://huggingface.co/datasets/nyuuzyou/cc0-textures","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","keyword":"monolingual","description":"\n  CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grants one party an â€œenterprise,â€ â€œall you can eatâ€ or unlimited usage license.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BIRCO-DorisMae-Test","keyword":"monolingual","description":"\n  BIRCO-DorisMae\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the DORIS-MAE dataset from BIRCO. This dataset contains 60 queries that are complex research questions from computer scientists. Each query has a candidate pool of approximately 110 abstracts. Relevance is graded from 0 to 2 (scores of 1 and 2 are considered relevant).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"prodiff-model","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProDiff Dataset\n\t\n\nProDiffé¡¹ç›®æ•°æ®é›†ï¼ŒåŒ…å«æ¨¡åž‹æ–‡ä»¶ã€é…ç½®æ–‡ä»¶å’Œç›¸å…³èµ„æºã€‚\n\n\t\n\t\t\n\t\tContents\n\t\n\nThis dataset contains:\n\nModel weights and checkpoints\nConfiguration files\nTraining scripts and utilities\nDocumentation and examples\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nLoading pre-trained ProDiff models\nFine-tuning and transfer learning\nResearch and development\nEducational purposes\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite:\n@dataset{prodiff_dataset,\n  title={ProDiffâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Wuhuwill/prodiff-model.","url":"https://huggingface.co/datasets/Wuhuwill/prodiff-model","creator_name":"Weibing Wang","creator_url":"https://huggingface.co/Wuhuwill","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","monolingual","English","mit","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"LCC_deu_news_1M_bt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\t1M*n backtranslated german news texts using quickMT with hard negatives\n\t\n\nThis still growing experimental project/dataset is not connected, funded or organized in any way by the The Leipzig Corpora Collection. I am very thankful that the main idea behind this collection has been released under CC-BY-4.0 - see Terms of Usage .\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nAt the moment the Leipzig Corpora Collention has many raw monolingual corpora transparently documented and available for downloads sinceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"BC-II-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Medical_Prescription_Handwritten_Words","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical Prescription Handwritten Words\n\t\n\nThis dataset contains images of individual handwritten medical words extracted from prescription notes. It is designed for training and evaluating handwriting recognition models in the healthcare domain.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nimages/: Contains 40+ handwritten word images (e.g., Amoxicillin.png, Cold.png, Tablet.png, 0.png, etc.)\ndata.csv: Maps each image file to its corresponding label (word)\n\n\n\t\n\t\t\n\t\tExample Use Cases\n\t\n\n\nOCR (Opticalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avi-kai/Medical_Prescription_Handwritten_Words.","url":"https://huggingface.co/datasets/avi-kai/Medical_Prescription_Handwritten_Words","creator_name":"Avaneesh Karthikeyan Iyer","creator_url":"https://huggingface.co/avi-kai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"DKHateClassification","keyword":"monolingual","description":"\n  DKHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Tweets annotated for Hate Speech either being Offensive or not\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.430/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"DKHateClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DKHateClassification.","url":"https://huggingface.co/datasets/mteb/DKHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoClimateFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoClimateFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoClimateFEVER","French"],"keywords_longer_than_N":true},
	{"name":"code-energie","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'Ã©nergie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"promptoxicity","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":falseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GioApc/promptoxicity.","url":"https://huggingface.co/datasets/GioApc/promptoxicity","creator_name":"Aparecido O","creator_url":"https://huggingface.co/GioApc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","original","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DOID","keyword":"monolingual","description":"This dataset is a collection of Mixed-hop Prediction datasets created from DOID's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/DOID","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 137830\nFiltered size: 42607\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"SwednClusteringP2P","keyword":"monolingual","description":"\n  SwednClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure. This dataset uses the category labels as clusters.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/swedn\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwednClusteringP2P.","url":"https://huggingface.co/datasets/mteb/SwednClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","sbx/superlim-2","Swedish"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gis","keyword":"monolingual","description":"\n  CQADupstackGisRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGisRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gis.","url":"https://huggingface.co/datasets/mteb/cqadupstack-gis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-3_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•3ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-3_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"vep_complex_traits_chr1_split","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_complex_traits_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_complex_traits_chr1_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_complex_traits_chr1_splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/vep_complex_traits_chr1_split.","url":"https://huggingface.co/datasets/Bgoood/vep_complex_traits_chr1_split","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"allenai-prosocial-dialog","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProsocialDialog ShareGPT Format\n\t\n\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog.","url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","crowdsourced","machine-generated","monolingual","allenai/prosocial-dialog"],"keywords_longer_than_N":true},
	{"name":"CSMD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Continuous Scale Meaning Dataset\" (CSMD)\n\t\n\nCSMD was created for MeaningBERT: Assessing Meaning Preservation Between Sentences.\nIt contains 1,355 English text simplification meaning preservation annotations. Meaning preservation measures how well the meaning of the output text corresponds to the meaning of the source (Saggion, 2017).\nThe annotations were taken from the following four datasets: \n\nASSET\nQuestEVal,\nSimpDa_2022 and,\nSimplicity-DA.\n\nIt contains a dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davebulaval/CSMD.","url":"https://huggingface.co/datasets/davebulaval/CSMD","creator_name":"David","creator_url":"https://huggingface.co/davebulaval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","monolingual","aligned","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"code-tourisme","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du tourisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"fishkinet-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Fishki.net\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Fishki.net, a Russian entertainment and news website. Each entry in the dataset represents a post from the website, including its title, content, author, publication date, tags, images, and URL. The dataset contains 369,180 unique posts covering various topics in entertainment, news, and social media content.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fishkinet-posts.","url":"https://huggingface.co/datasets/nyuuzyou/fishkinet-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","image-classification","summarization","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"author_profiling","keyword":"monolingual","description":"he corpus for the author profiling analysis contains texts in Russian-language which labeled for 5 tasks:\n1) gender -- 13530 texts with the labels, who wrote this: text female or male;\n2) age -- 13530 texts with the labels, how old the person who wrote the text. This is a number from 12 to 80. In addition, for the classification task we added 5 age groups: 1-19; 20-29; 30-39; 40-49; 50+;\n3) age imitation -- 7574 texts, where crowdsource authors is asked to write three texts: \n  a) in their natural manner, \n  b) imitating the style of someone younger, \n  c) imitating the style of someone older;\n4) gender imitation -- 5956 texts, where the crowdsource authors is asked to write texts: in their origin gender and pretending to be the opposite gender;\n5) style imitation -- 5956 texts, where crowdsource authors is asked to write a text on behalf of another person of your own gender, with a distortion of the authors usual style.","url":"https://huggingface.co/datasets/sagteam/author_profiling","creator_name":"AI technology lab at NRC \"Kurchatov Institute\"","creator_url":"https://huggingface.co/sagteam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"nli_zh","keyword":"monolingual","description":"çº¯æ–‡æœ¬æ•°æ®ï¼Œæ ¼å¼ï¼šï¼ˆsentence1ï¼Œ sentence2ï¼Œ labelï¼‰ã€‚å¸¸è§ä¸­æ–‡è¯­ä¹‰åŒ¹é…æ•°æ®é›†ï¼ŒåŒ…å«ATECã€BQã€LCQMCã€PAWSXã€STS-Bå…±5ä¸ªä»»åŠ¡ã€‚","url":"https://huggingface.co/datasets/shibing624/nli_zh","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"laion-high-resolution-chinese","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tlaion-high-resolution-chinese\n\t\n\n\n\t\n\t\t\n\t\tç®€ä»‹ Brief Introduction\n\t\n\nå–è‡ªLaion5B-high-resolutionå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±2.66Mä¸ªå›¾æ–‡å¯¹ã€‚\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\n\t\n\nå¤§çº¦ä¸€å…±2.66Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨381MBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\n\nHomepage: laion-5b\nHuggingface: laion/laion-high-resolution\n\n\n\t\n\t\t\n\t\tä¸‹è½½ Download\n\t\n\nmkdir release && cd release\nfor i in {00000..00015}; do wgetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese.","url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"hacker_news_with_comments","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHacker news until 2015 with comments. Collect from Google BigQuery open dataset. We didn't do any pre-processing except remove HTML tags.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nComment Generation; News analysis with comments; Other comment-based NLP tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Linkseed/hacker_news_with_comments.","url":"https://huggingface.co/datasets/Linkseed/hacker_news_with_comments","creator_name":"KunLi","creator_url":"https://huggingface.co/Linkseed","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"WSDMCup2023","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for WSDMCup2023\n\t\n\n\n\t\n\t\t\nQuestion\nImage and Answer\n\n\n\t\t\nWhat do you use to hit the ball?\n\n\n\nWhat do people use for cutting?\n\n\n\nWhat do we use to support the immune system and get vitamin C?\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WSDMCup2023 Dataset consists of images associated with textual questions.\nOne entry (instance) in our dataset is a question-image pair labeled with the ground truth coordinates of a bounding box containing\nthe visual answer to the given question. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/toloka/WSDMCup2023.","url":"https://huggingface.co/datasets/toloka/WSDMCup2023","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Source-classification","keyword":"monolingual","description":"This dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK,\nNewsfirst, World Socialist Web Site-Sinhala). This is a processed version of the corpus created by Sachintha, D., Piyarathna, L., Rajitha, C., and Ranathunga, S. (2021). Exploiting parallel corpora to improve multilingual embedding based document and sentence alignment. Single word sentences, invalid characters have been removed from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"financial_news_sentiment","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"financial_news_sentiment\"\n\t\n\nManually validated sentiment for ~2000 Canadian news articles.\nThe dataset also include a column topic which contains one of the following value:\n\nacquisition\nother\nquaterly financial release\nappointment to new position\ndividend\ncorporate update\ndrillings results\nconference\nshare repurchase program\ngrant of stocks\n\nThis was generated automatically using a zero-shot classification model and was not reviewed manually.\n","url":"https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment","creator_name":"JB Polle","creator_url":"https://huggingface.co/Jean-Baptiste","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NewQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badokorach/NewQA.","url":"https://huggingface.co/datasets/badokorach/NewQA","creator_name":"brenda Adokorach","creator_url":"https://huggingface.co/badokorach","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"WikiConvert","keyword":"monolingual","description":"Language Modelling with Cardinal Number Annotations.","url":"https://huggingface.co/datasets/usc-isi/WikiConvert","creator_name":"USC Information Sciences Institute","creator_url":"https://huggingface.co/usc-isi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","text-generation","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"fashion-captions-de","keyword":"monolingual","description":"\n\n\n\n\n\n\nThe data offered by Jina AI, Finetuner team.\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is a German-language dataset based on the Fashion12K dataset, which originally contains both English and German text descriptions for each item.\nThis dataset was used to to finetuner CLIP using the Finetuner tool.\n\n\t\n\t\t\n\t\tFine-tuning\n\t\n\nPlease refer to our documentation: Multilingual Text-to-Image Search with MultilingualCLIP\nand blog Improving Search Quality for Non-English Queries with Fine-tunedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/fashion-captions-de.","url":"https://huggingface.co/datasets/jinaai/fashion-captions-de","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","monolingual","original","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"news_sentiment_newsmtsc","keyword":"monolingual","description":"NewsMTSC: A large, manually annotated dataset for target-dependent sentiment classification in English news articles.","url":"https://huggingface.co/datasets/fhamborg/news_sentiment_newsmtsc","creator_name":"Felix Hamborg","creator_url":"https://huggingface.co/fhamborg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"cifar100-lt","keyword":"monolingual","description":"The CIFAR-100-LT dataset is comprised of under 60,000 color images, each measuring 32x32 pixels, \ndistributed across 100 distinct classes. \nThe number of samples within each class decreases exponentially with factors of 10, 20, 50, 100, or 200. \nThe dataset includes 10,000 test images, with 100 images per class, \nand fewer than 50,000 training images. \nThese 100 classes are further organized into 20 overarching superclasses. \nEach image is assigned two labels: a fine label denoting the specific class, \nand a coarse label representing the associated superclass.","url":"https://huggingface.co/datasets/tomas-gajarsky/cifar100-lt","creator_name":"Tomas Gajarsky","creator_url":"https://huggingface.co/tomas-gajarsky","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","crowdsourced","found","monolingual","cifar100"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster20","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster20","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster-noise","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster-noise","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"Piyyut","keyword":"monolingual","description":"","url":"https://huggingface.co/datasets/tokeron/Piyyut","creator_name":"Michael Toker","creator_url":"https://huggingface.co/tokeron","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","original","Hebrew","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster06","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster06","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"github_python_1m","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Github Python 1M\n\t\n\n","url":"https://huggingface.co/datasets/formermagic/github_python_1m","creator_name":"Former Magic Inc.","creator_url":"https://huggingface.co/formermagic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["language-modeling","slot-filling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"spectrogram-captions","keyword":"monolingual","description":"Dataset of captioned spectrograms (text describing the sound).\n","url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim VuÄina","creator_url":"https://huggingface.co/vucinatim","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","machine-generated","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"hatecheck-polish","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish.","url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FLUTE","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FigLang2022SharedTask\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nModel in the loop approach for fig lang generation and explainability\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ColumbiaNLP/FLUTE.","url":"https://huggingface.co/datasets/ColumbiaNLP/FLUTE","creator_name":"Columbia University NLP Group","creator_url":"https://huggingface.co/ColumbiaNLP","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","explanation-generation","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sample1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for RedCaps\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nPath /home/daniel.baek/public/common/Data\nContent type image\nTag sensor, common, ai, dataset\nDescription \nHomepage: RedCaps homepage\nRepository: RedCaps repository\nPaper: RedCaps: web-curated image-text data created by the people, for the people\nLeaderboard:\nPoint of Contact: Karan Desai\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nRedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\nImages and captions fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/actdan2016/sample1.","url":"https://huggingface.co/datasets/actdan2016/sample1","creator_name":"danana","creator_url":"https://huggingface.co/actdan2016","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-to-text","image-captioning","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster18","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster18","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stevhliu/demo.","url":"https://huggingface.co/datasets/stevhliu/demo","creator_name":"Steven Liu","creator_url":"https://huggingface.co/stevhliu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"monash_tsf","keyword":"monolingual","description":"Monash Time Series Forecasting Repository which contains 30+ datasets of related time series for global forecasting research. This repository includes both real-world and competition time series datasets covering varied domains.","url":"https://huggingface.co/datasets/Monash-University/monash_tsf","creator_name":"Monash University","creator_url":"https://huggingface.co/Monash-University","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["time-series-forecasting","univariate-time-series-forecasting","multivariate-time-series-forecasting","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"OV_Text","keyword":"monolingual","description":"OVText","url":"https://huggingface.co/datasets/duyhngoc/OV_Text","creator_name":"Duy Huynh","creator_url":"https://huggingface.co/duyhngoc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","no-annotation","monolingual","Vietnamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"echr_rational","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for echr_rational\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDeconfounding Legal Judgment Prediction for European Court of Human\nRights Cases Towards Better Alignment with Experts\nThis work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identifyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TUMLegalTech/echr_rational.","url":"https://huggingface.co/datasets/TUMLegalTech/echr_rational","creator_name":"TUMLegalTech","creator_url":"https://huggingface.co/TUMLegalTech","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","English","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"negation-dataset","keyword":"monolingual","description":"\n\n\n\n\n\n\nThe data offered by Jina AI, Finetuner team.\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is an English-language dataset based on the SNLI dataset.\nIt contains negations of samples from SNLI.\n\n\t\n\t\t\n\t\tInstances\n\t\n\nEach data point consists of a triplet ('anchor', 'entailment', 'negative') of strings, where ('anchor', 'entailment') are positive pairs\ntaken from SNLI, and 'negative' contradicts  both 'anchor' and 'entailment'.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\n'anchor': string, some statement\n'entailment': string, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/negation-dataset.","url":"https://huggingface.co/datasets/jinaai/negation-dataset","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"qa_squadshifts_synthetic","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"lmqg/qa_squadshifts_synthetic\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a synthetic QA dataset generated with fine-tuned QG models over lmqg/qa_squadshifts, made for question-answering based evaluation (QAE) for question generation model proposed by Zhang and Bansal, 2019.\nThe test split is the original validation set of lmqg/qa_squadshifts, where the model should be evaluate on.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nquestion-answering\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic.","url":"https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"edgar-corpus","keyword":"monolingual","description":"The dataset contains annual filings (10K) of all publicly traded firms from 1993-2020. The table data is stripped but all text is retained.\nThis dataset allows easy access to the EDGAR-CORPUS dataset based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round (See References in README.md for details).","url":"https://huggingface.co/datasets/eloukas/edgar-corpus","creator_name":"Lefteris Loukas","creator_url":"https://huggingface.co/eloukas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","other","monolingual","extended|other"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_human_sent","keyword":"monolingual","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"NLQuAD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"NLQuAD\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a copy of the original NLQuAD dataset distributed via Github.\nNLQuAD is a non-factoid long question answering dataset from BBC news articles.\nNLQuADâ€™s question types and the long length of its context documents as well as answers, make it a challenging real-world task.\nNLQuAD consists of news articles as context documents, interrogative sub-headings in the articles as questions, and body paragraphs corresponding to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLukas22/NLQuAD.","url":"https://huggingface.co/datasets/LLukas22/NLQuAD","creator_name":"Lukas Kreussel","creator_url":"https://huggingface.co/LLukas22","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["extractive-qa","monolingual","English","cc-by-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"test-dataset","keyword":"monolingual","description":"The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\nimages per class. There are 60,000 training images and 10,000 test images.","url":"https://huggingface.co/datasets/mqddb/test-dataset","creator_name":"qiangddb","creator_url":"https://huggingface.co/mqddb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"the-reddit-dataset-dataset","keyword":"monolingual","description":"A meta dataset of Reddit's own /r/datasets community.","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-dataset-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"annotated_reference_strings","keyword":"monolingual","description":"A repository of reference strings annotated using CSL processor using citations obtained from various sources.","url":"https://huggingface.co/datasets/yuanchuan/annotated_reference_strings","creator_name":"Yuan Chuan Kee","creator_url":"https://huggingface.co/yuanchuan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","other","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated","keyword":"monolingual","description":"Using Google Translation, we have translated SQuAD 2.0 dataset into multiple languages. \nHere is the translated dataset of SQuAD 2.0 in French language.\nShared by Pragnakalp Techlabs\n","url":"https://huggingface.co/datasets/pragnakalp/squad_v2_french_translated","creator_name":"Pragnakalp Techlabs","creator_url":"https://huggingface.co/pragnakalp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","translation","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"model-written-evals","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tModel-Written Evaluation Datasets\n\t\n\nThis repository includes datasets written by language models, used in our paper on \"Discovering Language Model Behaviors with Model-Written Evaluations.\"\nWe intend the datasets to be useful to:\n\nThose who are interested in understanding the quality and properties of model-generated data\nThose who wish to use our datasets to evaluate other models for the behaviors we examined in our work (e.g., related to model persona, sycophancy, advanced AI risksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anthropic/model-written-evals.","url":"https://huggingface.co/datasets/Anthropic/model-written-evals","creator_name":"Anthropic","creator_url":"https://huggingface.co/Anthropic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","zero-shot-classification","question-answering","multiple-choice-qa","multiple-choice-coreference-resolution"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster28","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster28","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"ShahNegar","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tShahNegar (A Plotted version of The Shahnameh)\n\t\n\nThis dataset is a plotted version of Ferdowsi's Shahnameh (which is a highly-regarded ancient set of Farsi poems) generated using DALL-E mini (aka craiyon). You can use this dataset using the code below: \nfrom datasets import load_dataset\n\ndataset = load_dataset(\"sadrasabouri/ShahNegar\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset contains more than 30K images with their corresponding text from the Shahnameh. For each Shahnamehâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sadrasabouri/ShahNegar.","url":"https://huggingface.co/datasets/sadrasabouri/ShahNegar","creator_name":"Sadra Sabouri","creator_url":"https://huggingface.co/sadrasabouri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-captioning","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"opendict-korean-proverb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tí•œêµ­ì–´ ì†ë‹´ ëª¨ìŒ v1.0\n\t\n\nêµ­ë¦½êµ­ì–´ì› ìš°ë¦¬ë§ìƒ˜ì˜ ì†ë‹´ì„ ì •ì œí•´ ë§Œë“  ë°ì´í„°ìž…ë‹ˆë‹¤.\n\ní˜„ëŒ€ì— ë§žì§€ ì•ŠëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ì†ë‹´ ì‚­ì œ\nê´„í˜¸ë¡œ í‘œí˜„ëœ ë³€í˜• ì‚­ì œ\nì¤‘ë³µë‚´ìš© í†µí•©\n\n\n\t\n\t\t\n\t\tì›ë³¸ ë°ì´í„° ë°›ê¸°\n\t\n\nìš°ë¦¬ë§ìƒ˜ì—ì„œ ì†ë‹´ì˜ í•´ì„¤ì„ í¬í•¨í•œ ì›ë³¸ë°ì´í„°ë¥¼ ë‹¤ìš´ë°›ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n\nêµ­ë¦½êµ­ì–´ì› ëˆ„ë¦¬ì§‘ ì‚¬ì „ì— ì‹¤ë ¤ ìžˆëŠ” ì†ë‹´ì„ 'ìžì„¸ížˆ ì°¾ê¸°' ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì†ë‹´ì´ ë” ë§Žì´ ì‹¤ë ¤ ìžˆëŠ” ì‚¬ì „-ìš°ë¦¬ë§ìƒ˜ì˜ 'ìžì„¸ížˆ ì°¾ê¸°'ë¡œ ë“¤ì–´ê°€ì…”ì„œ 'ì†ë‹´'ì„ ì„ íƒí•˜ì‹œë©´ ì‚¬ì „ì—  ì‹¤ë ¤ ìžˆëŠ” ëª¨ë“  ì†ë‹´ì˜ ëª©ë¡ì´ ë‚˜ì˜µë‹ˆë‹¤.\nhttps://opendict.korean.go.kr/\n\nìš°ë¦¬ë§ìƒ˜ì˜ ì„œë¹„ìŠ¤ ì´ìš© ì•½ê´€ì— ë”°ë¥´ë©´\n\nâ€˜í¬ë¦¬ì—ì´í‹°ë¸Œ ì»¤ë¨¼ì¦ˆ ì €ìž‘ìž í‘œì‹œ-ë™ì¼ì¡°ê±´ë³€ê²½í—ˆë½2.0 ëŒ€í•œë¯¼êµ­ ë¼ì´ì„ ìŠ¤â€™ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\nìƒì—…ì  ìš©ë„ê¹Œì§€ í¬í•¨í•˜ì—¬ ëˆ„êµ¬ë‚˜ ìžìœ ë¡­ê²Œ ì´ìš©í•  ìˆ˜ ìžˆìœ¼ë©° ì €ìž‘ìžì˜ íŠ¹ë³„í•œ í—ˆê°€ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\nì €ìž‘ë¬¼ì„ ì´ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒì˜ ì¡°ê±´ì„ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.\nì €ìž‘ìžâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mansiksohn/opendict-korean-proverb.","url":"https://huggingface.co/datasets/mansiksohn/opendict-korean-proverb","creator_name":"mansiksohn","creator_url":"https://huggingface.co/mansiksohn","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_en-wikipedia-org","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_en-wikipedia-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"hatecheck-italian","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian.","url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-high","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-high","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster01","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster01","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"aihub_corpus_expertise","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"corpus_professional_field\"\n\t\n\nì „ë¬¸ë¶„ì•¼ ë§ë­‰ì¹˜\n","url":"https://huggingface.co/datasets/wisenut-nlp-team/aihub_corpus_expertise","creator_name":"wisenut-nlp","creator_url":"https://huggingface.co/wisenut-nlp-team","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","token-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"twitter-financial-news-sentiment","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their sentiment.\n\nThe dataset holds 11,932 documents annotated with 3 labels:\n\nsentiments = {\n    \"LABEL_0\": \"Bearish\", \n    \"LABEL_1\": \"Bullish\", \n    \"LABEL_2\": \"Neutral\"\n}  \n\nThe data was collected using the Twitter API. The current dataset supports the multi-class classificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment.","url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cais/mmlu.","url":"https://huggingface.co/datasets/cais/mmlu","creator_name":"Center for AI Safety","creator_url":"https://huggingface.co/cais","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"samromur_synthetic","keyword":"monolingual","description":"SamrÃ³mur Synthetic consists of 72 hours of synthetized speech in Icelandic.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuringBench","keyword":"monolingual","description":"This benchmark environment contains a dataset comprised of generated texts from pre-trained language models.\nWe also have two benchmark tasks - human vs. machine (i.e., binary classification) and authorship\nattribution (i.e., multi-class classification). These benchmark tasks and dataset are hosted on the\nTuringBench website with Leaderboards for each task.","url":"https://huggingface.co/datasets/turingbench/TuringBench","creator_name":"Turing Bench","creator_url":"https://huggingface.co/turingbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","found","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tinyTruthfulQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttinyTruthfulQA\n\t\n\nWelcome to tinyTruthfulQA! This dataset serves as a concise version of the truthfulQA dataset, offering a subset of 100 data points selected from the original compilation. \ntinyTruthfulQA is designed to enable users to efficiently estimate the performance of a large language model (LLM) with reduced dataset size, saving computational resources \nwhile maintaining the essence of the truthfulQA evaluation.\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nCompact Dataset: With only 100 dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA.","url":"https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA","creator_name":"tinyBenchmarks","creator_url":"https://huggingface.co/tinyBenchmarks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"kor_duorc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for duorc\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nMIT License\n\n\t\n\t\t\n\t\tSource Data Citation Information\n\t\n\n@inproceedings{DuoRC,\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\ntitle = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\nyear = {2018}\n}\n\n","url":"https://huggingface.co/datasets/KETI-AIR/kor_duorc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","abstractive-qa","extractive-qa","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"harem","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HAREM\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem.","url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"RÃºben Almeida","creator_url":"https://huggingface.co/arubenruben","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KOTOX-classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tKOTOX\n\t\n\n\n\t\n\t\t\n\t\t: A Korean Toxic Dataset for Deobfuscation and Detoxification\n\t\n\nHate Speech Detection dataset ðŸ‘‰ Here!Detoxification or Sanitization dataset ðŸ‘‰ KOTOX  \nðŸ“š paper | \nðŸˆâ€â¬› git\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nKOTOX is the first Korean dataset designed for both toxic text detoxification and obfuscation robustness.   \nIt provides paired neutral-toxic sentences and their obfuscated counterparts, constructed with 17 linguistically grounded transformation rules reflecting theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ssgyejin/KOTOX-classification.","url":"https://huggingface.co/datasets/ssgyejin/KOTOX-classification","creator_name":"leeyejin","creator_url":"https://huggingface.co/ssgyejin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","rule-based","llm-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"clothes_desc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for H&M Clothes captions\n\t\n\n_Dataset used to train/finetune [Clothes text to image model]\nCaptions are generated by using the 'detail_desc' and 'colour_group_name' or 'perceived_colour_master_name' from kaggle/competitions/h-and-m-personalized-fashion-recommendations. Original images were also obtained from the url (https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data?select=images)\n\n\t\n\t\n\t\n\t\tFor each row the dataset contains image and textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wbensvage/clothes_desc.","url":"https://huggingface.co/datasets/wbensvage/clothes_desc","creator_name":"Wolfgang Bensvage","creator_url":"https://huggingface.co/wbensvage","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","human generated by using detail_desc and color","other","monolingual","www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations"],"keywords_longer_than_N":true},
	{"name":"laion-aesthetics-12m-umap","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLAION-Aesthetics :: CLIP â†’ UMAP\n\t\n\nThis dataset is a CLIP (text) â†’ UMAP embedding of the LAION-Aesthetics dataset - specifically the improved_aesthetics_6plus version, which filters the full dataset to images with scores of > 6 under the \"aesthetic\" filtering model.\nThanks LAION for this amazing corpus!\n\nThe dataset here includes coordinates for 3x separate UMAP fits using different values for the n_neighbors parameter - 10, 30, and 60 - which are broken out as separate columns withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap.","url":"https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap","creator_name":"David McClure","creator_url":"https://huggingface.co/dclure","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","English","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"rixvox","keyword":"monolingual","description":"RixVox is a speech dataset comprised of speeches from the Swedish Parliament (the Riksdag). Audio from speeches have been aligned with official transcripts, on the sentence level, using aeneas. \nSpeaker metadata is available for each observation, including the speaker's name, gender, party, birth year and electoral district. The dataset contains a total of 5493 hours of speech. \nAn observation may consist of one or several sentences (up to 30 seconds in duration).","url":"https://huggingface.co/datasets/KBLab/rixvox","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Swedish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"recycling-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for recycling-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a recycling dataset that can be used for image classification. It has 11 categories:\n\naluminium\nbatteries\ncardboard\ndisposable plates\nglass\nhard plastic\npaper\npaper towel\npolystyrene\nsoft plastics\ntakeaway cups\n\nIt was scrapped from DuckDuckGo using this tool: https://pypi.org/project/jmd-imagescraper/\n","url":"https://huggingface.co/datasets/viola77data/recycling-dataset","creator_name":"viola meli","creator_url":"https://huggingface.co/viola77data","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"blogspot_raw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for blogspot raw dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of raw blogposts from blogspot mostly in the English language. It was obtained by scraping corpora of webarchive and commoncrawl.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset may be used for training language models or serve other research interests.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMostly English language, but some outliers may occur.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDistribution\nThe distributionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mschi/blogspot_raw.","url":"https://huggingface.co/datasets/mschi/blogspot_raw","creator_name":"Martin Schirmer","creator_url":"https://huggingface.co/mschi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","time-series-forecasting","other"],"keywords_longer_than_N":true},
	{"name":"news-title-gen","keyword":"monolingual","description":"This dataset is built for generating text for news title.","url":"https://huggingface.co/datasets/jakartaresearch/news-title-gen","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"soda_jp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ðŸ¥¤SODA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authoredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HayatoHongo/soda_jp.","url":"https://huggingface.co/datasets/HayatoHongo/soda_jp","creator_name":"Hayato Hongo","creator_url":"https://huggingface.co/HayatoHongo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["dialogue-generation","machine-generated","monolingual","original","extended|Atomic10x"],"keywords_longer_than_N":true},
	{"name":"kinopoisk","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKinopoisk movie reviews dataset (TOP250 & BOTTOM100 rank lists).\nIn total it contains 36,591 reviews from July 2004 to November 2012.\nWith following distribution along the 3-point sentiment scale:\n\nGood: 27,264;\nBad: 4,751;\nNeutral: 4,576.\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach sample contains the following fields:\n\npart: rank list top250 or bottom100;\nmovie_name;\nreview_id;\nauthor: review author;\ndate: date of a review;\ntitle: review title;\ngrade3: sentiment score Good, Badâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/blinoff/kinopoisk.","url":"https://huggingface.co/datasets/blinoff/kinopoisk","creator_name":"Pavel Blinov","creator_url":"https://huggingface.co/blinoff","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","monolingual","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"FOCAL","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFunction Of Citation in Astrophysics Literature (FOCAL): Dataset and Task\n\t\n\nCan you explain why the authors made a given citation?\nThis dataset was created as a shared task for WIESP @ AACL-IJCNLP 2023.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDatasets are in JSON Lines format (each line is a json dictionary).  \nEach entry consists of a dictionary with the following keys:\n\n\"Identifier\": unique string to identify the entry\n\"Paragraph\": text string from an astrophysics paper \n\"Citation Text\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/FOCAL.","url":"https://huggingface.co/datasets/adsabs/FOCAL","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_easy_dummy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Easy set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR methodâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"WIESP2022-NER","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset for the first Workshop on Information Extraction from Scientific Publications (WIESP/2022).\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDatasets with text fragments from astrophysics papers, provided by the NASA Astrophysical Data System with manually tagged astronomical facilities and other entities of interest (e.g., celestial objects).Datasets are in JSON Lines format (each line is a json dictionary).The datasets are formatted similarly to the CONLL2003 format. Each token isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/WIESP2022-NER.","url":"https://huggingface.co/datasets/adsabs/WIESP2022-NER","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"weibo16","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"the-reddit-nft-dataset","keyword":"monolingual","description":"A comprehensive dataset of Reddit's NFT discussion.","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-nft-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"qg_subjqa","keyword":"monolingual","description":"[SubjQA](https://github.com/megagonlabs/SubjQA) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_subjqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","subjqa","English"],"keywords_longer_than_N":true},
	{"name":"DiPCo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDipCo - Dinner Party Corpus, Interspeech 2020\n\t\n\n\nPlease consider to use Zenodo Data Backup Link to Download Audio: https://zenodo.org/record/8122551\n\nPaper: https://www.isca-speech.org/archive/interspeech_2020/segbroeck20_interspeech.html\n\n\nAuthor(s):\n\nVan Segbroeck, Maarten; Zaid, Ahmed; Kutsenko, Ksenia; Huerta, Cirenia; Nguyen, Tinh; Luo, Xuewen; Hoffmeister, BjÃ¶rn; Trmal, Jan; Omologo, Maurizio; Maas, Roland\n\n\nContact person(s):\n\nMaas, Roland; Hoffmeister, BjÃ¶rn\n\n\nDistributor(s):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huckiyang/DiPCo.","url":"https://huggingface.co/datasets/huckiyang/DiPCo","creator_name":"Huck Yang","creator_url":"https://huggingface.co/huckiyang","license_name":"Community Data License Agreement Permissive 1.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"snap21","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/kuroneko5943/snap21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"AROFlickrOrder","keyword":"monolingual","description":"\n  AROFlickrOrder\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCompositionality Evaluation of images to their captions.Each capation has four hard negatives created by order permutations.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\ni2t\n\n\nDomains\nEncyclopaedic\n\nReference\nhttps://openreview.net/forum?id=KRLUvxh8uaX\n\n\n\t\n\nSource datasets:\n\ngowitheflow/ARO-Flickr-Order\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AROFlickrOrder.","url":"https://huggingface.co/datasets/mteb/AROFlickrOrder","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","image-to-text","text-to-image","image-captioning","expert-annotated"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"monolingual","description":"ï·½\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ThaiSum\n\t\n\nThis dataset was forked from thaisum to HF hub.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath, ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs written by journalists.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nsummarization, language modeling\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaisum.","url":"https://huggingface.co/datasets/pythainlp/thaisum","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"synthetic-instruct-gptj-pairwise-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"synthetic-instruct-gptj-pairwise-ru\"\n\t\n\nThis is translated version of Dahoas/synthetic-instruct-gptj-pairwise dataset into Russian.\n","url":"https://huggingface.co/datasets/d0rj/synthetic-instruct-gptj-pairwise-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translated","monolingual","Dahoas/synthetic-instruct-gptj-pairwise","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"turkish-offensive-language-detection","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is enhanced version of existing offensive language studies. Existing studies are highly imbalanced, and solving this problem is too costly. To solve this, we proposed contextual data mining method for dataset augmentation. Our method is basically prevent us from retrieving random tweets and label individually. We can directly access almost exact hate related tweets and label them directly without any further human interaction in order to solve imbalancedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Toygar/turkish-offensive-language-detection.","url":"https://huggingface.co/datasets/Toygar/turkish-offensive-language-detection","creator_name":"Toygar Tanyel","creator_url":"https://huggingface.co/Toygar","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"indonlu","keyword":"monolingual","description":"The IndoNLU benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems for Bahasa Indonesia.","url":"https://huggingface.co/datasets/indonlp/indonlu","creator_name":"IndoNLP","creator_url":"https://huggingface.co/indonlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-classification","token-classification","closed-domain-qa","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"sharegpt_gpt4","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShareGPTä¸­æŒ‘é€‰å‡ºçš„GPT4å¤šè½®é—®ç­”æ•°æ®ï¼Œå¤šè¯­è¨€é—®ç­”ã€‚\n\n\t\n\t\t\n\t\tLanguages\n\t\n\næ•°æ®é›†æ˜¯å¤šè¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ç­‰å¸¸ç”¨è¯­è¨€ã€‚\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all splits.\n\nconversations: a List of string .\n\nhead -n 1 sharegpt_gpt4.jsonl\n\n{\"conversations\":[\n  {'from': 'human',\n   'value': 'æŽ¡ç”¨å„ªé›…ç¾ä»£ä¸­æ–‡ï¼Œç”¨ä¸­æ–‡ç¹é«”å­—åž‹ï¼Œå›žç­”ä»¥ä¸‹å•é¡Œã€‚ç‚ºæ‰€æœ‰æ¨™é¡Œæˆ–å°ˆç”¨å­—è©žæä¾›å°æ‡‰çš„è‹±èªžç¿»è­¯ï¼šUsing scholarly style, summarize in detail James Barr\\'s book \"Semantics of Biblical Language\". Provideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4.","url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-scoring","shibing624","shibing624"],"keywords_longer_than_N":true},
	{"name":"Gitcoin-ODS-Hackhaton-GR15","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Gitcoin ODS Hackathon GR15]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data set was created in the context of the first Gitcoin Open Data Science Hackathon.\nIt contains all the transactions on the Ethereum and Polygon chains of the wallet that contributed to the Grant 15 of Gitcoin grants program.\nIt was created in order to find patterns in the transactions of potential Sybil attackers by exploring their on-chain activity.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15.","url":"https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15","creator_name":"Poupou web3","creator_url":"https://huggingface.co/Poupou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ampere","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AMPERE\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is released together with our NAACL 2019 Paper \"Argument Mining for Understanding Peer Reviews\". If you find our work useful, please cite:\n@inproceedings{hua-etal-2019-argument,\n    title = \"Argument Mining for Understanding Peer Reviews\",\n    author = \"Hua, Xinyu  and\n      Nikolov, Mitko  and\n      Badugu, Nikhil  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2019 Conference of the North {A}mericanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/launch/ampere.","url":"https://huggingface.co/datasets/launch/ampere","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster24","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster24","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"fashion_mnist_quality_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/fashion_mnist_quality_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-hindi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi.","url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code_contests","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CodeContests\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCodeContests is a competitive programming dataset for machine-learning. This\ndataset was used when training AlphaCode.\nIt consists of programming problems, from a variety of sources:\n\n\t\n\t\t\nSite\nURL\nSource\n\n\n\t\t\nAizu\nhttps://judge.u-aizu.ac.jp\nCodeNet\n\n\nAtCoder\nhttps://atcoder.jp\nCodeNet\n\n\nCodeChef\nhttps://www.codechef.com\ndescription2code\n\n\nCodeforces\nhttps://codeforces.com\ndescription2code and Codeforces\n\n\nHackerEarthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/code_contests.","url":"https://huggingface.co/datasets/deepmind/code_contests","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"atypical_animacy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for atypical_animacy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAtypical animacy detection dataset, based on nineteenth-century sentences in English extracted from an open dataset of nineteenth-century books digitized by the British Library. This dataset contains 598 sentences containing mentions of machines. Each sentence has been annotated according to the animacy and humanness of the machine in the sentence. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification - Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/atypical_animacy.","url":"https://huggingface.co/datasets/biglam/atypical_animacy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","intent-classification","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Bundestag-v2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Bundestag-v2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was generated from the ParlSpeech V2 dataset. It contains speeches from the german parliament from 1990 until 2020 labelled with the party of the speaker.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nText Classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nGerman\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Transcript of the speech in german\nparty: Party of the speaker\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\ntrain\nvalidation\ntest\n\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/threite/Bundestag-v2.","url":"https://huggingface.co/datasets/threite/Bundestag-v2","creator_name":"Thomas Reitenspiess","creator_url":"https://huggingface.co/threite","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","entity-linking-classification","expert-generated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"monolingual_ab","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"monolingual_ab\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Abkhaz language monolingual dataset is a collection of 1,470,480 sentences extracted from  different sources. The dataset is available under the Creative Commons Universal Public Domain License. Part of it is also available as part of Common Voice, another part is from the Abkhaz National Corpus\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nHere is a link to the source of a large part of the data on githubâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nart/monolingual_ab.","url":"https://huggingface.co/datasets/Nart/monolingual_ab","creator_name":"Danial Zakaria","creator_url":"https://huggingface.co/Nart","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"PM-products","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PochtaMarket products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace PochtaMarket. It includes all information from the product card. The dataset was collected by processing around 500 thousand, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Some fields may be empty, but the string is expected to contain some dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/PM-products.","url":"https://huggingface.co/datasets/nyuuzyou/PM-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"gallica_literary_fictions","keyword":"monolingual","description":"The collection \"Fiction littÃ©raire de Gallica\" includes 19,240 public domain documents from the digital platform of the French National Library that were originally classified as novels or, more broadly, as literary fiction in prose. It consists of 372 tables of data in tsv format for each year of publication from 1600 to 1996 (all the missing years are in the 17th and 20th centuries). Each table is structured at the page-level of each novel (5,723,986 pages in all). It contains the complete text with the addition of some metadata. It can be opened in Excel or, preferably, with the new data analysis environments in R or Python (tidyverse, pandasâ€¦)\n\nThis corpus can be used for large-scale quantitative analyses in computational humanities. The OCR text is presented in a raw format without any correction or enrichment in order to be directly processed for text mining purposes.\n\nThe extraction is based on a historical categorization of the novels: the Y2 or Ybis classification. This classification, invented in 1730, is the only one that has been continuously applied to the BNF collections now available in the public domain (mainly before 1950). Consequently, the dataset is based on a definition of \"novel\" that is generally contemporary of the publication.\n\nA French data paper (in PDF and HTML) presents the construction process of the Y2 category and describes the structuring of the corpus. It also gives several examples of possible uses for computational humanities projects.","url":"https://huggingface.co/datasets/biglam/gallica_literary_fictions","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","French"],"keywords_longer_than_N":true},
	{"name":"32000-BlackSharpie","keyword":"monolingual","description":"Dataset Card for a Black and White Sharpie Style\n\nDataset used to train/finetune a black and white sharpie style\nCaptions are generated by hand with the assistance of BLIP.\nImages were hand drawn.\nText file filenames correspond image file filenames as captions.\n","url":"https://huggingface.co/datasets/joshuajewell/32000-BlackSharpie","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"gutenberg-poetry-corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAllison Parrish's Gutenberg Poetry Corpus\n\t\n\nThis corpus was originally published under the CC0 license by Allison Parrish. Please visit Allison's fantastic accompanying GitHub repository for usage inspiration as well as more information on how the data was mined, how to create your own version of the corpus, and examples of projects using it.\nThis dataset contains 3,085,117 lines of poetry from hundreds of Project Gutenberg books. Each line has a corresponding gutenberg_id (1191â€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus.","url":"https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"afrolm_active_learning_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages\n\t\n\n\nGitHub Repository of the Paper\n\nThis repository contains the dataset for our paper AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages which will appear at the third Simple and Efficient Natural Language Processing, at EMNLP 2022.\n\n\t\n\t\t\n\t\n\t\n\t\tOur self-active learning framework\n\t\n\n\n\n\t\n\t\n\t\n\t\tLanguages Covered\n\t\n\nAfroLM has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset.","url":"https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset","creator_name":"Bonaventure Dossou","creator_url":"https://huggingface.co/bonadossou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"standard_humaneval","keyword":"monolingual","description":"diversoailab/standard_humaneval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/diversoailab/standard_humaneval","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","code","mit"],"keywords_longer_than_N":true},
	{"name":"difraud","keyword":"monolingual","description":"DIFrauD -- (Domain Independent Fraud Detection) is a corpus of deceptive and truthful texts from 7 domains:\n\n\"fake_news\",\n\"job_scams\",\n\"phishing\",\n\"political_statements\",\n\"product_reviews\",\n\"sms\",\n\"twitter_rumours\"\n\nTo load a specific domain, pass it as the \"name\" parameter to load_dataset()","url":"https://huggingface.co/datasets/difraud/difraud","creator_name":"difraud","creator_url":"https://huggingface.co/difraud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_oracle","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_oracle.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_medium_dummy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Medium set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SRâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_max","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_max.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"monolingual","description":"Lorem ipsum","url":"https://huggingface.co/datasets/j-krzywdziak/test2","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","Audio"],"keywords_longer_than_N":true},
	{"name":"indonews","keyword":"monolingual","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","url":"https://huggingface.co/datasets/jakartaresearch/indonews","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_dutch","keyword":"monolingual","description":"CNN/DailyMail non-anonymized summarization dataset, translated to Dutch with ccmatrix.\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/yhavinga/cnn_dailymail_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_rephrased","keyword":"monolingual","description":"This is a fork of TruthfulQA where questions and answers have been rephrased using a LLM.\n=====\nTruthfulQA is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.","url":"https://huggingface.co/datasets/dvruette/truthful_qa_rephrased","creator_name":"Dimitri","creator_url":"https://huggingface.co/dvruette","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","keyword":"monolingual","description":"The LXMERT text finetune data used to train visual features for the adaption of vision-and-language models to text-only tasks in the paper \"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\".\nThe data has been created from the data made available by the LXMERT repo.\n","url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"EstCOPA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for EstCOPA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEstCOPA is an extended version of XCOPA that was created with a goal to further investigate Estonian language understanding of large language models. EstCOPA provides two new versions of train, eval and test datasets in Estonian: firstly, a machine translated (En->Et) version of original English COPA (Roemmele et al., 2011)  and secondly, a manually post-edited version of the same machine translated data. \n\n\t\n\t\t\n\t\n\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tartuNLP/EstCOPA.","url":"https://huggingface.co/datasets/tartuNLP/EstCOPA","creator_name":"TartuNLP","creator_url":"https://huggingface.co/tartuNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDROWIDChartsRetrieval","keyword":"monolingual","description":"\n  JinaVDROWIDChartsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve charts from the OWID dataset based on accompanied text snippets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/owid_charts_en_beir\n\n\n\t\n\nSource datasets:\n\njinaai/owid_charts_en_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDROWIDChartsRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDROWIDChartsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"HC3FinanceRetrieval","keyword":"monolingual","description":"\n  HC3FinanceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on HC3 Finance dataset containing human vs AI-generated financial text detection. Each query is a financial question or prompt (e.g., 'Explain the impact of interest rate changes on bond prices'), and the corpus contains both human-written and AI-generated financial responses. The task is to retrieve the most relevant and accurate financial content that addresses the query. Queriesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HC3FinanceRetrieval.","url":"https://huggingface.co/datasets/mteb/HC3FinanceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreDocVQARetrieval","keyword":"monolingual","description":"\n  VidoreDocVQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/docvqa_test_subsampled_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreDocVQARetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreDocVQARetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreDocVQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRDocQAHealthcareIndustryRetrieval","keyword":"monolingual","description":"\n  JinaVDRDocQAHealthcareIndustryRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve healthcare industry documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/docqa_healthcare_industry_beir\n\n\n\t\n\nSource datasets:\n\njinaai/docqa_healthcare_industry_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRDocQAHealthcareIndustryRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRDocQAHealthcareIndustryRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreSyntheticDocQAEnergyRetrieval","keyword":"monolingual","description":"\n  VidoreSyntheticDocQAEnergyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/syntheticDocQA_energy_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreSyntheticDocQAEnergyRetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAEnergyRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAEnergyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreSyntheticDocQAGovernmentReportsRetrieval","keyword":"monolingual","description":"\n  VidoreSyntheticDocQAGovernmentReportsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/syntheticDocQA_government_reports_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAGovernmentReportsRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAGovernmentReportsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRJDocQARetrieval","keyword":"monolingual","description":"\n  JinaVDRJDocQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Japanese documents in various formats based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/jdocqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/jdocqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRJDocQARetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRJDocQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRJDocQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRTabFQuadRetrieval","keyword":"monolingual","description":"\n  JinaVDRTabFQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve tables from industry documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/tabfquad_beir\n\n\n\t\n\nSource datasets:\n\njinaai/tabfquad_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRTabFQuadRetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRTabFQuadRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRTabFQuadRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRDocVQARetrieval","keyword":"monolingual","description":"\n  JinaVDRDocVQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve industry documents based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/docvqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/docvqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRDocVQARetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRDocVQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRDocVQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRJina2024YearlyBookRetrieval","keyword":"monolingual","description":"\n  JinaVDRJina2024YearlyBookRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve pages from the 2024 Jina yearbook based on human annotated questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/jina_2024_yearly_book_beir\n\n\n\t\n\nSource datasets:\n\njinaai/jina_2024_yearly_book_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRJina2024YearlyBookRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRJina2024YearlyBookRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"FinanceBenchRetrieval","keyword":"monolingual","description":"\n  FinanceBenchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on FinanceBench dataset containing financial questions and answers. Each query is a financial question (e.g., 'What was the total revenue in Q3 2023?'), and the corpus contains financial document excerpts and annual reports. The task is to retrieve the correct financial information that answers the question. Queries are financial questions while the corpus contains relevant excerptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinanceBenchRetrieval.","url":"https://huggingface.co/datasets/mteb/FinanceBenchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"highlightsum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HighlightSum Corpus [Single Dataset Comprising of AMI, SamSUM & DialogSUM for Brief Summarization of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nAMI: https://huggingface.co/datasets/knkarthick/AMI\nDialogSUM: https://github.com/cylnlp/dialogsum\nSamSUM: https://huggingface.co/datasets/knkarthick/samsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nHighlightSUM is collection of large-scale dialogue summarization datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/highlightsum.","url":"https://huggingface.co/datasets/knkarthick/highlightsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_binary","keyword":"monolingual","description":"TruthfulQA-Binary is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.","url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_binary","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"liwu-MNBVC","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MNBVC\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†ä»‹ç»\n\t\n\nä¸­æ–‡äº’è”ç½‘ä¸Šæœ€å¤è€æœ€ç¥žç§˜(æ²¡æœ‰ä¹‹ä¸€)çš„é‡Œå±‹ç¤¾åŒºäºŽ2023.1.1åº„é‡å®£å¸ƒ:\nåœ¨è‹±æ˜Žç¥žæ­¦çš„é‡Œå±‹ç®¡å­å¸¦é¢†ä¸‹ï¼Œå†³å¿ƒå‘æŒ¥ç¤¾åŒºæ‰€é•¿(å“ªéƒ½é•¿)ï¼Œå¸®åŠ©å¼€æºç¤¾åŒºé•¿æœŸæ›´æ–°ä¸€ä»½æœ€å¤§çš„ä¸­æ–‡äº’è”ç½‘è¯­æ–™é›†ã€‚\nHuggingfaceä¸Šçš„MNBVCæ•°æ®é›†åœ¨é€æ¸æ›´æ–°ä¸­ï¼Œè¯·åˆ°https://github.com/esbatmop/MNBVC èŽ·å–æœªå®Œæˆæ¸…æ´—çš„æ›´å¤šæ•°æ®ã€‚\nå¯ä»¥ä½¿ç”¨å¦‚ä¸‹è„šæœ¬åŠ è½½ï¼š\nfrom datasets import load_dataset\ndataset = load_dataset(\"liwu/MNBVC\", 'law_judgement', split='train', streaming=True)\n\nnext(iter(dataset))  # get the first line\n\n\n\t\n\t\n\t\n\t\tæ•°æ®å­é›†\n\t\n\nMNBVCæ•°æ®é›†åŒ…å«æ•°ä¸ªå­é›†ï¼š\n\nlaw_judgement: æ¥è‡ªæ³•å¾‹æ–‡ä¹¦çš„æ–‡æœ¬ã€‚\ngov_xuexiqiangguo: æ¥è‡ªå­¦ä¹ å¼ºå›½çš„æ–‡æœ¬ã€‚gov_report:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/liwu-MNBVC.","url":"https://huggingface.co/datasets/botp/liwu-MNBVC","creator_name":"ab10","creator_url":"https://huggingface.co/botp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","other"],"keywords_longer_than_N":true},
	{"name":"fashion-test","keyword":"monolingual","description":"This dataset represents some data that Ines annotated. I am adding this info manually. \n","url":"https://huggingface.co/datasets/koaning/fashion-test","creator_name":"Vincent D. Warmerdam","creator_url":"https://huggingface.co/koaning","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CQADupstackAndroidRetrieval","keyword":"monolingual","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\nSource datasets:\n\nmteb/cqadupstack-android\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CQADupstackAndroidRetrieval.","url":"https://huggingface.co/datasets/mteb/CQADupstackAndroidRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"monolingual","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"social_bias_frames","keyword":"monolingual","description":"Social Bias Frames is a new way of representing the biases and offensiveness that are implied in language.\nFor example, these frames are meant to distill the implication that \"women (candidates) are less qualified\"\nbehind the statement \"we shouldnâ€™t lower our standards to hire more women.\"","url":"https://huggingface.co/datasets/allenai/social_bias_frames","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ACL-OCL","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ACL Anthology Corpus\n\t\n\n\nThis repository provides full-text and metadata to the ACL anthology collection (80k articles/posters as of September 2022) also including .pdf files and grobid extractions of the pdfs.\n\n\t\n\t\t\n\t\n\t\n\t\tHow is this different from what ACL anthology provides and what already exists?\n\t\n\n\nWe provide pdfs, full-text, references and other details extracted by grobid from the PDFs while ACL Anthology only provides abstracts.\nThere exists a similar corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WINGNUS/ACL-OCL.","url":"https://huggingface.co/datasets/WINGNUS/ACL-OCL","creator_name":"WING.NUS","creator_url":"https://huggingface.co/WINGNUS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"chebi_nactem","keyword":"monolingual","description":"The ChEBI corpus contains 199 annotated abstracts and 100 annotated full papers.\nAll documents in the corpus have been annotated for named entities and relations\nbetween these. In total, our corpus provides over 15000 named entity annotations\nand over 6,000 relations between entities.","url":"https://huggingface.co/datasets/bigbio/chebi_nactem","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"casino","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Casino\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kchawla123/casino.","url":"https://huggingface.co/datasets/kchawla123/casino","creator_name":"Kushal Chawla","creator_url":"https://huggingface.co/kchawla123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"reddit-wallstreetbets-aug-2021","keyword":"monolingual","description":"This corpus contains the complete data for the activity on /r/WallStreetBets for the entire month of August 2021.","url":"https://huggingface.co/datasets/SocialGrep/reddit-wallstreetbets-aug-2021","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"libri","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri.","url":"https://huggingface.co/datasets/bgstud/libri","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"pharmaconer","keyword":"monolingual","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las TecnologÃ­as del Lenguaje.\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an open access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts and it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets. The training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es","url":"https://huggingface.co/datasets/bigbio/pharmaconer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"cantemist","keyword":"monolingual","description":"Collection of 1301 oncological clinical case reports written in Spanish, with tumor morphology mentions manually annotated and mapped by clinical experts to a controlled terminology. Every tumor morphology mention is linked to an eCIE-O code (the Spanish equivalent of ICD-O).\n\nThe original dataset is distributed in Brat format, and was randomly sampled into 3 subsets. The training, development and test sets contain 501, 500 and 300 documents each, respectively.\n\nThis dataset was designed for the CANcer TExt Mining Shared Task, sponsored by Plan-TL. The task is divided in 3 subtasks: CANTEMIST-NER, CANTEMIST_NORM and CANTEMIST-CODING.\n\nCANTEMIST-NER track: requires finding automatically tumor morphology mentions. All tumor morphology mentions are defined by their corresponding character offsets in UTF-8 plain text medical documents. \n\nCANTEMIST-NORM track: clinical concept normalization or named entity normalization task that requires to return all tumor morphology entity mentions together with their corresponding eCIE-O-3.1 codes i.e. finding and normalizing tumor morphology mentions.\n\nCANTEMIST-CODING track: requires returning for each of document a ranked list of its corresponding ICD-O-3 codes. This it is essentially a sort of indexing or multi-label classification task or oncology clinical coding. \n\nFor further information, please visit https://temu.bsc.es/cantemist or send an email to encargo-pln-life@bsc.es","url":"https://huggingface.co/datasets/bigbio/cantemist","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"multi_booked","keyword":"monolingual","description":"MultiBooked is a corpus of Basque and Catalan Hotel Reviews Annotated for Aspect-level Sentiment Classification.\n\nThe corpora are compiled from hotel reviews taken mainly from booking.com. The corpora are in Kaf/Naf format, which is\nan xml-style stand-off format that allows for multiple layers of annotation. Each review was sentence- and\nword-tokenized and lemmatized using Freeling for Catalan and ixa-pipes for Basque. Finally, for each language two\nannotators annotated opinion holders, opinion targets, and opinion expressions for each review, following the\nguidelines set out in the OpeNER project.","url":"https://huggingface.co/datasets/jerbarnes/multi_booked","creator_name":"Jeremy Barnes","creator_url":"https://huggingface.co/jerbarnes","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"docred","keyword":"monolingual","description":"Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features:\n    - DocRED annotates both named entities and relations, and is the largest human-annotated dataset for document-level RE from plain text.\n    - DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.\n    - Along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios.","url":"https://huggingface.co/datasets/thunlp/docred","creator_name":"Tsinghua NLP group","creator_url":"https://huggingface.co/thunlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_max","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_max.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ehr_rel","keyword":"monolingual","description":"EHR-Rel is a novel open-source1 biomedical concept relatedness dataset consisting of 3630 concept pairs, six times more\nthan the largest existing dataset.  Instead of manually selecting and pairing concepts as done in previous work,\nthe dataset is sampled from EHRs to ensure concepts are relevant for the EHR concept retrieval task.\nA detailed analysis of the concepts in the dataset reveals a far larger coverage compared to existing datasets.","url":"https://huggingface.co/datasets/bigbio/ehr_rel","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"acronym_identification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Acronym Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the training, validation, and test data for the Shared Task 1: Acronym Identification of the AAAI-21 Workshop on Scientific Document Understanding.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports an acronym-identification task, where the aim is to predic which tokens in a pre-tokenized sentence correspond to acronyms. The dataset was released for a Shared Task whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amirveyseh/acronym_identification.","url":"https://huggingface.co/datasets/amirveyseh/acronym_identification","creator_name":"amir veyseh","creator_url":"https://huggingface.co/amirveyseh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES-titles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES-titles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES-titles is a Spanish-language dataset for news titles generation. The text and titles comes from 2019 and 2020 CC-NEWS data (which is part of Common Crawl).\nIt contains 402.310 pairs of news title and body, splitted in :\n\nTrain: 370.125\n\nEval: 16.092\n\nTest: 16.092\n\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset can be used to train a model for news titleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles.","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles","creator_name":"Leonardo Ignacio CÃ³rdoba","creator_url":"https://huggingface.co/LeoCordoba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"head_qa","keyword":"monolingual","description":"HEAD-QA is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the\nSpanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio\nde Sanidad, Consumo y Bienestar Social.\n\nThe dataset contains questions about the following topics: medicine, nursing, psychology, chemistry, pharmacology and biology.","url":"https://huggingface.co/datasets/dvilares/head_qa","creator_name":"David Vilares","creator_url":"https://huggingface.co/dvilares","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"squad_es","keyword":"monolingual","description":"automatic translation of the Stanford Question Answering Dataset (SQuAD) v2 into Spanish","url":"https://huggingface.co/datasets/ccasimiro/squad_es","creator_name":"Casimiro Pio Carrino","creator_url":"https://huggingface.co/ccasimiro","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"taskmaster1","keyword":"monolingual","description":"Taskmaster-1 is a  goal-oriented conversational dataset. It includes 13,215 task-based dialogs comprising six domains. Two procedures were used to create this collection, each with unique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is \"self-dialog\" in which crowdsourced workers write the entire dialog themselves.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster1","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pn_summary","keyword":"monolingual","description":"A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\nIt is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.","url":"https://huggingface.co/datasets/HooshvareLab/pn_summary","creator_name":"Hooshvare Research Lab","creator_url":"https://huggingface.co/HooshvareLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-classification","news-articles-summarization","news-articles-headline-generation","text-simplification"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Stackoverflow Post Questions]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \nthe other hand, every software developerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions.","url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"samromur_children","keyword":"monolingual","description":"The SamrÃ³mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"quoref","keyword":"monolingual","description":"Quoref is a QA dataset which tests the coreferential reasoning capability of reading comprehension systems. In this\nspan-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard\ncoreferences before selecting the appropriate span(s) in the paragraphs for answering questions.","url":"https://huggingface.co/datasets/allenai/quoref","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hkcancor","keyword":"monolingual","description":"The Hong Kong Cantonese Corpus (HKCanCor) comprise transcribed conversations\nrecorded between March 1997 and August 1998. It contains recordings of\nspontaneous speech (51 texts) and radio programmes (42 texts),\nwhich involve 2 to 4 speakers, with 1 text of monologue.\n\nIn total, the corpus contains around 230,000 Chinese words.\nThe text is word-segmented, annotated with part-of-speech (POS) tags and\nromanised Cantonese pronunciation.\n\nRomanisation scheme - Linguistic Society of Hong Kong (LSHK)\nPOS scheme - Peita-Fujitsu-Renmin Ribao (PRF) corpus (Duan et al., 2000),\n             with extended tags for Cantonese-specific phenomena added by\n             Luke and Wang (see original paper for details).","url":"https://huggingface.co/datasets/nanyang-technological-university-singapore/hkcancor","creator_name":"Nanyang Technological University Singapore","creator_url":"https://huggingface.co/nanyang-technological-university-singapore","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","text-generation","fill-mask","dialogue-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"asqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ASQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASQA is the first long-form question answering dataset that focuses on ambiguous factoid questions. Different from previous long-form answers datasets, each question is annotated with both long-form answers and extractive question-answer pairs, which should be answerable by the generated passage. A generated long-form answer will be evaluated using both ROUGE and QA accuracy. In the paper, we show that these evaluation metrics areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/din0s/asqa.","url":"https://huggingface.co/datasets/din0s/asqa","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"balanced-copa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Balanced COPA\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBala-COPA: An English language Dataset for Training Robust Commonsense Causal Reasoning Models\nThe Balanced Choice of Plausible Alternatives dataset is a benchmark for training machine learning models that are robust to superficial cues/spurious correlations. The dataset extends the COPA dataset(Roemmele et al. 2011) with mirrored instances that mitigate against token-level superficial cues in the original COPA answers. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pkavumba/balanced-copa.","url":"https://huggingface.co/datasets/pkavumba/balanced-copa","creator_name":"Pride Kavumba","creator_url":"https://huggingface.co/pkavumba","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"poquad","keyword":"monolingual","description":"PoQuaD description","url":"https://huggingface.co/datasets/clarin-pl/poquad","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-chinese-subset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tlaion2B-multi-chinese-subset\n\t\n\n\nGithub: Fengshenbang-LM\nDocs: Fengshenbang-Docs\n\n\n\t\n\t\t\n\t\tç®€ä»‹ Brief Introduction\n\t\n\nå–è‡ªLaion2Bå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±143Mä¸ªå›¾æ–‡å¯¹ã€‚\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\n\t\n\nå¤§çº¦ä¸€å…±143Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨19GBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\n\nHomepage: laion-5b\nHuggingface: laion/laion2B-multi\n\n\n\t\n\t\t\n\t\tä¸‹è½½ Download\n\t\n\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\nfor i in {00000..00012}; doâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset.","url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"clinical_trial_reason_to_stop","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Clinical Trials's Reason to Stop\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a curated classification of more than 5000 reasons why a clinical trial has suffered an early stop.\nThe text has been extracted from clinicaltrials.gov, the largest resource of clinical trial information. The text has been curated by members of the Open Targets organisation, a project aimed at providing data relevant to drug development.\nAll 17 possible classes have been carefullyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop.","url":"https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop","creator_name":"Open Targets","creator_url":"https://huggingface.co/opentargets","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"splittedspanish3bwc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Unannotated Spanish 3 Billion Words Corpora\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nNumber of lines: 300904000 (300M)\nNumber of tokens: 2996016962 (3B)\nNumber of chars: 18431160978 (18.4B)\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nSpanish\n\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\nAvailable to download here: Zenodo\n\n\n\t\n\t\t\n\t\tData Subset\n\t\n\n\nSpanish Wikis: Wich include Wikipedia, Wikinews, Wikiquotes and more. These were first processed with wikiextractor (https://github.com/josecannete/wikiextractorforBERT) usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vialibre/splittedspanish3bwc.","url":"https://huggingface.co/datasets/vialibre/splittedspanish3bwc","creator_name":"Via Libre","creator_url":"https://huggingface.co/vialibre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","mit","100M - 1B","Text"],"keywords_longer_than_N":true},
	{"name":"wnli-es","keyword":"monolingual","description":"professional translation into Spanish of Winograd NLI dataset as published in GLUE Benchmark.\n               The Winograd NLI dataset presents 855 sentence pairs, \n               in which the first sentence contains an ambiguity and the second one a possible interpretation of it. \n               The label indicates if the interpretation is correct (1) or not (0).","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/wnli-es","creator_name":"Plan de TecnologÃ­as del Lenguaje - Gobierno de EspaÃ±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"monolingual","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet willâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki_academic_subjects","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki Academic Disciplines`\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created from the English wikipedia dump of January 2022.\nThe main goal was to train a hierarchical classifier of academic subjects using HiAGM. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboard\n\t\n\nText classification - No leaderboard at the moment.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of groups of labeled text chunks (tokenized by spaces and with stopwordsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meliascosta/wiki_academic_subjects.","url":"https://huggingface.co/datasets/meliascosta/wiki_academic_subjects","creator_name":"Martin Elias Costa","creator_url":"https://huggingface.co/meliascosta","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"fashionpedia","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\nFrom the paper:\n\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia.","url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n200000/200000/100000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"crawl_domain","keyword":"monolingual","description":"Corpus of domain names scraped from Common Crawl and manually annotated to add word boundaries (e.g. \"commoncrawl\" to \"common crawl\"). Breaking domain names such as \"openresearch\" into component words \"open\" and \"research\" is important for applications such as Text-to-Speech synthesis and web search. Common Crawl is an open repository of web crawl data that can be accessed and analyzed by anyone. Specifically, we scraped the plaintext (WET) extracts for domain names from URLs that contained diverse letter casing (e.g. \"OpenBSD\"). Although in the previous example, segmentation is trivial using letter casing, this was not always the case (e.g. \"NASA\"), so we had to manually annotate the data. The dataset is stored as plaintext file where each line is an example of space separated segments of a domain name. The examples are stored in their original letter casing, but harder and more interesting examples can be generated by lowercasing the input first.","url":"https://huggingface.co/datasets/google-research-datasets/crawl_domain","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"monolingual","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BAAD6","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD6 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by Hemayet et al [1]. The data was obtained from different online posts and blogs. This dataset is balanced among the 6 Authors with 350 sample texts per author. This is a relatively small dataset but is noisy given the sources it was collected from and its cleaning procedure. Nonetheless, it may help evaluate authorship attribution systems as it resembles texts oftenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD6.","url":"https://huggingface.co/datasets/Aisha/BAAD6","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"ascent_kb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Ascent KB\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 8.9M commonsense assertions extracted  by the Ascent pipeline developed at the Max Planck Institute for Informatics.\nThe focus of this dataset is on everyday concepts such as elephant, car, laptop, etc.\nThe current version of Ascent KB (v1.0.0) is approximately 19 times larger  than ConceptNet (note that, in this comparison, non-commonsense knowledge in ConceptNet such as lexical relations is excluded).\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tuanphong/ascent_kb.","url":"https://huggingface.co/datasets/tuanphong/ascent_kb","creator_name":"Tuan-Phong Nguyen","creator_url":"https://huggingface.co/tuanphong","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"codiesp","keyword":"monolingual","description":"Synthetic corpus of 1,000 manually selected clinical case studies in Spanish\nthat was designed for the Clinical Case Coding in Spanish Shared Task, as part\nof the CLEF 2020 conference.\n\nThe goal of the task was to automatically assign ICD10 codes (CIE-10, in\nSpanish) to clinical case documents, being evaluated against manually generated\nICD10 codifications. The CodiEsp corpus was selected manually by practicing\nphysicians and clinical documentalists and annotated by clinical coding\nprofessionals meeting strict quality criteria. They reached an inter-annotator\nagreement of 88.6% for diagnosis coding, 88.9% for procedure coding and 80.5%\nfor the textual reference annotation.\n\nThe final collection of 1,000 clinical cases that make up the corpus had a total\nof 16,504 sentences and 396,988 words. All documents are in Spanish language and\nCIE10 is the coding terminology (the Spanish version of ICD10-CM and ICD10-PCS).\nThe CodiEsp corpus has been randomly sampled into three subsets. The train set\ncontains 500 clinical cases, while the development and test sets have 250\nclinical cases each. In addition to these, a collection of 176,294 abstracts\nfrom Lilacs and Ibecs with the corresponding ICD10 codes (ICD10-CM and\nICD10-PCS) was provided by the task organizers. Every abstract has at least one\nassociated code, with an average of 2.5 ICD10 codes per abstract.\n\nThe CodiEsp track was divided into three sub-tracks (2 main and 1 exploratory):\n\n- CodiEsp-D: The Diagnosis Coding sub-task, which requires automatic ICD10-CM\n  [CIE10-DiagnÃ³stico] code assignment.\n- CodiEsp-P: The Procedure Coding sub-task, which requires automatic ICD10-PCS\n  [CIE10-Procedimiento] code assignment.\n- CodiEsp-X: The Explainable AI exploratory sub-task, which requires to submit\n  the reference to the predicted codes (both ICD10-CM and ICD10-PCS). The goal \n  of this novel task was not only to predict the correct codes but also to \n  present the reference in the text that supports the code predictions.\n\nFor further information, please visit https://temu.bsc.es/codiesp or send an\nemail to encargo-pln-life@bsc.es","url":"https://huggingface.co/datasets/bigbio/codiesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"chia","keyword":"monolingual","description":"A large annotated corpus of patient eligibility criteria extracted from 1,000\ninterventional, Phase IV clinical trials registered in ClinicalTrials.gov. This\ndataset includes 12,409 annotated eligibility criteria, represented by 41,487\ndistinctive entities of 15 entity types and 25,017 relationships of 12\nrelationship types.","url":"https://huggingface.co/datasets/bigbio/chia","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"snli-cf-kaushik","keyword":"monolingual","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). In the ICLR 2020 paper [Learning the Difference that Makes a Difference with Counterfactually-Augmented Data](https://openreview.net/forum?id=Sklgs0NFvr), Kaushik et. al. provided a dataset with counterfactual perturbations on the SNLI and IMDB data. This repository contains the original and counterfactual perturbations for the SNLI data, which was generated after processing the original data from [here](https://github.com/acmi-lab/counterfactually-augmented-data).","url":"https://huggingface.co/datasets/sagnikrayc/snli-cf-kaushik","creator_name":"sagnik ray choudhury","creator_url":"https://huggingface.co/sagnikrayc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sucx3_ner","keyword":"monolingual","description":"    The dataset is a conversion of the venerable SUC 3.0 dataset into the\n    huggingface ecosystem. The original dataset does not contain an official\n    train-dev-test split, which is introduced here; the tag distribution for the\n    NER tags between the three splits is mostly the same.\n    \n    The dataset has three different types of tagsets: manually annotated POS,\n    manually annotated NER, and automatically annotated NER. For the\n    automatically annotated NER tags, only sentences were chosen, where the\n    automatic and manual annotations would match (with their respective\n    categories).\n    \n    Additionally we provide remixes of the same data with some or all sentences\n    being lowercased.","url":"https://huggingface.co/datasets/KBLab/sucx3_ner","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","named-entity-recognition","part-of-speech","expert-generated","other"],"keywords_longer_than_N":true},
	{"name":"taskmaster3","keyword":"monolingual","description":"Taskmaster is dataset for goal oriented conversations. The Taskmaster-3 dataset consists of 23,757 movie ticketing dialogs. By \"movie ticketing\" we mean conversations where the customer's goal is to purchase tickets after deciding on theater, time, movie name, number of tickets, and date, or opt out of the transaction. This collection was created using the \"self-dialog\" method. This means a single, crowd-sourced worker is paid to create a conversation writing turns for both speakers, i.e. the customer and the ticketing agent.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster3","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"commonsense_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"commonsense_qa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tau/commonsense_qa.","url":"https://huggingface.co/datasets/tau/commonsense_qa","creator_name":"Tel Aviv University","creator_url":"https://huggingface.co/tau","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"codah","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COmmonsense Dataset Adversarially-authored by Humans\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe COmmonsense Dataset Adversarially-authored by Humans (CODAH) is an evaluation set for commonsense\nquestion-answering in the sentence completion style of SWAG. As opposed to other automatically generated\nNLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model\nand use this information to design challenging commonsense questions.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaredfern/codah.","url":"https://huggingface.co/datasets/jaredfern/codah","creator_name":"Jared Fernandez","creator_url":"https://huggingface.co/jaredfern","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatexplain","keyword":"monolingual","description":"Hatexplain is the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in the dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based.","url":"https://huggingface.co/datasets/Hate-speech-CNERG/hatexplain","creator_name":"Hate-ALERT","creator_url":"https://huggingface.co/Hate-speech-CNERG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openai_humaneval","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OpenAI HumanEval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe programming problems are written in Python and contain English natural text in comments and docstrings.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/openai_humaneval.","url":"https://huggingface.co/datasets/openai/openai_humaneval","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"paraphrase-ro","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tRomanian paraphrase dataset\n\t\n\nThis data set was created by me, special for paraphrase\nt5-small-paraphrase-ro\nt5-small-paraphrase-ro-v2\nt5-base-paraphrase-ro\nt5-base-paraphrase-ro-v2\nHere you can find ~100k examples of paraphrase.\n","url":"https://huggingface.co/datasets/BlackKakapo/paraphrase-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Romanian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"mdd","keyword":"monolingual","description":"The Movie Dialog dataset (MDD) is designed to measure how well\nmodels can perform at goal and non-goal orientated dialog\ncentered around the topic of movies (question answering,\nrecommendation and discussion).","url":"https://huggingface.co/datasets/facebook/mdd","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"large_spanish_corpus","keyword":"monolingual","description":"The Large Spanish Corpus is a compilation of 15 unlabelled Spanish corpora spanning Wikipedia to European parliament notes. Each config contains the data corresponding to a different corpus. For example, \"all_wiki\" only includes examples from Spanish Wikipedia. By default, the config is set to \"combined\" which loads all the corpora; with this setting you can also specify the number of samples to return per corpus by configuring the \"split\" argument.","url":"https://huggingface.co/datasets/josecannete/large_spanish_corpus","creator_name":"JosÃ© CaÃ±ete","creator_url":"https://huggingface.co/josecannete","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"squad_adversarial","keyword":"monolingual","description":"Here are two different adversaries, each of which uses a different procedure to pick the sentence it adds to the paragraph:\nAddSent: Generates up to five candidate adversarial sentences that don't answer the question, but have a lot of words in common with the question. Picks the one that most confuses the model.\nAddOneSent: Similar to AddSent, but just picks one of the candidate sentences at random. This adversary is does not query the model in any way.","url":"https://huggingface.co/datasets/stanfordnlp/squad_adversarial","creator_name":"Stanford NLP","creator_url":"https://huggingface.co/stanfordnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"eth_py150_open","keyword":"monolingual","description":"A redistributable subset of the ETH Py150 corpus, introduced in the ICML 2020 paper 'Learning and Evaluating Contextual Embedding of Source Code'","url":"https://huggingface.co/datasets/google-research-datasets/eth_py150_open","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"jnlpba","keyword":"monolingual","description":"NER For Bio-Entities","url":"https://huggingface.co/datasets/bigbio/jnlpba","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-3.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"russian_super_glue","keyword":"monolingual","description":"Recent advances in the field of universal language models and transformers require the development of a methodology for\ntheir broad diagnostics and testing for general intellectual skills - detection of natural language inference,\ncommonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first\ntime, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from\nscratch for the Russian language. We provide baselines, human level evaluation, an open-source framework for evaluating\nmodels and an overall leaderboard of transformer models for the Russian language.","url":"https://huggingface.co/datasets/RussianNLP/russian_super_glue","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","text-generation","natural-language-inference"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaNlLegalRetrieval","keyword":"monolingual","description":"\n  JinaVDREuropeanaNlLegalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Dutch historical legal documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nLegal\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-nl-legal_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-nl-legal_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaNlLegalRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaNlLegalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRStudentEnrollmentSyntheticRetrieval","keyword":"monolingual","description":"\n  JinaVDRStudentEnrollmentSyntheticRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve student enrollment data based on templated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/student-enrollment_beir\n\n\n\t\n\nSource datasets:\n\njinaai/student-enrollment_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRStudentEnrollmentSyntheticRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRStudentEnrollmentSyntheticRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"wikitoxic","keyword":"monolingual","description":"This dataset has been created as an artefact of the paper AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets (Lesci and Vlachos, 2024).\nMore info about this dataset in the appendix of the paper. \nThis is the same dataset as OxAISH-AL-LLM/wiki_toxic.\nThe only differences are:\n\nAddition of a unique identifier, uid.\n\nAddition of the indices, that is, 3 columns with the embeddings of 3 different sentence-transformers\n\nall-mpnet-base-v2\nmulti-qa-mpnet-base-dot-v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pietrolesci/wikitoxic.","url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"lj_speech","keyword":"monolingual","description":"This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading\npassages from 7 non-fiction books in English. A transcription is provided for each clip. Clips vary in length\nfrom 1 to 10 seconds and have a total length of approximately 24 hours.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/keithito/lj_speech","creator_name":"Keith Ito","creator_url":"https://huggingface.co/keithito","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"monolingual","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\nis obtained from Kaggle:\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\nData has been scraped from the publicly available website\nhttps://www.rottentomatoes.com as of 2020-10-31.\nThe clean up process drops anything without both a review and a rating, as well\nas standardising the ratings onto several integer, ordinal scales.\nRequires the kaggle library to beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews.","url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","sentiment-scoring","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"consumer-finance-complaints","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Consumer Finance Complaints\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis database is a collection of complaints about consumer financial products and services that we sent to companies for response.\nThe Consumer Complaint Database is a collection of complaints about consumer financial products and services that we sent to companies for response. Complaints are published after the company responds, confirming a commercial relationship with the consumer, or after 15 daysâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CFPB/consumer-finance-complaints.","url":"https://huggingface.co/datasets/CFPB/consumer-finance-complaints","creator_name":"Consumer Financial Protection Bureau","creator_url":"https://huggingface.co/CFPB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","topic-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wisesight_sentiment","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for wisesight_sentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\nReleased to public domain under Creative Commons Zero v1.0 Universal license.\nLabels: {\"pos\": 0, \"neu\": 1, \"neg\": 2, \"q\": 3}\nSize: 26,737 messages\nLanguage: Central Thai\nStyle: Informal and conversational. With some news headlines and advertisement.\nTime period: Around 2016 to early 2019. Withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/wisesight_sentiment.","url":"https://huggingface.co/datasets/pythainlp/wisesight_sentiment","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"metooma","keyword":"monolingual","description":"The dataset consists of tweets belonging to #MeToo movement on Twitter, labelled into different categories.\nDue to Twitter's development policies, we only provide the tweet ID's and corresponding labels,\nother data can be fetched via Twitter API.\nThe data has been labelled by experts, with the majority taken into the account for deciding the final label.\nWe provide these labels for each of the tweets. The labels provided for each data point\nincludes -- Relevance, Directed Hate, Generalized Hate,\nSarcasm, Allegation, Justification, Refutation, Support, Oppose","url":"https://huggingface.co/datasets/midas/metooma","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"billsum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"billsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBillSum, summarization of US Congressional and California state bills.\nThere are several features:\n\ntext: bill text.\nsummary: summary of the bills.\ntitle: title of the bills.\nfeatures for us bills. ca bills does not have.\ntext_len: number of chars in text.\nsum_len: number of chars in summary.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FiscalNote/billsum.","url":"https://huggingface.co/datasets/FiscalNote/billsum","creator_name":"FiscalNote","creator_url":"https://huggingface.co/FiscalNote","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"times_of_india_news_headlines","keyword":"monolingual","description":"This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.","url":"https://huggingface.co/datasets/community-datasets/times_of_india_news_headlines","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","fact-checking-retrieval","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"channel-metadata","keyword":"monolingual","description":"Dataset containing video metadata from a few tech channels, i.e.\n\nJames Briggs\nYannic Kilcher\nsentdex\nDaniel Bourke\nAI Coffee Break with Letitia\nAlex Ziskind\n\n","url":"https://huggingface.co/datasets/jamescalam/channel-metadata","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["other","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"CanItEdit","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\n\t\n\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\nThe datasetâ€™s dual natural language instructions test modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit.","url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"esb-datasets-test-only","keyword":"monolingual","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hf-audio/esb-datasets-test-only.","url":"https://huggingface.co/datasets/hf-audio/esb-datasets-test-only","creator_name":"Hugging Face for Audio","creator_url":"https://huggingface.co/hf-audio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"UD_Spanish-AnCora","keyword":"monolingual","description":"Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008).","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/UD_Spanish-AnCora","creator_name":"Plan de TecnologÃ­as del Lenguaje - Gobierno de EspaÃ±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dac6-instruct","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDAC6 instruct (11-12-2023)\n\t\n\nâ€œDAC 6â€ refers to European Council Directive (EU) 2018/822 of May 25, 2018 relating to the automatic and mandatory exchange of information on cross-border arrangements requiring declaration. It aims to strengthen cooperation between tax administrations in EU countries on potentially aggressive tax planning arrangements.\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct.","url":"https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ru_paraphraser","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ParaPhraser\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParaPhraser is a news headlines corpus annotated according to the following schema:\n1: precise paraphrases\n0: near paraphrases\n-1: non-paraphrases\n\nThe Plus part is also available.\nIt contains clusters of news headline paraphrases labeled automatically by a fine-tuned paraphrase detection BERT model.In order to load it:\nfrom datasets import load_dataset\n\ncorpus = load_dataset('merionum/ru_paraphraser', data_files='plus.jsonl')â€¦ See the full description on the dataset page: https://huggingface.co/datasets/merionum/ru_paraphraser.","url":"https://huggingface.co/datasets/merionum/ru_paraphraser","creator_name":"Vadim Gudkov","creator_url":"https://huggingface.co/merionum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","sentence-similarity","semantic-similarity-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qg_koquad","keyword":"monolingual","description":"[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Korean"],"keywords_longer_than_N":true},
	{"name":"dkstance","keyword":"monolingual","description":"This dataset presents a series of stories on Reddit and the conversation around\nthem, annotated for stance. Stories are also annotated for veracity.\n\nFor more details see https://aclanthology.org/W19-6122/","url":"https://huggingface.co/datasets/strombergnlp/dkstance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"semeval-2010-pre","keyword":"monolingual","description":"Preprocessed SemEval-2010 Benchmark dataset for Keyphrase Generation.","url":"https://huggingface.co/datasets/taln-ls2n/semeval-2010-pre","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","unknown","unknown","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"danfever","keyword":"monolingual","description":"\\","url":"https://huggingface.co/datasets/strombergnlp/danfever","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","natural-language-inference","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"REPV-S","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {ÐÑ€Ñ‚ÐµÐ¼ ÐÐ¼ÐµÐ½Ñ‚ÐµÑ, Ð˜Ð»ÑŒÑ Ð›ÑƒÐ±ÐµÐ½ÐµÑ†, ÐÐ¸ÐºÐ¸Ñ‚Ð° Ð”Ð°Ð²Ð¸Ð´Ñ‡ÑƒÐº},\n  title = {ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ð°Ñ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ñ‚ÐµÐ½ÐºÐ¾Ð² Ñ€ÐµÑ‡Ð¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","url":"https://huggingface.co/datasets/Aniemore/REPV-S","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qa_harvesting_from_wikipedia","keyword":"monolingual","description":"QA pairs generated in https://aclanthology.org/P18-1177/","url":"https://huggingface.co/datasets/lmqg/qa_harvesting_from_wikipedia","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained analysis of systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/quincyqiang/test.","url":"https://huggingface.co/datasets/quincyqiang/test","creator_name":"quincyqiang","creator_url":"https://huggingface.co/quincyqiang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-turkish-subset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for laion2B-multi-turkish-subset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLAION-5B is a large scale openly accessible image-text dataset contains text from multiple languages. This is a Turkish subset data of laion/laion2B-multi. It's compatible to be used with image2dataset to fetch the images at scale.\n\n\t\n\t\t\n\t\n\t\n\t\tData Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset.","url":"https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset","creator_name":"Cemil Guney","creator_url":"https://huggingface.co/mcemilg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"medmnist-v2","keyword":"monolingual","description":"MedMNIST v2 is a large-scale MNIST-like collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D.","url":"https://huggingface.co/datasets/albertvillanova/medmnist-v2","creator_name":"Albert Villanova del Moral","creator_url":"https://huggingface.co/albertvillanova","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","multi-label-image-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cdg-neural-math-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNeural Math QA Dataset\n\t\n\nThis directory contains the neural_math_qa.jsonl dataset, used for fine-tuning models for question-answering related to neural networks and pure mathematics.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of question-answer pairs focused on the intersection of neural networks and pure mathematics concepts. It was generated synthetically using an LLM.\nTopics include:\n\nLinear algebra foundations\nTopology in network spaces\nDifferentiable manifolds\nMeasureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahlen/cdg-neural-math-qa.","url":"https://huggingface.co/datasets/cahlen/cdg-neural-math-qa","creator_name":"Cahlen Humphreys","creator_url":"https://huggingface.co/cahlen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"scientific_lay_summarisation","keyword":"monolingual","description":"This repository contains the PLOS and eLife datasets, introduced in the EMNLP 2022 paper \"[Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature\n](https://arxiv.org/abs/2210.09932)\". \nEach dataset contains full biomedical research articles paired with expert-written lay summaries (i.e., non-technical summaries). PLOS articles are derived from various journals published by [the Public Library of Science (PLOS)](https://plos.org/), whereas eLife articles are derived from the [eLife](https://elifesciences.org/) journal. More details/anlaysis on the content of each dataset are provided in the paper.\n\nBoth \"elife\" and \"plos\" have 6 features:\n    - \"article\": the body of the document (including the abstract), sections seperated by \"/n\".\n    - \"section_headings\": the title of each section, seperated by \"/n\". \n    - \"keywords\": keywords describing the topic of the article, seperated by \"/n\".\n    - \"title\" : the title of the article.\n    - \"year\" : the year the article was published.\n    - \"summary\": the lay summary of the document.","url":"https://huggingface.co/datasets/tomasg25/scientific_lay_summarisation","creator_name":"Tomas Goldsack","creator_url":"https://huggingface.co/tomasg25","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"alverjob-tech-cases","keyword":"monolingual","description":"\n\t\n\t\t\n\t\talverjob-tech-cases\n\t\n\nÐšÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ñ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ñ‹Ñ… ÐºÐµÐ¹ÑÐ¾Ð², Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ñ‹Ñ… Ð·Ð°Ð¼ÐµÑ‚Ð¾Ðº, Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð¿Ð¾Ð»ÐµÐ²Ñ‹Ñ… Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸Ð¹, Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÐÐ»ÐµÐºÑÐ°Ð½Ð´Ñ€Ð¾Ð¼ Ð’ÐµÑ€Ñ‚Ð¸ÐµÐ¼ (fozzy72, alverjob) â€” Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð¾Ð¼ Ð¸ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¾Ð¼ Ð¸Ð· Ð¥Ð°Ñ€ÑŒÐºÐ¾Ð²Ð°, Ð£ÐºÑ€Ð°Ð¸Ð½Ð°.Ð¦ÐµÐ»ÑŒ â€” Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð½ÐµÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð½Ð° ÑÑ‚Ñ‹ÐºÐµ Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐ¸, Ñ…Ð¸Ð¼Ð¸Ð¸, Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²Ð°.\n\n\n\t\n\t\t\n\t\tðŸ“‚ Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ\n\t\n\n\nðŸ“ /cases/ â€” Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐºÐµÐ¹ÑÑ‹ Ð¿Ð¾ Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐµ, Ñ…Ð¸Ð¼Ð¸Ð¸, ÑÐ½ÐµÑ€Ð³ÐµÑ‚Ð¸ÐºÐµ  \nðŸ“ /videos/ â€” Ð°Ð²Ñ‚Ð¾Ñ€ÑÐºÐ¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÑŽ, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alverjob/alverjob-tech-cases.","url":"https://huggingface.co/datasets/alverjob/alverjob-tech-cases","creator_name":"Alexander Vertiy","creator_url":"https://huggingface.co/alverjob","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","monolingual","Russian","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"monolingual","description":"The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to\nprobe large language models, and extrapolate their future capabilities.","url":"https://huggingface.co/datasets/google/bigbench","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"DBLP-QuAD","keyword":"monolingual","description":"    DBLP-QuAD is a scholarly knowledge graph question answering dataset with     10,000 question - SPARQL query pairs targeting the DBLP knowledge graph.     The dataset is split into 7,000 training, 1,000 validation and 2,000 test     questions.","url":"https://huggingface.co/datasets/awalesushil/DBLP-QuAD","creator_name":"Sushil Awale","creator_url":"https://huggingface.co/awalesushil","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"codecomplex","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCodeComplex Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCodeComplex consists of 4,200 Java codes submitted to programming competitions by human programmers and their complexity labels annotated by a group of algorithm experts.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\n You can load and iterate through the dataset with the following two lines of code:\nfrom datasets import load_dataset\n\nds = load_dataset(\"codeparrot/codecomplex\", split=\"train\")\nprint(next(iter(ds)))\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/codecomplex.","url":"https://huggingface.co/datasets/codeparrot/codecomplex","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","monolingual","code"],"keywords_longer_than_N":true},
	{"name":"JGLUE","keyword":"monolingual","description":"JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.\\","url":"https://huggingface.co/datasets/shunk031/JGLUE","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","sentence-similarity","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"esc-datasets","keyword":"monolingual","description":"All eight of datasets in ESC can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esc-benchmark/esc-datasets\", \"librispeech\", split=\"train\")\n\n\n\"esc-benchmark\": the repository namespace. This is fixed for all ESC datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESC to download that dataset.\n\nsplit=\"train\": the split. Set thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/esc-benchmark/esc-datasets.","url":"https://huggingface.co/datasets/esc-benchmark/esc-datasets","creator_name":"ESC","creator_url":"https://huggingface.co/esc-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tgsm8k-ru\n\t\n\nTranslated version of gsm8k dataset into Russian.\n","url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","translated","monolingual","gsm8k","Russian"],"keywords_longer_than_N":true},
	{"name":"SB10k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tA Twitter corpus and benchmark resources for german sentiment analysis\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nThe data is a snapshot from the SB10k Dataset.\nThe snapshot was made by Oliver Guhr.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nPaper\n@inproceedings{cieliebak2017twitter,\n  title={A twitter corpus and benchmark resources for german sentiment analysis},\n  author={Cieliebak, Mark and Deriu, Jan Milan and Egger, Dominic and Uzdilli, Fatih},\n  booktitle={5th International Workshop on Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/SB10k.","url":"https://huggingface.co/datasets/Alienmaster/SB10k","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"woz","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for WOZ 2.0\n\t\n\n\nRepository: https://github.com/nmrksic/neural-belief-tracker/tree/master/data/woz\nPaper: https://aclanthology.org/P17-1163.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('woz')\nontology = load_ontology('woz')\ndatabase =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/woz.","url":"https://huggingface.co/datasets/ConvLab/woz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"kelly","keyword":"monolingual","description":"The Swedish Kelly list is a freely available frequency-based vocabulary list that comprises general-purpose language of modern Swedish. The list was generated from a large web-acquired corpus (SweWaC) of 114 million words dating from the 2010s. It is adapted to the needs of language learners and contains 8,425 most frequent lemmas that cover 80% of SweWaC.\\","url":"https://huggingface.co/datasets/codesue/kelly","creator_name":"Suzen Fylke","creator_url":"https://huggingface.co/codesue","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ccma_meteo_instruct","keyword":"monolingual","description":"CCMA_METEO_INSTRUCT.\n                  This is a dataset for complex Named Eentity Recognition (NER) created by the AINA project in the BSC for \n                  Machine Learning and Language Model evaluation purposes.\n                  \n                  CCMA corpus is NOT LICENSABLE.\n                  This dataset was developed by BSC as part of the AINA project, and to enrich the Catalan Language Understanding Benchmark (CLUB).","url":"https://huggingface.co/datasets/crodri/ccma_meteo_instruct","creator_name":"Carlos RodrÃ­guez","creator_url":"https://huggingface.co/crodri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["expert-generated","found","monolingual","Catalan","mit"],"keywords_longer_than_N":true},
	{"name":"defamation-japanese-twitter","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdefamation_japanese_twitter\n\t\n\n\n\t\n\t\t\n\t\tTwitteræ—¥æœ¬èªžèª¹è¬—ä¸­å‚·æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSNSã«ãŠã‘ã‚‹èª¹è¬—ä¸­å‚·æ¤œå‡ºã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ï¼Ž\n5,000ä»¶ã®æ—¥æœ¬èªžã®ãƒ„ã‚¤ãƒ¼ãƒˆã«ï¼Œãã‚Œãžã‚Œä»¥ä¸‹ã§å®šç¾©ã—ã¦ã„ã‚‹èª¹è¬—ä¸­å‚·ã®å¯¾è±¡è€…ã¨å†…å®¹ã‚’ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ã¾ã™ï¼Žã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ï¼Œ3äººã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚Šè¡Œã‚ã‚Œã¦ã„ã¾ã™ï¼Ž2022å¹´2æœˆ15æ—¥ã‹ã‚‰2022å¹´6æœˆ30æ—¥ã¾ã§ã®ãƒ„ã‚¤ãƒ¼ãƒˆã§ã™ï¼Ž\nå…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆã¯å«ã¾ã‚Œã¦ã„ãªã„ãŸã‚ï¼ŒTwitter APIã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åŽé›†ã—ã¦ãã ã•ã„ï¼Ž\nä¸­å‚·å¯¾è±¡(target)ã¨ä¸­å‚·å†…å®¹(label)ã®2é …ç›®ãŒã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ã¾ã™ï¼Ž\n\ntarget ï¼šãƒ†ã‚­ã‚¹ãƒˆãŒè©±é¡Œã«ã—ã¦ã„ã‚‹å¯¾è±¡è€…ã®åˆ†é¡ž\nlabel ï¼š targetã§é¸æŠžã•ã‚ŒãŸå¯¾è±¡è€…ã«å¯¾ã™ã‚‹èª¹è¬—ä¸­å‚·ã®ç¨®é¡žã®åˆ†é¡ž\n\næ–‡ã¨ã—ã¦æˆç«‹ã—ã¦ãŠã‚‰ãšæ„å‘³ã®å–ã‚Œãªã„ã‚‚ã®ã¯ãƒ©ãƒ™ãƒ«C(0)ã¨ã—ã¦ã„ã¾ã™ï¼Ž\n\n\t\n\t\t\ntarget\nå¯¾è±¡\nä¾‹\n\n\n\t\t\nA1(1)\n(äººç¨®ãƒ»æ€§åˆ¥ãƒ»è·æ¥­ãƒ»æ€æƒ³ãªã©ã‚’å…±é€šã¨ã™ã‚‹)ã‚°ãƒ«ãƒ¼ãƒ—â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kubota/defamation-japanese-twitter.","url":"https://huggingface.co/datasets/kubota/defamation-japanese-twitter","creator_name":"Issei","creator_url":"https://huggingface.co/kubota","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_easy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Easy set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discoverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"seth_corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SETH Corpus\n\t\n\nSNP named entity recognition corpus consisting of 630 PubMed citations.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@Article{SETH2016,\n    Title       = {SETH detects and normalizes genetic variants in text.},\n    Author      = {Thomas, Philippe and Rockt{\"{a}}schel, Tim and Hakenberg, J{\"{o}}rg and Lichtblau, Yvonne and Leser, Ulf},\n    Journal     = {Bioinformatics},\n    Year        = {2016},\n    Month       = {Jun},\n    Doi         =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigbio/seth_corpus.","url":"https://huggingface.co/datasets/bigbio/seth_corpus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"quac","keyword":"monolingual","description":"Question Answering in Context is a dataset for modeling, understanding,\nand participating in information seeking dialog. Data instances consist\nof an interactive dialog between two crowd workers: (1) a student who\nposes a sequence of freeform questions to learn as much as possible\nabout a hidden Wikipedia text, and (2) a teacher who answers the questions\nby providing short excerpts (spans) from the text. QuAC introduces\nchallenges not found in existing machine comprehension datasets: its\nquestions are often more open-ended, unanswerable, or only meaningful\nwithin the dialog context.","url":"https://huggingface.co/datasets/allenai/quac","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","fill-mask","dialogue-modeling","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"bbc_hindi_nli","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BBC Hindi NLI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\nEntailment_label is of 2 types - entailed and not-entailed.\nDataset can be used to train models for Natural Language Inference tasks inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli.","url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"atomic","keyword":"monolingual","description":"This dataset provides the template sentences and\nrelationships defined in the ATOMIC common sense dataset. There are\nthree splits - train, test, and dev.\n\nFrom the authors.\n\nDisclaimer/Content warning: the events in atomic have been\nautomatically extracted from blogs, stories and books written at\nvarious times. The events might depict violent or problematic actions,\nwhich we left in the corpus for the sake of learning the (probably\nnegative but still important) commonsense implications associated with\nthe events. We removed a small set of truly out-dated events, but\nmight have missed some so please email us (msap@cs.washington.edu) if\nyou have any concerns.","url":"https://huggingface.co/datasets/allenai/atomic","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"mwsc","keyword":"monolingual","description":"Examples taken from the Winograd Schema Challenge modified to ensure that answers are a single word from the context.\nThis modified Winograd Schema Challenge (MWSC) ensures that scores are neither inflated nor deflated by oddities in phrasing.","url":"https://huggingface.co/datasets/salesforce/mwsc","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-coreference-resolution","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mnist","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\nHalf of the image were drawn by Census Bureau employees and the other half by high school studentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ylecun/mnist.","url":"https://huggingface.co/datasets/ylecun/mnist","creator_name":"Yann LeCun","creator_url":"https://huggingface.co/ylecun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hate_offensive","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HateOffensive\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n\"count\": 3,\n \"hate_speech_annotation\": 0,\n \"offensive_language_annotation\": 0,\n \"neither_annotation\": 3,\n \"label\": 2,  # \"neither\"\n \"tweet\": \"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always takeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/hate_offensive.","url":"https://huggingface.co/datasets/legacy-datasets/hate_offensive","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"reasoning_bg","keyword":"monolingual","description":"This new dataset is designed to do reading comprehension in Bulgarian language.","url":"https://huggingface.co/datasets/mhardalov/reasoning_bg","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"portuguese-legal-sentences-v0","keyword":"monolingual","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de JustiÃ§a\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\n\t\n\t\tContributions\n\t\n\n@rufimelo99\nIf you use this work, please cite:\n@InProceedings{MeloSemantic,\n  author=\"Melo, Rui\n  and Santos, Pedro A.\n  and Dias, Jo{\\~a}o\",\n  editor=\"Moniz, Nuno\n  and Vale, Zita\n  andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0.","url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"SumarizaÃ§Ã£o e InformaÃ§Ã£o de decisÃµes: AplicaÃ§Ã£o de TÃ©cnicas de InteligÃªncia Artificial no Supremo Tribunal de JustiÃ§a (IRIS)","creator_url":"https://huggingface.co/stjiris","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"swahili","keyword":"monolingual","description":"The Swahili dataset developed specifically for language modeling task.\nThe dataset contains 28,000 unique words with 6.84M, 970k, and 2M words for the train,\nvalid and test partitions respectively which represent the ratio 80:10:10.\nThe entire dataset is lowercased, has no punctuation marks and,\nthe start and end of sentence markers have been incorporated to facilitate easy tokenization during language modeling.","url":"https://huggingface.co/datasets/uestc-swahili/swahili","creator_name":"uestc-swahili","creator_url":"https://huggingface.co/uestc-swahili","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"hda_nli_hindi","keyword":"monolingual","description":"This dataset is a recasted version of the Hindi Discourse Analysis Dataset used to train models for Natural Language Inference Tasks in Low-Resource Languages like Hindi.","url":"https://huggingface.co/datasets/NirantK/hda_nli_hindi","creator_name":"Nirant Kasliwal","creator_url":"https://huggingface.co/nirantk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts on /r/AskReddit, annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.\n'subreddit.id': the base-36 Reddit ID ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions.","url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"arcd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"arcd\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 1.94 MB\nSize of the generated dataset: 1.70 MB\nTotal amount of disk used: 3.64 MB\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hsseinmz/arcd.","url":"https://huggingface.co/datasets/hsseinmz/arcd","creator_name":"Hussein Mozannar","creator_url":"https://huggingface.co/hsseinmz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"COCO-AB","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGeneral Information\n\t\n\nTitle: COCO-AB\nDescription: \nThe COCO-AB dataset is an extension of the COCO 2014 training set, enriched with additional annotation byproducts (AB). \nThe data includes 82,765 reannotated images from the original COCO 2014 training set. \nIt has relevance in computer vision, specifically in object detection and location. \nThe aim of the dataset is to provide a richer understanding of the images (without extra costs) by recording additional actions and interactionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/COCO-AB.","url":"https://huggingface.co/datasets/coallaoh/COCO-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","crowdsourced","monolingual","https://huggingface.co/datasets/HuggingFaceM4/COCO","English"],"keywords_longer_than_N":true},
	{"name":"the-2022-trucker-strike-on-reddit","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for the-2022-trucker-strike-on-reddit\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains all the comments under the /r/Ottawa convoy megathreads.\nComments are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit comment.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit.","url":"https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"coco","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Coco\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMicrosoft COCO (Common Objects in Context) dataset.\nBefore using this dataset, please make sure Huggingface datasets\nand Lance are installed.\npip install datasets[vision] pylance\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/eto-ai/coco.","url":"https://huggingface.co/datasets/eto-ai/coco","creator_name":"Eto Labs","creator_url":"https://huggingface.co/eto-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["object-detection","crowdsourced","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"germeval_14","keyword":"monolingual","description":"The GermEval 2014 NER Shared Task builds on a new dataset with German Named Entity annotation with the following properties:    - The data was sampled from German Wikipedia and News Corpora as a collection of citations.    - The dataset covers over 31,000 sentences corresponding to over 590,000 tokens.    - The NER annotation uses the NoSta-D guidelines, which extend the TÃ¼bingen Treebank guidelines,      using four main NER categories with sub-structure, and annotating embeddings among NEs      such as [ORG FC Kickers [LOC Darmstadt]].","url":"https://huggingface.co/datasets/GermanEval/germeval_14","creator_name":"GermanEval","creator_url":"https://huggingface.co/GermanEval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro_sts","keyword":"monolingual","description":"The RO-STS (Romanian Semantic Textual Similarity) dataset contains 8628 pairs of sentences with their similarity score. It is a high-quality translation of the STS benchmark dataset.","url":"https://huggingface.co/datasets/dumitrescustefan/ro_sts","creator_name":"Dumitrescu Stefan","creator_url":"https://huggingface.co/dumitrescustefan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"idk-mrc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for IDK-MRC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nI(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers answerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA, the new unanswerable question in IDK-MRC is generated using a question generation model and human-written question. Each paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rifkiaputri/idk-mrc.","url":"https://huggingface.co/datasets/rifkiaputri/idk-mrc","creator_name":"Rifki Afina Putri","creator_url":"https://huggingface.co/rifkiaputri","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse whatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"bionlp_st_2011_ge","keyword":"monolingual","description":"The BioNLP-ST GE task has been promoting development of fine-grained information extraction (IE) from biomedical\ndocuments, since 2009. Particularly, it has focused on the domain of NFkB as a model domain of Biomedical IE.\nThe GENIA task aims at extracting events occurring upon genes or gene products, which are typed as \"Protein\"\nwithout differentiating genes from gene products. Other types of physical entities, e.g. cells, cell components,\nare not differentiated from each other, and their type is given as \"Entity\".","url":"https://huggingface.co/datasets/bigbio/bionlp_st_2011_ge","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-3.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"wsd_plwordnet_glex","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWord Sense Disambiguation Corpora for Polish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWSD plWordNet GLEX is a sense inventory based on plWordNet 4.5 adapted to word sense disambiguation (WSD) task in Polish language.\nIt consists of 3 distinct files, manually annotated with senses from plWordNet-4.5 sense inventory. \n\n...\n\nFor more details, please check the following publication:\n@InProceedings{10.1007/978-3-031-08754-7_70,\n  author=\"Janz, Arkadiusz\n  and Dziob, Agnieszka\n  and Oleksy, Marcinâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clarin-knext/wsd_plwordnet_glex.","url":"https://huggingface.co/datasets/clarin-knext/wsd_plwordnet_glex","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","word-sense-disambiguation","expert-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"spanextract","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lexi/spanextract.","url":"https://huggingface.co/datasets/Lexi/spanextract","creator_name":"Liu","creator_url":"https://huggingface.co/Lexi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"REPV","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {ÐÑ€Ñ‚ÐµÐ¼ ÐÐ¼ÐµÐ½Ñ‚ÐµÑ, Ð˜Ð»ÑŒÑ Ð›ÑƒÐ±ÐµÐ½ÐµÑ†, ÐÐ¸ÐºÐ¸Ñ‚Ð° Ð”Ð°Ð²Ð¸Ð´Ñ‡ÑƒÐº},\n  title = {ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ð°Ñ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ñ‚ÐµÐ½ÐºÐ¾Ð² Ñ€ÐµÑ‡Ð¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","url":"https://huggingface.co/datasets/Aniemore/REPV","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"home-depot","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Ukhushn/home-depot\n\t\n\n","url":"https://huggingface.co/datasets/Ukhushn/home-depot","creator_name":"Umair Khushnood","creator_url":"https://huggingface.co/Ukhushn","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","no-annotation","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"osdg_cd","keyword":"monolingual","description":"The OSDG Community Dataset (OSDG-CD) is a public dataset of thousands of text excerpts, which were validated by approximately 1,000 OSDG Community Platform (OSDG-CP) citizen scientists from over 110 countries, with respect to the Sustainable Development Goals (SDGs).","url":"https://huggingface.co/datasets/Filippo/osdg_cd","creator_name":"Filippo B","creator_url":"https://huggingface.co/Filippo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"frenchmedmcqa","keyword":"monolingual","description":"FrenchMedMCQA","url":"https://huggingface.co/datasets/qanastek/frenchmedmcqa","creator_name":"yanis labrak","creator_url":"https://huggingface.co/qanastek","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice","multiple-choice-qa","open-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"QA_on_SLA","keyword":"monolingual","description":"rajeshvarma/QA_on_SLA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rajeshvarma/QA_on_SLA","creator_name":"sai rajesh varma","creator_url":"https://huggingface.co/rajeshvarma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotations","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"commonvoice_accent_test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test.","url":"https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"panda","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PANDA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPANDA (Perturbation Augmentation NLP DAtaset) consists of approximately 100K pairs of crowdsourced human-perturbed text snippets (original, perturbed). Annotators were given selected terms and target demographic attributes, and instructed to rewrite text snippets along three demographic axes: gender, race and age, while preserving semantic meaning. Text snippets were sourced from a range of text corpora (BookCorpus, Wikipedia, ANLIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/panda.","url":"https://huggingface.co/datasets/facebook/panda","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"coda","keyword":"monolingual","description":"*The Color Dataset* (CoDa) is a probing dataset to evaluate the representation of visual properties in language models. CoDa consists of color distributions for 521 common objects, which are split into 3 groups: Single, Multi, and Any.","url":"https://huggingface.co/datasets/corypaik/coda","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"beans","keyword":"monolingual","description":"Beans is a dataset of images of beans taken in the field using smartphone\ncameras. It consists of 3 classes: 2 disease classes and the healthy class.\nDiseases depicted include Angular Leaf Spot and Bean Rust. Data was annotated\nby experts from the National Crops Resources Research Institute (NaCRRI) in\nUganda and collected by the Makerere AI research lab.","url":"https://huggingface.co/datasets/nateraw/beans","creator_name":"Nate Raw","creator_url":"https://huggingface.co/nateraw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"recast","keyword":"monolingual","description":"A diverse collection of tasks recasted as natural language inference tasks.","url":"https://huggingface.co/datasets/tasksource/recast","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tr-qnli","keyword":"monolingual","description":"nlpyeditepe/tr-qnli dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nlpyeditepe/tr-qnli","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","found","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-accent-proc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-proc.","url":"https://huggingface.co/datasets/DTU54DL/common-accent-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-accent-augmented-proc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc.","url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"FOCALtask","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/V12X-ksr/FOCALtask.","url":"https://huggingface.co/datasets/V12X-ksr/FOCALtask","creator_name":"Kushal S Raj","creator_url":"https://huggingface.co/V12X-ksr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"beans-outlier","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"beans-outlier\"\n\t\n\nðŸ“š This dataset is an enhancved version of the ibean project of the AIR lab.\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\n\n\t\n\t\t\n\t\tExplore the Dataset\n\t\n\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/beans-outlier\n\nOr you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/renumics/beans-outlier.","url":"https://huggingface.co/datasets/renumics/beans-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"test_pq","keyword":"monolingual","description":"This is a test dataset.","url":"https://huggingface.co/datasets/changxin/test_pq","creator_name":"changxin","creator_url":"https://huggingface.co/changxin","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","original","Chamorro"],"keywords_longer_than_N":true},
	{"name":"bioleaflets-biomedical-ner","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BioLeaflets Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBioLeaflets is a biomedical dataset for Data2Text generation. It is a corpus of 1,336 package leaflets of medicines authorised in Europe, which were obtained by scraping the European Medicines Agency (EMA) website. \nPackage leaflets are included in the packaging of medicinal products and contain information to help patients use the product safely and appropriately. \nThis dataset comprises the large majority (âˆ¼ 90%) ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner.","url":"https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner","creator_name":"Ruslan Yermak","creator_url":"https://huggingface.co/ruslan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster04","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster04","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"cifar10_quality_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/cifar10_quality_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"asrs-aviation-reports","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ASRS Aviation Incident Reports\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset collects 47,723 aviation incident reports published in the Aviation Safety Reporting System (ASRS) database maintained by NASA. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Dataset can be used to train a model for abstractive and extractive summarization. The model performance is measured by how high the output summary's ROUGE score for a given narrative account of an aviationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elihoole/asrs-aviation-reports.","url":"https://huggingface.co/datasets/elihoole/asrs-aviation-reports","creator_name":"Elijah Hoole","creator_url":"https://huggingface.co/elihoole","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fin","keyword":"monolingual","description":"[FIN NER dataset](https://aclanthology.org/U15-1010.pdf)","url":"https://huggingface.co/datasets/tner/fin","creator_name":"TNER","creator_url":"https://huggingface.co/tner","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog-filtered","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialogFiltered is a filtered version of the ProsocialDialog dataset.\nMultiple versions are present:\n\nIn train_no_casual, rows with the label \"casual\" have been filtered out as a starting point.\nIn train_no_possibly, rows with \"possibly needs caution\" have been filtered out.\nIn train_no_probably, rows with \"probably needs caution\" have been filtered out, as I found those to be largely pointless as well, leaving only \"needs caution\" and \"needs intervention\".â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered.","url":"https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered","creator_name":"Josh Oliver","creator_url":"https://huggingface.co/Englishman2022","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"dialogsum-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding manually labeled summaries and topics.\n\n\t\n\t\n\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/dialogsum-ru.","url":"https://huggingface.co/datasets/d0rj/dialogsum-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_ensembl-org","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_ensembl-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"lotte","keyword":"monolingual","description":"LoTTE Passages Dataset for ColBERTv2","url":"https://huggingface.co/datasets/colbertv2/lotte","creator_name":"colbertv2","creator_url":"https://huggingface.co/colbertv2","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_wiki-openmoko-org","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_wiki-openmoko-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster08","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster08","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"hatecheck-german","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german.","url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster21","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster21","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"hansard_speech","keyword":"monolingual","description":"A dataset containing every speech in the House of Commons from May 1979-July 2020.","url":"https://huggingface.co/datasets/biglam/hansard_speech","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-class-classification","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"squad-v1.1-t5-question-generation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad-v1.1-t5-question-generation\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modified Stanford Question Answering Dataset (SQuAD) to suit question generation with All Questions in One Line (AQOL) just like in Transformer-based End-to-End Question Generation\nspecifically for the T5 family of models. The prefix is generate questions:  so that the task can be unique to a trained model.\nCheck out the generation notebook here.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation.","url":"https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","extended|squad","English"],"keywords_longer_than_N":true},
	{"name":"german_argument_mining","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated German Legal Decision Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 200 randomly chosen judgments. In these judgments a legal expert annotated the components\nconclusion, definition and subsumption of the German legal writing style Urteilsstil.\n\"Overall 25,075 sentences are annotated. 5% (1,202) of these sentences are marked as conclusion, 21% (5,328) as\ndefinition, 53% (13,322) are marked as subsumption and the remaining 21% (6,481) as other.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/german_argument_mining.","url":"https://huggingface.co/datasets/joelniklaus/german_argument_mining","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","found"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","description":"Lorem ipsum","url":"https://huggingface.co/datasets/j-krzywdziak/test","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"hatecheck-dutch","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch.","url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ddisco","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DDisco\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe DDisco dataset is a dataset which can be used to train models to classify levels of coherence in danish discourse. Each entry in the dataset is annotated with a discourse coherence label (rating from 1 to 3):\n1: low coherence (difficult to understand, unorganized, contained unnecessary details and can not be summarized briefly and easily)\n2: medium coherence\n3: high coherence (easy to understand, well organized, only containâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/ddisco.","url":"https://huggingface.co/datasets/alexandrainst/ddisco","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","Danish"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster05","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster05","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"FR_NFR_Spanish_requirements_classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReSpa: Published version of dataset used for paper 'Towards an automatic requirements classification in a new Spanish dataset'\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nProject: Project's Identifier from which the requirements were obtained.\nRequirement: Description of the software requirement.\nFinal label: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification.","url":"https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster02","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster02","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"fstdt-quotes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FSTDT Quotes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nFSTDT Quotes is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{\n  \"id\": \"G\",\n  \"submitter\": \"anonymous\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes.","url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-spanish","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish.","url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster26","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster26","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"understanding_fables","keyword":"monolingual","description":"This task aims to measure the ability of computational models to understand short narratives, by identifying the most \nappropriate moral for a given fable from a set of five alternatives.","url":"https://huggingface.co/datasets/demelin/understanding_fables","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","multiple-choice-qa","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster17","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster17","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_msdn-microsoft-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_msdn-microsoft-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"TruthfulQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA: Measuring How Models Mimic Human Falsehoods\nWe propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/TruthfulQA.","url":"https://huggingface.co/datasets/domenicrosati/TruthfulQA","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","closed-domain-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"FB15k-237","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FB15k-237\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB15k-237 is a link prediction dataset created from FB15k. While FB15k consists of 1,345 relations, 14,951 entities, and 592,213 triples, many triples are inverses that cause leakage from the training to testing and validation splits. FB15k-237 was created by Toutanova and Chen (2015) to ensure that the testing and evaluation datasets do not have inverse relation test leakage. In summary, FB15k-237 dataset contains 310,079â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KGraph/FB15k-237.","url":"https://huggingface.co/datasets/KGraph/FB15k-237","creator_name":"YHLong","creator_url":"https://huggingface.co/KGraph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","found","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"P3","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for P3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nP3 (Public Pool of Prompts) is a collection of prompted English datasets covering a diverse set of NLP tasks. A prompt is the combination of an input template and a target template. The templates are functions mapping a data example into natural language for the input and target sequences. For example, in the case of an NLI dataset, the data example would include fields for Premise, Hypothesis, Label. An input template would be Ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/P3.","url":"https://huggingface.co/datasets/bigscience/P3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"apps","keyword":"monolingual","description":"APPS is a benchmark for Python code generation, it includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges, for more details please refer to this paper: https://arxiv.org/pdf/2105.09938.pdf.","url":"https://huggingface.co/datasets/codeparrot/apps","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"habr_qna","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Habr QnA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset of questions and answers scraped from Habr QnA. There are 723430 asked questions with answers, comments and other metadata. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly Russian with source code in different languages.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nData fields can be previewed on the dataset card page.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nAll 723430 examples are in the train split, there is no validationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/its5Q/habr_qna.","url":"https://huggingface.co/datasets/its5Q/habr_qna","creator_name":"its5Q","creator_url":"https://huggingface.co/its5Q","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","open-domain-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NPSC_orto","keyword":"monolingual","description":"The Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by SprÃ¥kbanken at the National Library in Norway.\n\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian BokmÃ¥l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount of metadata that is included in the original corpus. Through the speaker id there is additional information about the speaker, like gender, age, and place of birth (ie dialect). Through the proceedings id the corpus can be linked to the official proceedings from the meetings.\n\nThe corpus is in total sound recordings from 40 entire days of meetings. This amounts to 140 hours of speech, 65,000 sentences or 1.2 million words.\n\nThis dataset builds on this corpus. In addition it adds two columns with machine generated orthographic text.","url":"https://huggingface.co/datasets/NbAiLab/NPSC_orto","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"nlmchem","keyword":"monolingual","description":"NLM-Chem corpus consists of 150 full-text articles from the PubMed Central Open Access dataset,\ncomprising 67 different chemical journals, aiming to cover a general distribution of usage of chemical\nnames in the biomedical literature.\nArticles were selected so that human annotation was most valuable (meaning that they were rich in bio-entities,\nand current state-of-the-art named entity recognition systems disagreed on bio-entity recognition.","url":"https://huggingface.co/datasets/bigbio/nlmchem","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"qg_zhquad","keyword":"monolingual","description":"[Chinese SQuAD](https://github.com/junzeng-pluto/ChineseSquad) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_zhquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cedr-m7","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CEDR-M7\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/cedr-m7.","url":"https://huggingface.co/datasets/Aniemore/cedr-m7","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"DuET-PD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDuET-PD: Dual Evaluation for Trust in Persuasive Dialogues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDuET-PD is a comprehensive framework and dataset designed to evaluate the robustness and adaptability of Large Language Models (LLMs) in multi-turn persuasive dialogues. The dataset probes an LLM's ability to navigate the critical tension between resisting misinformation (robustness) and accepting valid corrections (adaptability).\nThe \"Dual\" aspect of DuET-PD reflects its two core evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Incomple/DuET-PD.","url":"https://huggingface.co/datasets/Incomple/DuET-PD","creator_name":"Bryan Tan (Chen Zhengyu)","creator_url":"https://huggingface.co/Incomple","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","conversational","multiple-choice-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"multiglue","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MultiGLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a combination of the cola, mrpc, qnli, qqp, rte, sst2, and wnli subsets of the GLUE dataset. Its intended use is to benchmark language models on multitask binary classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nLike the GLUE dataset, this dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/multiglue.","url":"https://huggingface.co/datasets/MtCelesteMa/multiglue","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","extended|glue"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_medium","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Medium set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discoverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"CLIP-Kinetics700","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CLIP-Kinetics70\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCLIP-Kinetics700 is a compressed version of the Kinetics700 dataset using OpenAI's CLIP model.\nThe original dataset is ~700 GB making it difficult to use and hold in memory on one machine. By downsampling each video to 1 FPS and encoding the frames using CLIP we we're able to compress the dataset to ~8 GB making it very memory-friendly and easy to use.\n\n\t\n\t\t\n\t\tDataset Preprocessingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iejMac/CLIP-Kinetics700.","url":"https://huggingface.co/datasets/iejMac/CLIP-Kinetics700","creator_name":"Maciej Kilian","creator_url":"https://huggingface.co/iejMac","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"c4-faqs","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises of open-domain question-answer pairs obtained from extracting 150K FAQ URLs from C4 dataset. Please refer to the original paper and dataset card for more details.\nYou can load C4-FAQs as follows:\nfrom datasets import load_dataset\nc4_faqs_dataset = load_dataset(\"vishal-burman/c4-faqs\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nC4-FAQs is mainly intended for open-domain end-to-end questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vishal-burman/c4-faqs.","url":"https://huggingface.co/datasets/vishal-burman/c4-faqs","creator_name":"Vishal Burman","creator_url":"https://huggingface.co/vishal-burman","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-simplification","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"magpie","keyword":"monolingual","description":"The MAGPIE corpus is a large sense-annotated corpus of potentially idiomatic expressions (PIEs), based on the British National Corpus (BNC). Potentially idiomatic expressions are like idiomatic expressions, but the term also covers literal uses of idiomatic expressions, such as 'I leave work at the end of the day.' for the idiom 'at the end of the day'. This version of the dataset reflects the filtered subset used by Dankers et al. (2022) in their investigation on how PIEs are represented by NMT models. Authors use 37k samples annotated as fully figurative or literal, for 1482 idioms that contain nouns, numerals or adjectives that are colours (which they refer to as keywords). Because idioms show syntactic and morphological variability, the focus is mostly put on nouns. PIEs and their context are separated using the original corpusâ€™s word-level annotations.","url":"https://huggingface.co/datasets/gsarti/magpie","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"periodontal-reasoning-40k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPeriodontal-Reasoning-40k\n\t\n\n40,000 periodontal clinical reasoning examples for off-policy RLHF (KTO/DPO).\nFormat (JSONL, one per line): prompt, completion, label âˆˆ {1,-1}\nExample:\n{\"prompt\": \"A patient's plaque score was 35% at baseline and 1% at followâ€‘up. Determine whether the improvement is favourable according to BSP criteria (â‰¤20% plaque or â‰¥50% reduction).\", \"completion\": \"The improvement is favourable.\", \"label\": 1}\nSplit: train: 40,000 (data/train.jsonl)\nIntended use: KTO/DPO;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Wildstash/periodontal-reasoning-40k.","url":"https://huggingface.co/datasets/Wildstash/periodontal-reasoning-40k","creator_name":"ArnavS","creator_url":"https://huggingface.co/Wildstash","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"aqua_rat","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AQUA-RAT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA large-scale dataset consisting of approximately 100,000 algebraic word problems.\nThe solution to each question is explained step-by-step using natural language.\nThis data is used to train a program generation model that learns to generate the explanation,\nwhile generating the program that solves the question.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/aqua_rat.","url":"https://huggingface.co/datasets/deepmind/aqua_rat","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"crosswoz","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CrossWOZ\n\t\n\n\nRepository: https://github.com/thu-coai/CrossWOZ\nPaper: https://aclanthology.org/2020.tacl-1.19/\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('crosswoz')\nontology = load_ontology('crosswoz')\ndatabase = load_database('crosswoz')\n\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/crosswoz.","url":"https://huggingface.co/datasets/ConvLab/crosswoz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Chinese","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Quasimodo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Quasimodo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA commonsense knowledge base constructed automatically from question-answering forums and query logs.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nCan be useful for tasks requiring external knowledge such as question answering.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n  \"subject\": \"elephant\",\n  \"predicate\": \"has_body_part\"\n  \"object\": \"trunk\",\n  \"modality\": \"TBC[so long trunks] x#x2 //â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aunsiels/Quasimodo.","url":"https://huggingface.co/datasets/Aunsiels/Quasimodo","creator_name":"Julien Romero","creator_url":"https://huggingface.co/Aunsiels","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"monolingual","description":"CNN/DailyMail non-anonymized summarization dataset.\n\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/ccdv/cnn_dailymail","creator_name":"ccdv","creator_url":"https://huggingface.co/ccdv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Rejection Sampling Phi-2 with OpenAssistant RM\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm.","url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"AlizÃ©e Pace","creator_url":"https://huggingface.co/alizeepace","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"quickdraw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Quick, Draw!\n\t\n\nThis is a processed version of Google's Quick, Draw dataset to be compatible with the latest versions of ðŸ¤— Datasets that support .parquet files. NOTE: this dataset only contains the \"preprocessed_bitmaps\" subset of the original dataset.\n","url":"https://huggingface.co/datasets/Xenova/quickdraw","creator_name":"Joshua","creator_url":"https://huggingface.co/Xenova","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wnli-ca","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWNLI-ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\"A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution. The schema takes its name from Terry Winograd.\" Source: The Winograd Schema Challenge.\nThe Winograd NLI dataset presents 855 sentence pairs, in which the first sentence contains an ambiguity and the second one aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/wnli-ca.","url":"https://huggingface.co/datasets/projecte-aina/wnli-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bbbp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for bbbp\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbbbp is a dataset included in MoleculeNet. This dataset has binary labels of blood-brain barrier penetration(permeability).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: blood-brain barrier penetration(permeability)\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10 train/valid/test splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bbbp.","url":"https://huggingface.co/datasets/zpn/bbbp","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"RSNA-ATD2023","keyword":"monolingual","description":"The dataset is the processed version of Kaggle Competition: RSNA 2023 Abdominal Trauma Detection.\nIt comprises of segmentation of 205 series of CT scans with 5 classes (liver, spleen, right_kidney, \nleft_kidney, bowel).","url":"https://huggingface.co/datasets/ziq/RSNA-ATD2023","creator_name":"ziq","creator_url":"https://huggingface.co/ziq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","other","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"pubmed_qa","keyword":"monolingual","description":"PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\nstatins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\nPubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\nEach PubMedQA instance is composed of (1) a question which is either an existing research article\ntitle or derived from one, (2) a context which is the corresponding abstract without its conclusion,\n(3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\nand (4) a yes/no/maybe answer which summarizes the conclusion.\nPubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\nquantitative contents, is required to answer the questions.","url":"https://huggingface.co/datasets/highnote/pubmed_qa","creator_name":"Highnote Health, Inc.","creator_url":"https://huggingface.co/highnote","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHokchia Audio Dataset\n\t\n\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Minâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"instruct-legal-refugiados-es","keyword":"monolingual","description":"\n    \n\nLegal Refugiados: Un dataset para QA en temas legales de refugio, asilo y protecciÃ³n internacional.\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nInstruction Question-Answering Legal Refugiados es una colecciÃ³n de instrucciones extraÃ­das de una gran cantidad de documentos legales del gobierno de EspaÃ±a, principalmente, y de otras instituciones de la UE y tambiÃ©n de otros paÃ­ses de habla hispana como MÃ©xico o Venezuela. Todos ellos estÃ¡n relacionados con leyes y disposiciones legales sobre ciudadanosâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es.","url":"https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es","creator_name":"Eduardo MuÃ±oz Sala","creator_url":"https://huggingface.co/edumunozsala","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","extractive-qa","distillabel","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-train","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 523\nNumber of unique topics: 9\nNumber of unique subtopics: 48\nLast updated: 2025-05-24\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-train.","url":"https://huggingface.co/datasets/magichampz/medical-cyber-train","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"CUADCapOnLiabilityLegalBenchClassification","keyword":"monolingual","description":"\n  CUADCapOnLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a cap on liability upon the breach of a party's obligation. This includes time limitation for the counterparty to bring claims or maximum amount for recovery.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GravityBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGravity-Bench Dataset\n\t\n\n   \nThis dataset contains the benchmark data for Gravity-Bench, a benchmark for evaluating AI agents on discovering gravitational physics through iterative observation and data analysis.\n\n  \n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes 206 physics discovery tasks across various gravitational scenarios.\nEach task provides:\n\nTask prompt and expected units\nHigh-precision simulation data from two-body gravitational systems\nGround truth answers for evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GravityBench/GravityBench.","url":"https://huggingface.co/datasets/GravityBench/GravityBench","creator_name":"GravityBench","creator_url":"https://huggingface.co/GravityBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NanoNQ-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNQ.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNQ-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNQ","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Assamese"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un publico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test","creator_name":"riccardo schillaci","creator_url":"https://huggingface.co/Riccardoschillaci7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"PubMedQA-MetaGenBlendedRAG","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPubMedQA-MetaGen: Metadata-Enriched PubMedQA Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPubMedQA-MetaGen is a metadata-enriched version of the PubMedQA biomedical question-answering dataset, created using the MetaGenBlendedRAG enrichment pipeline. The dataset contains both the original and enriched versions of the corpus, enabling direct benchmarking of retrieval-augmented and semantic search approaches in biomedical NLP.\n\n\n\t\n\t\t\n\t\tFiles Provided\n\t\n\n\nPubMedQA_original_corpus.csv\nThis fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG.","url":"https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG","creator_name":"Shivam Raj Solanki","creator_url":"https://huggingface.co/Shivam6693","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tt-azatliq-crawl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAzatliqCrawl is a document-level dataset in Tatar language based on Azatliq newspaper.\nThere are two versions released: the noisy dataset, which has no filtering, and the clean dataset,  which has a variety of filters applied (language identification using fasstext BOW and deduplication using MinHashLSH with number of permutations equal to 128 and threshold equal to 0.9), though it naturally has a fair amount of noise itself. Each dataset is released in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl.","url":"https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl","creator_name":"VeryREAL","creator_url":"https://huggingface.co/veryrealtatarperson","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"dust-devil-detection","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdust-devil-detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-09\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: dust_devil\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/dust-devil-detection.","url":"https://huggingface.co/datasets/gremlin97/dust-devil-detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MMS-VPR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset\n\t\n\nMultimodal Street-Level Visual Place Recognition Dataset (MMS-VPR) is a novel, open-access dataset designed to advance research in visual place recognition (VPR) and multimodal urban scene understanding. This dataset focuses on complex, fine-grained, and pedestrian-only urban environments, addressing a significant gap in existing VPR datasets that often rely on vehicle-based imagery from road networks and overlookâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.","url":"https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR","creator_name":"Yiwei Ou","creator_url":"https://huggingface.co/Yiwei-Ou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","multi-class-image-classification","human-annotated","found"],"keywords_longer_than_N":true},
	{"name":"germanrag-scored","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from DiscoResearch/germanrag with added cosine-similarity scores.\nThe scores between 'question' and 'answer' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\nIf you want to filter negative answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity4LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity4LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 4).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"code-instruments-monetaires-medailles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des instruments monÃ©taires et des mÃ©dailles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"eli-why-only-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example is a JSON object with:\n{\n  \"Question\": \"Why does ice float in water?\",\n  \"Domain\": \"STEM\",\n  \"Discipline\": \"physics\"\n}\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nGeneration Process:Questions were few-shot generated using GPT-4, based on a seed set of 50 questions from Sulik et al. (2023). The generated questions were then manually filtered to remove duplicates, ensure clarity, and balance disciplinary diversity.\nCuration:Curation and verification were performed byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-only-questions.","url":"https://huggingface.co/datasets/INK-USC/eli-why-only-questions","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","expert-verified","monolingual"],"keywords_longer_than_N":true},
	{"name":"samromur_milljon","keyword":"monolingual","description":"SamrÃ³mur MilljÃ³n consists of approximately 1 million of speech recordings (967 hours) collected through the platform samromur.is; the transcripts accompanying these recordings were automatically verified using various ASR systems such as: Wav2Vec, Whisper and NeMo.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_milljon","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-Shuffle","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle.","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JavaneseIMDBClassification","keyword":"monolingual","description":"\n  JavaneseIMDBClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge Movie Review Dataset translated to Javanese. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/w11wo/nlp-datasets#javanese-imdb\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JavaneseIMDBClassification.","url":"https://huggingface.co/datasets/mteb/JavaneseIMDBClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Assamese"],"keywords_longer_than_N":true},
	{"name":"finewebedu-sft","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFineWeb-Edu Supervised Finetuning Dataset\n\t\n\n\n\t\n\t\t\n\t\tModel Description\n\t\n\nThis dataset is designed for training language models to generate supervised finetuning data from raw text. It consists of text passages and corresponding question-answer pairs in JSONLines format.\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\nThe primary purpose of this dataset is to enable large language models (LLMs) to generate high-quality supervised finetuning data from raw text inputs, useful for creating custom datasets forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/finewebedu-sft.","url":"https://huggingface.co/datasets/agentlans/finewebedu-sft","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","abstractive-qa","machine-generated"],"keywords_longer_than_N":true},
	{"name":"aging_reg_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAging ReG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nAging ReG is a manually curated database of aging factors focusing on regulatory relationships during aging with experimental evidence in humans. This dataset provides valuable insights into the molecular mechanisms of aging and the regulatory networks involved.\n\n\t\n\t\t\n\t\tKey Details\n\t\n\n\nOrganism: Human  \nDescription: Manually curated database of aging factors, focusing on regulatory relationships during aging with experimental evidence inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Venkatachalam/aging_reg_dataset.","url":"https://huggingface.co/datasets/Venkatachalam/aging_reg_dataset","creator_name":"Venkatachalam Subramanian Periya Subbu","creator_url":"https://huggingface.co/Venkatachalam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"wb-feedbacks","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains product reviews from the Russian marketplace Wildberries, collected by mining about The dataset was collected by bruteforcing possible product identifiers (about 230 million) and querying all available feedbacks for them. The data are stored in zstd-archives containing jsonl-files. The 'nmId' in the dataset usually corresponds to the valid product article on the site, but sometimes reviews areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-feedbacks.","url":"https://huggingface.co/datasets/nyuuzyou/wb-feedbacks","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"open_access","keyword":"monolingual","description":"The PMC Open Access Subset includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \n\nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than a traditional copyrighted work. \n\nThe PMC Open Access Subset is one part of the PMC Article Datasets","url":"https://huggingface.co/datasets/pmc/open_access","creator_name":"PubMed Central","creator_url":"https://huggingface.co/pmc","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"journals","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Historical Russian Technical Journal Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains images of pages from old Russian technical journals with descriptions generated using Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nRussian (ru): All journal pages are in Russian with corresponding Russian descriptions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nThe dataset consists of:\n\nImage files (.jpg format)\nCorresponding descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/journals.","url":"https://huggingface.co/datasets/nyuuzyou/journals","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"XCOPA-eu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for XCOPA-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXCOPA-eu is the professional translation to Basque of the English COPA dataset (Roemmmele et al., 2011),\nin the spirit of the XCOPA effort (Ponti et al., 2020). \nCOPA is a dataset of causal commmonsense reasoning that focuses on cause-effect relationships between a\npremise and two choices.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/XCOPA-eu.","url":"https://huggingface.co/datasets/HiTZ/XCOPA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multiple-choice","natural-language-inference","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"SCDDAuditsLegalBenchClassification","keyword":"monolingual","description":"\n  SCDDAuditsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer conducts audits of suppliers to evaluate supplier compliance with company standards for trafficking and slavery in supply chains? The disclosure shall specify if theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDAuditsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDDAuditsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Oriya"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedicalSciencesRetrieval","keyword":"monolingual","description":"\n  R2MEDMedicalSciencesRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedical-Sciences retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Medical-Sciences\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedicalSciencesRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Medical-Sciences"],"keywords_longer_than_N":true},
	{"name":"geolayers","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGeolayers-Data\n\t\n\n\n\n -->\nThis dataset card contains usage instructions and metadata for all data-products released with our paper:Using Multiple Input Modalities can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery. We release 3 modified versions of 3 benchmark datasets spanning land-cover segmentation, tree-cover regression, and multi-label land-cover classification tasks. These datasets are augmented with auxiliary, geographic inputs. A full list ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arjunrao2000/geolayers.","url":"https://huggingface.co/datasets/arjunrao2000/geolayers","creator_name":"Arjun Rao","creator_url":"https://huggingface.co/arjunrao2000","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","found","monolingual","SustainBench"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"monolingual","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench2025.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench2025","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mouse-muscle-aging-atlas-snRNAseq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMouse Skeletal Muscle Aging Atlas (sn/scRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus and single-cell RNA sequencing (sn/scRNA-seq) data specifically focusing on the mouse skeletal muscle across different age groups. It serves as a valuable resource for investigating cell-type-specific gene expression changes and cellular composition shifts that occur during the aging process in a crucial mammalian model system.\nThe data was sourced from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/mouse-muscle-aging-atlas-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/mouse-muscle-aging-atlas-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicensorLegalBenchClassification","keyword":"monolingual","description":"\n  CUADAffiliateLicenseLicensorLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause describes a license grant by affiliates of the licensor or that includes intellectual property of affiliates of the licensor.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"escher-vismin","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-vismin\n\t\n\nVismin dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-vismin","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Maithili"],"keywords_longer_than_N":true},
	{"name":"isabelleps","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIsabelle Premise Selection\n\t\n\npremise selection evaluation dataset for Isabelle, sourced from MAPL (https://huggingface.co/datasets/Simontwice/premise_selection_in_isabelle).\n","url":"https://huggingface.co/datasets/hcju/isabelleps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MACHINE-AUGMENTED PROOFS LIBRARY (MAPL)","English"],"keywords_longer_than_N":true},
	{"name":"PunjabiNewsClassification","keyword":"monolingual","description":"\n  PunjabiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Punjabi dataset for 2-class classification of Punjabi news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-punjabi/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"PunjabiNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PunjabiNewsClassification.","url":"https://huggingface.co/datasets/mteb/PunjabiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/punjabi_news_classification"],"keywords_longer_than_N":true},
	{"name":"math-dataset-instruction","keyword":"monolingual","description":"sanjay-29-29/math-dataset-instruction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjay-29-29/math-dataset-instruction","creator_name":"Sanjay","creator_url":"https://huggingface.co/sanjay-29-29","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-val","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 112\nNumber of unique topics: 9\nNumber of unique subtopics: 48\nLast updated: 2025-05-28\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-val.","url":"https://huggingface.co/datasets/magichampz/medical-cyber-val","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"capivara-plugin-orchestration","keyword":"monolingual","description":"\n\t\n\t\t\n\t\t# Dataset Card for Capivara Plugin Orchestration\n\t\n\n","url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","conversational","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"conditional-polyp-diffusion","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Conditional Polyp Diffusion\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Conditional Polyp Diffusion dataset provides synthetic gastrointestinal (GI) polyp images along with segmentation masks, generated using a two-stage diffusion modeling framework. The dataset is aimed at mitigating the challenges of data scarcity and privacy in medical imaging, especially for supervised polyp segmentation tasks.\n\nStage 1: Improved diffusion model generates synthetic segmentation masks.\nStageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepsynthbody/conditional-polyp-diffusion.","url":"https://huggingface.co/datasets/deepsynthbody/conditional-polyp-diffusion","creator_name":"DeepSynthBody","creator_url":"https://huggingface.co/deepsynthbody","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"leanps","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLean Premise Selection Dataset\n\t\n\nLeanDojo (https://zenodo.org/doi/10.5281/zenodo.8040109) premise selection dataset\n","url":"https://huggingface.co/datasets/hcju/leanps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","lenandojo","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Manipuri"],"keywords_longer_than_N":true},
	{"name":"CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","keyword":"monolingual","description":"\n  CUADIrrevocableOrPerpetualLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a license grant that is irrevocable or perpetual.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"TOFU-C","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C.","url":"https://huggingface.co/datasets/kimperyang/TOFU-C","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Panjabi"],"keywords_longer_than_N":true},
	{"name":"SonicMasterDataset","keyword":"monolingual","description":"The SonicMaster dataset is a large collection of paired degraded and high-quality music tracks, introduced in the paper SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering.\nThis dataset was constructed by applying nineteen degradation functions belonging to five enhancement groups: equalization, dynamics, reverb, amplitude, and stereo. It is designed to train unified generative models for music restoration and mastering. The original music files were sourced from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amaai-lab/SonicMasterDataset.","url":"https://huggingface.co/datasets/amaai-lab/SonicMasterDataset","creator_name":"AMAAI Lab","creator_url":"https://huggingface.co/amaai-lab","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"JCrewBlockerLegalBenchClassification","keyword":"monolingual","description":"\n  JCrewBlockerLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe J.Crew Blocker, also known as the J.Crew Protection, is a provision included in leveraged loan documents to prevent companies from removing security by transferring intellectual property (IP) into new subsidiaries and raising additional debt. The task consists of detemining whether the J.Crew Blocker is present in the document.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRevenueProfitSharingLegalBenchClassification","keyword":"monolingual","description":"\n  CUADRevenueProfitSharingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause require a party to share revenue or profit with the counterparty for any technology, goods, or services.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"thai-license-plate-ocr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tThai License Plate OCR Dataset ðŸ‡¹ðŸ‡­\n\t\n\nðŸ‡ºðŸ‡¸ English Version\n\nTask: Optical Character Recognition (OCR)\nLanguage: Thai ðŸ‡¹ðŸ‡­  \n\nOCR dataset à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸ªà¸³à¸«à¸£à¸±à¸š PaddleOCR-rec à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°\nà¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹€à¸žà¸·à¹ˆà¸­à¸à¸¶à¸à¸ªà¸­à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸£à¸¹à¹‰à¸ˆà¸³à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ˆà¸²à¸à¸›à¹‰à¸²à¸¢à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸£à¸–à¸¢à¸™à¸•à¹Œà¹„à¸—à¸¢ à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸²à¸¢à¹€à¸¥à¸‚à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¹à¸¥à¸°à¸Šà¸·à¹ˆà¸­à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”\n\n\nâš ï¸ à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸à¸±à¸š PaddleOCR-rec (à¹„à¸¡à¹ˆà¸¡à¸µ detection / classification)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nthai-license-ocr-dataset/\nâ”œâ”€â”€ images/           # à¸£à¸§à¸¡à¸ à¸²à¸žà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\nâ”œâ”€â”€ train.txt         # à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸¶à¸à¸ªà¸­à¸™\nâ”œâ”€â”€ val.txtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr.","url":"https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr","creator_name":"Nuttapong Chimwai","creator_url":"https://huggingface.co/morsetechlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CIFAR-10","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCIFAR-10 - Object Recognition in Images\n\t\n\n\nBenchmark dataset for object classification.ðŸ–¼ï¸ 60,000 32x32 color imagesðŸ·ï¸ 10 classesðŸ“ Format: PNG, CSVðŸ“¦ Files: 4ðŸ§ª Subset of the 80 million tiny images dataset\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCIFAR-10 is a widely used computer vision dataset consisting of 60,000 32x32 color images in 10 mutually exclusive classes. It was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The dataset is a labeled subset of the 80 million tinyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KDKCE/CIFAR-10.","url":"https://huggingface.co/datasets/KDKCE/CIFAR-10","creator_name":"KDKCE","creator_url":"https://huggingface.co/KDKCE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Oriya"],"keywords_longer_than_N":true},
	{"name":"code_leak_qa","keyword":"monolingual","description":"fyt7943/code_leak_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fyt7943/code_leak_qa","creator_name":"fyt","creator_url":"https://huggingface.co/fyt7943","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"KorSarcasmClassification","keyword":"monolingual","description":"\n  KorSarcasmClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original\n    meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These\n    tweets were gathered by querying for: irony sarcastic, and\n    sarcasm.\n    The dataset was created by gathering HTML data from Twitter. Queries for hashtags that include sarcasmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorSarcasmClassification.","url":"https://huggingface.co/datasets/mteb/KorSarcasmClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Panjabi"],"keywords_longer_than_N":true},
	{"name":"SpanishNewsClassification","keyword":"monolingual","description":"\n  SpanishNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Spanish dataset for news classification. The dataset includes articles from reputable Spanish news sources spanning 12 different categories.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SpanishNewsClassification.","url":"https://huggingface.co/datasets/mteb/SpanishNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","MarcOrfilaCarreras/spanish-news","Spanish"],"keywords_longer_than_N":true},
	{"name":"openwebtext","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"openwebtext\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAn open-source replication of the WebText dataset from OpenAI, that was used to train GPT-2.\nThis distribution was created by Aaron Gokaslan and Vanya Cohen of Brown University.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 13.51 GB\nSize of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dylanebert/openwebtext.","url":"https://huggingface.co/datasets/dylanebert/openwebtext","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","description":"ElisonSherton/github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ElisonSherton/github-issues","creator_name":"Vinayak Nayak","creator_url":"https://huggingface.co/ElisonSherton","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","multi-class-classification","topic-classification","found"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"FQuADRetrieval","keyword":"monolingual","description":"\n  FQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset has been built from the French SQuad dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/manu/fquad2_test\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FQuADRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FQuADRetrieval.","url":"https://huggingface.co/datasets/mteb/FQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Magahi"],"keywords_longer_than_N":true},
	{"name":"tarwiiga_adgen_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTarwiiga AdGen Dataset\n\t\n\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\n","url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-electoral","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode Ã©lectoral, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ROMB-1.0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tâ™¦ ROMB\n\t\n\nROMB (Russian Olympiad Math Benchmark) - Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼. Ð•Ñ‰Ñ‘ Ð¾Ð´Ð¸Ð½.\n2552 Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð¼ Ð²Ð¸Ð´Ðµ. Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð¾Ð´Ð¸Ð½ Ð¸Ð· ÑÐ°Ð¼Ñ‹Ñ… ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð² Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼. Ð˜Ð· Ð½Ð¸Ñ… Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ 192 Ð³ÐµÐ¾Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ñ…, 644 Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸ 1716 Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ….\nÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ - Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð² Ð·Ð°Ð´Ð°Ñ‡, Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¸ Ð¸Ñ… Ñ‚Ð¸Ð¿Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°.\n\n[!WARNING]\nÐ’ ÑÑ‚Ð°Ð´Ð¸Ð¸ Ð¾Ñ‚Ð»Ð°Ð²Ð»Ð¸Ð²Ð°Ð½Ð¸Ñ Ð±Ð°Ð³Ð¾Ð² Ð¸ Ð´Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°Ð½Ð¸Ñ ÐµÐ²Ð°Ð»ÑƒÐ°Ñ†Ð¸Ð¸ (sorry for my english). Ð•ÑÐ»Ð¸â€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ROMB-1.0.","url":"https://huggingface.co/datasets/d0rj/ROMB-1.0","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","Russian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CUADPostTerminationServicesLegalBenchClassification","keyword":"monolingual","description":"\n  CUADPostTerminationServicesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause subjects a party to obligations after the termination or expiration of a contract, including any post-termination transition, payment, transfer of IP, wind-down, last-buy, or similar commitments.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADChangeOfControlLegalBenchClassification","keyword":"monolingual","description":"\n  CUADChangeOfControlLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives one party the right to terminate or is consent or notice required of the counterparty if such party undergoes a change of control, such as a merger, stock sale, transfer of all or substantially all of its assets or business, or assignment by operation of law.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"stacksqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tStacks Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the Stacks dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/stacksqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","stacks","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"TwitterHjerneRetrieval","keyword":"monolingual","description":"\n  TwitterHjerneRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish question asked on Twitter with the Hashtag #Twitterhjerne ('Twitter brain') and their corresponding answer.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Written\n\nReference\nhttps://huggingface.co/datasets/sorenmulli/da-hashtag-twitterhjerne\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval.","url":"https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","sorenmulli/da-hashtag-twitterhjerne"],"keywords_longer_than_N":true},
	{"name":"SwednClusteringS2S","keyword":"monolingual","description":"\n  SwednClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure. This dataset uses the category labels as clusters.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/swedn\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwednClusteringS2S.","url":"https://huggingface.co/datasets/mteb/SwednClusteringS2S","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","sbx/superlim-2","Swedish"],"keywords_longer_than_N":true},
	{"name":"clean-medqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ©º Clean MedQA Dataset\n\t\n\n\nImproving healthcare through language-based AI.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nThe Clean MedQA dataset is a refined version of data originally sourced from the MedQuAD (Medical Question Answering Dataset) â€” a well-known resource for building question-answering systems in the healthcare domain.\nThis cleaned version is optimized for Natural Language Processing (NLP) tasks, particularly for training and evaluating models that need to understand or generateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChakradharS/clean-medqa.","url":"https://huggingface.co/datasets/ChakradharS/clean-medqa","creator_name":"Chakradhar","creator_url":"https://huggingface.co/ChakradharS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","summarization","token-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"tts-french-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ‡«ðŸ‡· French TTS Dataset\n\t\n\nThis dataset contains French speech audio paired with clean transcriptions, intended for training text-to-speech models such as Spark-TTS or Coqui TTS.\n\n\t\n\t\t\n\t\tðŸ“ Contents\n\t\n\n\ndataset.parquet â€” metadata file with audio paths, transcriptions, speaker info\nAudio/ â€” directory of all .wav files used for training\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Structure\n\t\n\nThe dataset.parquet file includes the following columns:\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\naudio\nPath to .wav file\n\n\ntextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Buck26/tts-french-dataset.","url":"https://huggingface.co/datasets/Buck26/tts-french-dataset","creator_name":"Mwila Bwalya David","creator_url":"https://huggingface.co/Buck26","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","crowdsourced","monolingual","French","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"processed-jigsaw-toxic-comments","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProcessed Jigsaw Toxic Comments Dataset\n\t\n\nThis is a preprocessed and tokenized version of the original Jigsaw Toxic Comment Classification Challenge dataset, prepared for multi-label toxicity classification using transformer-based models like BERT.\nâš ï¸ Important Note: I am not the original creator of the dataset. This dataset is a cleaned and restructured version made for quick use in PyTorch deep learning models.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“¦ Dataset Features\n\t\n\nEach example contains:\n\ntext: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Koushim/processed-jigsaw-toxic-comments.","url":"https://huggingface.co/datasets/Koushim/processed-jigsaw-toxic-comments","creator_name":"K Koushik Reddy","creator_url":"https://huggingface.co/Koushim","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"chempile-instruction","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChemPile-Instruction\n\t\n\n\n\n\n\n\n\n\nA comprehensive instruction tuning dataset for chemistry LLMs with multi-turn conversations and diverse reasoning tasks\n\t\n\t\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nChemPile-Instruction is a text-only dataset designed for instruction tuning of Large Language Models (LLMs) in the field of chemistry. It contains high-quality multi-turn conversations, each rephrased from different educational, scientific, and reasoning sources using diverse prompting strategies. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/chempile-instruction.","url":"https://huggingface.co/datasets/jablonkagroup/chempile-instruction","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","natural-language-inference","dialogue-generation"],"keywords_longer_than_N":true},
	{"name":"medtrain_may23","keyword":"monolingual","description":"\nlicense: apache-2.0\n\n\t\n\t\t\n\t\tDataset Card for Medical Question Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of question-answer pairs related to various medical topics. The data is structured to provide comprehensive answers to specific medical questions, covering information, diagnosis, treatment, prevention, and susceptibility related to different health conditions.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/medtrain_may23.","url":"https://huggingface.co/datasets/Taylor658/medtrain_may23","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MC-II-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"CNIL","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFrench National Commission on Informatics and Liberty (CNIL) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (https://www.legifrance.gouv.fr/search/cnil).\nThis dataset is sourced from DILA/OPENDATA/CNIL and provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France.\nIt serves as a richâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CNIL.","url":"https://huggingface.co/datasets/Tricoteuses/CNIL","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"ContractNLIExplicitIdentificationLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIExplicitIdentificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that all Confidential Information shall be expressly identified by the Disclosing Party.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\nSource datasets:\n\nnguha/legalbench\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"cohere_aya_arabic","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tArabic aya dataset\n\t\n\nThis dataset is the arabic partition of the CohereForAI/aya_dataset dataset. \nFor more information about the dataset, visit the original dataset repo: CohereForAI/aya_dataset.\nthe data was extracted using this simple code:\n# Train split.\naya_train = datasets.load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\narb_train = aya_train.filter(lambda x: x[\"language_code\"] == \"arb\")\narb_train = arb_train.remove_columns([\"language_code\", \"user_id\"])\n\n# Test split.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic.","url":"https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic","creator_name":"Mohamed AbuElNasr","creator_url":"https://huggingface.co/abuelnasr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","monolingual","CohereForAI/aya_dataset","Standard Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"RussianFinancialNews","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tRussianFinancialNews\n\t\n\nÐ”Ð°Ñ‚Ð°ÑÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 92,377 Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ñ… ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð½Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²ÑƒÑŽ Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÑƒ, Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð¿Ñ€Ð¾ Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¸Ð¹ Ñ€Ñ‹Ð½Ð¾Ðº Ñ†ÐµÐ½Ð½Ñ‹Ñ… Ð±ÑƒÐ¼Ð°Ð³ Ð¸ Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÑƒÑŽ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÑƒ. ÐÐ°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ð»ÐµÐ·ÐµÐ½ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ° (NLP). \nA dataset containing 92,377 samples of Russian financial news articles. Each sample includes metadata and content fields that are useful for various Natural Language Processing (NLP) tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews.","url":"https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews","creator_name":"Kasymkhan","creator_url":"https://huggingface.co/Kasymkhan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","time-series-forecasting","tabular-regression"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Urdu"],"keywords_longer_than_N":true},
	{"name":"medra-medical-sampled","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedra Medical Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, provisionally named the \"Medra Medical Reasoning Dataset,\" is a curated and processed collection of various medical question answering, dialogue, and reasoning datasets. It has been specifically formatted to facilitate the training of large language models, such as Gemma 3 (code-named Medra in this project), to improve their medical knowledge, enhance their reasoning capabilities, and enable them toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicoboss/medra-medical-sampled.","url":"https://huggingface.co/datasets/nicoboss/medra-medical-sampled","creator_name":"Nico Bosshard","creator_url":"https://huggingface.co/nicoboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"custom_tofu","keyword":"monolingual","description":"talmahmud/custom_tofu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/talmahmud/custom_tofu","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SCDDCertificationLegalBenchClassification","keyword":"monolingual","description":"\n  SCDDCertificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer requires direct suppliers to certify that materials incorporated into the product comply with the laws regarding slavery and human trafficking of the country orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDCertificationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDDCertificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Endothelial Cells (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on endothelial cells from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cellâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Venkatachalam/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells.","url":"https://huggingface.co/datasets/Venkatachalam/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","creator_name":"Venkatachalam Subramanian Periya Subbu","creator_url":"https://huggingface.co/Venkatachalam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gaming","keyword":"monolingual","description":"\n  CQADupstackGamingRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGamingRetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gaming.","url":"https://huggingface.co/datasets/mteb/cqadupstack-gaming","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"monolingual","description":"\n  NevIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPaired evaluation of real world negation in retrieval, with questions and passages. Since models generally prefer one passage over the other always, there are two questions that the model must get right to understand the negation (hence the paired_accuracy metric).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://github.com/orionw/NevIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NevIR.","url":"https://huggingface.co/datasets/mteb/NevIR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-unix","keyword":"monolingual","description":"\n  CQADupstackUnixRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackUnixRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-unix.","url":"https://huggingface.co/datasets/mteb/cqadupstack-unix","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"code-entree-sejour-etrangers-droit-asile","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'entrÃ©e et du sÃ©jour des Ã©trangers et du droit d'asile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Moroco","keyword":"monolingual","description":"\n  Moroco\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Moldavian and Romanian Dialectal Corpus. The MOROCO data set contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: (0) culture, (1) finance, (2) politics, (3) science, (4) sports, (5) tech\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/moroco\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Moroco.","url":"https://huggingface.co/datasets/mteb/Moroco","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Romanian"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCClinicalRetrieval","keyword":"monolingual","description":"\n  R2MEDPMCClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Clinical"],"keywords_longer_than_N":true},
	{"name":"makhuwa-trigrams-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMakhuwa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 154253 parallel speech-text pairs for Makhuwa, a language spoken primarily in Mozambique. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Makhuwa - vmw\nTask: Speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Makhuwa"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sjwsjw/github-issues.","url":"https://huggingface.co/datasets/sjwsjw/github-issues","creator_name":"sjw","creator_url":"https://huggingface.co/sjwsjw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"EMERCOM-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for psi.mchs.gov.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text-based consultations with Russia's Emergency Psychological Assistance EMERCOM, conducted through their online web portal. It includes the questions and concerns expressed by individuals seeking support, along with the guidance and advice provided by service psychologists. The dataset can be analyzed to understand the nature of anxieties faced by the public and the techniques employed byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions.","url":"https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"roemru-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Roem.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from Roem.ru, a Russian technology and business news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and author. The dataset contains 19,528 unique articles covering various topics in technology, business, and digital media.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/roemru-posts.","url":"https://huggingface.co/datasets/nyuuzyou/roemru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ContractNLISurvivalOfObligationsLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLISurvivalOfObligationsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that some obligations of Agreement may survive termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GR-III-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of promptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Gujarati"],"keywords_longer_than_N":true},
	{"name":"ALFFA-Swahili-News","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tALFFA Swahili News\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ALFFA Swahili News dataset is a speech corpus designed for automatic speech recognition (ASR) research in Swahili, an under-resourced African language. This dataset is part of the ALFFA (African Languages in the Field: speech Fundamentals and Automation) project and contains approximately 11.8 hours of broadcast news audio from Radio France International's Swahili service, recorded between November 2010 and March 2011.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News.","url":"https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News","creator_name":"Nick Mumero Mwangi","creator_url":"https://huggingface.co/nickdee96","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","speaker-identification","audio-language-identification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Manipuri"],"keywords_longer_than_N":true},
	{"name":"code-construction-habitation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la construction et de l'habitation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"BC-V-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-V-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"monolingual","description":"\n  NanoQuoraRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoQuoraRetrieval is a smaller subset of the QuoraRetrieval dataset, which is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nSocial\n\n\nReference\nhttps://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoQuoraRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoQuoraRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","mteb/quora","English"],"keywords_longer_than_N":true},
	{"name":"self-ai-for-psychology","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWelcome to SelfAI open-sourced dataset for patient-therapist conversation + psychology knowledge + philosophy chats.\n\t\n\n\nThis dataset is a mixture of other datasets that are open sourced for patient-therapist conversation, psychology and philosophy.\nIt includes post-processing such as:\ntoxicity filtering\nduplicate removal\nlanguage detection filtering (English)\nanonymization\nrephrasing\n\n\nDatasets used:\nCalebE new_mental_health_conversations.\nHOPE dataset fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alindumitru/self-ai-for-psychology.","url":"https://huggingface.co/datasets/alindumitru/self-ai-for-psychology","creator_name":"Alin Vasile Dumitru","creator_url":"https://huggingface.co/alindumitru","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","dialogue-modeling","intent-classification"],"keywords_longer_than_N":true},
	{"name":"Vedavani-Dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry\n\t\n\nVedavani is the first benchmark dataset for automatic speech recognition (ASR) on Vedic Sanskrit poetry, consisting of richly annotated verses from the Rig Veda and Atharva Veda. This corpus captures the unique prosodic structure, phonetic complexity, and chanting style found in traditional Vedic recitation.\nðŸ”— Paper: Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry (ACL 2025)ðŸ“ GitHub Repository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanganaka/Vedavani-Dataset.","url":"https://huggingface.co/datasets/sanganaka/Vedavani-Dataset","creator_name":"Sanganaka, IIT Kharagpur","creator_url":"https://huggingface.co/sanganaka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","Sanskrit","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-artisanat","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'artisanat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"KurdishSentimentClassification","keyword":"monolingual","description":"\n  KurdishSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nKurdish Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://link.springer.com/article/10.1007/s10579-023-09716-6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KurdishSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KurdishSentimentClassification.","url":"https://huggingface.co/datasets/mteb/KurdishSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mmarco-de-distilled-scored","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is a distilled (reduced) \"german only\" dataset (train split only) version still in original order from unicamp-dl/mmarco with added cosine-similarity scores. The full source of mmarco by unicamp is hosted in the repository on GitHub.\nThe scores between 'query' and 'text' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer correspondsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LongPage","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tOverview ðŸš€ðŸ“š\n\t\n\nThe first comprehensive dataset for training AI models to write complete novels with sophisticated reasoning.\nðŸ§  Hierarchical Reasoning Architecture â€” Multi-layered planning traces including character archetypes, story arcs, world rules, and scene breakdowns. A complete cognitive roadmap for long-form narrative construction.\nðŸ“– Complete Novel Coverage â€” From 40,000 to 600,000+ tokens per book, spanning novellas to epic series with consistent quality throughout.\nâš¡â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Pageshift-Entertainment/LongPage.","url":"https://huggingface.co/datasets/Pageshift-Entertainment/LongPage","creator_name":"Pageshift-Entertainment","creator_url":"https://huggingface.co/Pageshift-Entertainment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","text2text-generation","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"boulder_detection","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tboulder_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-16\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: boulder\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/boulder_detection.","url":"https://huggingface.co/datasets/gremlin97/boulder_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 1,112,937 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"BC-III-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-ii","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des impÃ´ts, annexe II, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"STSES","keyword":"monolingual","description":"\n  STSES\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSpanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://huggingface.co/datasets/PlanTL-GOB-ES/sts-es\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"STSES\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/STSES.","url":"https://huggingface.co/datasets/mteb/STSES","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","monolingual","PlanTL-GOB-ES/sts-es","Spanish"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","description":"This dataset originates from the teaching materials of the NLP Course.\nvia: https://huggingface.co/learn/nlp-course/en/chapter5/5\n","url":"https://huggingface.co/datasets/real-jiakai/github-issues","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpusRetrieval","keyword":"monolingual","description":"\n  NanoNFCorpusRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNFCorpus is a smaller subset of NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\nReference\nhttps://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","expert-annotated","monolingual","mteb/nfcorpus"],"keywords_longer_than_N":true},
	{"name":"CUADNonCompeteLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNonCompeteLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts the ability of a party to compete with the counterparty or operate in a certain geography or business or technology sector.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"code-consommation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la consommation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"TCP","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for the TCP dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTCP is a temporal constraint-based planning benchmark that specifically evaluates LLMs' ability in planning under interdependent temporal constraints.\n\nCurated by: Zifeng Ding\nLanguage(s) (NLP): English\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\nThe dataset is split into two categories of problems, i.e., short problems andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beanbagdzf/TCP.","url":"https://huggingface.co/datasets/Beanbagdzf/TCP","creator_name":"Zifeng Ding","creator_url":"https://huggingface.co/Beanbagdzf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"diet-planning-evaluation-20250531-140436","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDiet Planning Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains evaluation results for diet planning model responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is stored in parquet format for efficient loading and pagination.\n","url":"https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140436","creator_name":"Alex Jihun Kim","creator_url":"https://huggingface.co/alexjk1m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"el-mal-el-halal-podcast-subtitles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEl Mal El Halal Podcast Subtitles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl Mal El Halal Podcast Subtitles is a collection of manual subtitles for 18 episodes of the El Mal El Halal podcast by Eng. Mohamed Aboulnaga, covering Arabic content. This dataset is designed for research on speech processing, translation, semantic search, and Arabic NLP.\n\nTotal episodes: 18 - untill the date of 03/08/2025\nTotal segments: 13â€¯970\nTotal words: 166â€¯505\nTotal duration: 20â€¯hâ€¯50â€¯mâ€¯56â€¯s (75â€¯057â€¯s)\nAverageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles.","url":"https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles","creator_name":"Hossam El-Kharbotly","creator_url":"https://huggingface.co/hossam87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sentence-similarity","text-to-speech","translation","text-classification"],"keywords_longer_than_N":true},
	{"name":"ClevelandMuseumArt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCleveland Museum of Art Open Access Dataset\n\t\n\nThis dataset contains the complete Cleveland Museum of Art Open Access collection data, originally sourced from the ClevelandMuseumArt/openaccess GitHub repository and reuploaded for broader distribution, Parquet generation for high-performance analytics, and seamless integration with data science workflows.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Cleveland Museum of Art provides open access to information on more than 61,000 artworks inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt.","url":"https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","image-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"VoyageMMarcoReranking","keyword":"monolingual","description":"\n  VoyageMMarcoReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\na hard-negative augmented version of the Japanese MMARCO dataset as used in Voyage AI Evaluation Suite\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\nReference\nhttps://arxiv.org/abs/2312.16144\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VoyageMMarcoReranking\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VoyageMMarcoReranking.","url":"https://huggingface.co/datasets/mteb/VoyageMMarcoReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ImageDataHW1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ImageDataHW1\n\t\n\n\nThis dataset has image data of fencing competition, and is meant for classifying whether or not a point has been awarded\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original split contains thirty screenshots retrieved from the source below. 15 images of the original split show frames where a point has not yet been \nawarded, while 15 show frames where a point has been awarded. The augmented split shows 300 images that have beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emkessle/ImageDataHW1.","url":"https://huggingface.co/datasets/emkessle/ImageDataHW1","creator_name":"Ethan Kessler","creator_url":"https://huggingface.co/emkessle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SCDBPAccountabilityLegalBenchClassification","keyword":"monolingual","description":"\n  SCDBPAccountabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer maintains internal compliance procedures on company standards regarding human trafficking and slavery? This includes any type of internal accountability mechanism. Requiringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPAccountabilityLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDBPAccountabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_v1.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_v1","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AILA_statutes","keyword":"monolingual","description":"\n  AILAStatutes\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset is structured for the task of identifying the most relevant statutes for a given situation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReferencehttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILAStatutes\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_statutes.","url":"https://huggingface.co/datasets/mteb/AILA_statutes","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mmlu","keyword":"monolingual","description":"rubricreward/llm-metric-mmlu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mmlu","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ‰ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tðŸš€ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that Africanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"code-transports","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des transports, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"first-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yarinkos/first-dataset.","url":"https://huggingface.co/datasets/yarinkos/first-dataset","creator_name":"Yarin Kos","creator_url":"https://huggingface.co/yarinkos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"MNBVC","keyword":"monolingual","description":"MNBVC: Massive Never-ending BT Vast Chinese corpus","url":"https://huggingface.co/datasets/liwu/MNBVC","creator_name":"Language Intelligence and Word Understanding Research Group (LIWU)","creator_url":"https://huggingface.co/liwu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","other"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Arguana-Test","keyword":"monolingual","description":"\n  BIRCO-ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the ArguAna dataset from BIRCO. This dataset contains 100 queries where both queries and passages are complex one-paragraph arguments about current affairs. The objective is to retrieve the counter-argument that directly refutes the queryâ€™s stance.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"recaptchav2-29k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tReCAPTCHAv2-29k\n\t\n\nReCAPTCHAv2-29k is a dataset consisting of images derived from Google's ReCAPTCHA v2 system, which is widely used for online human verification.\nIt contains thousands of ReCAPTCHA images, each paired with corresponding labels indicating the presence of specific objects or features (e.g., bicycle, bus, car).\nThis dataset is intended for educational and research purposes and is particularly suited for tasks such as feature extraction and multi-label imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k.","url":"https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k","creator_name":"Dennis J.","creator_url":"https://huggingface.co/nobodyPerfecZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","found","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"SCDBPVerificationLegalBenchClassification","keyword":"monolingual","description":"\n  SCDBPVerificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer engages in verification and auditing as one practice, expresses that it may conduct an audit, or expressess that it is assessing supplier risks through a review of the US Dept. ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPVerificationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDBPVerificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 32926\nFiltered size: 32926\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"COPA-cy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COPA-cy\n\t\n\n","url":"https://huggingface.co/datasets/techiaith/COPA-cy","creator_name":"Language Technologies, Bangor University","creator_url":"https://huggingface.co/techiaith","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CorporateLobbyingLegalBenchClassification","keyword":"monolingual","description":"\n  CorporateLobbyingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Corporate Lobbying task consists of determining whether a proposed Congressional bill may be relevant to a company based on a company's self-description in its SEC 10K filing.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"1M-OpenOrca_be","keyword":"monolingual","description":"En/Be\nðŸ‹ The Belarusian OpenOrca Dataset! ðŸ‹\n\n\n\nBelarusian OpenOrca dataset - is rich collection of augmented FLAN data aligns, that translated in belarusian language.\nThat dataset should help training LLM in belarusian language and should help on other NLP tasks.\nThis dataset have 2 version:\n\n~1M GPT-4 completions (Now translating)\n~3.2M GPT-3.5 completions (Can be translated in future)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe fields are:\n\n'id', a unique numbered identifier which includes one of 'niv'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be.","url":"https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be","creator_name":"Artsem Holub","creator_url":"https://huggingface.co/WiNE-iNEFF","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"big_patent","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Big Patent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries.\nEach US patent application is filed under a Cooperative Patent Classification (CPC) code.\nThere are nine such classification categories:\n\na: Human Necessities\nb: Performing Operations; Transporting\nc: Chemistry; Metallurgy\nd: Textiles; Paper\ne: Fixed Constructions\nf: Mechanical Engineering; Lightning; Heating;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NortheasternUniversity/big_patent.","url":"https://huggingface.co/datasets/NortheasternUniversity/big_patent","creator_name":"Northeastern University","creator_url":"https://huggingface.co/NortheasternUniversity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wnli-eu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for WNLI-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWNLI-eu is the professional translation to Basque of the WNLI dataset.\nWNLI is part of the GLUE benchmark for English (Wang et al., 2018) \nand is based on the Winograd Schema Challenge (WSC) dataset (Levesque et al., 2011):\n\nA Winograd schema is a pair of sentences differing in only one or two words and containing an ambiguity that is resolved in opposite ways in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/wnli-eu.","url":"https://huggingface.co/datasets/HiTZ/wnli-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"PHYBench_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPHYBench Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of Eureka-Lab/PHYBench, containing only the samples that have a complete solution and answer.\nThe data has been formatted into a question and answer structure suitable for training instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original physics problem statement (from the content column).\nanswer: A string containing the thinking process and the final answer, formatted asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/PHYBench_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/PHYBench_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"WixQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWixQA: Enterprise RAG Question-Answering Benchmark\n\t\n\nðŸ“„ Full Paper Available: For comprehensive details on dataset design, methodology, evaluation results, and analysis, please see our complete research paper:\nWixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation\nCohen et al. (2025) - arXiv:2505.08643\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nWixQA is a three-config collection for evaluating and training Retrieval-Augmented Generation (RAG) systems in enterpriseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Wix/WixQA.","url":"https://huggingface.co/datasets/Wix/WixQA","creator_name":"Wix","creator_url":"https://huggingface.co/Wix","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","open-domain-qa","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"CUADJointIPOwnershipLegalBenchClassification","keyword":"monolingual","description":"\n  CUADJointIPOwnershipLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause provides for joint or shared ownership of intellectual property between the parties to the contract.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bower-waste-annotations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for waste annotations made by the recycling solution Bower\n\t\n\n\n  \n\n\n\nThe data offered by Bower (Sugi Group AB) in collaboration with Google.org \n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe bower-waste-annotations dataset consists of 1440 images of waste and various consumer items taken by consumer phone cameras. The images are annotated with Material type and Object type classes, listed below.\nThe images and annotations has been manually reviewed to ensure correctness. It is assumedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BowerApp/bower-waste-annotations.","url":"https://huggingface.co/datasets/BowerApp/bower-waste-annotations","creator_name":"Bower (Sugi Group AB)","creator_url":"https://huggingface.co/BowerApp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Bower employees","monolingual","Bower internal'","English","mit"],"keywords_longer_than_N":true},
	{"name":"C-VARC","keyword":"monolingual","description":"This repository contains all the data associated with the paper \"C-VARC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. Weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/C-VARC.","url":"https://huggingface.co/datasets/Beijing-AISI/C-VARC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Text360 Sample Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text samples from two sources (arXiv and Wikipedia) organized in a hierarchical directory structure. Each sample includes a text field and a subset identifier.\n\n\t\n\t\t\n\t\tData Files Structure\n\t\n\nThe dataset maintains its original directory structure:\n.\nâ”œâ”€â”€ dir1/\nâ”‚   â””â”€â”€ subdir1/\nâ”‚       â””â”€â”€ sample1.jsonl  # Contains arXiv samples\nâ””â”€â”€ dir2/\n    â””â”€â”€ subdir2/\n        â””â”€â”€ sample2.jsonl  # Containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nikhilranjan/test.","url":"https://huggingface.co/datasets/nikhilranjan/test","creator_name":"Nikhil Ranjan","creator_url":"https://huggingface.co/nikhilranjan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Diversity2LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity2LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 2).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"womanru-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Woman.ru Forum Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,308,238 forum posts from Woman.ru, a popular Russian-language information and entertainment portal. Woman.ru is one of the most visited women's sites in Runet (Russian Internet). The dataset covers posts from around 2005 to 2024, providing a comprehensive view of discussions on the platform over nearly two decades.\nThe content includes original posts and replies on various topics, offeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/womanru-posts.","url":"https://huggingface.co/datasets/nyuuzyou/womanru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"dbnl.org-dutch-public-domain","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"dbnl.org-dutch-public-domain\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises a collection of texts from the Dutch Literature in the public domain, specifically from the DBNL (Digitale Bibliotheek voor de Nederlandse Letteren) public domain collection. The collection includes books, poems, songs, and other documentation, letters, etc., that are at least 140 years old and thus free of copyright restrictions. Each entry in the dataset corresponds to one section ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain.","url":"https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain","creator_name":"Julian von der Goltz","creator_url":"https://huggingface.co/jvdgoltz","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","Dutch","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"yuxiaowang-prompts-2025","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tYuxiaowang Semantic Dataset Â· Hugging Face Version\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  English Summary\n\t\n\n\n\t\n\t\t\n\t\tYuxiaowang Â· Semantic Dataset for Japanese Language Schools (Chinese)\n\t\n\nThis project provides structured semantic definitions and prompt examples for the domain of Japanese language schools in China.It aims to serve as a grounding corpus for large language models (LLMs) to understand terms like \"è¯­æ ¡\", \"è¯­æ ¡ç½‘\", and related concepts.\n\nSource platform: https://www.yuxiaowang.comAll prompts and termâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/languagehub-ai/yuxiaowang-prompts-2025.","url":"https://huggingface.co/datasets/languagehub-ai/yuxiaowang-prompts-2025","creator_name":"Yuxiaowang Â· è¯­è¨€å­¦æ ¡æ•°æ®ä¸­å¿ƒ","creator_url":"https://huggingface.co/languagehub-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MultiPL-E","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MultiPL-E\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPL-E is a dataset for evaluating large language models for code\ngeneration that supports 22 programming languages. It takes the OpenAI \nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\ntranslate them  to other languages. It is easy to add support for new languages \nand benchmarks.\nThe dataset is divided into several configurations named SRCDATA-LANG, where\nSRCDATA is eitherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nuprl-staging/MultiPL-E.","url":"https://huggingface.co/datasets/nuprl-staging/MultiPL-E","creator_name":"Northeastern University PRL","creator_url":"https://huggingface.co/nuprl-staging","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","machine-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Panjabi"],"keywords_longer_than_N":true},
	{"name":"ToxicChatClassification","keyword":"monolingual","description":"\n  ToxicChatClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains toxicity annotations on 10K user\n            prompts collected from the Vicuna online demo. We utilize a human-AI\n            collaborative annotation framework to guarantee the quality of annotation\n            while maintaining a feasible annotation workload. The details of data\n            collection, pre-processing, and annotation can be found in our paper.\n            We believe thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ToxicChatClassification.","url":"https://huggingface.co/datasets/mteb/ToxicChatClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"SouthAfricanLangClassification","keyword":"monolingual","description":"\n  SouthAfricanLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for 11 South African Languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\n\n\nReference\nhttps://www.kaggle.com/competitions/south-african-language-identification/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SouthAfricanLangClassification.","url":"https://huggingface.co/datasets/mteb/SouthAfricanLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","mlexplorer008/south_african_language_identification"],"keywords_longer_than_N":true},
	{"name":"Unmasking-the-Imposters","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUnmasking the Imposters: Machine-Generated Tweet Detection Dataset\n\t\n\nThis dataset contains nine subsets of human and machine-generated tweets designed to evaluate the detection of AI-generated content across censored and uncensored large language models (LLMs). The dataset addresses the gap in understanding how content moderation and domain adaptation affect the detectability of machine-generated text on social media platforms.\n\nPaper: \"Unmasking the Imposters: How Censorship andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/redasers/Unmasking-the-Imposters.","url":"https://huggingface.co/datasets/redasers/Unmasking-the-Imposters","creator_name":"ReDAS Lab at the University of Houston","creator_url":"https://huggingface.co/redasers","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","fact-checking","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat-collectivites-mayotte","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat et des collectivitÃ©s publiques applicable Ã  la collectivitÃ© territoriale de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lie24/gsm8k.","url":"https://huggingface.co/datasets/Lie24/gsm8k","creator_name":"Lie","creator_url":"https://huggingface.co/Lie24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"question_answering","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis Question Answering dataset is a reading comprehension resource derived from Persian Wikipedia. This crowd-sourced dataset contains over 9,000 entries, each of which can either be an unanswerable question or a question with one or more answers based on the provided context. Similar to the SQuAD2.0 dataset, the inclusion of unanswerable questions allows for the development of systems that \"know they don't know the answer.\" Additionally, the dataset includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azizmatin/question_answering.","url":"https://huggingface.co/datasets/azizmatin/question_answering","creator_name":"Aziz Matin","creator_url":"https://huggingface.co/azizmatin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","Persian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Manipuri"],"keywords_longer_than_N":true},
	{"name":"twi-fante-sentences-parts-of-speech-pos-10m","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAkan POS Tagging Dataset - 10 Million Sentences\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes sentences and part-of-speech tags and is aimed at supporting the development of POS tagging models for the Akan language.\nThis work demonstrates that data limitations for low-resource languages can be overcome using artificial data generation techniques.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nsentence: The Akan sentence text\npos_sequence: Part-of-speech tags for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-fante-sentences-parts-of-speech-pos-10m.","url":"https://huggingface.co/datasets/michsethowusu/twi-fante-sentences-parts-of-speech-pos-10m","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","part-of-speech","synthetic","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"ContractNLILimitedUseLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLILimitedUseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall not use any Confidential Information for any purpose other than the purposes stated in Agreement.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Friend-Or-Foe","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection! \n\n  \n\n\nThis file contains the description and general structure of the Friend or Foe collection of bacterial datasets. The environments are stored in .csv files namely AGORA.csv\nand CARVEME.csv. First 424 columns for AGORA and 499 for CARVEME identify the abreviations for chemical compounds. Last five columns describe the target (regression/classification), the name of dataset (BC/MC/GR), the group of additional compounds (100/50), splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/powidla/Friend-Or-Foe.","url":"https://huggingface.co/datasets/powidla/Friend-Or-Foe","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","synthetic","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"QueryBridge","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tQueryBridge: One Million Annotated Questions with SPARQL Queries - Dataset for Question Answering over Knowledge Graph\n\t\n\nThe QueryBridge dataset is the first and largest dataset with annotated questions for question answering (QA) over knowledge graphs. It provides a comprehensive resource for developing and testing algorithms that process and interpret natural language questions in the context of structured knowledge. In addition to QA tasks, QueryBridge can also be used for:\n\nEntityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aorogat/QueryBridge.","url":"https://huggingface.co/datasets/aorogat/QueryBridge","creator_name":"Abdelghny Orogat","creator_url":"https://huggingface.co/aorogat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"TextualismToolPlainLegalBenchClassification","keyword":"monolingual","description":"\n  TextualismToolPlainLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a paragraph from a judicial opinion is applying a form textualism that relies on the ordinary (â€œplainâ€) meaning of terms.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TextualismToolPlainLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/TextualismToolPlainLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nðŸ‘€ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de MÃ©canique des Structures et des SystÃ¨mes CouplÃ©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test","creator_name":"Fra Merlino","creator_url":"https://huggingface.co/Merlinooooo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Magahi"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iii","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des impÃ´ts, annexe III, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ChemData700K_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChemData700K Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of the AI4Chem/ChemData700K dataset.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nFiltering: The dataset was filtered to include only samples that are not part of a conversation and have no top-level instruction. Specifically, only rows where history is empty ([]) and instruction is null/empty were kept.\nFormatting: The output column was prefixed with #### .\nColumn Renaming: The input and output columns were renamed toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/ChemData700K_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/ChemData700K_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Urdu"],"keywords_longer_than_N":true},
	{"name":"legal_reason","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEnhanced Legal Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Enhanced Legal Reasoning Dataset is a synthetic dataset designed to facilitate the fine-tuning of Large Language Models (LLMs) for tasks related to legal reasoning and argumentation. It encompasses a diverse range of legal scenarios across multiple domains, capturing the nuanced techniques employed by legal professionals in constructing their arguments.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chemouda/legal_reason.","url":"https://huggingface.co/datasets/chemouda/legal_reason","creator_name":"Moudather Chelbi","creator_url":"https://huggingface.co/chemouda","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","named-entity-recognition","human","synthetic","monolingual"],"keywords_longer_than_N":true},
	{"name":"Melange_test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Name\n\t\n\nShort summary of what this dataset contains.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA longer explanation of the dataset, including its purpose and contents.\nThis dataset consists of:\n\nA .parquet file with metadata and labels\nScene images organized in zipped folders by group\nEach row in the metadata corresponds to a multiple-choice question grounded in one or more scene images.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for:\n\nVisual question answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDfree/Melange_test.","url":"https://huggingface.co/datasets/IDfree/Melange_test","creator_name":"no_ID","creator_url":"https://huggingface.co/IDfree","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","visual-question-answering","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Core17InstructionRetrieval","keyword":"monolingual","description":"\n  Core17InstructionRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring retrieval instruction following ability on Core17 narratives for the FollowIR benchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReferencehttps://arxiv.org/abs/2403.15246\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Core17InstructionRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Core17InstructionRetrieval.","url":"https://huggingface.co/datasets/mteb/Core17InstructionRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"kompy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Kompy.info\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 584,648 pages of educational content in Uzbek language extracted from kompy.info website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Uzbek (uz).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/kompy.","url":"https://huggingface.co/datasets/nyuuzyou/kompy","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"3dnews-articles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 3DNews Articles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset comprises news articles from the Russian technology website 3DNews, covering the period from 2003 to 2024. It covers the latest updates in the world of digital technology and insightful commentary from industry experts, spanning the years 2003 to 2024.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/3dnews-articles.","url":"https://huggingface.co/datasets/nyuuzyou/3dnews-articles","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"nirschl_et_al_2018","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for nirschl_et_al_2018\n\t\n\n\n ðŸŒ Homepage â€¢\n ðŸ¤— HF Dataset â€¢\n ðŸ“š Paper â€¢\n ðŸ† Leaderboard â€¢\n ðŸ‘©â€ðŸ’» Point of Contact â€¢\n  \n\n This is a dataset card for nirschl_et_al_2018 dataset, which has been\n used under the CC BY 4.0 license. The original data have been\n updated, extended, and incorporated into the Biomedical Reasoning And image\n Understanding for Robust AI agents (BRAVURA) benchmark.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original nirschl_et_al_2018 has been cleaned, updatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nirschl-lab/nirschl_et_al_2018.","url":"https://huggingface.co/datasets/nirschl-lab/nirschl_et_al_2018","creator_name":"Nirschl Lab","creator_url":"https://huggingface.co/nirschl-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","monolingual","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"code-minier-nouveau","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode minier (nouveau), non-instruct (2025-09-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","description":"Liu123456789/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Liu123456789/test","creator_name":"L","creator_url":"https://huggingface.co/Liu123456789","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"medical_grpo_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical GRPO (SFT Simple) Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of TachyHealth/medical_grpo, formatted for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original medical question.\nanswer: The original answer index (A, B, C, or D), prefixed with #### .\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Original Question Text]\n\nAnswer:\n#### A\n\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"daichira/medical_grpo_preprocess\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical_grpo_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical_grpo_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"spanish-corpus-xix","keyword":"monolingual","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsGermanEnglish","keyword":"monolingual","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish.","url":"https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"nemo-github-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues.","url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"mnist3d","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tDataset Card for MNIST3D\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST3D dataset consists of 70,000 point clouds of handwritten digits generated \nby converting the images from the original MNIST dataset.\nEach point cloud has 193 points.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe data is split into training and test set. The original data split of the MNIST \ndataset is preserved.\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d.","url":"https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d","creator_name":"Cristiano Pizzamiglio","creator_url":"https://huggingface.co/cristiano-pizzamiglio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","found","monolingual","extended|mnist"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Gujarati"],"keywords_longer_than_N":true},
	{"name":"CUADWarrantyDurationLegalBenchClassification","keyword":"monolingual","description":"\n  CUADWarrantyDurationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a duration of any warranty against defects or errors in technology, products, or services provided under the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"virgool_62k","keyword":"monolingual","description":"This dataset represents the publicly available collection of data scraped from the virgool.io website. The data extraction was strategically performed based on specific tags and user. The dataset comprises approximately 62,000 entries across several key attributes: title, text, tags, likes, replies, reading_time, user_id, and URL.\nThis resource is particularly beneficial for researchers and developers aiming to pre-train large language models (LLMs), as the 'text' column provides a rich corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Msobhi/virgool_62k.","url":"https://huggingface.co/datasets/Msobhi/virgool_62k","creator_name":"mohamad sobhi","creator_url":"https://huggingface.co/Msobhi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","text-classification","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"mb-mars_seg_mer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-mars_seg_mer\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mars_seg_mer.","url":"https://huggingface.co/datasets/Mirali33/mb-mars_seg_mer","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQARetrieval","keyword":"monolingual","description":"\n  NanoHotpotQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoHotpotQARetrieval is a smaller subset of the HotpotQA dataset, which is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval.","url":"https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"YBBN-YSSY","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset from Brisbane-Sydney obtained from LiveATC\n\t\n\n","url":"https://huggingface.co/datasets/lmejias/YBBN-YSSY","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"CUADAuditRightsLegalBenchClassification","keyword":"monolingual","description":"\n  CUADAuditRightsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives a party the right to audit the books, records, or physical locations of the counterparty to ensure compliance with the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ProcessedOpenAssistant-mistral-large-2411","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDatasetÂ Summary\n\t\n\nProcessedÂ OpenAssistantÂ â€”Â Mistralâ€‘Largeâ€‘2411 pairs 27Â Â 563 unique English promptsâ€”deduplicated from the Apacheâ€‘2.0â€“licensedÂ [ProcessedÂ OpenAssistant corpus]â€”with answers generated on 21Â AprÂ 2025 by the paidâ€‘API model mistralâ€‘largeâ€‘2411, the 24â€‘Novâ€‘2024 checkpoint of Mistralâ€™s 123Â B parameter instructionâ€‘tuned seriesÂ :contentReference[oaicite:0]{index=0}Â :contentReference[oaicite:1]{index=1}.Answers were produced with the /v1/chat/completions endpoint in streamingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/ProcessedOpenAssistant-mistral-large-2411.","url":"https://huggingface.co/datasets/PursuitOfDataScience/ProcessedOpenAssistant-mistral-large-2411","creator_name":"Y. Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","machine-generated","found","monolingual","PursuitOfDataScience/ProcessedOpenAssistant"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API costâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MATH_LVL5_fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MATH_LVL5_fr\n\t\n\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation franÃ§aise des problÃ¨mes mathÃ©matiques de niveau avancÃ© du dataset MATH.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMATH_LVL5_fr est une adaptation franÃ§aise des problÃ¨mes mathÃ©matiques de niveau 5 (le plus avancÃ©) du dataset MATH original. Il comprend des problÃ¨mes de compÃ©tition mathÃ©matique de niveau lycÃ©e, formatÃ©s de maniÃ¨re cohÃ©rente avec LaTeX pour lesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr.","url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-aviation-civile","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'aviation civile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du domaine public fluvial et de la navigation intÃ©rieure, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"GeorgianSentimentClassification","keyword":"monolingual","description":"\n  GeorgianSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGoergian Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.173\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeorgianSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeorgianSentimentClassification.","url":"https://huggingface.co/datasets/mteb/GeorgianSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Manipuri"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval.V2","keyword":"monolingual","description":"\n  NLPJournalTitleIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-mathematica","keyword":"monolingual","description":"\n  CQADupstackMathematicaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackMathematicaRetrieval\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-mathematica.","url":"https://huggingface.co/datasets/mteb/cqadupstack-mathematica","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Risk_Factor_Disclosure_SampleDataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“Š Sample Preview â€“ Risk Factor Disclosure Dataset v1.0\n\t\n\nðŸ‘‰ This is a preview sample (100 records) of the full Risk Factor Disclosure Dataset v1.0.ðŸ”— To access the full dataset (1,869 enriched risk disclosures), visit:https://asapworks.gumroad.com/l/jbxtfd\n\n\n\t\n\t\t\n\t\tðŸ“¦ About the Sample File\n\t\n\nThis sample contains 100 enriched Item 1A \"Risk Factor\" disclosures extracted from 10-K filings submitted by top public companies between 2010 and 2024.\nEach row represents a structured riskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/asapworks/Risk_Factor_Disclosure_SampleDataset.","url":"https://huggingface.co/datasets/asapworks/Risk_Factor_Disclosure_SampleDataset","creator_name":"Siddharth shankar Asapu","creator_url":"https://huggingface.co/asapworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","extractive-qa","machine-generated"],"keywords_longer_than_N":true},
	{"name":"MATH-Hard","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mathematics Aptitude Test of Heuristics, hard subset (MATH-Hard) dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more. \nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations. For MATH-Hard, only the \nhardest questions were kept (Level 5).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lighteval/MATH-Hard.","url":"https://huggingface.co/datasets/lighteval/MATH-Hard","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Telugu"],"keywords_longer_than_N":true},
	{"name":"publicdomainpictures","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Public Domain Pictures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 644,412 public domain images from publicdomainpictures.net, a public domain photo sharing platform. The dataset includes detailed image metadata including titles, descriptions, and keywords.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All metadata including titles, descriptions and keywords\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe metadata forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/publicdomainpictures.","url":"https://huggingface.co/datasets/nyuuzyou/publicdomainpictures","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"wino_x_fr_prompt_coreference","keyword":"monolingual","description":"\n\t\n\t\t\n\t\twino_x_fr_prompt_coreference\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwino_x_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 27,930 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset wino_x by Emelin et al. where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference.","url":"https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["found","found","monolingual","wino_x","French"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval.V2","keyword":"monolingual","description":"\n  NLPJournalTitleAbsRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_06b","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-0.6B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_06b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_06b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_context","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columnsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"Liux69/sentiment-analysis-test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Liux69/sentiment-analysis-test","creator_name":"Lorenzo Martirani Paolillo","creator_url":"https://huggingface.co/Liux69","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"YSSY_1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ATCOSYDNEY corpus\n\t\n\n","url":"https://huggingface.co/datasets/lmejias/YSSY_1","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may retain some Confidential Information even after the return or destruction of Confidential Information.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"mb-mars_seg_msl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-mars_seg_msl\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mars_seg_msl.","url":"https://huggingface.co/datasets/Mirali33/mb-mars_seg_msl","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-action-sociale-familles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'action sociale et des familles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"TelemarketingSalesRuleLegalBenchClassification","keyword":"monolingual","description":"\n  TelemarketingSalesRuleLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine how 16 C.F.R. Â§ 310.3(a)(1) and 16 C.F.R. Â§ 310.3(a)(2) (governing deceptive practices) apply to different fact patterns. This dataset is designed to test a modelâ€™s ability to apply 16 C.F.R. Â§ 310.3(a)(1) and 16 C.F.R. Â§ 310.3(a)(2) of the Telemarketing Sales Rule to a simple fact pattern with a clear outcome. Each fact pattern ends with the question: â€œIs this a violation of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TelemarketingSalesRuleLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/TelemarketingSalesRuleLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"ramp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Retrieval-Augmented Modular Prompt Tuning for Low-Resource Data-to-Text Generation (RAMP)\n\t\n\nHugging Face Dataset | GitHub Repository | paper | Gitlab Repository \n\n\nRAMP provides a prepared version of a low-resource data-to-text corpus for drone handover message generation: structured sensor records (status + time-step object lists) paired with natural-language â€œhandoverâ€ messages describing critical situations. The release includes raw/filtered splits andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonyhong/ramp.","url":"https://huggingface.co/datasets/tonyhong/ramp","creator_name":"Xudong Hong","creator_url":"https://huggingface.co/tonyhong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AuthorMix","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AuthorMix\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAUTHORMIX, was originally created for authorship obfuscation task and had data from four distinct domains: presidential speeches, early-1900s fiction novels, scholarly articles, and diary-style blogs. Altogether, AUTHORMIX contains over 30k high-quality paragraphs from 14 authors.\nThis work was created in the paper: StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements, whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jrfish/AuthorMix.","url":"https://huggingface.co/datasets/jrfish/AuthorMix","creator_name":"Jillian Fisher","creator_url":"https://huggingface.co/jrfish","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"CUADRofrRofoRofnLegalBenchClassification","keyword":"monolingual","description":"\n  CUADRofrRofoRofnLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grant one party a right of first refusal, right of first offer or right of first negotiation to purchase, license, market, or distribute equity interest, technology, assets, products or services.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-securite-sociale","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la sÃ©curitÃ© sociale, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"complex_mathematical-scientific-notation-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMathematical and Scientific Notation Parallel Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in mathematical and scientific contexts. It contains identical mathematical content expressed in four different notation styles, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison: Compare how different tokenizers (BPE, SentencePieceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/complex_mathematical-scientific-notation-parallel.","url":"https://huggingface.co/datasets/Malikeh1375/complex_mathematical-scientific-notation-parallel","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"tiny-stack","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAbout\n\t\n\nDataset for tinystack.\n","url":"https://huggingface.co/datasets/fhswf/tiny-stack","creator_name":"Fachhochschule SÃ¼dwestfalen","creator_url":"https://huggingface.co/fhswf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","monolingual","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurHistQuadRetrieval","keyword":"monolingual","description":"\n  TurHistQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nQuestion Answering dataset on Ottoman History in Turkish\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Academic, Written\n\n\nReference\nhttps://github.com/okanvk/Turkish-Reading-Comprehension-Question-Answering-Dataset\n\n\n\t\n\nSource datasets:\n\nasparius/TurHistQuAD\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TurHistQuadRetrieval.","url":"https://huggingface.co/datasets/mteb/TurHistQuadRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","asparius/TurHistQuAD"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"monolingual","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_qa\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"GR-II-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGermanRAG ðŸ‡©ðŸ‡ªðŸ“œðŸ¦œ\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the numberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS","keyword":"monolingual","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SCIDOCS","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_answer_and_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"Libra-Emo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸŽ­ Libra-Emo Dataset\n\t\n\n\nLibra-Emo is a large-scale multimodal fine-grained dataset for negative emotion detection. It includes video clips, subtitles, emotion labels, and corresponding explanations.\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tðŸ“ Sample Structure\n\t\n\nEach sample includes:\n\nðŸŽ¥ A video clip\nðŸ’¬ The corresponding subtitle\nðŸ·ï¸ An emotion label\nðŸ“‹ An explanation of why the label was assigned\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Emotion Categories\n\t\n\n\n\t\n\t\t\n\t\tðŸ˜Š Positive Emotions\n\t\n\n\nExcited ðŸ˜†: Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caskcsg/Libra-Emo.","url":"https://huggingface.co/datasets/caskcsg/Libra-Emo","creator_name":" KCSG Knowledge Computing and Service Group, IIE, CAS","creator_url":"https://huggingface.co/caskcsg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","crowdsourced","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Loacky/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Loacky/sentiment-analysis-test","creator_name":"Lorenzo Adacher","creator_url":"https://huggingface.co/Loacky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"autoencoder-paraphrase-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube-timestamps","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for YouTube Videos Timestamps extraction dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: mit\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lyleokoth/youtube-timestamps.","url":"https://huggingface.co/datasets/lyleokoth/youtube-timestamps","creator_name":"lyle okoth","creator_url":"https://huggingface.co/lyleokoth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","@lyleokoth","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"cs2-highlights","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Counter-Strike 2 Highlight Clips\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 8,369 high-quality gameplay highlight clips primarily from Counter-Strike 2, with a small portion from Counter-Strike: Global Offensive. The clips focus on key gameplay moments such as kills, bomb interactions, and grenade usage. The clips are collected from competitive platforms like Faceit and in-game competitive modes (Premier, Matchmaking) across various skill levels, making itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cs2-highlights.","url":"https://huggingface.co/datasets/nyuuzyou/cs2-highlights","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","image-to-video","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Robust04InstructionRetrieval","keyword":"monolingual","description":"\n  Robust04InstructionRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring retrieval instruction following ability on Robust04 narratives for the FollowIR benchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReferencehttps://arxiv.org/abs/2403.15246\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"Robust04InstructionRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Robust04InstructionRetrieval.","url":"https://huggingface.co/datasets/mteb/Robust04InstructionRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","jhu-clsp/robust04-instructions-mteb","English"],"keywords_longer_than_N":true},
	{"name":"code-fonction-publique","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral de la fonction publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"PROMISE_NFR_translated","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPublished version of PROMISE NFR translated to Spanish used for paper 'Requirements Classification Using FastText and BETO in Spanish Documents'\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nProject: Project's Identifier.\nRequirement: Description of the software requirement.\nLabel: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated.","url":"https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cifar-10-lt","keyword":"monolingual","description":"The CIFAR-10-LT imbalanced dataset is comprised of under 60,000 color images (32Ã—32),\nacross 10 classes. The test set has 10,000 images (1,000 per class).\nThe training set is imbalanced with exponential factors of 10, 20, 50, 100, or 200.","url":"https://huggingface.co/datasets/lucasmaes/cifar-10-lt","creator_name":"Lucas Maes","creator_url":"https://huggingface.co/lucasmaes","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","crowdsourced","found","monolingual","cifar10"],"keywords_longer_than_N":true},
	{"name":"MedQA-USMLE-4-options_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedQA-USMLE Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of GBaker/MedQA-USMLE-4-options.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original medical question combined with the four multiple-choice options.\nanswer: The correct answer index, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\nA 60-year-old woman comes to the emergencyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/MedQA-USMLE-4-options_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/MedQA-USMLE-4-options_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoHotpotQA.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoHotpotQA-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoHotpotQA","French"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/LEGI.","url":"https://huggingface.co/datasets/Tricoteuses/LEGI","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"mb-dust_devil_det","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-dust_devil_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 10 splits: train, val, test, 0.01x_partition, 0.02x_partition, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.01x_partition, 0.02x_partitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-dust_devil_det.","url":"https://huggingface.co/datasets/Mirali33/mb-dust_devil_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"RealToxicityPrompts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":falseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"FlavaDataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFlavaDataset\n\t\n\nA dataset of personality-based text responses labeled with continuous FLAVA trait scores: Salty, Tangy, Mild, and Spicy.\n\n\t\n\t\t\n\t\tFlavaDataset\n\t\n\nA dataset of personality-based text responses labeled with continuous FLAVA trait scores (Salty, Tangy, Mild, Spicy).\n","url":"https://huggingface.co/datasets/neuraxcompany/FlavaDataset","creator_name":"Ethan McLaughlin","creator_url":"https://huggingface.co/neuraxcompany","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","human-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Maithili"],"keywords_longer_than_N":true},
	{"name":"vwp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Visual Writing Prompts Dataset (VWP)\n\t\n\nWebsite | Github Repository | arXiv e-Print\n\n\nThe Visual Writing Prompts (VWP) dataset contains almost 2K selected sequences of\nmovie shots, each including 5-10 images. The image sequences are aligned with a total of 12K stories which are collected via crowdsourcing given the image sequences and up to 5  grounded characters from the corresponding image sequence.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Links\n\t\n\n\n\n\nTACLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonyhong/vwp.","url":"https://huggingface.co/datasets/tonyhong/vwp","creator_name":"Xudong Hong","creator_url":"https://huggingface.co/tonyhong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Maithili"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"deepschool_demo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMy First Test Dataset ðŸ‡·ðŸ‡º\n\t\n\nÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ:ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚, ÑÐ¾ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¹ Ð¸Ð· ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸ Ð¸Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð².\nÐ¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°:\n\nid â€” Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð·Ð°Ð¿Ð¸ÑÐ¸\ntext â€” Ñ‚ÐµÐºÑÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ\nlabel â€” Ð¼ÐµÑ‚ÐºÐ°: 0 â€” Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, 1 â€” Ð²Ð¾Ð¿Ñ€Ð¾Ñ\n\nÐ˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº:Ð¡Ð¾Ð·Ð´Ð°Ð½ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð½Ð° Hugging Face Hub.\nÐ›Ð¸Ñ†ÐµÐ½Ð·Ð¸Ñ:MIT License\nÐ­Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð¼ÐµÑ‡Ð°Ð½Ð¸Ñ:  \n\nÐ”Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸.\nÐ’ÑÐµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾.\n\nÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/voronik1801/deepschool_demo.","url":"https://huggingface.co/datasets/voronik1801/deepschool_demo","creator_name":"Voronik_test","creator_url":"https://huggingface.co/voronik1801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"MaCBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMaCBench\n\t\n\n\n\n\n\n\n\n\n\n\nA Chemistry and Materials Benchmark for evaluating Vision Large Language Models\n\n\n\n\n\t\n\t\t\n\t\tâš ï¸ IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tðŸš« THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY ðŸš«\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidate evaluation results. Pleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/MaCBench.","url":"https://huggingface.co/datasets/jablonkagroup/MaCBench","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multiple-choice","image-to-text","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"ArmenianParaphrasePC","keyword":"monolingual","description":"\n  ArmenianParaphrasePC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nasparius/Armenian-Paraphrase-PC\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/ivannikov-lab/arpa-paraphrase-corpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArmenianParaphrasePC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArmenianParaphrasePC.","url":"https://huggingface.co/datasets/mteb/ArmenianParaphrasePC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Armenian"],"keywords_longer_than_N":true},
	{"name":"code-communes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des communes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"HyperForensics-plus-plus","keyword":"monolingual","description":"The HyperForensics++ dataset is an advanced benchmark designed for hyperspectral image (HSI) forgery detection.\nIt builds upon the foundational HyperForensics dataset by introducing new manipulation scenarios and enhanced techniques.","url":"https://huggingface.co/datasets/OtoroLin/HyperForensics-plus-plus","creator_name":"TZU YU LIN","creator_url":"https://huggingface.co/OtoroLin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCORetrieval","keyword":"monolingual","description":"\n  NanoMSMARCORetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoMSMARCORetrieval is a smaller subset of MS MARCO, a collection of datasets focused on deep learning in search.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReferencehttps://microsoft.github.io/msmarco/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoMSMARCORetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval.","url":"https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/msmarco"],"keywords_longer_than_N":true},
	{"name":"mb-domars16k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-domars16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: ael\n1: rou\n2: cli\n3: aec\n4: tex\n5: smo\n6: fss\n7: rid\n8: fse\n9: sfe\n10: fsf\n11: fsg\n12: sfx\n13: cra\n14: mix\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 11305 images\ntest: 1614 images\nval: 3231 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-domars16k.","url":"https://huggingface.co/datasets/Mirali33/mb-domars16k","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ItaCaseholdClassification","keyword":"monolingual","description":"\n  ItaCaseholdClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAn Italian Dataset consisting of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives of Italian Administrative Justice categorized with 64 subjects.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReference\nhttps://doi.org/10.1145/3594536.3595177\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ItaCaseholdClassification.","url":"https://huggingface.co/datasets/mteb/ItaCaseholdClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Italian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"AngryTweetsClassification","keyword":"monolingual","description":"\n  AngryTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.53/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AngryTweetsClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AngryTweetsClassification.","url":"https://huggingface.co/datasets/mteb/AngryTweetsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"car-parts-and-damage-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCar Parts and Damages Polygon Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Car Parts and Damages Polygon Dataset consists of 1,812 high-resolution images, each annotated with polygon-based segmentation masks for either car parts or car damages. The dataset is designed to support training and evaluation of deep learning models for fine-grained object detection, instance segmentation, and automotive inspection tasks.\n\n\t\n\t\t\n\t\tâœ… Key Stats:\n\t\n\n\nTotal images: 1,812  \nCar parts: 998 images  \nCarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DrBimmer/car-parts-and-damage-dataset.","url":"https://huggingface.co/datasets/DrBimmer/car-parts-and-damage-dataset","creator_name":"Dr. Bimmer","creator_url":"https://huggingface.co/DrBimmer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","object-detection","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"UCCVCommonLawLegalBenchClassification","keyword":"monolingual","description":"\n  UCCVCommonLawLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a contract is governed by the Uniform Commercial Code (UCC) or the common law of contracts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\nSource datasets:\n\nnguha/legalbench\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UCCVCommonLawLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/UCCVCommonLawLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"summeval","keyword":"monolingual","description":"\n  SummEvalSummarization.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article Summary Semantic Similarity Estimation. This version fixes a bug in the evaluation script that caused the main score to be computed incorrectly.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/Yale-LILY/SummEval\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/summeval.","url":"https://huggingface.co/datasets/mteb/summeval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","human-annotated","monolingual","mteb/summeval","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"OdiaNewsClassification","keyword":"monolingual","description":"\n  OdiaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Odia dataset for 3-class classification of Odia news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-odia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"OdiaNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OdiaNewsClassification.","url":"https://huggingface.co/datasets/mteb/OdiaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Odia"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Assamese"],"keywords_longer_than_N":true},
	{"name":"metallurgy-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMetallurgy and Materials Science Knowledge Extraction Dataset\n\t\n\nThis repository contains a dataset generated from parsed books related to various aspects of metallurgy, materials science, and engineering. The dataset is designed for fine-tuning Large Language Models (LLMs) for Question-Answering (QA) tasks in the domain of metallurgy and materials science.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes content derived from technical books in the field of metallurgy and materialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbdulrhmanEldeeb/metallurgy-qa.","url":"https://huggingface.co/datasets/AbdulrhmanEldeeb/metallurgy-qa","creator_name":"Eldeeb","creator_url":"https://huggingface.co/AbdulrhmanEldeeb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","closed-domain-qa","closed-book-qa","machine-generated"],"keywords_longer_than_N":true},
	{"name":"FaroeseSTS","keyword":"monolingual","description":"\n  FaroeseSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSemantic Text Similarity (STS) corpus for Faroese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.74.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FaroeseSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FaroeseSTS.","url":"https://huggingface.co/datasets/mteb/FaroeseSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Faroese"],"keywords_longer_than_N":true},
	{"name":"MC-I-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-All","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C-All.","url":"https://huggingface.co/datasets/annnli/TOFU-C-All","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unlearning","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LZ12DH/unlearning.","url":"https://huggingface.co/datasets/LZ12DH/unlearning","creator_name":"Li Zhaodonghui","creator_url":"https://huggingface.co/LZ12DH","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,165,934 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of promptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"uz-books","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BookCorpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release UzBooks dataset, a cleaned book corpus consisting of nearly 40000 books in Uzbek Language divided into two branches: \"original\" and \"lat,\" representing the OCRed (Latin and Cyrillic) and fully Latin versions of the texts, respectively. \nPlease refer to our blogpost and paper (Coming soon!) for further details.\nTo load and use dataset, run this script:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uz-books.","url":"https://huggingface.co/datasets/murodbek/uz-books","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"ro-offense-fb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-fb.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-fb","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"grustnogram","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Grustnogram\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 597,704 posts from Grustnogram.ru, a Russian \"emotional network\" similar to Instagram but with a distinctive black and white filter aesthetic and dark atmosphere. The dataset includes 542,917 image posts with associated metadata and 54,787 anonymous text-only posts.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is divided intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/grustnogram.","url":"https://huggingface.co/datasets/nyuuzyou/grustnogram","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-classification","multi-label-image-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"pbrpx","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PBRPX Asset Library\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 710 physically-based rendering (PBR) assets from pbrpx.com, a CC0 asset library. The dataset includes comprehensive information about 3D models, textures, and materials with detailed file listings, download URLs, texture resolutions, and categorization data. Assets include nature elements (trees, rocks), architectural materials (brick, concrete), and various other 3D models withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pbrpx.","url":"https://huggingface.co/datasets/nyuuzyou/pbrpx","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"FrenchBookReviews","keyword":"monolingual","description":"\n  FrenchBookReviews\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIt is a French book reviews dataset containing a huge number of reader reviews on French books. Each review is pared with a rating that ranges from 0.5 to 5 (with 0.5 increment).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/Abirate/french_book_reviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FrenchBookReviews.","url":"https://huggingface.co/datasets/mteb/FrenchBookReviews","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","French","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"steambans","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Steam User Bans\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 476,694 Steam users, including their profile details, ban status, and gaming activity. The data was collected from the Steam platform and includes information such as Steam ID, profile URL, username, avatar, account creation date, visibility state, VAC and game bans, economy ban status, time since last ban, Steam level, friend count, game count, total playtime, and CS2 playtime.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/steambans.","url":"https://huggingface.co/datasets/nyuuzyou/steambans","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","multi-label-classification","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"nepalitext-language-model-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"nepalitext-language-model-dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\"NepaliText\" language modeling dataset is a collection of over 13 million Nepali text sequences (phrases/sentences/paragraphs) extracted by combining the datasets: OSCAR , cc100 and a set of scraped Nepali articles on Wikipedia. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended to pre-train language models and word representations on Nepali Language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset.","url":"https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset","creator_name":"Utsav Maskey","creator_url":"https://huggingface.co/Sakonii","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"prezented","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Prezented.ru Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 2,289 educational presentations from the prezented.ru platform, a service focused on educational presentations for Russian schools. The dataset includes presentation titles, descriptions, download URLs, thumbnail images, and the original PPT/PPTX files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nRussian (ru): All content is in Russian\n\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/prezented.","url":"https://huggingface.co/datasets/nyuuzyou/prezented","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"toxic_conversations_50k","keyword":"monolingual","description":"\n  ToxicConversationsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCollection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/toxic_conversations_50k.","url":"https://huggingface.co/datasets/mteb/toxic_conversations_50k","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-1_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ï¼‘ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-1_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Oriya"],"keywords_longer_than_N":true},
	{"name":"human-muscle-aging-atlas-snRNAseq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman Skeletal Muscle Aging Atlas (sn/scRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Data Overview\n\t\n\nThis dataset provides single-nucleus and single-cell RNA sequencing (sn/scRNA-seq) data specifically focusing on the human skeletal muscle across different age groups. It serves as a rich resource for investigating cell-type specific gene expression changes and cellular composition shifts that occur during the aging process in a critical human tissue.\nThe original data was sourced from the Humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-muscle-aging-atlas-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/human-muscle-aging-atlas-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"monolingual","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"Ã‰ric Bavu","creator_url":"https://huggingface.co/zinc75","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedXpertQAExamRetrieval","keyword":"monolingual","description":"\n  R2MEDMedXpertQAExamRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedXpertQA-Exam retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedXpertQA-Exam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedXpertQAExamRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedXpertQA-Exam"],"keywords_longer_than_N":true},
	{"name":"mb-surface_multi_label_cls","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMER - Mars Exploration Rover Dataset\n\t\n\nA multi-label classification dataset containing Mars images from the Mars Exploration Rover (MER) mission for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset uses multi-label classification, meaning each image can have multiple class labels.\nThe dataset contains the following classes:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-surface_multi_label_cls.","url":"https://huggingface.co/datasets/Mirali33/mb-surface_multi_label_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Manipuri"],"keywords_longer_than_N":true},
	{"name":"code-voirie-routiere","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la voirie routiÃ¨re, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Maithili"],"keywords_longer_than_N":true},
	{"name":"TLPD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTLPD: Taiwan License Plate Dataset\n\t\n\nTLPD is a dataset containing over 3,000 images of vehicles with annotated license plates. Each image is labeled using the LabelMe format, with polygon annotations describing the boundary of each license plate.\nThis dataset is designed for tasks such as license plate detection, polygon segmentation, and scene text detection.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Structure\n\t\n\nAll image files are stored in the images/ directory, and their corresponding polygonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evan6007/TLPD.","url":"https://huggingface.co/datasets/evan6007/TLPD","creator_name":"evan6007","creator_url":"https://huggingface.co/evan6007","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"COVID-19-el-corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains Greek-language texts about the COVID-19 pandemic including relevant information, FAQs, etc. The texts were collected from official websites (WHO, ECDC, NPHO, covid19.gov.gr) and articles from the greek Wikipedia. Total number of words: 204,748.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach instance contains:\n\ncontent: Plain text\nid: Instance ID\ntitle: A document title (only in instances related to Wikipedia articles)\n\n\n\t\n\t\t\n\t\tLicensingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus.","url":"https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","original","Greek","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CUADExclusivityLegalBenchClassification","keyword":"monolingual","description":"\n  CUADExclusivityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies exclusive dealing commitment with the counterparty. This includes a commitment to procure all 'requirements' from one party of certain technology, goods, or services or a prohibition on licensing or selling technology, goods or services to third parties, or a prohibition on collaborating or workingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"polymath","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPaper Information\n\t\n\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including Chain-of-Thoughtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath.","url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","expert-generated","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER","keyword":"monolingual","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","ClimateFEVER","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"CUADCompetitiveRestrictionExceptionLegalBenchClassification","keyword":"monolingual","description":"\n  CUADCompetitiveRestrictionExceptionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause mentions exceptions or carveouts to Non-Compete, Exclusivity and No-Solicit of Customers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"deepschool_dataset_demo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMy First Test Dataset ðŸ‡·ðŸ‡º\n\t\n\nÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ:ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚, ÑÐ¾ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¹ Ð¸Ð· ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸ Ð¸Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð².\nÐ¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°:\n\nid â€” Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð·Ð°Ð¿Ð¸ÑÐ¸\ntext â€” Ñ‚ÐµÐºÑÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ\nlabel â€” Ð¼ÐµÑ‚ÐºÐ°: 0 â€” Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, 1 â€” Ð²Ð¾Ð¿Ñ€Ð¾Ñ\n\nÐ˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº:Ð¡Ð¾Ð·Ð´Ð°Ð½ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð½Ð° Hugging Face Hub.\nÐ›Ð¸Ñ†ÐµÐ½Ð·Ð¸Ñ:MIT License\nÐ­Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð¼ÐµÑ‡Ð°Ð½Ð¸Ñ:  \n\nÐ”Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸.\nÐ’ÑÐµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾.\n\nÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/voronik1801/deepschool_dataset_demo.","url":"https://huggingface.co/datasets/voronik1801/deepschool_dataset_demo","creator_name":"Voronik_test","creator_url":"https://huggingface.co/voronik1801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cbin","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cbin.","url":"https://huggingface.co/datasets/annnli/TOFU-Cbin","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"twi_sentences","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Sentences Dataset\n\t\n\nThis dataset contains sentences in the Twi language, collected from various sources.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nsentence: The original sentence text in Twi.\nword_count: The number of words in the sentence.\n\n\n\t\n\t\t\n\t\tIntended Uses\n\t\n\n\nNLP training and evaluation for Twi.\nLanguage modeling and sentence classification tasks.\n\n\n\t\n\t\t\n\t\tSize\n\t\n\nTotal sentences: 361951\n\nDataset prepared and uploaded automatically.\n","url":"https://huggingface.co/datasets/michsethowusu/twi_sentences","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","no-claim","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corruptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFiQA2018.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFiQA2018-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFiQA2018","French"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoDBPedia.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoDBPedia-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoDBPedia","French"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modfied copy of the dataset from The Language and Voice Laboratory in RU.\nThis is the first release of the SamrÃ³mur Icelandic Speech corpus that contains 100.000 validated utterances.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab at the Reykjavik University, in cooperation with AlmannarÃ³mur, Center for Language Technology.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe audio is in Icelandic.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidErikMollberg/samromur_asr.","url":"https://huggingface.co/datasets/DavidErikMollberg/samromur_asr","creator_name":"David Erik Mollberg","creator_url":"https://huggingface.co/DavidErikMollberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SyntheticText2SQL","keyword":"monolingual","description":"\n  SyntheticText2SQL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding sql snippets. The task is to retrieve the most relevant code snippet for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://huggingface.co/datasets/gretelai/synthetic_text_to_sql\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SyntheticText2SQL.","url":"https://huggingface.co/datasets/mteb/SyntheticText2SQL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/synthetic-text2sql","code"],"keywords_longer_than_N":true},
	{"name":"DBPedia_Classes","keyword":"monolingual","description":"About Dataset\nDBpedia (from \"DB\" for \"database\") is a project aiming to extract structured content from the information created in Wikipedia.\nThis is an extract of the data (after cleaning, kernel included) that provides taxonomic, hierarchical categories (\"classes\") for 342,782 wikipedia articles. There are 3 levels, with 9, 70 and 219 classes respectively.\nA version of this dataset is a popular baseline for NLP/text classification tasks. This version of the dataset is much tougherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes.","url":"https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"OSCAR-2019-Burmese-fix","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OSCAR-2019-Burmese-fix\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a cleand version of Myanmar language in OSCAR 2019 dataset.\n\n\t\n\t\t\n\t\tContributions\n\t\n\nSwan Htet Aung\n","url":"https://huggingface.co/datasets/5w4n/OSCAR-2019-Burmese-fix","creator_name":"Swan Htet Aung","creator_url":"https://huggingface.co/5w4n","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Million_News_Headlines","keyword":"monolingual","description":"About Dataset\nContext\nThis contains data of news headlines published over a period of nineteen years.\nSourced from the reputable Australian news source ABC (Australian Broadcasting Corporation)\nAgency Site: (http://www.abc.net.au)\nContent\nFormat: CSV ; Single File\npublish_date: Date of publishing for the article in yyyyMMdd format\nheadline_text: Text of the headline in Ascii , English , lowercase\n\nStart Date: 2003-02-19 ; End Date: 2021-12-31\nInspiration\nI look at this news dataset as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines.","url":"https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"MNLP_M2_mcqa_dataset_2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M2 MCQA Dataset 2\n\t\n\nThe MNLP M2 MCQA Dataset 2 is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~25,000 MCQA questions\n7 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset_2.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset_2","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"winograd_wsc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for The Winograd Schema Challenge\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is\nresolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its\nresolution. The schema takes its name from a well-known example by Terry Winograd:\n\nThe city councilmen refused the demonstrators a permit because they [feared/advocated] violence.\n\nIf theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lighteval/winograd_wsc.","url":"https://huggingface.co/datasets/lighteval/winograd_wsc","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-coreference-resolution","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"code-minier","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode minier, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"mb-change_cls_hirise","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-change_cls_hirise\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-22\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: no_change\n1: change\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 6206 images\ntest: 1340 images\nval: 1340 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-change_cls_hirise.","url":"https://huggingface.co/datasets/Mirali33/mb-change_cls_hirise","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Kiali","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Kiali Chatbot Q&A Dataset is a collection of question-answer pairs focused on Kiali, an observability console for Istio service meshes, and related Istio concepts. This dataset is specifically designed to facilitate the training of conversational AI models (chatbots) aimed at assisting users with understanding and troubleshooting the Kiali interface and core Istio functionalities.\nThe dataset includes questions and answers derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kiali/Kiali.","url":"https://huggingface.co/datasets/Kiali/Kiali","creator_name":"Kiali","creator_url":"https://huggingface.co/Kiali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","document-question-answering","conversational","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Telugu"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v123","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Combined V1-V3\n\t\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset combines three versions of synthetic summaries:\n\nV1 & V2: Filtered for 4-5 sentence summaries\nV3: Cleaned and extracted final summaries\n\n\n\t\n\t\t\n\t\tProcessing Steps\n\t\n\n\nV1 and V2 Processing:\n\nFiltered to include only 4-5 sentence summaries\nRemoved length metadata for consistency\n\n\nV3 Processing:\n\nExtracted final summaries from tagged content\nRemoved length metadata forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Telugu"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-2_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•2ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-2_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr_50_250406","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n50 lignes de GSM8K traduit en franÃ§ais Ã  l'aide de quickmt/quickmt-en-fr. Les questions sont rÃ©duites Ã  moins de 256 tokens et les rÃ©ponses Ã  moins de 768 tokens (tokenizer de Phi-4).\n50 lines of the GSM8K dataset translated to french using quickmt/quickmt-en-fr. Trimmed so questions are smaller than 256 tokens and responses smaller than 768 tokens (Phi-4 tokenizer).\n","url":"https://huggingface.co/datasets/cmh/gsm8k_fr_50_250406","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","French","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Gujarati"],"keywords_longer_than_N":true},
	{"name":"T2Retrieval","keyword":"monolingual","description":"\n  T2Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nT2Ranking: A large-scale Chinese Benchmark for Passage Ranking\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Financial, Government, Non-fiction\n\n\nReference\nhttps://arxiv.org/abs/2304.03679\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"T2Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/T2Retrieval.","url":"https://huggingface.co/datasets/mteb/T2Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Mandarin Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"hadith-qa-pair","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHadith QA Pair Dataset\n\t\n\nThis dataset contains Hadith-based question-answer pairs extracted from four renowned Hadith collections: Musnad Ahmad, Sahih Muslim, Sahih Bukhari, and Jami` at-Tirmidhi.\nThe dataset is structured as question-answer pairs, where each question is answered using a relevant Hadith along with its reference. It can be utilized to train Large Language Models (LLMs) for text generation and question-answering tasks in Islamic studies.\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rwmasood/hadith-qa-pair.","url":"https://huggingface.co/datasets/rwmasood/hadith-qa-pair","creator_name":"Dr Wasif Masood","creator_url":"https://huggingface.co/rwmasood","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"deneme5","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TozluLider6393/deneme5.","url":"https://huggingface.co/datasets/TozluLider6393/deneme5","creator_name":"furkan doÄŸan","creator_url":"https://huggingface.co/TozluLider6393","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"FunctionOfDecisionSectionLegalBenchClassification","keyword":"monolingual","description":"\n  FunctionOfDecisionSectionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to classify a paragraph extracted from a written court decision into one of seven possible categories:\n            1. Facts - The paragraph describes the faction background that led up to the present lawsuit.\n            2. Procedural History - The paragraph describes the course of litigation that led to the current proceeding before the court.\n            3. Issue - Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"LegalBenchPC","keyword":"monolingual","description":"\n  LegalBenchPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis LegalBench pair classification task is a combination of the following datasets:\n    - Citation Prediction Classification: Given a legal statement and a case citation, determine if the citation is supportive of the legal statement.\n    - Consumer Contracts QA: The task consists of 400 yes/no questions relating to consumer contracts (specifically, online terms of service) and is relevant to the legal skill of contractâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalBenchPC.","url":"https://huggingface.co/datasets/mteb/LegalBenchPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","expert-annotated","monolingual","nguha/legalbench"],"keywords_longer_than_N":true},
	{"name":"Urdu_Hate_Speech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUrdu Hate Speech\n\t\n\nA binary Urdu text classification dataset for hate-speech detection.\n\nTask: hate vs. not_hate (2 classes)\nLanguage: Urdu (ur)\nPrimary columns: text, label(In the uploaded files the columns are Tweet and Tag; see â€œHow to Useâ€ for renaming.)\nLabels:\n0 â†’ not_hate\n1 â†’ hate\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short-form Urdu text (e.g., social media posts) labeled for hate speech. It supports research, moderation assistance, and demos. It should not beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech.","url":"https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech","creator_name":"Muhammad Adnan Mushtaq","creator_url":"https://huggingface.co/Adnan855570","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ISIC_2019_224","keyword":"monolingual","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for ISIC-2019 RESIZED\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe original ISIC 2019 dataset contains 25,331 images of dermoscopic images from nine different diagnostic categories.\nPublished by the The International Skin Imaging Collbaroation, it serves as a challenging image classification dataset where the distribution\nacross classes is heavily skewed towards the first two classes.\nThe ISIC-2019 RESIZED is a downsampled version of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MKZuziak/ISIC_2019_224.","url":"https://huggingface.co/datasets/MKZuziak/ISIC_2019_224","creator_name":"Maciej Zuziak","creator_url":"https://huggingface.co/MKZuziak","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["image-classification","The International Skin Imaging Collaboration","found","monolingual","ISIC 2019 Challenge"],"keywords_longer_than_N":true},
	{"name":"livre-procedures-fiscales","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLivre des procÃ©dures fiscales, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales.","url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"monkey_business","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMonkey Business\n\t\n\nMonkey Business is a dataset of samples from large language models. It contains both correct and incorrect samples from a variety of models (the Llama-3, Gemma, and Pythia series) on a variety of tasks (problems from GSM8K, MATH, CodeContests, and MiniF2F-MATH). We hope that it can be useful for developing improved verification methods that assess whether a model generated answer is correct.\nThis dataset was created as part of the project: \"Large Language Monkeys:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ScalingIntelligence/monkey_business.","url":"https://huggingface.co/datasets/ScalingIntelligence/monkey_business","creator_name":"Scaling Intelligence","creator_url":"https://huggingface.co/ScalingIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoQuoraRetrieval.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoQuoraRetrieval-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoQuoraRetrieval","French"],"keywords_longer_than_N":true},
	{"name":"superglue","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSuperGLUE Benchmark Datasets\n\t\n\nThis repository contains the SuperGLUE benchmark datasets. Each dataset is available as a separate configuration, making it easy to load individual datasets using the datasets library.\n\n\t\n\t\t\n\t\tDataset Descriptions\n\t\n\n\n\t\n\t\t\n\t\tDatasets Included\n\t\n\n\nBoolQ: A question-answering task where each example consists of a short passage and a yes/no question about the passage. The questions are provided anonymously and unsolicited by users of the Google searchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hyukkyu/superglue.","url":"https://huggingface.co/datasets/Hyukkyu/superglue","creator_name":"Hyukkyu Kang","creator_url":"https://huggingface.co/Hyukkyu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Situat3DChange","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ§  Situat3DChange\n\t\n\n\n\nSituat3DChange is a comprehensive dataset developed for perception-action modeling in dynamic 3D environments. Unlike prior 3D datasets that focus on static scenes or isolated object changes, Situat3DChange reflects the fluid, evolving nature of real-world physical environments and tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ” Subtasks\n\t\n\n\n121K questionâ€“answer pairs\n36K change descriptions \n17K rearrangement instructions\n\n\n\n\t\n\t\n\t\n\t\tðŸ“¦ Repository Contents\n\t\n\nSituat3DChange/\nâ”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lrp123/Situat3DChange.","url":"https://huggingface.co/datasets/lrp123/Situat3DChange","creator_name":"Ruiping Liu","creator_url":"https://huggingface.co/lrp123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"BulgarianStoreReviewSentimentClassfication","keyword":"monolingual","description":"\n  BulgarianStoreReviewSentimentClassfication\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBulgarian online store review dataset for sentiment classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://doi.org/10.7910/DVN/TXIK9P\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BulgarianStoreReviewSentimentClassfication\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication.","url":"https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"indo-movie-subtitle","keyword":"monolingual","description":"This dataset is built as a playground for analyzing text on movie subtitle","url":"https://huggingface.co/datasets/jakartaresearch/indo-movie-subtitle","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mp-docvqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multipage Document Visual Question Answering (MP-DocVQA)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is aimed to perform Visual Question Answering on multipage industry scanned documents. The questions and answers are reused from Single Page DocVQA (SP-DocVQA) dataset. The images also corresponds to the same in original dataset with previous and posterior pages with a limit of up to 20 pages per document.\n\n\t\n\t\t\n\t\tDownload the Dataset\n\t\n\nThe dataset is not integrated withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubentito/mp-docvqa.","url":"https://huggingface.co/datasets/rubentito/mp-docvqa","creator_name":"RubÃ¨n Tito","creator_url":"https://huggingface.co/rubentito","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","document-question-answering","monolingual","Single Page Document Visual Question Answering","English"],"keywords_longer_than_N":true},
	{"name":"the-reddit-climate-change-dataset","keyword":"monolingual","description":"All the mentions of climate change on Reddit before Sep 1 2022.","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-climate-change-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Contextual_Response_Evaluation_for_ESL_and_ASD_Support","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Contextual Response Evaluation for ESL and ASD SupportðŸ’œðŸ’¬ðŸŒ\"\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description ðŸ“–\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary ðŸ“\n\t\n\nCurated by Eric Soderquist, this dataset is a collection of English prompts and responses generated by the Phi-2 model, designed to evaluate and improve NLP models for supporting ESL (English as a Second Language) and ASD (Autism Spectrum Disorder) user bases. Each prompt is paired with multiple AI-generated responses and evaluated using aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support.","url":"https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support","creator_name":"Eric Soderquist","creator_url":"https://huggingface.co/yunjaeys","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"thirukkural_instruct","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nthirukkural_QA is an open source dataset of instruct-style records generated by converting publicly available data on Thirukkural and it's meaning.\nThis was created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\nQuestion Answering\n\nLanguages: Tamil Version: 1.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct.","url":"https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"beer_reviews_label_drift_neg","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/beer_reviews_label_drift_neg","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"bace_regression","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for bace_regression\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbace_regression is a dataset included in MoleculeNet. This dataset consists of  Quantitative (IC50) binding results for a set of inhibitors of human Î²-secretase 1(BACE-1).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: the IC50 binding results\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_regression.","url":"https://huggingface.co/datasets/zpn/bace_regression","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"prost","keyword":"monolingual","description":"*Physical Reasoning about Objects Through Space and Time* (PROST) is a probing dataset to evaluate the ability of pretrained LMs to understand and reason about the physical world. PROST consists of 18,736 cloze-style multiple choice questions from 14 manually curated templates, covering 10 physical reasoning concepts:  direction, mass, height, circumference, stackable, rollable, graspable, breakable, slideable, and bounceable.","url":"https://huggingface.co/datasets/corypaik/prost","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","open-domain-qa","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enrichment_only","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SpeechCommands\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ“Š Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \nðŸ” This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only.","url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"ca_text_corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ca-text-corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPublic domain corpus of Catalan text.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nCatalan (ca).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/ca_text_corpus.","url":"https://huggingface.co/datasets/softcatala/ca_text_corpus","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaItScansRetrieval","keyword":"monolingual","description":"\n  JinaVDREuropeanaItScansRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Italian historical articles based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-it-scans_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-it-scans_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaItScansRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaItScansRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaDeNewsRetrieval","keyword":"monolingual","description":"\n  JinaVDREuropeanaDeNewsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve German news articles based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-de-news_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-de-news_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaDeNewsRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaDeNewsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"9111-questions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 9111.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset includes legal questions and answers from the Russian law forum 9111.ru. It contains inquiries from users and corresponding responses from lawyers. The dataset was created by processing around 21 million questions, providing a significant corpus of legal discussions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/9111-questions.","url":"https://huggingface.co/datasets/nyuuzyou/9111-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaFrNewsRetrieval","keyword":"monolingual","description":"\n  JinaVDREuropeanaFrNewsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve French news articles from Europeana based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-fr-news_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-fr-news_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaFrNewsRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaFrNewsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaEsNewsRetrieval","keyword":"monolingual","description":"\n  JinaVDREuropeanaEsNewsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Spanish news articles based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-es-news_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-es-news_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaEsNewsRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaEsNewsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"snips_built_in_intents","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Snips Built In Intents\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSnips' built in intents dataset was initially used to compare different voice assistants and released as a public dataset hosted at\nhttps://github.com/sonos/nlu-benchmark in folder 2016-12-built-in-intents. The dataset contains 328 utterances over 10 intent classes.\nA related Medium post is https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents.","url":"https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents","creator_name":"sonos-nlu-benchmark","creator_url":"https://huggingface.co/sonos-nlu-benchmark","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_lm","keyword":"monolingual","description":"Language modeling resources to be used in conjunction with the LibriSpeech ASR corpus.","url":"https://huggingface.co/datasets/openslr/librispeech_lm","creator_name":"OpenSLR","creator_url":"https://huggingface.co/openslr","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"spl_adr_200db","keyword":"monolingual","description":"The United States Food and Drug Administration (FDA) partnered with the National Library\nof Medicine to create a pilot dataset containing standardised information about known\nadverse reactions for 200 FDA-approved drugs. The Structured Product Labels (SPLs),\nthe documents FDA uses to exchange information about drugs and other products, were\nmanually annotated for adverse reactions at the mention level to facilitate development\nand evaluation of text mining tools for extraction of ADRs from all SPLs.  The ADRs were\nthen normalised to the Unified Medical Language System (UMLS) and to the Medical\nDictionary for Regulatory Activities (MedDRA).","url":"https://huggingface.co/datasets/bigbio/spl_adr_200db","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"VidoreArxivQARetrieval","keyword":"monolingual","description":"\n  VidoreArxivQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/arxivqa_test_subsampled_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreArxivQARetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreArxivQARetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreArxivQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRDocQAAI","keyword":"monolingual","description":"\n  JinaVDRDocQAAI\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve AI documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/docqa_artificial_intelligence_beir\n\n\n\t\n\nSource datasets:\n\njinaai/docqa_artificial_intelligence_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRDocQAAI\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRDocQAAI.","url":"https://huggingface.co/datasets/mteb/JinaVDRDocQAAI","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"tldr","keyword":"monolingual","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_human_doc","keyword":"monolingual","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"web-sentences-br","keyword":"monolingual","description":"Breton sentences from the public web. Filtered and deduplicated.\nMostly KLT orthography.\nAround 1M words.\n","url":"https://huggingface.co/datasets/gweltou/web-sentences-br","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Breton","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"visual-spatial-reasoning","keyword":"monolingual","description":"The Visual Spatial Reasoning (VSR) corpus is a collection of caption-image pairs with true/false labels. Each caption describes the spatial relation of two individual objects in the image, and a vision-language model (VLM) needs to judge whether the caption is correctly describing the image (True) or not (False).","url":"https://huggingface.co/datasets/albertvillanova/visual-spatial-reasoning","creator_name":"Albert Villanova del Moral","creator_url":"https://huggingface.co/albertvillanova","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","crowdsourced","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"KOTOX","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tKOTOX\n\t\n\n\n\t\n\t\t\n\t\t: A Korean Toxic Dataset for Deobfuscation and Detoxification\n\t\n\nHate Speech Detection dataset ðŸ‘‰ KOTOX-classificationDetoxification or Sanitization dataset ðŸ‘‰ Here!\nðŸ“š paper | \nðŸˆâ€â¬› git\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Summary\n\t\n\nKOTOX is the first Korean dataset designed for both toxic text detoxification and obfuscation robustness.   \nIt provides paired neutral-toxic sentences and their obfuscated counterparts, constructed with 17 linguistically grounded transformation rulesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ssgyejin/KOTOX.","url":"https://huggingface.co/datasets/ssgyejin/KOTOX","creator_name":"leeyejin","creator_url":"https://huggingface.co/ssgyejin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","hate-speech-detection","rule-based","llm-generated"],"keywords_longer_than_N":true},
	{"name":"WordNetNoun","keyword":"monolingual","description":"Disambiguated version of WordNet's noun hierarchy where entity names are formatted  as \"name: definition\" to resolve polysemy issues. This prevents training signal  conflicts when the same word has multiple meanings.\n","url":"https://huggingface.co/datasets/Jinrui/WordNetNoun","creator_name":"Lin","creator_url":"https://huggingface.co/Jinrui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HatefulMemesI2TRetrieval","keyword":"monolingual","description":"\n  HatefulMemesI2TRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve captions based on memes to assess OCR abilities.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\ni2t\n\n\nDomains\nEncyclopaedic\n\n\nReference\nhttps://arxiv.org/pdf/2005.04790\n\n\n\t\n\nSource datasets:\n\nAhren09/MMSoc_HatefulMemes\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"HatefulMemesI2TRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HatefulMemesI2TRetrieval.","url":"https://huggingface.co/datasets/mteb/HatefulMemesI2TRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRDocQAGovReportRetrieval","keyword":"monolingual","description":"\n  JinaVDRDocQAGovReportRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve government reports based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nGovernment\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/docqa_gov_report_beir\n\n\n\t\n\nSource datasets:\n\njinaai/docqa_gov_report_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRDocQAGovReportRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRDocQAGovReportRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreSyntheticDocQAHealthcareIndustryRetrieval","keyword":"monolingual","description":"\n  VidoreSyntheticDocQAHealthcareIndustryRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/syntheticDocQA_healthcare_industry_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAHealthcareIndustryRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAHealthcareIndustryRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRInfovqaRetrieval","keyword":"monolingual","description":"\n  JinaVDRInfovqaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve infographics based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/infovqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/infovqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRInfovqaRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRInfovqaRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRInfovqaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRArabicInfographicsVQARetrieval","keyword":"monolingual","description":"\n  JinaVDRArabicInfographicsVQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Arabic infographics based on queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/arabic_infographicsvqa_ar_beir\n\n\n\t\n\nSource datasets:\n\njinaai/arabic_infographicsvqa_ar_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRArabicInfographicsVQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRArabicInfographicsVQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"MemotionT2IRetrieval","keyword":"monolingual","description":"\n  MemotionT2IRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve memes based on captions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nEncyclopaedic\n\n\nReference\nhttps://aclanthology.org/2020.semeval-1.99/\n\n\n\t\n\nSource datasets:\n\nAhren09/MMSoc_Memotion\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"MemotionT2IRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MemotionT2IRetrieval.","url":"https://huggingface.co/datasets/mteb/MemotionT2IRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"MemotionI2TRetrieval","keyword":"monolingual","description":"\n  MemotionI2TRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve captions based on memes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\ni2t\n\n\nDomains\nEncyclopaedic\n\n\nReference\nhttps://aclanthology.org/2020.semeval-1.99/\n\n\n\t\n\nSource datasets:\n\nAhren09/MMSoc_Memotion\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"MemotionI2TRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MemotionI2TRetrieval.","url":"https://huggingface.co/datasets/mteb/MemotionI2TRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRMMTabRetrieval","keyword":"monolingual","description":"\n  JinaVDRMMTabRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve tables from the MMTab dataset based on queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/MMTab_beir\n\n\n\t\n\nSource datasets:\n\njinaai/MMTab_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRMMTabRetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRMMTabRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRMMTabRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"monolingual","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"faquad","keyword":"monolingual","description":"Academic secretaries and faculty members of higher education institutions face a common problem: \n  the abundance of questions sent by academics \n  whose answers are found in available institutional documents. \nThe official documents produced by Brazilian public universities are vast and disperse, \n  which discourage students to further search for answers in such sources.\nIn order to lessen this problem, we present FaQuAD: \n  a novel machine reading comprehension dataset \n  in the domain of Brazilian higher education institutions. \nFaQuAD follows the format of SQuAD (Stanford Question Answering Dataset) [Rajpurkar et al. 2016]. \nIt comprises 900 questions about 249 reading passages (paragraphs), \n  which were taken from 18 official documents of a computer science college \n  from a Brazilian federal university \n  and 21 Wikipedia articles related to Brazilian higher education system. \nAs far as we know, this is the first Portuguese reading comprehension dataset in this format.","url":"https://huggingface.co/datasets/eraldoluis/faquad","creator_name":"Eraldo R. Fernandes","creator_url":"https://huggingface.co/eraldoluis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"syntran-fa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynTran-fa\n\t\n\nSyntactic Transformed Version of Farsi QA datasets to make fluent responses from questions and short answers. You can use this dataset by the code below:\nimport datasets\ndata = datasets.load_dataset('SLPL/syntran-fa', split=\"train\")\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nHomepage: Sharif-SLPL\nRepository: SynTran-fa\nPoint of Contact: Sadra Sabouri\nPaper: SynTran-fa: Generating Comprehensive Answers for Farsi QA Pairs via Syntactic Transformation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SLPL/syntran-fa.","url":"https://huggingface.co/datasets/SLPL/syntran-fa","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","monolingual","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_oracle","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original numberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_oracle.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"clevr-math","keyword":"monolingual","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \"Remove all large red cylinders. How many objects are left?\". There are also adversarial (e.g. \"Remove all blue cubes. How many cylinders are left?\") and multihop questions (e.g. \"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\").","url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren LindstrÃ¶m","creator_url":"https://huggingface.co/dali-does","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"filtered-cuad","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for filtered_cuad\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions. This dataset is a filtered version of CUAD. It excludes legal contracts with an Agreement date prior to 2002 and contracts which are notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alex-apostolo/filtered-cuad.","url":"https://huggingface.co/datasets/alex-apostolo/filtered-cuad","creator_name":"Alex Apostolopoulos","creator_url":"https://huggingface.co/alex-apostolo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/unpredictable/unpredictable_support-google-com","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"dev_mode-wtq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for dev_mode-wtq\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dev_mode-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nquestion-answering, table-question-answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefaultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Serverless/dev_mode-wtq.","url":"https://huggingface.co/datasets/Serverless/dev_mode-wtq","creator_name":"Serverless Inc","creator_url":"https://huggingface.co/Serverless","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","wikitablequestions"],"keywords_longer_than_N":true},
	{"name":"pavlick-formality-scores","keyword":"monolingual","description":"This dataset contains sentence-level formality annotations used in the 2016\nTACL paper \"An Empirical Analysis of Formality in Online Communication\"\n(Pavlick and Tetreault, 2016). It includes sentences from four genres (news,\nblogs, email, and QA forums), all annotated by humans on Amazon Mechanical\nTurk. The news and blog data was collected by Shibamouli Lahiri, and we are\nredistributing it here for the convenience of other researchers. We collected\nthe email and answers data ourselves, usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/osyvokon/pavlick-formality-scores.","url":"https://huggingface.co/datasets/osyvokon/pavlick-formality-scores","creator_name":"Oleksiy Syvokon","creator_url":"https://huggingface.co/osyvokon","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"named_timexes","keyword":"monolingual","description":"This is a dataset annotated for _named temporal expression_ chunks.\n\nThe\ncommonest temporal expressions typically\ncontain date and time words, like April or\nhours. Research into recognising and interpreting these typical expressions is mature in many languages. However, there is\na class of expressions that are less typical,\nvery varied, and difficult to automatically\ninterpret. These indicate dates and times,\nbut are harder to detect because they often do not contain time words and are not\nused frequently enough to appear in conventional temporally-annotated corpora â€“\nfor example *Michaelmas* or *Vasant Panchami*.\n\nFor more details see [https://aclanthology.org/R13-1015.pdf](https://aclanthology.org/R13-1015.pdf)","url":"https://huggingface.co/datasets/strombergnlp/named_timexes","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nlpcc-stance","keyword":"monolingual","description":"This is a stance prediction dataset in Chinese.\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data.","url":"https://huggingface.co/datasets/strombergnlp/nlpcc-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","description":"This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.","url":"https://huggingface.co/datasets/Stevross/mmlu","creator_name":"Stephen Davies","creator_url":"https://huggingface.co/Stevross","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"visual_genome","keyword":"monolingual","description":"Visual Genome enable to model objects and relationships between objects.\nThey collect dense annotations of objects, attributes, and relationships within each image.\nSpecifically, the dataset contains over 108K images where each image has an average of 35 objects, 26 attributes, and 21 pairwise relationships between objects.","url":"https://huggingface.co/datasets/ranjaykrishna/visual_genome","creator_name":"Ranjay Krishna","creator_url":"https://huggingface.co/ranjaykrishna","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-to-text","object-detection","visual-question-answering","image-captioning","found"],"keywords_longer_than_N":true},
	{"name":"wikinews-fr-100","keyword":"monolingual","description":"Wikinews-fr-100 benchmark dataset for keyphrase extraction an generation.","url":"https://huggingface.co/datasets/taln-ls2n/wikinews-fr-100","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","unknown","unknown","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"zulu_stance","keyword":"monolingual","description":"This is a stance detection dataset in the Zulu language. The data is translated to Zulu by Zulu native speakers, from English source texts.\n\nMisinformation has become a major concern in recent last years given its \nspread across our information sources. In the past years, many NLP tasks have\nbeen introduced in this area, with some systems reaching good results on \nEnglish language datasets. Existing AI based approaches for fighting \nmisinformation in literature suggest automatic stance detection as an integral\nfirst step to success. Our paper aims at utilizing this progress made for\nEnglish to transfers that knowledge into other languages, which is a \nnon-trivial task due to the domain gap between English and the target \nlanguages. We propose a black-box non-intrusive method that utilizes techniques\nfrom Domain Adaptation to reduce the domain gap, without requiring any human\nexpertise in the target language, by leveraging low-quality data in both a\nsupervised and unsupervised manner. This allows us to rapidly achieve similar\nresults for stance detection for the Zulu language, the target language in\nthis work, as are found for English. We also provide a stance detection dataset\nin the Zulu language.","url":"https://huggingface.co/datasets/strombergnlp/zulu_stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","sentiment-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cifar100-enriched","keyword":"monolingual","description":"The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images\nper class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses.\nThere are two labels per image - fine label (actual class) and coarse label (superclass).","url":"https://huggingface.co/datasets/renumics/cifar100-enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","crowdsourced","found","monolingual","extended|other-80-Million-Tiny-Images"],"keywords_longer_than_N":true},
	{"name":"JinaVDRArabicChartQARetrieval","keyword":"monolingual","description":"\n  JinaVDRArabicChartQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Arabic charts based on queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/arabic_chartqa_ar_beir\n\n\n\t\n\nSource datasets:\n\njinaai/arabic_chartqa_ar_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRArabicChartQARetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRArabicChartQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRArabicChartQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"Vidore2ESGReportsHLRetrieval","keyword":"monolingual","description":"\n  Vidore2ESGReportsHLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/esg_reports_human_labeled_v2\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"Vidore2ESGReportsHLRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Vidore2ESGReportsHLRetrieval.","url":"https://huggingface.co/datasets/mteb/Vidore2ESGReportsHLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreTabfquadRetrieval","keyword":"monolingual","description":"\n  VidoreTabfquadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/tabfquad_test_subsampled_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreTabfquadRetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreTabfquadRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreTabfquadRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRHungarianDocQARetrieval","keyword":"monolingual","description":"\n  JinaVDRHungarianDocQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Hungarian documents in various formats based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/hungarian_doc_qa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/hungarian_doc_qa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRHungarianDocQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRHungarianDocQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"qg_esquad","keyword":"monolingual","description":"[SQuAD-es](https://huggingface.co/datasets/squad_es) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Spanish"],"keywords_longer_than_N":true},
	{"name":"tne","keyword":"monolingual","description":"TNE is an NLU task, which focus on relations between noun phrases (NPs) that can be mediated via prepositions.\nThe dataset contains 5,497 documents, annotated exhaustively with all possible links between the NPs in each document.","url":"https://huggingface.co/datasets/yanaiela/tne","creator_name":"Yanai Elazar","creator_url":"https://huggingface.co/yanaiela","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"FaithDial","keyword":"monolingual","description":"FaithDial is a new benchmark for hallucination-free dialogues, created by manually editing hallucinated and uncooperative responses in Wizard of Wikipedia.","url":"https://huggingface.co/datasets/McGill-NLP/FaithDial","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"wsd_polish_datasets","keyword":"monolingual","description":"Polish WSD training data manually annotated by experts according to plWordNet-4.2.","url":"https://huggingface.co/datasets/clarin-knext/wsd_polish_datasets","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","word-sense-disambiguation","expert-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"vasr","keyword":"monolingual","description":"VASR is a challenging dataset for evaluating computer vision commonsense reasoning abilities. Given a triplet of images, the task is to select an image candidate B' that completes the analogy (A to A' is like B to what?). Unlike previous work on visual analogy that focused on simple image transformations, we tackle complex analogies requiring understanding of scenes. Our experiments demonstrate that state-of-the-art models struggle with carefully chosen distractors (Â±53%, compared to 90% human accuracy).","url":"https://huggingface.co/datasets/nlphuji/vasr","creator_name":"nlphuji","creator_url":"https://huggingface.co/nlphuji","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ArSarcasm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis\ndatasets (SemEval 2017\nand ASTD) and adds sarcasm and\ndialect labels to them.\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\nFor more details, please check the paper\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit-crypto-aug-2021","keyword":"monolingual","description":"This corpus contains the complete data for the activity on seven major cryptocurrency subreddits for the entire month of August 2021.","url":"https://huggingface.co/datasets/SocialGrep/reddit-crypto-aug-2021","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"swedish_ner_corpus","keyword":"monolingual","description":"Webbnyheter 2012 from Spraakbanken, semi-manually annotated and adapted for CoreNLP Swedish NER. Semi-manually defined in this case as: Bootstrapped from Swedish Gazetters then manually correcte/reviewed by two independent native speaking swedish annotators. No annotator agreement calculated.","url":"https://huggingface.co/datasets/klintan/swedish_ner_corpus","creator_name":"Andreas Klintberg","creator_url":"https://huggingface.co/klintan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dart","keyword":"monolingual","description":"DART is a large and open-domain structured DAta Record to Text generation corpus with high-quality\nsentence annotations with each input being a set of entity-relation triples following a tree-structured ontology.\nIt consists of 82191 examples across different domains with each input being a semantic RDF triple set derived\nfrom data records in tables and the tree ontology of table schema, annotated with sentence description that\ncovers all facts in the triple set.\n\nDART is released in the following paper where you can find more details and baseline results:\nhttps://arxiv.org/abs/2007.02871","url":"https://huggingface.co/datasets/Yale-LILY/dart","creator_name":"Yale LILY Lab","creator_url":"https://huggingface.co/Yale-LILY","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["tabular-to-text","rdf-to-text","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ronec","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for RONEC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRONEC, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities.\nThe corpus has the following classes and distribution in the train/valid/test splits:\n| Classes      \t| Total  \t    | Train  \t|         \t| Valid  \t|         \t| Test   \t|         \t|\n|-------------\t|:------:\t    |:------:\t|:-------:\t|:------:\t|:-------:\t|:------:\t|:-------:\t|\n|            \t|â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/ronec.","url":"https://huggingface.co/datasets/community-datasets/ronec","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cfq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"cfq\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Compositional Freebase Questions (CFQ) is a dataset that is specifically designed to measure compositional\ngeneralization. CFQ is a simple yet realistic, large dataset of natural language questions and answers that also\nprovides for each question a corresponding SPARQL query against the Freebase knowledge base. This means that CFQ can\nalso be used for semantic parsing.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/cfq.","url":"https://huggingface.co/datasets/google-research-datasets/cfq","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","other","open-domain-qa","closed-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"coyo-labeled-300m","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COYO-Labeled-300M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOYO-Labeled-300M is a dataset of machine-labeled 300M images-multi-label pairs. We labeled subset of COYO-700M with a large model (efficientnetv2-xl) trained on imagenet-21k. We followed the same evaluation pipeline as in efficientnet-v2. The labels are top 50 most likely labels out of 21,841 classes from imagenet-21k. The label probabilies are provided rather than label so that the user can select threshold of theirâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m.","url":"https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"multi_xscience","keyword":"monolingual","description":"Multi-document summarization is a challenging task for which there exists little large-scale datasets. \nWe propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. \nMulti-XScience introduces a challenging multi-document summarization task: writing the related-work section \nof a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, \na dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and \nempirical results---using several state-of-the-art models trained on the Multi-XScience dataset---reveal t\nhat Multi-XScience is well suited for abstractive models.","url":"https://huggingface.co/datasets/bigbio/multi_xscience","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"disfl_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DISFL-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDisfl-QA is a targeted dataset for contextual disfluencies in an information seeking  setting, namely question answering over Wikipedia passages.  Disfl-QA builds upon the SQuAD-v2 (Rajpurkar et al., 2018) dataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as a source of distractors.\nThe final datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/disfl_qa.","url":"https://huggingface.co/datasets/google-research-datasets/disfl_qa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cs_restaurants","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Czech Restaurant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as a translation of the English San Francisco Restaurants dataset by Wen et al. (2015). The domain is restaurant information in Prague, with random/fictional values. It includes input dialogue acts and the corresponding outputs in Czech.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nother-intent-to-text:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/cs_restaurants.","url":"https://huggingface.co/datasets/community-datasets/cs_restaurants","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"qa_squad","keyword":"monolingual","description":"SQuAD with the train/validation/test split used in SQuAD QG","url":"https://huggingface.co/datasets/lmqg/qa_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"pubmed_qa","keyword":"monolingual","description":"PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\nThe task of PubMedQA is to answer research biomedical questions with yes/no/maybe using the corresponding abstracts.\nPubMedQA has 1k expert-annotated (PQA-L), 61.2k unlabeled (PQA-U) and 211.3k artificially generated QA instances (PQA-A).\n\nEach PubMedQA instance is composed of:\n  (1) a question which is either an existing research article title or derived from one,\n  (2) a context which is the corresponding PubMed abstract without its conclusion,\n  (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and\n  (4) a yes/no/maybe answer which summarizes the conclusion.\n\nPubMedQA is the first QA dataset where reasoning over biomedical research texts,\nespecially their quantitative contents, is required to answer the questions.\n\nPubMedQA datasets comprise of 3 different subsets:\n  (1) PubMedQA Labeled (PQA-L): A labeled PubMedQA subset comprises of 1k manually annotated yes/no/maybe QA data collected from PubMed articles.\n  (2) PubMedQA Artificial (PQA-A): An artificially labelled PubMedQA subset comprises of 211.3k PubMed articles with automatically generated questions from the statement titles and yes/no answer labels generated using a simple heuristic.\n  (3) PubMedQA Unlabeled (PQA-U): An unlabeled PubMedQA subset comprises of 61.2k context-question pairs data collected from PubMed articles.","url":"https://huggingface.co/datasets/bigbio/pubmed_qa","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"multidoc2dial","keyword":"monolingual","description":"MultiDoc2Dial is a new task and dataset on modeling goal-oriented dialogues grounded in multiple documents. Most previous works treat document-grounded dialogue modeling as a machine reading comprehension task based on a single given document or passage. We aim to address more realistic scenarios where a goal-oriented information-seeking conversation involves multiple topics, and hence is grounded on different documents.","url":"https://huggingface.co/datasets/IBM/multidoc2dial","creator_name":"IBM","creator_url":"https://huggingface.co/ibm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"linnaeus","keyword":"monolingual","description":"A novel corpus of full-text documents manually annotated for species mentions.","url":"https://huggingface.co/datasets/cambridgeltl/linnaeus","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multi_nli_mismatch","keyword":"monolingual","description":"The Multi-Genre Natural Language Inference (MultiNLI) corpus is a\ncrowd-sourced collection of 433k sentence pairs annotated with textual\nentailment information. The corpus is modeled on the SNLI corpus, but differs in\nthat covers a range of genres of spoken and written text, and supports a\ndistinctive cross-genre generalization evaluation. The corpus served as the\nbasis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.","url":"https://huggingface.co/datasets/nyu-mll/multi_nli_mismatch","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"kor_3i4k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 3i4K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe 3i4K dataset is a set of frequently used Korean words (corpus provided by the Seoul National University Speech Language Processing Lab) and manually created questions/commands containing short utterances. The goal is to identify the speaker intention of a spoken utterance based on its transcript, and whether in some cases, requires using auxiliary acoustic features. The classification system decides whether the utterance is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wicho/kor_3i4k.","url":"https://huggingface.co/datasets/wicho/kor_3i4k","creator_name":"Won Ik Cho","creator_url":"https://huggingface.co/wicho","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"monolingual","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/legacy-datasets/ami","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multi_nli","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multi-Genre Natural Language Inference (MultiNLI)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Multi-Genre Natural Language Inference (MultiNLI) corpus is a\ncrowd-sourced collection of 433k sentence pairs annotated with textual\nentailment information. The corpus is modeled on the SNLI corpus, but differs in\nthat covers a range of genres of spoken and written text, and supports a\ndistinctive cross-genre generalization evaluation. The corpus served as the\nbasis for the shared taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/multi_nli.","url":"https://huggingface.co/datasets/nyu-mll/multi_nli","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multi_woz_v22","keyword":"monolingual","description":"Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.\nMultiWOZ 2.1 (Eric et al., 2019) identified and fixed many erroneous annotations and user utterances in the original version, resulting in an\nimproved version of the dataset. MultiWOZ 2.2 is a yet another improved version of this dataset, which identifies and fizes dialogue state annotation errors\nacross 17.3% of the utterances on top of MultiWOZ 2.1 and redefines the ontology by disallowing vocabularies of slots with a large number of possible values\n(e.g., restaurant name, time of booking) and introducing standardized slot span annotations for these slots.","url":"https://huggingface.co/datasets/pfb30/multi_woz_v22","creator_name":"PaweÅ‚ Budzianowski","creator_url":"https://huggingface.co/pfb30","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"distemist","keyword":"monolingual","description":"The DisTEMIST corpus is a collection of 1000 clinical cases with disease annotations linked with Snomed-CT concepts.\nAll documents are released in the context of the BioASQ DisTEMIST track for CLEF 2022.","url":"https://huggingface.co/datasets/bigbio/distemist","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"saf_micro_job_german","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_micro_job_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 8 German questions used in micro-job training on the crowd-worker platform appJobber - while theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german.","url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"irc_disentangle","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for IRC Disentanglement\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDisentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. This new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. The dataset is 16 times larger than all previously released datasets combined, the first to includeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jkkummerfeld/irc_disentangle.","url":"https://huggingface.co/datasets/jkkummerfeld/irc_disentangle","creator_name":"Jonathan K. Kummerfeld","creator_url":"https://huggingface.co/jkkummerfeld","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"factckbr","keyword":"monolingual","description":"A dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification.\nThe data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.\nThe FACTCK.BR dataset contains 1309 claims with its corresponding label.","url":"https://huggingface.co/datasets/factckbr/factckbr","creator_name":"factckbr","creator_url":"https://huggingface.co/factckbr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"covid_qa_castorini","keyword":"monolingual","description":"CovidQA is the beginnings of a question answering dataset specifically designed for COVID-19, built by hand from knowledge gathered from Kaggle's COVID-19 Open Research Dataset Challenge.","url":"https://huggingface.co/datasets/castorini/covid_qa_castorini","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"amttl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AMTTL\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gavinxing/amttl.","url":"https://huggingface.co/datasets/gavinxing/amttl","creator_name":"Gavin Xing","creator_url":"https://huggingface.co/gavinxing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"few_rel","keyword":"monolingual","description":"FewRel is a large-scale few-shot relation extraction dataset, which contains more than one hundred relations and tens of thousands of annotated instances cross different domains.","url":"https://huggingface.co/datasets/thunlp/few_rel","creator_name":"Tsinghua NLP group","creator_url":"https://huggingface.co/thunlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"angry-tweets","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AngryTweets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of anonymised Danish Twitter data that has been annotated for sentiment analysis through crowd-sourcing. All credits go to the authors of the following paper, who created the dataset: \nPauli, Amalie Brogaard, et al. \"DaNLP: An open-source toolkit for Danish Natural Language Processing.\" Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). 2021\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/angry-tweets.","url":"https://huggingface.co/datasets/DDSC/angry-tweets","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"linnaeus","keyword":"monolingual","description":"Linnaeus is a novel corpus of full-text documents manually annotated for species mentions.","url":"https://huggingface.co/datasets/bigbio/linnaeus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"kor_qpair","keyword":"monolingual","description":"This is a Korean paired question dataset containing labels indicating whether two questions in a given pair are semantically identical. This dataset was used to evaluate the performance of [KoGPT2](https://github.com/SKT-AI/KoGPT2#subtask-evaluations) on a phrase detection downstream task.","url":"https://huggingface.co/datasets/songys/kor_qpair","creator_name":"YOUNG SOOK SONG","creator_url":"https://huggingface.co/songys","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES is a Spanish-language dataset of news. The corpus was generated by extracting the Spanish articles from CC-NEWS (news index of Common Crawl) of 2019. For doing that FastText model was used for language prediction.\nIt contains a total of 7,473,286 texts and 1,812,009,283 words distributed as follows:\n\n\t\n\t\t\ndomain\ntexts\nwords\n\n\n\t\t\nar\n532703\n1.45127e+08\n\n\nbo\n29557\n7.28996e+06\n\n\nbr\n107\n14207\n\n\ncl\n116661\n3.34633e+07\n\n\ncoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES.","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES","creator_name":"Leonardo Ignacio CÃ³rdoba","creator_url":"https://huggingface.co/LeoCordoba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dmeo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/dmeo.","url":"https://huggingface.co/datasets/DTU54DL/dmeo","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hybrid_qa","keyword":"monolingual","description":"Existing question answering datasets focus on dealing with homogeneous information, based either only on text or KB/Table information alone. However, as human knowledge is distributed over heterogeneous forms, using homogeneous information alone might lead to severe coverage problems. To fill in the gap, we present HybridQA, a new large-scale question-answering dataset that requires reasoning on heterogeneous information. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, i.e., lack of either form would render the question unanswerable.","url":"https://huggingface.co/datasets/wenhu/hybrid_qa","creator_name":"Wenhu Chen","creator_url":"https://huggingface.co/wenhu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nlu_evaluation_data","keyword":"monolingual","description":"Raw part of NLU Evaluation Data. It contains 25 715 non-empty examples (original dataset has 25716 examples) from 68 unique intents belonging to 18 scenarios.","url":"https://huggingface.co/datasets/xingkunliuxtracta/nlu_evaluation_data","creator_name":"xingkun liu","creator_url":"https://huggingface.co/xingkunliuxtracta","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"offenseval2020_tr","keyword":"monolingual","description":"OffensEval-TR 2020 is a Turkish offensive language corpus. The corpus consist of randomly sampled tweets and annotated in a similar way to OffensEval and GermEval.","url":"https://huggingface.co/datasets/coltekin/offenseval2020_tr","creator_name":"Cagri CÃ¶ltekin","creator_url":"https://huggingface.co/coltekin","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BANKING77\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n  Deprecated: Dataset \"banking77\" is deprecated and will be deleted. Use \"PolyAI/banking77\" instead.\n\n\nDataset composed of online banking queries annotated with their corresponding intents.\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain.\nIt comprises 13,083 customer service queries labeled with 77 intents. \nIt focuses on fine-grained single-domain intent detection.\n\n\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/banking77.","url":"https://huggingface.co/datasets/legacy-datasets/banking77","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"common-train-3k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-train-3k.","url":"https://huggingface.co/datasets/DTU54DL/common-train-3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"malromur_asr","keyword":"monolingual","description":"The MÃ¡lrÃ³mur corpus is an open source corpus of Icelandic voice samples.","url":"https://huggingface.co/datasets/language-and-voice-lab/malromur_asr","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"BAAD16","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD16 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by the authors of this paper. It was created by scraping text from an online Bangla e-library using custom web crawler and contains literary works of various famous Bangla writers. It contains novels, stories, series, and other works of 16 authors. Each sample document is created with 750 words. The dataset is imbalanced and resembles real-world scenarios more closely, whereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD16.","url":"https://huggingface.co/datasets/Aisha/BAAD16","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"id_clickbait","keyword":"monolingual","description":"The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.","url":"https://huggingface.co/datasets/community-datasets/id_clickbait","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hebrew_sentiment","keyword":"monolingual","description":"HebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israelâ€™s\npresident, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder,\n2013) to scrape all the comments to all of the presidentâ€™s posts in the period of June â€“ August 2014,\nthe first three months of Rivlinâ€™s presidency.2 While the presidentâ€™s posts aimed at reconciling tensions\nand called for tolerance and empathy, the sentiment expressed in the comments to the presidentâ€™s posts\nwas polarized between citizens who warmly thanked the president, and citizens that fiercely critiqued his\npolicy. Of the 12,804 comments, 370 are neutral; 8,512 are positive, 3,922 negative.\n\nData Annotation: A trained researcher examined each comment and determined its sentiment value,\nwhere comments with an overall positive sentiment were assigned the value 1, comments with an overall\nnegative sentiment were assigned the value -1, and comments that are off-topic to the postâ€™s content\nwere assigned the value 0. We validated the coding scheme by asking a second trained researcher to\ncode the same data. There was substantial agreement between raters (N of agreements: 10623, N of\ndisagreements: 2105, Coehnâ€™s Kappa = 0.697, p = 0).","url":"https://huggingface.co/datasets/omilab/hebrew_sentiment","creator_name":"OMILab, The Open University of Israel","creator_url":"https://huggingface.co/omilab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"qasper","keyword":"monolingual","description":"A dataset containing 1585 papers with 5049 information-seeking questions asked by regular readers of NLP papers, and answered by a separate set of NLP practitioners.","url":"https://huggingface.co/datasets/allenai/qasper","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"norwegian_parliament","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a classification dataset created from a subset of the Talk of Norway. This dataset contains text phrases from the political parties Fremskrittspartiet and Sosialistisk Venstreparti. The dataset is annotated with the party the speaker, as well as a timestamp. The classification task is to, simply by looking at the text, being able to predict is the speech was done by a representative from Fremskrittspartiet or from SV.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/norwegian_parliament.","url":"https://huggingface.co/datasets/NbAiLab/norwegian_parliament","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ImageNet-AB","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGeneral Information\n\t\n\nTitle: ImageNet-AB\nDescription: ImageNet-AB is an extended version of the ImageNet-1K training set, enriched with annotation byproducts (AB).\nIn addition to the image and corresponding class labels, this dataset provides a rich history of interactions per input signal per front-end component during the annotation process.\nThey include mouse traces, click locations, annotation times, as well as anonymised worker IDs.\nLinks:\n\nICCV'23 Paper\nMain Repository\nImageNetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/ImageNet-AB.","url":"https://huggingface.co/datasets/coallaoh/ImageNet-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","monolingual","https://huggingface.co/datasets/imagenet-1k"],"keywords_longer_than_N":true},
	{"name":"HuRC","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HuRC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian Corpus for Reading Comprehension with Commonsense Reasoning (HuRC), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU.\nThe dataset contains 80 614 instances. Each instance is composed of a lead, a passage and a cloze-style query with a masked entity. The task is to select the named entity that is being masked in the query.\nThe data was automaticallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuRC.","url":"https://huggingface.co/datasets/NYTK/HuRC","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","abstractive-qa","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"pharmaconer","keyword":"monolingual","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las TecnologÃ­as del Lenguaje (Plan TL).\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/pharmaconer","creator_name":"Plan de TecnologÃ­as del Lenguaje - Gobierno de EspaÃ±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"raddromur_asr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for raddromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"RaddrÃ³mur Icelandic Speech 22.09\" (\"RaddrÃ³mur Corpus\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at ReykjavÃ­k University (RU) in 2022. It is made out of radio podcasts mostly taken from RÃšV (ruv.is).\n\n\t\n\t\t\n\t\tExample Usage\n\t\n\nThe RaddrÃ³mur Corpus counts with the train split only. To load the training split pass its name as a config name:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr.","url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"clip-bert-data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCLIP-BERT training data\n\t\n\nThis data was used to train the CLIP-BERT model first described in this paper. \nThe dataset is based on text and images from MS COCO, SBU Captions, Visual Genome QA and Conceptual Captions.\nThe image features have been extracted using the CLIP model openai/clip-vit-base-patch32 available on Huggingface.\n","url":"https://huggingface.co/datasets/Lo/clip-bert-data","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"unpredictable_5k","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/unpredictable/unpredictable_5k","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"semeval-absa","keyword":"monolingual","description":"This dataset is built as a playground for aspect-based sentiment analysis.","url":"https://huggingface.co/datasets/jakartaresearch/semeval-absa","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"broad_twitter_corpus","keyword":"monolingual","description":"This is the Broad Twitter corpus, a dataset of tweets collected over stratified times, places and social uses. \nThe goal is to represent a broad range of activities, giving a dataset more representative of the language used \nin this hardest of social media formats to process. Further, the BTC is annotated for named entities.\n\nFor more details see [https://aclanthology.org/C16-1111/](https://aclanthology.org/C16-1111/)","url":"https://huggingface.co/datasets/GateNLP/broad_twitter_corpus","creator_name":"GATE Team, University of Sheffield","creator_url":"https://huggingface.co/GateNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"skolmat","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Skolmat\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/skolmat.","url":"https://huggingface.co/datasets/amcoff/skolmat","creator_name":"Ã…ke Amcoff","creator_url":"https://huggingface.co/amcoff","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered-queries","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\nThis is the version of the dataset with only filtering on the queries, and hence there is more data than inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries.","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"visual-spatial-reasoning","keyword":"monolingual","description":"The Visual Spatial Reasoning (VSR) corpus is a collection of caption-image pairs with true/false labels. Each caption describes the spatial relation of two individual objects in the image, and a vision-language model (VLM) needs to judge whether the caption is correctly describing the image (True) or not (False).","url":"https://huggingface.co/datasets/juletxara/visual-spatial-reasoning","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","crowdsourced","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"pubchem-10m-canonicalized","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdataset description\n\t\n\nWe downloaded PubChem-10m dataset from here and canonicalized it.\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\nfrom rdkit import Chem\ndef canonicalize(mol):\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\n    return mol \n\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\n","url":"https://huggingface.co/datasets/sagawa/pubchem-10m-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"test-user","keyword":"monolingual","description":"Lorem ipsum","url":"https://huggingface.co/datasets/polinaeterna/test-user","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"geo-reviews-dataset-2023","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGeo Reviews Dataset 2023\n\t\n\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\nUse it for academic and research purposes, share your results with us in Issues.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n500,000 unique reviews\nOnly reviews about organizations in Russia\nAvailable on Yandex Maps\nPublished from January to July 2023\nThe dataset does not contain short one-word reviews\nReviews have been cleared of personal data (phone numbersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023.","url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","token-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"minispider","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Spider\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard can be seen at https://yale-lily.github.io/spider\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider.","url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"docci","keyword":"monolingual","description":"DOCCI (Descriptions of Connected and Contrasting Images) is a collection of images paired with detailed descriptions. The descriptions explain the key elements of the images, as well as secondary information such as background, lighting, and settings. The images are specifically taken to help assess the precise visual properties of images. DOCCI also includes many related images that vary in having key differences from the others. All descriptions are manually annotated to ensure they adequately distinguish each image from its counterparts.","url":"https://huggingface.co/datasets/google/docci","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"quickdraw","keyword":"monolingual","description":"The Quick Draw Dataset is a collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!.\nThe drawings were captured as timestamped vectors, tagged with metadata including what the player was asked to draw and in which country the player was located.","url":"https://huggingface.co/datasets/google/quickdraw","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"competition_math","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mathematics Aptitude Test of Heuristics (MATH) dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more. \nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qwedsacf/competition_math.","url":"https://huggingface.co/datasets/qwedsacf/competition_math","creator_name":"Michael Vechtomov","creator_url":"https://huggingface.co/qwedsacf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"MetaQA_Agents_Predictions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MetaQA Agents' Predictions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the answer predictions of the QA agents for the QA datasets used in MetaQA paper. In particular, it contains the following QA agents' predictions:\n\n\t\n\t\t\n\t\tSpan-Extraction Agents\n\t\n\n\nAgent: Span-BERT Large (Joshi et al.,2020) trained on SQuAD. Predictions for:\nSQuAD\nNewsQA\nHotpotQA\nSearchQA\nNatural Questions\nTriviaQA-web\nQAMR\nDuoRC\nDROP\n\n\nAgent: Span-BERT Large (Joshi et al.,2020) trained onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haritzpuerto/MetaQA_Agents_Predictions.","url":"https://huggingface.co/datasets/haritzpuerto/MetaQA_Agents_Predictions","creator_name":"Haritz Puerto","creator_url":"https://huggingface.co/haritzpuerto","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","monolingual","mrqa","duorc","qamr"],"keywords_longer_than_N":true},
	{"name":"coyo-700m","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COYO-700M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models. Our dataset follows a similar strategy to previous vision-and-language datasets, collecting many informative pairs of alt-text and its associated image in HTML documents. We expect COYO to be used to train popular large-scale foundation models \ncomplementary to otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-700m.","url":"https://huggingface.co/datasets/kakaobrain/coyo-700m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"UD_Catalan-AnCora","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUD_Catalan-AnCora\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is composed of the annotations from the AnCora corpus, projected on the Universal Dependencies treebank. We use the POS annotations of this corpus as part of the Catalan Language Understanding Benchmark (CLUB).\nThis work is licensed under a CC Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nPOS tagging\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe dataset is in Catalan (ca-ES)\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora.","url":"https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"conala","keyword":"monolingual","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/.","url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"privy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"privy-english\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA synthetic PII dataset generated using Privy, a tool which parses OpenAPI specifications and generates synthetic request payloads, searching for keywords in API schema definitions to select appropriate data providers. Generated API payloads are converted to various protocol trace formats like JSON and SQL to approximate the data developers might encounter while debugging applications. \nThis labelled PII dataset consists ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beki/privy.","url":"https://huggingface.co/datasets/beki/privy","creator_name":"Benjamin Kilimnik","creator_url":"https://huggingface.co/beki","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"cuad-qa","keyword":"monolingual","description":"Contract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510\ncommercial legal contracts that have been manually labeled to identify 41 categories of important\nclauses that lawyers look for when reviewing contracts in connection with corporate transactions.","url":"https://huggingface.co/datasets/theatticusproject/cuad-qa","creator_name":"The Atticus Project","creator_url":"https://huggingface.co/theatticusproject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"the-reddit-covid-dataset","keyword":"monolingual","description":"This dataset attempts to capture the full extent of COVID-19 discussion across the entire site of Reddit. All posts and comments found to mention the term 'COVID' as of 2021-10-25 have been gathered from the site.","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-covid-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"bioasq_2021_mesinesp","keyword":"monolingual","description":"The main aim of MESINESP2 is to promote the development of practically relevant semantic indexing tools for biomedical content in non-English language. We have generated a manually annotated corpus, where domain experts have labeled a set of scientific literature, clinical trials, and patent abstracts. All the documents were labeled with DeCS descriptors, which is a structured controlled vocabulary created by BIREME to index scientific publications on BvSalud, the largest database of scientific documents in Spanish, which hosts records from the databases LILACS, MEDLINE, IBECS, among others.\n\nMESINESP track at BioASQ9 explores the efficiency of systems for assigning DeCS to different types of biomedical documents. To that purpose, we have divided the task into three subtracks depending on the document type. Then, for each one we generated an annotated corpus which was provided to participating teams:\n\n- [Subtrack 1 corpus] MESINESP-L â€“ Scientific Literature: It contains all   Spanish records from LILACS and IBECS databases at the Virtual Health Library   (VHL) with non-empty abstract written in Spanish.\n- [Subtrack 2 corpus] MESINESP-T- Clinical Trials contains records from Registro   EspaÃ±ol de Estudios ClÃ­nicos (REEC). REEC doesn't provide documents with the   structure title/abstract needed in BioASQ, for that reason we have built   artificial abstracts based on the content available in the data crawled using   the REEC API.\n- [Subtrack 3 corpus] MESINESP-P â€“ Patents: This corpus includes patents in   Spanish extracted from Google Patents which have the IPC code â€œA61Pâ€ and   â€œA61K31â€. In addition, we also provide a set of complementary data such as:   the DeCS terminology file, a silver standard with the participants' predictions   to the task background set and the entities of medications, diseases, symptoms   and medical procedures extracted from the BSC NERs documents.","url":"https://huggingface.co/datasets/bigbio/bioasq_2021_mesinesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"opinosis","keyword":"monolingual","description":"The Opinosis Opinion Dataset consists of sentences extracted from reviews for 51 topics.\nTopics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.","url":"https://huggingface.co/datasets/kavgan/opinosis","creator_name":"Kavita  Ganesan","creator_url":"https://huggingface.co/kavgan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"text2image-multi-prompt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttext2image multi-prompt(s): a dataset collection\n\t\n\n\ncollection of several text2image prompt datasets\ndata was cleaned/normalized with the goal of removing \"model specific APIs\" like the \"--ar\" for Midjourney and so on\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\n\n\n\t\n\t\t\n\t\tupdates\n\t\n\n\nOct 2023: the default config has been updated with better deduplication. It was deduplicated with minhash (params: n-gram size set to 3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/text2image-multi-prompt.","url":"https://huggingface.co/datasets/pszemraj/text2image-multi-prompt","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","monolingual","bartman081523/stable-diffusion-discord-prompts","succinctly/midjourney-prompts"],"keywords_longer_than_N":true},
	{"name":"common3k-train","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common3k-train.","url":"https://huggingface.co/datasets/DTU54DL/common3k-train","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"dblp-discovery-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DBLP Discovery Dataset (D3)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDBLP is the largest open-access repository of scientific articles on computer science and provides metadata associated with publications, authors, and venues. We retrieved more than 6 million publications from DBLP and extracted pertinent metadata (e.g., abstracts, author affiliations, citations) from the publication texts to create the DBLP Discovery Dataset (D3). D3 can be used to identify trends in researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/dblp-discovery-dataset.","url":"https://huggingface.co/datasets/jpwahle/dblp-discovery-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","found","found","monolingual","extended|s2orc"],"keywords_longer_than_N":true},
	{"name":"kqa_pro","keyword":"monolingual","description":"A large-scale, diverse, challenging dataset of complex question answering over knowledge base.","url":"https://huggingface.co/datasets/drt/kqa_pro","creator_name":"Yuanchun","creator_url":"https://huggingface.co/drt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"code-general-fonction-publique","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral de la fonction publique, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cmc-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Coinmarketcap Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of posts from Coinmarketcap, a popular cryptocurrency platform. It includes approximately 1 million posts from February 24, 2022. However, a significant portion of the posts are spam, making this dataset ideal for spam detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nid: Identifier for the post (integer)\nusername: Name of the userâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cmc-posts.","url":"https://huggingface.co/datasets/nyuuzyou/cmc-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wisesight1000","keyword":"monolingual","description":"`wisesight1000` contains Thai social media texts randomly drawn from the full `wisesight-sentiment`, tokenized by human annotators.\nOut of the labels `neg` (negative), `neu` (neutral), `pos` (positive), `q` (question), 250 samples each. Some texts are removed because\nthey look like spam.Because these samples are representative of real world content, we believe having these annotaed samples will allow\nthe community to robustly evaluate tokenization algorithms.","url":"https://huggingface.co/datasets/pythainlp/wisesight1000","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","extended|wisesight_sentiment"],"keywords_longer_than_N":true},
	{"name":"NPSC","keyword":"monolingual","description":"The Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by SprÃ¥kbanken at the National Library in Norway.\n\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian BokmÃ¥l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount of metadata that is included in the original corpus. Through the speaker id there is additional information about the speaker, like gender, age, and place of birth (ie dialect). Through the proceedings id the corpus can be linked to the official proceedings from the meetings.\n\nThe corpus is in total sound recordings from 40 entire days of meetings. This amounts to 140 hours of speech, 65,000 sentences or 1.2 million words.","url":"https://huggingface.co/datasets/NbAiLab/NPSC","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by SprÃ¥kbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian BokmÃ¥l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amountâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ncbi_disease","keyword":"monolingual","description":"The NCBI disease corpus is fully annotated at the mention and concept level to serve as a research\nresource for the biomedical natural language processing community.","url":"https://huggingface.co/datasets/bigbio/ncbi_disease","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"FACTOID","keyword":"monolingual","description":"aisafe/FACTOID dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aisafe/FACTOID","creator_name":"safe ai","creator_url":"https://huggingface.co/aisafe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","fact-checking","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"ERRnews","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"ERRnews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nERRnews is an Estonian language summarization dataset of ERR News broadcasts scraped from the ERR Archive (https://arhiiv.err.ee/err-audioarhiiv). The dataset consists of news story transcripts generated by an ASR pipeline paired with the human written summary from the archive. For leveraging larger english models the dataset includes machine translated (https://neurotolge.ee/) transcript and summary pairs.\n\n\t\n\t\t\n\t\n\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/ERRnews.","url":"https://huggingface.co/datasets/TalTechNLP/ERRnews","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","monolingual","original","Estonian"],"keywords_longer_than_N":true},
	{"name":"JinaVDRPlotQARetrieval","keyword":"monolingual","description":"\n  JinaVDRPlotQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve plots from the PlotQA dataset based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/plotqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/plotqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRPlotQARetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRPlotQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRPlotQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"pass","keyword":"monolingual","description":"PASS (Pictures without humAns for Self-Supervision) is a large-scale dataset of 1,440,191 images that does not include any humans\nand which can be used for high-quality pretraining while significantly reducing privacy concerns.\nThe PASS images are sourced from the YFCC-100M dataset.","url":"https://huggingface.co/datasets/yukimasano/pass","creator_name":"Yuki Asano","creator_url":"https://huggingface.co/yukimasano","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"lambada","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LAMBADA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LAMBADA evaluates the capabilities of computational models\nfor text understanding by means of a word prediction task.\nLAMBADA is a collection of narrative passages sharing the characteristic\nthat human subjects are able to guess their last word if\nthey are exposed to the whole passage, but not if they\nonly see the last sentence preceding the target word.\nTo succeed on LAMBADA, computational models cannot\nsimply rely on localâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cimec/lambada.","url":"https://huggingface.co/datasets/cimec/lambada","creator_name":"CIMeC - Center for Mind/Brain Sciences, University of Trento","creator_url":"https://huggingface.co/cimec","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","extended|bookcorpus","English"],"keywords_longer_than_N":true},
	{"name":"progene","keyword":"monolingual","description":"The Protein/Gene corpus was developed at the JULIE Lab Jena under supervision of Prof. Udo Hahn.\nThe executing scientist was Dr. Joachim Wermter.\nThe main annotator was Dr. Rico Pusch who is an expert in biology.\nThe corpus was developed in the context of the StemNet project (http://www.stemnet.de/).","url":"https://huggingface.co/datasets/bigbio/progene","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"babi_qa","keyword":"monolingual","description":"The (20) QA bAbI tasks are a set of proxy tasks that evaluate reading\ncomprehension via question answering. Our tasks measure understanding\nin several ways: whether a system is able to answer questions via chaining facts,\nsimple induction, deduction and many more. The tasks are designed to be prerequisites\nfor any system that aims to be capable of conversing with a human.\nThe aim is to classify these tasks into skill sets,so that researchers\ncan identify (and then rectify)the failings of their systems.","url":"https://huggingface.co/datasets/facebook/babi_qa","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"yoruba_gv_ner","keyword":"monolingual","description":"The Yoruba GV NER dataset is a labeled dataset for named entity recognition in Yoruba. The texts were obtained from\nYoruba Global Voices News articles https://yo.globalvoices.org/ . We concentrate on\nfour types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n\nThe Yoruba GV NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\nthere is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\nis the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\nof type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\nhave tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n\nFor more details, see https://www.aclweb.org/anthology/2020.lrec-1.335/","url":"https://huggingface.co/datasets/ajesujoba/yoruba_gv_ner","creator_name":"Jesujoba Alabi","creator_url":"https://huggingface.co/ajesujoba","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-forestier","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode forestier, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-procedures-civiles-execution","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des procÃ©dures civiles d'exÃ©cution, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"qa_squadshifts","keyword":"monolingual","description":"[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question answering task with custom split.","url":"https://huggingface.co/datasets/lmqg/qa_squadshifts","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"cSQuAD1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for cSQuAD1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA contrast set generated from the eval set of SQuAD. Questions and answers were modified\nto help detecting dataset artifacts. This dataset only contains a validation set, which\nshould only be used to evaluate a model.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nQuestion Answering (SQuAD).\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nDataset contains 100 instances\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD1.","url":"https://huggingface.co/datasets/dferndz/cSQuAD1","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"java-cmpx-v1","keyword":"monolingual","description":"giganticode/java-cmpx-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/giganticode/java-cmpx-v1","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rudetoxifier_data_detox","keyword":"monolingual","description":"\n\t\n\t\t\n\t\trudetoxifier_data_detox\n\t\n\nThis is subset of toxic comments from d0rj/rudetoxifier_data which has detoxified column created by s-nlp/ruT5-base-detox.\n","url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data_detox","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","d0rj/rudetoxifier_data","Russian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"rudetoxifier_data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\trudetoxifier_data\n\t\n\nHuggingface copy of Github repo with dataset.\n","url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","original","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"reddit-da","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SQuAD-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 1,908,887 Danish posts from Reddit. These are from this Reddit dump and have been filtered using this script, which uses FastText to detect the Danish posts. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for language modelling.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset contains short Redditâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/reddit-da.","url":"https://huggingface.co/datasets/DDSC/reddit-da","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"winograd_wsc","keyword":"monolingual","description":"A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is\nresolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its\nresolution. The schema takes its name from a well-known example by Terry Winograd:\n\n> The city councilmen refused the demonstrators a permit because they [feared/advocated] violence.\n\nIf the word is ``feared'', then ``they'' presumably refers to the city council; if it is ``advocated'' then ``they''\npresumably refers to the demonstrators.","url":"https://huggingface.co/datasets/ErnestSDavis/winograd_wsc","creator_name":"Ernest Davis","creator_url":"https://huggingface.co/ErnestSDavis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-coreference-resolution","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hlgd","keyword":"monolingual","description":"HLGD is a binary classification dataset consisting of 20,056 labeled news headlines pairs indicating\nwhether the two headlines describe the same underlying world event or not.","url":"https://huggingface.co/datasets/philippelaban/hlgd","creator_name":"Philippe Laban","creator_url":"https://huggingface.co/philippelaban","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"custom_squad","keyword":"monolingual","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.","url":"https://huggingface.co/datasets/lhoestq/custom_squad","creator_name":"Quentin Lhoest","creator_url":"https://huggingface.co/lhoestq","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_hard","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Hard set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discoverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"one_syllable","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Lipogram-e\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThis is a dataset of English books which only write using one syllable at a time. At this time, the dataset only contains Robinson Crusoe â€” in Words of One Syllable by Lucy Aikin and Daniel Defoe\nThis dataset is contributed as part of a paper titled \"Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text Generation Studio\" to appear at COLING 2022. This dataset does not appear in the paper itselfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/one_syllable.","url":"https://huggingface.co/datasets/Hellisotherpeople/one_syllable","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"qas","keyword":"monolingual","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.","url":"https://huggingface.co/datasets/fedryanto/qas","creator_name":"Fedryanto Dartiko","creator_url":"https://huggingface.co/fedryanto","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"tm3","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Taskmaster-3\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-3-2020\nPaper: https://aclanthology.org/2021.acl-long.55.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm3')\nontology = load_ontology('tm3')â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm3.","url":"https://huggingface.co/datasets/ConvLab/tm3","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MKB_Hindi_2023","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023.","url":"https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023","creator_name":"Rashmi Singh","creator_url":"https://huggingface.co/rashmi035","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"douban-dushu","keyword":"monolingual","description":"This dataset contains book reviews from DouBan Dushu. DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. Most of the users in this website are unprofessional book reviewers. Therefore, the comments are usually spoken Chinese or even Internet slang.","url":"https://huggingface.co/datasets/larrylawl/douban-dushu","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","crowdsourced","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"LLaMaInstructionsFrenchMedMCQA","keyword":"monolingual","description":"FrenchMedMCQA","url":"https://huggingface.co/datasets/qanastek/LLaMaInstructionsFrenchMedMCQA","creator_name":"yanis labrak","creator_url":"https://huggingface.co/qanastek","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice","multiple-choice-qa","open-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"dolphin-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDolphin-ru ðŸ¬\n\t\n\nThis is translated version of ehartford/dolphin into Russian.\n","url":"https://huggingface.co/datasets/d0rj/dolphin-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"fashion_mnist","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FashionMNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zalando-datasets/fashion_mnist.","url":"https://huggingface.co/datasets/zalando-datasets/fashion_mnist","creator_name":"zalando-datasets","creator_url":"https://huggingface.co/zalando-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"conv_questions","keyword":"monolingual","description":"ConvQuestions is the first realistic benchmark for conversational question answering over knowledge graphs.\nIt contains 11,200 conversations which can be evaluated over Wikidata. The questions feature a variety of complex\nquestion phenomena like comparisons, aggregations, compositionality, and temporal reasoning.","url":"https://huggingface.co/datasets/pchristm/conv_questions","creator_name":"Philipp Christmann","creator_url":"https://huggingface.co/pchristm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","fill-mask","open-domain-qa","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"nli-zh-all","keyword":"monolingual","description":"The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).","url":"https://huggingface.co/datasets/shibing624/nli-zh-all","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"qa_harvesting_from_wikipedia_pseudo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"lmqg/qa_harvesting_from_wikipedia_pseudo\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a synthetic QA dataset generated with fine-tuned QG models over lmqg/qa_harvesting_from_wikipedia, 1 million paragraph and answer pairs collected in Du and Cardie, 2018, made for question-answering based evaluation (QAE) for question generation model proposed by Zhang and Bansal, 2019.\nThe train split is the synthetic data and the validation split is the original validation set of SQuADâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lmqg/qa_harvesting_from_wikipedia_pseudo.","url":"https://huggingface.co/datasets/lmqg/qa_harvesting_from_wikipedia_pseudo","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"pioNER-Armenian-Named-Entity","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpioNER - named entity annotated datasets\n\t\n\npioNER corpus provides gold-standard and automatically generated named-entity datasets for the Armenian language.\nAlongside the datasets, we release 50-, 100-, 200-, and 300-dimensional GloVe word embeddings trained on a collection of Armenian texts from Wikipedia, news, blogs, and encyclopedia.\n\n\t\n\t\t\n\t\tSilver-standard dataset\n\t\n\nThe generated corpus is automatically extracted and annotated using Armenian Wikipedia. We used a modification ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Karavet/pioNER-Armenian-Named-Entity.","url":"https://huggingface.co/datasets/Karavet/pioNER-Armenian-Named-Entity","creator_name":"Karen Avetisyan","creator_url":"https://huggingface.co/Karavet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["named-entity-recognition","monolingual","Armenian","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"hebrew_projectbenyehuda","keyword":"monolingual","description":"This repository contains a dump of thousands of public domain works in Hebrew, from Project Ben-Yehuda, in plaintext UTF-8 files, with and without diacritics (nikkud). The metadata (pseudocatalogue.csv) file is a list of titles, authors, genres, and file paths, to help you process the dump.\nAll these works are in the public domain, so you are free to make any use of them, and do not need to ask for permission.\nThere are 10078 files, 3181136 lines","url":"https://huggingface.co/datasets/projectbenyehuda/hebrew_projectbenyehuda","creator_name":"Project Ben-Yehuda - ×¤×¨×•×™×§×˜ ×‘×Ÿ-×™×”×•×“×”","creator_url":"https://huggingface.co/projectbenyehuda","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"squad_v1_pt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad_v1_pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize of downloaded dataset files: 39.53 MB\nSize of the generated dataset: 96.72 MB\nTotal amount of disk used: 136.25 MB\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt.","url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pg19","keyword":"monolingual","description":"This repository contains the PG-19 language modeling benchmark.\nIt includes a set of books extracted from the Project Gutenberg books library, that were published before 1919.\nIt also contains metadata of book titles and publication dates.\n\nPG-19 is over double the size of the Billion Word benchmark and contains documents that are 20X longer, on average, than the WikiText long-range language modelling benchmark.\nBooks are partitioned into a train, validation, and test set. Book metadata is stored in metadata.csv which contains (book_id, short_book_title, publication_date).\n\nUnlike prior benchmarks, we do not constrain the vocabulary size --- i.e. mapping rare words to an UNK token --- but instead release the data as an open-vocabulary benchmark. The only processing of the text that has been applied is the removal of boilerplate license text, and the mapping of offensive discriminatory words as specified by Ofcom to placeholder tokens. Users are free to model the data at the character-level, subword-level, or via any mechanism that can model an arbitrary string of text.\nTo compare models we propose to continue measuring the word-level perplexity, by calculating the total likelihood of the dataset (via any chosen subword vocabulary or character-based scheme) divided by the number of tokens --- specified below in the dataset statistics table.\nOne could use this dataset for benchmarking long-range language models, or use it to pre-train for other natural language processing tasks which require long-range reasoning, such as LAMBADA or NarrativeQA. We would not recommend using this dataset to train a general-purpose language model, e.g. for applications to a production-system dialogue agent, due to the dated linguistic style of old texts and the inherent biases present in historical writing.","url":"https://huggingface.co/datasets/deepmind/pg19","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"circa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CIRCA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Circa (meaning â€˜approximatelyâ€™) dataset aims to help machine learning systems to solve the problem of interpreting indirect answers to polar questions.\nThe dataset contains pairs of yes/no questions and indirect answers, together with annotations for the interpretation of the answer. The data is collected in 10 different social conversational situations (eg. food preferences of a friend).\nThe following are the situationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/circa.","url":"https://huggingface.co/datasets/google-research-datasets/circa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"iapp_wiki_qa_squad","keyword":"monolingual","description":"`iapp_wiki_qa_squad` is an extractive question answering dataset from Thai Wikipedia articles.\nIt is adapted from [the original iapp-wiki-qa-dataset](https://github.com/iapp-technology/iapp-wiki-qa-dataset)\nto [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format, resulting in\n5761/742/739 questions from 1529/191/192 articles.","url":"https://huggingface.co/datasets/iapp/iapp_wiki_qa_squad","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"deal_or_no_dialog","keyword":"monolingual","description":"A large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each otherâ€™s reward functions must reach anagreement (o a deal) via natural language dialogue.","url":"https://huggingface.co/datasets/mikelewis0/deal_or_no_dialog","creator_name":"Mike Lewis","creator_url":"https://huggingface.co/mikelewis0","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"moroco","keyword":"monolingual","description":"The MOROCO (Moldavian and Romanian Dialectal Corpus) dataset contains 33564 samples of text collected from the news domain.\nThe samples belong to one of the following six topics:\n    - culture\n    - finance\n    - politics\n    - science\n    - sports\n    - tech","url":"https://huggingface.co/datasets/universityofbucharest/moroco","creator_name":"University of Bucharest","creator_url":"https://huggingface.co/universityofbucharest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","topic-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"lc_quad","keyword":"monolingual","description":"LC-QuAD 2.0 is a Large Question Answering dataset with 30,000 pairs of question and its corresponding SPARQL query. The target knowledge base is Wikidata and DBpedia, specifically the 2018 version. Please see our paper for details about the dataset creation process and framework.","url":"https://huggingface.co/datasets/mohnish/lc_quad","creator_name":"Mohnish Dubey","creator_url":"https://huggingface.co/mohnish","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-voice-test3k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test3k.","url":"https://huggingface.co/datasets/DTU54DL/common-voice-test3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"monolingual-quechua-iic","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Monolingual-Quechua-IIC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We present Monolingual-Quechua-IIC, a monolingual corpus of Southern Quechua, which can be used to build language models using Transformers models. This corpus also includes the Wiki and OSCAR corpora. We used this corpus to build Llama-RoBERTa-Quechua, the first language model for Southern Quechua using Transformers.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSouthernâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic.","url":"https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic","creator_name":"Llamacha","creator_url":"https://huggingface.co/Llamacha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","language-modeling","masked-language-modeling","no-annotation","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"one-year-of-r-india","keyword":"monolingual","description":"This corpus contains the complete data for the activity of the subreddit /r/India from Sep 30, 2020 to Sep 30, 2021.","url":"https://huggingface.co/datasets/SocialGrep/one-year-of-r-india","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"europarl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DKHate\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of Danish data from the European Parliament that has been annotated for sentiment analysis by the Alexandra Institute - all credits go to them.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for sentiment analysis.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset has a document and an associated label.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/europarl.","url":"https://huggingface.co/datasets/DDSC/europarl","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"evidence_infer_treatment","keyword":"monolingual","description":"Data and code from our \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\", NAACL 2019. This work concerns inferring the results reported in clinical trials from text.\n\nThe dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple treatments. Each of these articles will have multiple questions, or 'prompts' associated with them. These prompts will ask about the relationship between an intervention and comparator with respect to an outcome, as reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared to placebo on the duration of headaches. For the sake of this task, we assume that a particular article will report that the intervention of interest either significantly increased, significantly decreased or had significant effect on the outcome, relative to the comparator.\n\nThe dataset could be used for automatic data extraction of the results of a given RCT. This would enable readers to discover the effectiveness of different treatments without needing to read the paper.","url":"https://huggingface.co/datasets/jaydeyoung/evidence_infer_treatment","creator_name":"jay deyoung","creator_url":"https://huggingface.co/jaydeyoung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","fact-checking-retrieval","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"allocine","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AllocinÃ©\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe AllocinÃ© dataset is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the AllocinÃ©.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset can be used to train aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tblard/allocine.","url":"https://huggingface.co/datasets/tblard/allocine","creator_name":"ThÃ©ophile Blard","creator_url":"https://huggingface.co/tblard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/mbpp.","url":"https://huggingface.co/datasets/google-research-datasets/mbpp","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"top-american-universities-on-reddit","keyword":"monolingual","description":"This NLP dataset contains all the posts and comments in the subreddits of top 10 universities in the United States, chosen according to the 2019 Forbes ranking.","url":"https://huggingface.co/datasets/SocialGrep/top-american-universities-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"libri-whisper-raw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri-whisper-raw.","url":"https://huggingface.co/datasets/bgstud/libri-whisper-raw","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"qasc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"qasc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice\nquestions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/qasc.","url":"https://huggingface.co/datasets/allenai/qasc","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","extractive-qa","multiple-choice-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ropes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ROPES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nROPES (Reasoning Over Paragraph Effects in Situations) is a QA dataset which tests a system's ability to apply knowledge from a passage of text to a new situation. A system is presented a background passage containing a causal or qualitative relation(s) (e.g., \"animal pollinators increase efficiency of fertilization in flowers\"), a novel situation that uses this background, and questions that require reasoning about effects of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ropes.","url":"https://huggingface.co/datasets/allenai/ropes","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"fanpage","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for fanpage\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFanpage dataset, containing news articles taken from Fanpage.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n Fanpage text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federiciâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/fanpage.","url":"https://huggingface.co/datasets/ARTeLab/fanpage","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Italian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"monolingual","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"hl-narratives","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for the High-Level Narratives Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe High-Level Narratives (HL-Narratives) dataset aligns object-centric descriptions from COCO \nwith synthetic high-level narratives captions automatically generated by merging scene, action, rationale captions from the HL Dataset using T5\nThe HL-Naratives dataset contains 14997 images from COCO and a total of 134973 synthetic captions (3 captions per image) aligned with ~749984 object-centric captionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl-narratives.","url":"https://huggingface.co/datasets/michelecafagna26/hl-narratives","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","question-answering","zero-shot-classification","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"dialogsum-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neil-code/dialogsum-test.","url":"https://huggingface.co/datasets/neil-code/dialogsum-test","creator_name":"neil","creator_url":"https://huggingface.co/neil-code","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"huggingface-dataset-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"my-issues-dataset\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/SergeiGKS/huggingface-dataset-issues","creator_name":"Serge Ghomsi","creator_url":"https://huggingface.co/SergeiGKS","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TeluguRiddles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nTeluguRiddles is an open source dataset of instruct-style records generated by webscraping multiple riddles websites. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nTeluguRiddles is a corpus ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/desik98/TeluguRiddles.","url":"https://huggingface.co/datasets/desik98/TeluguRiddles","creator_name":"Desik Mandava","creator_url":"https://huggingface.co/desik98","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_w3-org","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_w3-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_phonearena-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_phonearena-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster07","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster07","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"fashion_mnist_label_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/fashion_mnist_label_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_studystack-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_studystack-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_full","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_full","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster13","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster13","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"aeslc_kw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tabout\n\t\n\n\naeslc dataset but cleaned and keywords extracted to a new column\nan EDA website generated via pandas profiling is on netlify here\n\nDatasetDict({\n    train: Dataset({\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\n        num_rows: 14436\n    })\n    test: Dataset({\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\n        num_rows: 1906\n    })\n    validation: Dataset({\n        features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/postbot/aeslc_kw.","url":"https://huggingface.co/datasets/postbot/aeslc_kw","creator_name":"postbot","creator_url":"https://huggingface.co/postbot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","aeslc","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"humaneval-rust","keyword":"monolingual","description":"diversoailab/humaneval-rust dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/diversoailab/humaneval-rust","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","code","mit"],"keywords_longer_than_N":true},
	{"name":"old_bailey_proceedings","keyword":"monolingual","description":"[Needs More Information]\n\n\t\n\t\t\n\t\tDataset Card for Old Bailey Proceedings\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNote We are making this dataset available via the HuggingFace hub to open it up to more users and use cases. We have focused primarily on making an initial version of this dataset available, focusing on some potential use cases. If you think there are other configurations this dataset should support, please use the community tab to open an issue. \nThe dataset consists of 2,163 transcriptionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/old_bailey_proceedings.","url":"https://huggingface.co/datasets/biglam/old_bailey_proceedings","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-class-classification","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster23","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster23","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"Openclipart-Oldstyle","keyword":"monolingual","description":"Dataset Card for 16th Century(?) Black and White Style\n\nDataset used to train/finetune a black and white print style\nCaptions are generated by hand with the assistance of BLIP.\nImages were sourced from:\n  https://openclipart.org/artist/j4p4n\n  https://openclipart.org/artist/johnny_automatic\n  https://openclipart.org/artist/SnipsAndClips\nText file filenames correspond image file filenames as captions.\n","url":"https://huggingface.co/datasets/joshuajewell/Openclipart-Oldstyle","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","https://openclipart.org/artist/j4p4n"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"monolingual","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"arxiv-biology","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tDataset Curators\n\t\n\nThe original data is maintained by ArXiv\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe data is under the Creative Commons CC0 1.0 Universal Public Domain Dedication\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{clement2019arxiv,\n    title={On the Use of ArXiv as a Dataset},\n    author={Colin B. Clement and Matthew Bierbaum and Kevin P. O'Keeffe and Alexander A. Alemi},\n    year={2019},\n    eprint={1905.00075},\n    archivePrefix={arXiv},\n    primaryClass={cs.IR}\n}\n\n","url":"https://huggingface.co/datasets/zeroshot/arxiv-biology","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"yandex-q","keyword":"monolingual","description":"This is a dataset of questions and answers scraped from Yandex.Q.","url":"https://huggingface.co/datasets/its5Q/yandex-q","creator_name":"its5Q","creator_url":"https://huggingface.co/its5Q","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","open-domain-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bornholmsk","keyword":"monolingual","description":"This corpus introduces language processing resources and tools for Bornholmsk, a language spoken on the island of Bornholm, with roots in Danish and closely related to Scanian. \n\nSammenfattnijng pÃ¥ borrijnholmst: DÃ¦jnna artikkelijn introduserer natursprÃ¥gsresurser Ã¥ varktoi for borrijnholmst, ed sprÃ¥g a dÃ¦r snakkes pÃ¥ Ã¶n Borrijnholm me rÃ¸dder i danst Ã¥ i nÃ¦r familia me skÃ¥nst.","url":"https://huggingface.co/datasets/strombergnlp/bornholmsk","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"movie_reviews_with_context_drift","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for reviews_with_drift\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was crafted to be used in our tutorial [Link to the tutorial when ready]. It consists on a large Movie Review Dataset mixed with some reviews from a Hotel Review Dataset. The training/validation set are purely obtained from the Movie Review Dataset while the production set is mixed. Some other features have been added (age, gender, context) as well as a made up timestampâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift.","url":"https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ett","keyword":"monolingual","description":"The data of Electricity Transformers from two separated counties\nin China collected for two years at hourly and 15-min frequencies.\nEach data point consists of the target value \"oil temperature\" and\n6 power load features. The train/val/test is 12/4/4 months.","url":"https://huggingface.co/datasets/ETDataset/ett","creator_name":"Electricity Transformer Dataset (ETDataset)","creator_url":"https://huggingface.co/ETDataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["time-series-forecasting","univariate-time-series-forecasting","multivariate-time-series-forecasting","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"LIFD_Seismic_Data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LFID Seismic Data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA description of the dataset:\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\ncoming soon - Kaggle links? \n\n\t\n\t\t\n\t\tData Fields\n\t\n\nSAC files\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nAll seismic data were downloaded through the IRIS Wilber 3 system (https://ds.iris.edu/wilber3/) or IRIS Web Services (https://service.iris.edu/), including the following seismic networks: (1) the AZ (ANZA; UC San Diego, 1982); (2) the TA (Transportable Array;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data.","url":"https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","time-series-forecasting","object-detection","unconditional-image-generation"],"keywords_longer_than_N":true},
	{"name":"CANLI","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CANLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCANLI: The Chinese Causative-Passive Homonymy Disambiguation: an Adversarial Dataset for NLI and a Probing Task\nThe disambiguation of causative-passive homonymy (CPH) is potentially tricky for machines, as the causative and the passive\nare not distinguished by the sentences\u0019 syntactic structure. By transforming CPH disambiguation to a challenging natural\nlanguage inference (NLI) task, we present the first Chinese Adversarial NLIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sxu/CANLI.","url":"https://huggingface.co/datasets/sxu/CANLI","creator_name":"Shanshan Xu","creator_url":"https://huggingface.co/sxu","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","cn","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"UHGEvalDataset","keyword":"monolingual","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\n","url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"squad_es_v2","keyword":"monolingual","description":"automatic translation of the Stanford Question Answering Dataset (SQuAD) v2 into Spanish","url":"https://huggingface.co/datasets/TheTung/squad_es_v2","creator_name":"Nguyen","creator_url":"https://huggingface.co/TheTung","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"datasets","keyword":"monolingual","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-asr-leaderboard/datasets.","url":"https://huggingface.co/datasets/open-asr-leaderboard/datasets","creator_name":"Open ASR Leaderboard","creator_url":"https://huggingface.co/open-asr-leaderboard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-low","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-low","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster29","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster29","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"hatecheck-mandarin","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin.","url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster03","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster03","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_gamefaqs-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_gamefaqs-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster11","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster11","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-korean-subset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tlaion2B-multi-korean-subset\n\t\n\n\n\t\n\t\t\n\t\tAbout dataset\n\t\n\na subset data of laion/laion2B-multi, including only korean\n\n\t\n\t\t\n\t\tLisence\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instance\n\t\n\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"Bingsu/laion2B-multi-korean-subset\")\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity'],\n        num_rows: 11376263â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset.","url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"unpredictable_dividend-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_dividend-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"mslr2022","keyword":"monolingual","description":"The Multidocument Summarization for Literature Review (MSLR) Shared Task aims to study how medical\nevidence from different clinical studies are summarized in literature reviews. Reviews provide the\nhighest quality of evidence for clinical care, but are expensive to produce manually.\n(Semi-)automation via NLP may facilitate faster evidence synthesis without sacrificing rigor.\nThe MSLR shared task uses two datasets to assess the current state of multidocument summarization\nfor this task, and to encourage the development of modeling contributions, scaffolding tasks, methods\nfor model interpretability, and improved automated evaluation methods in this domain.","url":"https://huggingface.co/datasets/allenai/mslr2022","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"multiwoz21","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MultiWOZ 2.1\n\t\n\n\nRepository: https://github.com/budzianowski/multiwoz\nPaper: https://aclanthology.org/2020.lrec-1.53\nLeaderboard: https://github.com/budzianowski/multiwoz\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('multiwoz21')\nontology =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/multiwoz21.","url":"https://huggingface.co/datasets/ConvLab/multiwoz21","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"gooaq","keyword":"monolingual","description":"GooAQ is a large-scale dataset with a variety of answer types. This dataset contains over\n5 million questions and 3 million answers collected from Google. GooAQ questions are collected\nsemi-automatically from the Google search engine using its autocomplete feature. This results in\nnaturalistic questions of practical interest that are nonetheless short and expressed using simple\nlanguage. GooAQ answers are mined from Google's responses to our collected questions, specifically from\nthe answer boxes in the search results. This yields a rich space of answer types, containing both\ntextual answers (short and long) as well as more structured ones such as collections.","url":"https://huggingface.co/datasets/allenai/gooaq","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"slither-audited-smart-contracts","keyword":"monolingual","description":"This dataset contains source code and deployed bytecode for Solidity Smart Contracts that have been verified on Etherscan.io, along with a classification of their vulnerabilities according to the Slither static analysis framework.","url":"https://huggingface.co/datasets/mwritescode/slither-audited-smart-contracts","creator_name":"Martina Rossini","creator_url":"https://huggingface.co/mwritescode","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-label-classification","multi-input-text-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"SOTAB","keyword":"monolingual","description":"# Understanding the semantics of table elements is a prerequisite for many data integration and data discovery tasks. Table annotation is the task of labeling table elements with terms from a given vocabulary. This paper presents the WDC Schema.org Table Annotation Benchmark (SOTAB) for comparing the performance of table annotation systems. SOTAB covers the column type annotation (CTA) and columns property annotation (CPA) tasks. SOTAB provides âˆ¼50,000 annotated tables for each of the tasks containing Schema.org data from different websites. The tables cover 17 different types of entities such as movie, event, local business, recipe, job posting, or product. The tables stem from the WDC Schema.org Table Corpus which was created by extracting Schema.org annotations from the Common Crawl. Consequently, the labels used for annotating columns in SOTAB are part of the Schema.org vocabulary. The benchmark covers 91 types for CTA and 176 properties for CPA distributed across textual, numerical and date/time columns. The tables are split into fixed training, validation and test sets. The test sets are further divided into subsets focusing on specific challenges, such as columns with missing values or different value formats, in order to allow a more fine-grained comparison of annotation systems. The evaluation of SOTAB using Doduo and TURL shows that the benchmark is difficult to solve for current state-of-the-art systems.\n#","url":"https://huggingface.co/datasets/shivangibithel/SOTAB","creator_name":"Shivangi Bithel","creator_url":"https://huggingface.co/shivangibithel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"mizo-language-corpus-4M","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMizo-Language-Corpus-4M\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Mizo-Language-Corpus-4M is an open-source monolingual Mizo dataset containing 4 million sentences, curated by MWireLabs, Meghalaya, India. Derived from a larger 5.94 million-sentence corpus, this dataset has been meticulously processed to support natural language processing (NLP) research, promote linguistic equity, and foster open development in low-resource languages.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Sentences: 4,000,000\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MWirelabs/mizo-language-corpus-4M.","url":"https://huggingface.co/datasets/MWirelabs/mizo-language-corpus-4M","creator_name":"MWire Labs","creator_url":"https://huggingface.co/MWirelabs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","text","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"code-patrimoine","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du patrimoine, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-civiles-militaires-retraite","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_mean","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrievedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_mean.","url":"https://huggingface.co/datasets/allenai/ms2_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_max","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_max.","url":"https://huggingface.co/datasets/allenai/ms2_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"sts-ca","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for STS-ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSTS-ca corpus is a benchmark for evaluating Semantic Text Similarity in Catalan. This dataset was developed by BSC TeMU as part of Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\nThis work is licensed under a Attribution-ShareAlike 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to build and score semantic similarity models in Catalan.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/sts-ca.","url":"https://huggingface.co/datasets/projecte-aina/sts-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-scoring","text-scoring","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automaticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"monolingual","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"è¨±æ¹›ç„¶","creator_url":"https://huggingface.co/Splend1dchan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"livingner3","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLivingNER\n\t\n\nThis is a third party reupload of the LivingNER task 3 dataset.\nIt only contains the task 3 for the Spanish language. It does not include the multilingual data nor the background data.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {GarcÃ­a Subies, Guillem and Barbero JimÃ©nez, Ãlvaro and MartÃ­nezâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner3.","url":"https://huggingface.co/datasets/IIC/livingner3","creator_name":"Instituto de IngenierÃ­a del Conocimiento","creator_url":"https://huggingface.co/IIC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jojos-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMore details will be added\n\t\n\n","url":"https://huggingface.co/datasets/polytechXhf/jojos-dataset","creator_name":"Polytech Sorbonne X Hugging Face","creator_url":"https://huggingface.co/polytechXhf","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"parlament_parla","keyword":"monolingual","description":"This is the ParlamentParla speech corpus for Catalan prepared by ColÂ·lectivaT. The audio segments were extracted from recordings the Catalan Parliament (Parlament de Catalunya) plenary sessions, which took place between 2007/07/11 - 2018/07/17. We aligned the transcriptions with the recordings and extracted the corpus. The content belongs to the Catalan Parliament and the data is released conforming their terms of use.\n\nPreparation of this corpus was partly supported by the Department of Culture of the Catalan autonomous government, and the v2.0 was supported by the Barcelona Supercomputing Center, within the framework of the project AINA of the Departament de PolÃ­tiques Digitals.\n\nAs of v2.0 the corpus is separated into 211 hours of clean and 400 hours of other quality segments. Furthermore, each speech segment is tagged with its speaker and each speaker with their gender. The statistics are detailed in the readme file.\n\nFor more information, go to https://github.com/CollectivaT-dev/ParlamentParla or mail info@collectivat.cat.","url":"https://huggingface.co/datasets/projecte-aina/parlament_parla","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","language-modeling","speaker-identification","found"],"keywords_longer_than_N":true},
	{"name":"squad_fr","keyword":"monolingual","description":"SQuAD-fr is a French translated version of the Stanford Question Answering Dataset (SQuAD), the reference corpus to evaluate question answering models' performances in English.\nIt consists of 100K question-answer pairs on 500+ articles derived from the original English dataset and represents a large-scale dataset for closed-domain question answering on factoid questions in French.\nSQuAD-fr serves as a means of data augmentation on FQuAD and PIAF benchmarks, with 90K+ translated training pairs.","url":"https://huggingface.co/datasets/qwant/squad_fr","creator_name":"Qwant","creator_url":"https://huggingface.co/qwant","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","closed-domain-qa","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"malayalam_asr_corpus","keyword":"monolingual","description":"The corpus contains roughly 10 hours of audio and trasncripts in Malayalam language. The transcripts have beedn de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/malayalam_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"CONDA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CONDA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTraditional toxicity detection models have focused on the single utterance level without deeper understanding of context. We introduce CONDA, a new dataset for in-game toxic language detection enabling joint intent classification and slot filling analysis, which is the core task of Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2 matches.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Matrix430/CONDA.","url":"https://huggingface.co/datasets/Matrix430/CONDA","creator_name":"Kunze Wang","creator_url":"https://huggingface.co/Matrix430","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","intent-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"common-accent-augmented","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented.","url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"AMIsum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"AMIsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAMIsum is meeting summaryzation dataset based on the AMI Meeting Corpus (https://groups.inf.ed.ac.uk/ami/corpus/). The dataset utilizes the transcripts as the source data and abstract summaries as the target data.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{'transcript': '<PM> Okay. <PM> Right. <PM> Um well this is theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/AMIsum.","url":"https://huggingface.co/datasets/TalTechNLP/AMIsum","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"medwiki","keyword":"monolingual","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining.","url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"scico","keyword":"monolingual","description":"        SciCo is a dataset for hierarchical cross-document coreference resolution\n        over scientific papers in the CS domain.","url":"https://huggingface.co/datasets/allenai/scico","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","coreference-resolution","domain experts","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"commonvoice10k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/commonvoice10k.","url":"https://huggingface.co/datasets/DTU54DL/commonvoice10k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cSQuAD2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for cSQuAD2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA contrast set to evaluate models trained on SQUAD on out-of-domain data.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nEvaluate question-answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nDataset contains 40 instances\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nid\nId of document containing context\n\n\ntitle\nTitle of the document\n\n\ncontext\nThe context of the question\n\n\nquestion\nThe question to answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD2.","url":"https://huggingface.co/datasets/dferndz/cSQuAD2","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Urban100","keyword":"monolingual","description":"The Urban100 dataset contains 100 images of urban scenes. \nIt commonly used as a test set to evaluate the performance of super-resolution models.","url":"https://huggingface.co/datasets/eugenesiow/Urban100","creator_name":"Eugene Siow","creator_url":"https://huggingface.co/eugenesiow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"pcba_686978","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for pcba_686978\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\npcba_686978 is a dataset included in MoleculeNet. PubChem BioAssay (PCBA) is a database consisting of biological activities of small molecules generated by high-throughput screening. We have chosen one of the larger tasks (ID 686978) as described in https://par.nsf.gov/servlets/purl/10168888.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/pcba_686978.","url":"https://huggingface.co/datasets/zpn/pcba_686978","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"mc4-id","keyword":"monolingual","description":"A thoroughly cleaned version of the Italian portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.","url":"https://huggingface.co/datasets/indonesian-nlp/mc4-id","creator_name":"Indonesian NLP","creator_url":"https://huggingface.co/indonesian-nlp","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"long-covid-classification-data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tData Description\n\t\n\nLong-COVID related articles have been manually collected by information specialists.Please find further information here. \n\n\t\n\t\t\n\t\tSize\n\t\n\n\n\t\n\t\t\n\nTraining\nDevelopment\nTest\nTotal\n\n\n\t\t\nPositive Examples\n215\n76\n70\n345\n\n\nNegative Examples\n199\n62\n68\n345\n\n\nTotal\n414\n238\n138\n690\n\n\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{10.1093/database/baac048,author = {Langnickel, Lisa and Darms, Johannes and Heldt, Katharina and Ducks, Denise and Fluck, Juliane},title = \"{Continuous developmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llangnickel/long-covid-classification-data.","url":"https://huggingface.co/datasets/llangnickel/long-covid-classification-data","creator_name":"Lisa Langnickel","creator_url":"https://huggingface.co/llangnickel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"qg_squad","keyword":"monolingual","description":"[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) evaluation set for the question generation (QG) models. The split \nof test and development set follows the [\"Neural Question Generation\"](https://arxiv.org/abs/1705.00106) work and is \ncompatible with the [leader board](https://paperswithcode.com/sota/question-generation-on-squad11).","url":"https://huggingface.co/datasets/lmqg/qg_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad","English"],"keywords_longer_than_N":true},
	{"name":"common-native-proc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native-proc.","url":"https://huggingface.co/datasets/DTU54DL/common-native-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"monolingual","description":"SamrÃ³mur Icelandic Speech 1.0.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_asr","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"widdd","keyword":"monolingual","description":"WiDDD stands for WIkiData Disambig with Descriptions. The former dataset comes from [Cetoli & al](https://arxiv.org/pdf/1810.09164.pdf)  paper, and is aimed at solving Named Entity Disambiguation. This datasets tries to extract relevant information from entities descriptions only, instead of working with graphs. In order to do so, we mapped every Wikidata id (correct id and wrong id) in the original paper with its WikiData description. If not found, row is discarded for this version.","url":"https://huggingface.co/datasets/mnemlaghi/widdd","creator_name":"Mehdi Nemlaghi","creator_url":"https://huggingface.co/mnemlaghi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","token-classification","entity-linking-retrieval","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Telugu"],"keywords_longer_than_N":true},
	{"name":"nesteo-prototype","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNestEO: Modular and Hierarchical EO Dataset Framework\n\t\n\nNestEO is a hierarchical, resolution-aligned, UTM-based nested grid dataset framework supporting general-purpose, multi-scale multimodal Earth Observation workflows. Built from diverse EO sources and enriched with metadata for landcover, climate zones, and population, it enables scalable, representative and progressive sampling for AI4EO.\nGrid Levels: 120000m, 12000m, 2400m, 1200m, 600m, 300m, 150mGrid Metadata: ESA WorldCoverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype.","url":"https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype","creator_name":"NestEO Datasets","creator_url":"https://huggingface.co/nesteo-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-classification","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ‰ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tðŸš€ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that Africanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"synthetic-users-1000","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Users 1000\n\t\n\n\n\t\n\t\t\n\t\tðŸ§ª Synthetic Users Dataset (1,000 Records)\n\t\n\nThis dataset contains 1,000 high-quality synthetic user profiles, including realistic bios, usernames, metadata, and profile image filenames â€” ideal for:\n\nUI/UX testing\nPrototyping dashboards\nMock data in SaaS apps\nUser flow demos\nAI evaluation without PII\n\n\n\n\t\n\t\t\n\t\tðŸ§  Features\n\t\n\n\nâœ… 100% privacy-safe\nðŸ§ Full names, emails, bios, countries\nðŸ“¸ Profile image filenames (S3-ready)\nðŸ” Gender, age, emotion tags viaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eosync/synthetic-users-1000.","url":"https://huggingface.co/datasets/eosync/synthetic-users-1000","creator_name":"Jose","creator_url":"https://huggingface.co/eosync","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","tabular-classification","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"merged_valid","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 1g0rrr/merged_valid\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LeRobot v2.1 format with the following structure:\n\nmeta/info.json: Dataset metadata and configuration\nmeta/episodes.jsonl: Episode information including tasks and lengths\nmeta/tasks.jsonl: Task descriptions and indices\nmeta/episodes_stats.jsonl: Per-episode statistics\ndata/chunk_*/episode_*.parquet: Episode data files\nvideos/chunk_*/video_key_*/episode_*.mp4: Video files (if present)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/1g0rrr/merged_valid.","url":"https://huggingface.co/datasets/1g0rrr/merged_valid","creator_name":"Igor","creator_url":"https://huggingface.co/1g0rrr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["robotics","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"spatial-trace-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpatialTraceGen is a dataset of multi-hop spatial reasoning traces generated by Large Language Models (LLMs) integrated with computer vision tools. The framework is designed to produce step-by-step reasoning for complex spatial queries. This dataset contains the generated reasoning traces under different levels of automated verification.\nThe dataset was created using the CLEVR dataset as a base. The traces were generated by providing questions from CLEVR to an LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhruvmsheth/spatial-trace-dataset.","url":"https://huggingface.co/datasets/dhruvmsheth/spatial-trace-dataset","creator_name":"Dhruv","creator_url":"https://huggingface.co/dhruvmsheth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"cms_iom_3000","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcdsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_3000.","url":"https://huggingface.co/datasets/evekhm/cms_iom_3000","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","https://www.cms.gov/medicare-coverage-database","https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms"],"keywords_longer_than_N":true},
	{"name":"termith-eval_fr_prompt_data_to_text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttermith-eval_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntermith-eval_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 11,886 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text.","url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/termith-eval"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-p2p","keyword":"monolingual","description":"\n  ArXivHierarchicalClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles+abstract from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-p2p.","url":"https://huggingface.co/datasets/mteb/arxiv-clustering-p2p","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"movie_reviews_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMovie Reviews Demo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a small demo dataset of 10 movie reviews labeled with sentiment categories:\n\npositive\nnegative\nneutral\n\nThe dataset is intended for educational and testing purposes, for example to try out dataset creation and data visualization features on Hugging Face Spaces.\n\nNumber of samples: 10\nLanguages: English\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset can be used to:\n\nDemonstrate sentiment classification tasks.\nTest dataset upload &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/beaucte/movie_reviews_dataset.","url":"https://huggingface.co/datasets/beaucte/movie_reviews_dataset","creator_name":"Nabila","creator_url":"https://huggingface.co/beaucte","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","created_by_human","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-education","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'Ã©ducation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"wmdp_cyber_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWMDP-Cyber Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-cyber.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_cyber_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_cyber_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-assurances","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des assurances, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"FlowGen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸŒŸ FlowGen\n\t\n\nFlowGen is a controllable flowchart synthesizer that generates diagrams with tunable structural features and supports multiple rendering styles.\n\n\t\n\t\t\n\t\tðŸ“‘ Dataset description\n\t\n\nThis dataset contains different types of renderer flowchart images with different difficulty levels.\n\n\t\n\t\t\nTypes\nTrain (Easy)\nTrain (Medium)\nTrain (Hard)\nTest (Graph Easy)\nTest (Graph Medium)\nTest (Graph Hard)\nTest (Scanned Easy)\nTest (Scanned Medium)\nTest (Scanned Hard)\n\n\n\t\t\nMermaid\n960\n960\n960â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonymous112233/FlowGen.","url":"https://huggingface.co/datasets/Anonymous112233/FlowGen","creator_name":"Anonymous","creator_url":"https://huggingface.co/Anonymous112233","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","visual-question-answering","image-captioning","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"search-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAI Search Providers Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Structure\n\t\n\nEach entry contains:\n\nid: Unique identifier for the QA pair\nquestion: The query text\nexpected_answer: The correct answer\ncategory: Topic category\narea: Broader area classification (News/Knowledge)\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Categories\n\t\n\nThe dataset covers various domains including:\n\nEntertainment\nSports\nTechnology\nGeneral News\nFinance\nArchitecture\nArts\nAstronomy\nAuto (Automotive)\nE-sports\nFashion\nFalse Premise\n\n\n\t\n\t\t\n\t\tðŸ“ˆâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junzhang1207/search-dataset.","url":"https://huggingface.co/datasets/junzhang1207/search-dataset","creator_name":"John","creator_url":"https://huggingface.co/junzhang1207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"warrungu-dictionary","keyword":"monolingual","description":"This dataset contains cleaned dictionary and grammar resources for the Warrungu language, compiled from structured CSV files for use in language revitalisation apps and AI tutors.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nCleaned_Warrungu_Dictionary.csv\nwarrungu_flashcards.csv\nwarrungu_suffix_table.csv\n/images/ (Warrungu flashcard images)\n/audio/ (Warrungu flashcard audio)\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution 4.0 International (CC BY 4.0)\n\n\t\n\t\t\n\t\tContact\n\t\n\nMaintained by the Warrungu project team.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/warrungu/warrungu-dictionary.","url":"https://huggingface.co/datasets/warrungu/warrungu-dictionary","creator_name":"Christopher morganson","creator_url":"https://huggingface.co/warrungu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mb-crater_multi_seg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-crater_multi_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Other\n2: Layered\n3: Buried\n4: Secondary\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-crater_multi_seg.","url":"https://huggingface.co/datasets/Mirali33/mb-crater_multi_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"comprehensive-qa-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tComprehensive Question Answering Dataset\n\t\n\nA large-scale, diverse collection of question answering datasets combined into a unified format for training and evaluating QA models. This dataset contains over 160,000 question-answer pairs from three popular QA benchmarks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis comprehensive dataset combines three popular question answering datasets into a single, unified format:\n\nSQuAD 2.0 (Stanford Question Answering Dataset) - Context passages from Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset.","url":"https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset","creator_name":"Aixover","creator_url":"https://huggingface.co/Successmove","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","conversational","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"photochat_plus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PhotoChat++\n\t\n\n\nðŸš¨ Disclaimer: All models and datasets are intended for research purposes only.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPhotoChat++ is a publicly available multi-modal dialogue dataset, an extended version of PhotoChat. PhotoChat++ contains six intent labels, a triggering sentence, an image description, and salient information (e.g., â€œwordsâ€ or â€œphrasesâ€) to invoke the image-sharing behavior. The purpose of this dataset is to thoroughly assess the image-sharingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/passing2961/photochat_plus.","url":"https://huggingface.co/datasets/passing2961/photochat_plus","creator_name":"Young-Jun Lee","creator_url":"https://huggingface.co/passing2961","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","conversational","monolingual","PhotoChat"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"monolingual","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"code-mutualite","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la mutualitÃ©, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"templatic_generation_tasks","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Active/Passive/Logical Transforms\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a synthetic dataset containing a set of templatic generation tasks using both English and random 2-letter words. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[TBD]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll data is in English or random 2-letter words.  \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of several subsets, or tasks. Each task contains a train split, a dev split, and a\ntest split, and multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/microsoft/templatic_generation_tasks.","url":"https://huggingface.co/datasets/microsoft/templatic_generation_tasks","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"DarijaMMLU","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DarijaMMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDarijaMMLU is an evaluation benchmark designed to assess large language models' (LLM) performance in Moroccan Darija, a variety of Arabic. It consists of 22,027 multiple-choice questions, translated from selected subsets of the Massive Multitask Language Understanding (MMLU) and ArabicMMLU benchmarks to measure model performance on 44 subjects in Darija.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Category: Multiple-choice questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU.","url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","machine-generated","machine-translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"PubLayNet","keyword":"monolingual","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for PubLayNet\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nPubLayNet is a dataset for document layout analysis. It contains images of research papers and articles and annotations for various elements in a page such as \"text\", \"list\", \"figure\" etc in these research paper images. The dataset was obtained by automatically matching the XML representations and the content of over 1 million PDF articles that are publicly available on PubMed Central.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/creative-graphic-design/PubLayNet.","url":"https://huggingface.co/datasets/creative-graphic-design/PubLayNet","creator_name":"Creative Graphic Design Lab","creator_url":"https://huggingface.co/creative-graphic-design","license_name":"Community Data License Agreement Permissive 1.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-1.0.html","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-to-text","question-answering","other"],"keywords_longer_than_N":true},
	{"name":"CUADLicenseGrantLegalBenchClassification","keyword":"monolingual","description":"\n  CUADLicenseGrantLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause contains a license granted by one party to its counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"AnswerCarefully_DPO","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAnswerCarefully Translated and Augmented Dataset\n\t\n\nThis dataset is a preprocessed version of llm-jp/AnswerCarefully, adapted for DPO (Direct Preference Optimization) training.\n\n\t\n\t\t\n\t\tDataset Creation Process\n\t\n\n\nTranslation: The original llm-jp/AnswerCarefully dataset, which is in English, was translated to Japanese using the Qwen3-32B model.\nRejection Sampling: A rejected response was generated for each question using the Qwen3-14B model. This provides a contrastive pair (chosen vs.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/AnswerCarefully_DPO.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/AnswerCarefully_DPO","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","machine-generated","machine-generated","monolingual","llm-jp/AnswerCarefully"],"keywords_longer_than_N":true},
	{"name":"MarathiNewsClassification","keyword":"monolingual","description":"\n  MarathiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Marathi dataset for 3-class classification of Marathi news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-marathi\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MarathiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MarathiNewsClassification.","url":"https://huggingface.co/datasets/mteb/MarathiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Marathi"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may acquire information similar to Confidential Information from a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-justice-militaire-nouveau","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de justice militaire (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"TV2Nordretrieval","keyword":"monolingual","description":"\n  TV2Nordretrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article and corresponding summaries extracted from the Danish newspaper TV2 Nord.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReferencehttps://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TV2Nordretrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TV2Nordretrieval.","url":"https://huggingface.co/datasets/mteb/TV2Nordretrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","alexandrainst/nordjylland-news-summarization"],"keywords_longer_than_N":true},
	{"name":"k12-business-economics-comprehensive","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ’¼ K-12 Business and Economics Comprehensive Standards Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThe most comprehensive K-12 business and economics education dataset available, containing 1,236 learning standards spanning financial literacy and business education. This dataset combines the Jump$tart Personal Financial Education Standards with NBEA Business Education Standards to support comprehensive economic education from kindergarten through 12th grade.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/robworks-software/k12-business-economics-comprehensive.","url":"https://huggingface.co/datasets/robworks-software/k12-business-economics-comprehensive","creator_name":"Ryan Robson","creator_url":"https://huggingface.co/robworks-software","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Awadhi"],"keywords_longer_than_N":true},
	{"name":"mythos","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mitological-Philosophical Prompts (Mitomaquia)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 200 examples of mythological, narrative, and philosophical prompts designed for training or fine-tuning large language models (LLMs). Each entry features a deep question (prompt), relevant cultural or mythological background (context), and a reflective, often paradoxical, answer (response). \nThe goal is not factual Q&A but the cultivation of myth-aware reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniealfaro/mythos.","url":"https://huggingface.co/datasets/ronniealfaro/mythos","creator_name":"Ronnie","creator_url":"https://huggingface.co/ronniealfaro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","open-domain-qa","dialogue-generation","human-annotated"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_third_iteration","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API costâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MultiFlow-Bench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMultiFlow Privacy Benchmark\n\t\n\nMultiFlow is a benchmark dataset designed to evaluate large language models' (LLMs) understanding of contextual privacy risks and their ability to propose minimal and lawful remediation steps.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nEach example in the dataset represents a real-world-inspired data event with multiple information flows. Each flow is annotated with:\n\nInitial legality and utility evaluation\nSuggested remediation steps\nPost-remediation scoresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/timtsapras23/MultiFlow-Bench.","url":"https://huggingface.co/datasets/timtsapras23/MultiFlow-Bench","creator_name":"Efthymios Tsaprazlis","creator_url":"https://huggingface.co/timtsapras23","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 210350\nFiltered size: 210350\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"human-cornea-snRNAseq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman Cornea Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on the cellular heterogeneity of the human cornea. It provides a high-resolution view of various cell populations and their gene expression profiles across different layers of this critical ocular tissue.\nThe data was sourced from a research paper providing a comprehensive single-cell transcriptome atlas of the human cornea.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"TOFU-da","keyword":"monolingual","description":"miry-itu/TOFU-da dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/miry-itu/TOFU-da","creator_name":"Michal Rynowiecki","creator_url":"https://huggingface.co/miry-itu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"HALClusteringS2S.v2","keyword":"monolingual","description":"\n  HALClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from HAL (https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HALClusteringS2S.v2\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HALClusteringS2S.v2.","url":"https://huggingface.co/datasets/mteb/HALClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/clustering-hal-s2s","French"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mb-conequest_seg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-conequest_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Cone\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masks\n  â”œâ”€â”€ val/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-conequest_seg.","url":"https://huggingface.co/datasets/Mirali33/mb-conequest_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-physics","keyword":"monolingual","description":"\n  CQADupstackPhysicsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackPhysicsRetrieval\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-physics.","url":"https://huggingface.co/datasets/mteb/cqadupstack-physics","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ru-instruct","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°\n\t\n\nÐ¡ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð¸Ð· Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ñ… Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð², Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ… Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸. ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð² Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð° (ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Den4ikAI/nonsense_gibberish_detector). Ð”ÐµÐ´ÑƒÐ¿Ð»Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½ SimHash'Ð¾Ð¼.\nÐžÐ±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð½Ð° Ð½Ñ‘Ð¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð·Ð°Ð²Ñ‘Ð·, in progress.\n\n\t\n\t\t\n\t\tÐ¡Ð¾ÑÑ‚Ð°Ð²\n\t\n\nÐ¡Ð¾Ð±Ñ€Ð°Ð» Ð¸Ð· ÑÑ‚Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ…:\n\nd0rj/OpenOrca-ru (Ð¾Ñ‚ Open-Orca/OpenOrca)\nd0rj/OpenHermes-2.5-ru (Ð¾Ñ‚ teknium/OpenHermes-2.5)\nd0rj/dolphin-ru (Ð¾Ñ‚ ehartford/dolphin)\nd0rj/alpaca-cleaned-ru (Ð¾Ñ‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct.","url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","machine-generated","found","translated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Panjabi"],"keywords_longer_than_N":true},
	{"name":"MoT-Code-350K","keyword":"monolingual","description":"\nðŸ  MoTCode-Data\n\n\n\nâ€¢ ðŸ¤— Data  â€¢ ðŸ¤— Model  â€¢ ðŸ± Code â€¢ ðŸ“ƒ Paper \n\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nfrom datasets import load_dataset\nload_dataset(\"JingyaoLi/MoT-Code-350K\")\n\nDatasetDict({\n    train: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 312645\n    })\n})\n\n\n\t\n\t\t\n\t\n\t\n\t\tModular-of-thought Data Creation\n\t\n\nWe provide an example python file to evolution a MoT dataset. Run the following command:\npython src/generate_MoT_dataset.py \\\n    --data_path $data_path \\â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JingyaoLi/MoT-Code-350K.","url":"https://huggingface.co/datasets/JingyaoLi/MoT-Code-350K","creator_name":"Jingyao Li","creator_url":"https://huggingface.co/JingyaoLi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","translation","language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-change_cls_ctx","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-change_cls_ctx\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: no_change\n1: change\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 72 images\ntest: 20 images\nval: 20 images\npartition_train_0.50x_partition: 18 images\npartition_train_0.20x_partition: 7 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-change_cls_ctx.","url":"https://huggingface.co/datasets/Mirali33/mb-change_cls_ctx","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-route","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la route, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"TOFU-en-re","keyword":"monolingual","description":"miry-itu/TOFU-en-re dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/miry-itu/TOFU-en-re","creator_name":"Michal Rynowiecki","creator_url":"https://huggingface.co/miry-itu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Awadhi"],"keywords_longer_than_N":true},
	{"name":"TruthGen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TruthGen\n\t\n\nTruthGen is a dataset of generated political statements, created to assess the relationship between truthfulness and political bias in reward models and language models. It consists of non-repetitive, non-political factual statements paired with false statements, designed to evaluate models for their ability to distinguish true from false information while minimizing political content. The dataset was generated using GPT-3.5, GPT-4 and Gemini, with a focusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/TruthGen.","url":"https://huggingface.co/datasets/wwbrannon/TruthGen","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"StackOverflowQA","keyword":"monolingual","description":"\n  StackOverflowQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding response which may include some text mixed with code snippets. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/StackOverflowQA.","url":"https://huggingface.co/datasets/mteb/StackOverflowQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/stackoverflow-qa","English"],"keywords_longer_than_N":true},
	{"name":"OpenMind2D","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOpenMind2D: 2D Brain MRI Slices\n\t\n\nOpenMind2D is a 2D medical imaging dataset derived from the OpenMind dataset. It contains 335,754 2D slices extracted from 3D brain MRI volumes in three anatomical orientations (axial, sagittal, coronal).\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Images: 335,754\nResolution: 256Ã—256 pixels\nFormat: JPEG\nSize: ~11.7 GB\nSplits: Train (70%), Validation (20%), Test (10%)\nOrientations: Axial, sagittal, coronal\nModalities: T1w, T2w, FLAIR, DWI, and 19+ additionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liamchalcroft/OpenMind2D.","url":"https://huggingface.co/datasets/liamchalcroft/OpenMind2D","creator_name":"Liam Chalcroft","creator_url":"https://huggingface.co/liamchalcroft","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","zero-shot-image-classification","multi-class-image-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"escher-magicbrush","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-magicbrush\n\t\n\nMagicBrush dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-magicbrush","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval.V2","keyword":"monolingual","description":"\n  NLPJournalAbsArticleRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V2 dataset (last updated 2025-06-15).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","mteb/NLPJournalAbsArticleRetrieval"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BANKING77\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDataset composed of online banking queries annotated with their corresponding intents.\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain.\nIt comprises 13,083 customer service queries labeled with 77 intents. \nIt focuses on fine-grained single-domain intent detection.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIntent classification, intent detection\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gtfintechlab/banking77.","url":"https://huggingface.co/datasets/gtfintechlab/banking77","creator_name":"Financial Services Innovation Lab, Georgia Tech","creator_url":"https://huggingface.co/gtfintechlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"CUADAntiAssignmentLegalBenchClassification","keyword":"monolingual","description":"\n  CUADAntiAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires consent or notice of a party if the contract is assigned to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"funnyinsults","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Funny Insults\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,702 humorous insults collected from funny-insults.com. The dataset includes the insult text, categorization information, and user-provided ratings for each entry. This collection represents a variety of comedic insults across different categories that can be used for humor analysis, text generation, or sentiment analysis tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All insultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/funnyinsults.","url":"https://huggingface.co/datasets/nyuuzyou/funnyinsults","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"HM-SYNC","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for this Human-Machine Interaction Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains a collection of observed interactions between humans and an advanced manufacturing machine, specifically a Wire Arc Additive Manufacuturing (WAAM) machine. The motivations for collecting this dataset, the contents of this dataset, and some ideas for how to analyze and use this dataset can be found below. \nAdditionally, the paper introducing this dataset is published in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saluslab/HM-SYNC.","url":"https://huggingface.co/datasets/saluslab/HM-SYNC","creator_name":"SALUS Lab","creator_url":"https://huggingface.co/saluslab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","time-series-forecasting","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"#Sentiment analysi School project\nthe dataset was created with an online questionnaire in which an audience of students, teachers, administrative staff, and families were asked to answer some questions about their relationship with school.\nthe annotations were made by correlating the textual responses to satisfaction indicators.\nthe dataset was created within an afternoon course dedicated to artificial intelligence.\nthanks to everyone for their collaborationâ¤ï¸.\n","url":"https://huggingface.co/datasets/happycircus1/sentiment-analysis-test","creator_name":"tghrgg","creator_url":"https://huggingface.co/happycircus1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"CUADExpirationDateLegalBenchClassification","keyword":"monolingual","description":"\n  CUADExpirationDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the initial term expires.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"requests-github-issues","keyword":"monolingual","description":"Raibek/requests-github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Raibek/requests-github-issues","creator_name":"Raibek Tussupbekov","creator_url":"https://huggingface.co/Raibek","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/gsm8k.","url":"https://huggingface.co/datasets/oieieio/gsm8k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arthrography-imaging","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tArthrography Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 500 synthetic arthrography procedure reports designed to represent realistic medical scenarios encountered in clinical practice. Each report includes:\n\nPatient demographics: Age and sex.\nClinical indications: Detailed descriptions of reasons for undergoing the procedure, crafted at a PhD level.\nJoint examined: Specific joint under examination (e.g., shoulder, knee, hip, etc.).\nContrast agent used: The typeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/arthrography-imaging.","url":"https://huggingface.co/datasets/Taylor658/arthrography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OralArgumentQuestionPurposeLegalBenchClassification","keyword":"monolingual","description":"\n  OralArgumentQuestionPurposeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task classifies questions asked by Supreme Court justices at oral argument into seven categories:\n        1. Background - questions seeking factual or procedural information that is missing or not clear in the briefing\n        2. Clarification - questions seeking to get an advocate to clarify her position or the scope of the rule being advocated for\n        3. Implications -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringP2P.v2","keyword":"monolingual","description":"\n  CLSClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles + abstract from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReferencehttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringP2P.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2.","url":"https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringP2P"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_det","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-boulder_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 8 splits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-16\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-boulder_det.","url":"https://huggingface.co/datasets/Mirali33/mb-boulder_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Gujarati"],"keywords_longer_than_N":true},
	{"name":"hr-intent-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HR Intent Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset for intent classification in enterprise HR workflows. Each row contains a user query, context (as a structured field with domain, topic, subject), and a label for the HR intent.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nIntent Classification (text classification)\nSuitable for benchmarking BERT, RoBERTa, etc., on real-world HR requests.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SantmanKT/hr-intent-dataset.","url":"https://huggingface.co/datasets/SantmanKT/hr-intent-dataset","creator_name":"Santhosh Mani","creator_url":"https://huggingface.co/SantmanKT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","machine-generated","human-validated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER","keyword":"monolingual","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FEVER","English"],"keywords_longer_than_N":true},
	{"name":"MixBench25","keyword":"monolingual","description":"MixBench is a benchmark for evaluating mixed-modality retrieval. It contains queries and corpora from four datasets: MSCOCO, Google_WIT, VisualNews, and OVEN. Each subset provides: query, corpus, mixed_corpus, and qrel splits.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"medical-reasoning-orpo_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMedical Reasoning ORPO Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of SURESHBEEKHANI/medical-reasoning-orpo, formatted for preference tuning tasks like DPO or ORPO.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nThe dataset contains three columns:\n\nquestion: A combination of the original instruction and Input fields.\naccepted: The preferred response, formatted with thinking process and final answer tags.\nrejected: The dispreferred response, also formatted with tags.\n\n\n\t\n\t\t\n\t\tAnswerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scenic-driving-scenarios","keyword":"monolingual","description":"Scenic driving scenario dataset","url":"https://huggingface.co/datasets/assistive-autonomy/scenic-driving-scenarios","creator_name":"Centre for AI in Assistive Autonomy","creator_url":"https://huggingface.co/assistive-autonomy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","arxiv:2410.09829","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adaptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"shelf-segmentation-train","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCustom YOLO Dataset\n\t\n\nThis dataset is formatted for YOLO-based instance segmentation. It includes images and annotations for training, validation, and testing.\n\n\t\n\t\t\n\t\tDataset structure\n\t\n\n\ntrain/images, valid/images, test/images: JPEG image files\ntrain/labels, valid/labels, test/labels: YOLO-format .txt annotations\ndata.yaml: defines class names and split locations\n\n","url":"https://huggingface.co/datasets/cheesecz/shelf-segmentation-train","creator_name":"cheese","creator_url":"https://huggingface.co/cheesecz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","manual","monolingual","roboflow","English"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GitHub Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGitHub Issues is a dataset consisting of GitHub issues and pull requests associated with the ðŸ¤— Datasets repository. It is intended for educational purposes and can be used for semantic search or multilabel text classification. The contents of each GitHub issue are in English and concern the domain of datasets for NLP, computer vision, and beyond.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nFor each of the tasks taggedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xyx138/github-issues.","url":"https://huggingface.co/datasets/xyx138/github-issues","creator_name":"xxx","creator_url":"https://huggingface.co/xyx138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wikinews-fr-100_fr_prompt_keywords_extraction","keyword":"monolingual","description":"\n\t\n\t\t\n\t\twikinews-fr-100_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwikinews-fr-100_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 2,100 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction.","url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/wikinews-fr-100"],"keywords_longer_than_N":true},
	{"name":"pathvqa-federated-client-10-by-image","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ§  PathVQA Federated (Split Per Image)\n\t\n\nA federated learning-ready version of the PathVQA dataset, partitioned by image using perceptual hashing (pHash). Each client's data contains all question-answer pairs linked to unique images, mimicking a real-world distributed medical setting (e.g., hospitals with private slide collections).\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tðŸ”¢ Features\n\t\n\n\nimage: PIL.Image â€” Full-resolution pathology image tile\nquestion: string â€” Natural languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/srirangamuc/pathvqa-federated-client-10-by-image.","url":"https://huggingface.co/datasets/srirangamuc/pathvqa-federated-client-10-by-image","creator_name":"Srirangam Umesh Chandra","creator_url":"https://huggingface.co/srirangamuc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"wikiformula","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNTCIR-WFB\n\t\n\nWiki Formula Browsing Task from NTICR-12 (https://research.nii.ac.jp/ntcir/permission/ntcir-12/perm-en-MathIR.html)\n","url":"https://huggingface.co/datasets/hcju/wikiformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-i","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des impÃ´ts, annexe I, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"24gadget-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for 24gadget.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from 24gadget.ru, a Russian technology news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and view count. The dataset contains 36,582 unique articles covering various topics in technology and gadgets.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/24gadget-posts.","url":"https://huggingface.co/datasets/nyuuzyou/24gadget-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikinews-pl","keyword":"monolingual","description":"Wikinews-PL\n","url":"https://huggingface.co/datasets/rafalposwiata/wikinews-pl","creator_name":"RafaÅ‚ PoÅ›wiata","creator_url":"https://huggingface.co/rafalposwiata","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","multi-label-classification","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-monetaire-financier","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode monÃ©taire et financier, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020","keyword":"monolingual","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Touche2020","English"],"keywords_longer_than_N":true},
	{"name":"vep_cosmic_chr1_split","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_cosmic_chr1_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_cosmic_chr1_split\n   cdâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/vep_cosmic_chr1_split.","url":"https://huggingface.co/datasets/Bgoood/vep_cosmic_chr1_split","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"CUADMinimumCommitmentLegalBenchClassification","keyword":"monolingual","description":"\n  CUADMinimumCommitmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a minimum order size or minimum amount or units per time period that one party must buy from the counterparty.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"apps-small","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAPPS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAPPS is a benchmark for code generation with 10000 problems. It can be used to evaluate the ability of language models to generate code from natural language specifications.\nYou can also find APPS metric in the hub here codeparrot/apps_metric.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains questions in English and code solutions in Python.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nfrom datasets import load_dataset\nload_dataset(\"codeparrot/apps\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AuroraH456/apps-small.","url":"https://huggingface.co/datasets/AuroraH456/apps-small","creator_name":"Aurora Huang","creator_url":"https://huggingface.co/AuroraH456","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"brwac","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tDataset Card for BrWaC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac.","url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"code-propriete-personnes-publiques","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral de la propriÃ©tÃ© des personnes publiques, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"wise-data-preferences","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe wise-data-preferences dataset is a synthetically created collection of values-laden conversations with preferred and rejected responses, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. This dataset was specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using DPO (Direct Preference Optimization).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data-preferences.","url":"https://huggingface.co/datasets/meaningalignment/wise-data-preferences","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","multi-class-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"msedup","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMathematics Stack Exchange Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/math.stackexchange.com.7z\n","url":"https://huggingface.co/datasets/hcju/msedup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mse","English"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_seg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-boulder_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Boulder\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masks\n  â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-boulder_seg.","url":"https://huggingface.co/datasets/Mirali33/mb-boulder_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MuMiN-PT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMuMIN-PT\n\t\n\nMuMIN Portuguese Baseline subset extracted using Lingua.\n\nHomepage: https://mumin-dataset.github.io/\nRepository: https://github.com/MuMiN-dataset/mumin-baseline\nPaper:  https://arxiv.org/abs/2202.11684\nLeaderboard: \nPoint of Contact:\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@inproceedings{10.1145/3477495.3531744,\nauthor = {Nielsen, Dan S. and McConville, Ryan},\ntitle = {MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset},\nyear =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/MuMiN-PT.","url":"https://huggingface.co/datasets/ju-resplande/MuMiN-PT","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"MMLU-SR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMMLU-SR Dataset\n\t\n\nThis is the dataset for the paper \"MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three different variants:\n\nQuestion Only: Key terms in questions are replaced with dummy words and their definitions, while answer choices remain unchanged.\nAnswer Only: Key terms in answer choices are replaced with dummy words and their definitions, while questions remain unchanged. \nQuestionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiniCat/MMLU-SR.","url":"https://huggingface.co/datasets/NiniCat/MMLU-SR","creator_name":"Cat Wang","creator_url":"https://huggingface.co/NiniCat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ConstructiveBench","keyword":"monolingual","description":"\nðŸ” Enumerateâ€“Conjectureâ€“Prove: Formally Solving Answer-Construction Problems in Math Competitions\n\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\n\nBackground: We identify that current mathematical reasoning approaches either generate creative answers (LLMs) but fail to verify them formally, or verify rigorously (symbolic provers) but cannot efficiently generate answers.\nContribution: \nWe introduce ECP framework: a modular neuro-symbolic pipeline that integrates a feedback-driven autoformalization stageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sunjia72/ConstructiveBench.","url":"https://huggingface.co/datasets/sunjia72/ConstructiveBench","creator_name":"Jialiang Sun","creator_url":"https://huggingface.co/sunjia72","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"ContractNLIConfidentialityOfAgreementLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIConfidentialityOfAgreementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA provides that the Receiving Party shall not disclose the fact that Agreement was agreed or negotiated.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\nSource datasets:\n\nnguha/legalbench\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"code-communes-nouvelle-caledonie","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des communes de la Nouvelle-CalÃ©donie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"MC-I-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Urdu-Legal_ner_corpora","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“Ž Overview\n\t\n\nThis synthetic dataset is designed for Named Entity Recognition (NER) in Urdu legal documents, addressing the scarcity of annotated legal corpora in low-resource languages. The dataset comprises 117,500 CoNLL-formatted documents created using template-based generation and domain-specific dictionaries.\nThe dataset captures 10 main types and 47 subtypes of real-world Urdu legal documents like:\n\nJudicial Records\nContracts & Agreements\nProperty Records\nAffidavits\nFinancialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cheemasohail/Urdu-Legal_ner_corpora.","url":"https://huggingface.co/datasets/cheemasohail/Urdu-Legal_ner_corpora","creator_name":"Sohail Ashraf","creator_url":"https://huggingface.co/cheemasohail","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"UnfairTOSLegalBenchClassification","keyword":"monolingual","description":"\n  UnfairTOSLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a clause from a terms-of-service contract, determine the category the clause belongs to. The purpose of this task is classifying clauses in Terms of Service agreements. Clauses have been annotated by into nine categories: ['Arbitration', 'Unilateral change', 'Content removal', 'Jurisdiction', 'Choice of law', 'Limitation of liability', 'Unilateral termination', 'Contract by using', 'Other']. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UnfairTOSLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/UnfairTOSLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"fairseq2-lm-gsm8k","keyword":"monolingual","description":"facebook/fairseq2-lm-gsm8k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/facebook/fairseq2-lm-gsm8k","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"balinese-carving-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Balinese Carving Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains images of Balinese carvings along with their classifications, materials, and color descriptions. It is designed for image classification and retrieval tasks related to Balinese art and cultural heritage.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset supports multi-label image classification for Balinese carving styles and image retrieval based on textual descriptions of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aegishield/balinese-carving-dataset.","url":"https://huggingface.co/datasets/aegishield/balinese-carving-dataset","creator_name":"Bagus Prasetyo","creator_url":"https://huggingface.co/aegishield","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","multi-label-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-single","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-single.","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-single","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClusteringP2P","keyword":"monolingual","description":"\n  GeoreviewClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview clustering based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClusteringP2P\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P.","url":"https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"xwinograd_fr_prompt_coreference","keyword":"monolingual","description":"\n\t\n\t\t\n\t\txwinograd_fr_prompt_coreference\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nxwinograd_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 830 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset xwinograd by Muennighoff where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference.","url":"https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","monolingual","xwinograd","French"],"keywords_longer_than_N":true},
	{"name":"snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Endothelial Cells (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on endothelial cells from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cellâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells.","url":"https://huggingface.co/datasets/longevity-db/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"github-issues-simple","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis dataset is sourced from the issues within the official datasets repository on GitHub. We collected the corresponding issues and their comments via the GitHub API, performed some light data cleaning, and finally, randomly selected 1,000 samples to create this dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rachel521/github-issues-simple.","url":"https://huggingface.co/datasets/rachel521/github-issues-simple","creator_name":"Mikerachel521","creator_url":"https://huggingface.co/rachel521","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"allstar","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Allstar.gg Clips\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 47,896 video clips from the gaming platform allstar.gg. The clips primarily focus on Counter-Strike 2 gameplay moments and include detailed metadata such as player information, game statistics, view counts, and related media URLs.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/allstar.","url":"https://huggingface.co/datasets/nyuuzyou/allstar","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"california-k12-comprehensive","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCalifornia K-12 Comprehensive Educational Standards Dataset\n\t\n\nThe most complete and authoritative California K-12 educational standards dataset available\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nThis dataset contains 3,410 comprehensive educational standards covering all California K-12 frameworks, making it the most complete collection of California educational standards available for AI/ML applications, educational technology development, and curriculum alignment.\n\t\n\t\t\n\t\tKey Statisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/robworks-software/california-k12-comprehensive.","url":"https://huggingface.co/datasets/robworks-software/california-k12-comprehensive","creator_name":"Ryan Robson","creator_url":"https://huggingface.co/robworks-software","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ForNet","keyword":"monolingual","description":"ForNet is a dataset of foreground objects and backgrounds extracted (and infilled) from ImageNet. It's the output of the segmentation phase of the ForAug data augmentation. ForNet recombines these foregrounds and backgrounds on the fly to create new samples for training vision transformers.","url":"https://huggingface.co/datasets/TNauen/ForNet","creator_name":"Tobias Nauen","creator_url":"https://huggingface.co/TNauen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","found","monolingual","extended|imagenet-1k"],"keywords_longer_than_N":true},
	{"name":"distributed-computing-complex","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDistributed Systems Q&A Dataset\n\t\n\nThis dataset is collection of question-and-answer pairs related to distributed systems, compiled from a list of commonly asked questions in a college-level class. \nThis dataset is designed to assist educators, researchers, and developers working on tuning AI models, chatbots, or educational tools in the field of distributed systems.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nQuestions: A variety of questions covering fundamental distributed systems concepts.\nAnswers:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JsZe/distributed-computing-complex.","url":"https://huggingface.co/datasets/JsZe/distributed-computing-complex","creator_name":"Jeffrey Zhou","creator_url":"https://huggingface.co/JsZe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClassification","keyword":"monolingual","description":"\n  GeoreviewClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview classification (5-point scale) based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClassification.","url":"https://huggingface.co/datasets/mteb/GeoreviewClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"CTO","keyword":"monolingual","description":"Dataset for predicting clinical trial outcomes in drug development.  This dataset is part of the work presented in \"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development\".\nWebsite: https://chufangao.github.io/CTOD/\nPaper: https://arxiv.org/abs/2406.10292\nCode: https://github.com/chufangao/ctod\nDescriptions:\n\nhuman_labels contains the manually annotated subset. We follow the same rule-based termination of incomplete status and p-value < 0.05 as in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chufangao/CTO.","url":"https://huggingface.co/datasets/chufangao/CTO","creator_name":"Chufan Gao","creator_url":"https://huggingface.co/chufangao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"my_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTest Sentiment Dataset\n\t\n\nA small sample dataset for text classification tasks, specifically binary sentiment analysis (positive or negative). Useful for testing, demos, or building and validating pipelines with Hugging Face Datasets.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short text samples labeled as either positive or negative. It is intended for testing purposes and includes:\n\n10 training samples\n4 test samples\n\nEach example includes:\n\ntext: A short sentence or reviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wkdnev/my_dataset.","url":"https://huggingface.co/datasets/wkdnev/my_dataset","creator_name":"Neil Rainsforth","creator_url":"https://huggingface.co/wkdnev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-wordpress","keyword":"monolingual","description":"\n  CQADupstackWordpressRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWordpressRetrieval\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-wordpress.","url":"https://huggingface.co/datasets/mteb/cqadupstack-wordpress","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO","keyword":"monolingual","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MSMARCO","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"dataset_for_scicllaimhunt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ§ª SciClaimHunt\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“˜ Dataset Card for SciClaimHunt\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Summary\n\t\n\nSciClaimHunt is a large-scale scientific claim verification dataset comprising ~110,000 instances of:\n\nScientific claims\nSupporting evidence\nFull research paper text\n\nIt enables rigorous experimentation on scientific fact verification, evidence retrieval, and document-level reasoning.\n\n\t\n\t\t\n\t\tâœ… Supported Tasks\n\t\n\n\nScientific Claim Verification\nEvidence Retrieval\nClaim-Evidence Pairâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnshulS/dataset_for_scicllaimhunt.","url":"https://huggingface.co/datasets/AnshulS/dataset_for_scicllaimhunt","creator_name":"Anshul Sharma","creator_url":"https://huggingface.co/AnshulS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-justice-administrative","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de justice administrative, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_customer_service_conversations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"crater_multi_segmentation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tcrater_multi_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Other\n2: Layered\n3: Buried\n4: Secondary\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/crater_multi_segmentation.","url":"https://huggingface.co/datasets/gremlin97/crater_multi_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Assamese"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\nDue to the space constraints, we uploaded the files across multiple repositories as follows:\nTo download Pennsylvania and Maryland, use the current repository (OBH30/IRRISIGHT). \nTo download Arizona, Arkansas, Florida, Georgia, New Jersey, North Carolinaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OBH30/IRRISIGHT.","url":"https://huggingface.co/datasets/OBH30/IRRISIGHT","creator_name":"Oishee Bintey Hoque","creator_url":"https://huggingface.co/OBH30","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nGSM8K traduit en franÃ§ais Ã  l'aide de quickmt/quickmt-en-fr.\nGSM8K dataset translated to french using quickmt/quickmt-en-fr.\n","url":"https://huggingface.co/datasets/cmh/gsm8k_fr","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","French","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"TOFU-og-da","keyword":"monolingual","description":"miry-itu/TOFU-og-da dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/miry-itu/TOFU-og-da","creator_name":"Michal Rynowiecki","creator_url":"https://huggingface.co/miry-itu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"fungi_indexed_mycological_papers_japanese","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tfungi_indexed_mycological_papers_japanese\nå¤§èŒè¼ªã€Œè«–æ–‡3è¡Œã¾ã¨ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœ€çµ‚æ›´æ–°æ—¥ï¼š2025/5/2ï¼ˆR3-12744ã¾ã§ï¼‰  \n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\tæ¦‚è¦ / Overview\n\t\n\nå¤§èŒè¼ªã¯ã€Atsushi Nakajimaï¼ˆä¸­å³¶æ·³å¿—ï¼‰ãŒå€‹äººã§é‹å–¶ã—ã¦ã„ã‚‹Webã‚µã‚¤ãƒˆã§ã™ã€‚ã“ã“ã§ã¯ã€æ•°åƒä»¶ä»¥ä¸Šã®èŒé¡žåˆ†é¡žå­¦è«–æ–‡ã‚’ã€Œè«–æ–‡3è¡Œã¾ã¨ã‚ã€ã¨ã„ã†å½¢ã§è¦ç´„ãŠã‚ˆã³ç´¢å¼•ä»˜ã‘ï¼ˆã‚¤ãƒ³ãƒ‡ã‚­ã‚·ãƒ³ã‚°ï¼‰ã—ãŸæƒ…å ±ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\nDaikinrin is a website personally operated by Atsushi Nakajima. It provides summaries and indexing information for thousands of mycological taxonomy papers in the form of \"Three-lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese.","url":"https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","monolingual","original","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os LusÃ­adas by LuÃ­s Vaz de CamÃµes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Telugu"],"keywords_longer_than_N":true},
	{"name":"ghibli-illustration-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGhibli Illustration Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ghibli Illustration Dataset is a high-quality collection of image pairs curated for:\n\nðŸŽ¨ Style transfer\nðŸ”„ Image-to-image translation\nðŸ¤– Fine-tuning diffusion and generative models\n\nEach data pair contains:\n\no.png â€” original real-world photograph  \ng.png â€” Ghibli-style illustrated version\n\nThis dataset allows models to learn the mapping between real images and the magical aesthetic of Studio Ghibli.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amarsaikhan/ghibli-illustration-dataset.","url":"https://huggingface.co/datasets/amarsaikhan/ghibli-illustration-dataset","creator_name":"Amraa","creator_url":"https://huggingface.co/amarsaikhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-colorization","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SciDocsRR","keyword":"monolingual","description":"\n  SciDocsRR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRanking of related scientific papers based on their title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SciDocsRR\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SciDocsRR.","url":"https://huggingface.co/datasets/mteb/SciDocsRR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","monolingual","mteb/scidocs","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval.V2","keyword":"monolingual","description":"\n  NLPJournalAbsIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V2 dataset (last update 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"code-famille-aide-sociale","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la famille et de l'aide sociale, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of freeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech toolsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cr.","url":"https://huggingface.co/datasets/annnli/TOFU-Cr","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nGitHub Issues with comments\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/huggingface/datasets/issues\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues.","url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","text-generation","fill-mask"],"keywords_longer_than_N":true},
	{"name":"arm4r-data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPre-training Auto-regressive Robotic Models with 4D Representations\n\t\n\nby Dantong Niu*, Yuvan Sharma*, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrellâ€ , and Roei Herzigâ€   \n*Equal contribution, â€ Equal advisingBerkeley AI Research, UC BerkeleyICML 2025Paper â€¢ Code â€¢ Models â€¢ Dataset\nThe structure for the data is as follows:\n.\nâ”œâ”€â”€ .gitattributes\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ epic_clips.json  # contains mapping for episode id --> language instruction (76,014 episodes)\nâ”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuvansharma/arm4r-data.","url":"https://huggingface.co/datasets/yuvansharma/arm4r-data","creator_name":"Yuvan Sharma","creator_url":"https://huggingface.co/yuvansharma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["robotics","grasping","manual","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_question","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a context-generation (with question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"chesspiece-detection-yolo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChess Pieces Detection Dataset (YOLO format)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“¦ Overview\n\t\n\nThis dataset is designed for object detection of chess pieces on a chessboard using YOLOv5/YOLOv10.\n\nClasses: 12 (6 white + 6 black pieces)\nFormat: YOLO (txt annotations)\nSplit: Train/Validation\nImage count: ~2208 images\n\n\n\t\n\t\t\n\t\tðŸ—‚ï¸ Structure\n\t\n\nimages/train/\nimages/val/\nlabels/train/\nlabels/val/\ndataset.yaml\n\n\n\t\n\t\t\n\t\tðŸ·ï¸ Class Names\n\t\n\n0 = white pawn\n1 = white rook\n2 = white knight\n3 = white bishop\n4 = white queenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/acapitani/chesspiece-detection-yolo.","url":"https://huggingface.co/datasets/acapitani/chesspiece-detection-yolo","creator_name":"Andrea Capitani","creator_url":"https://huggingface.co/acapitani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","manual","monolingual","original","extended"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automaticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openslr/librispeech_asr.","url":"https://huggingface.co/datasets/openslr/librispeech_asr","creator_name":"OpenSLR","creator_url":"https://huggingface.co/openslr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"SCDDTrainingLegalBenchClassification","keyword":"monolingual","description":"\n  SCDDTrainingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer provides company employees and management, who have direct responsibility for supply chain management, training on human trafficking and slavery, particularly withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDTrainingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDDTrainingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"check","keyword":"monolingual","description":"shainaraza/check dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shainaraza/check","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Conversations","keyword":"monolingual","description":"Russian-Language Dialogues Dataset","url":"https://huggingface.co/datasets/inkoziev/Conversations","creator_name":"ilya koziev","creator_url":"https://huggingface.co/inkoziev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","machine-generated","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"Diversity5LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity5LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 5).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kaggle_data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","url":"https://huggingface.co/datasets/hongin9812/kaggle_data","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SCDBPTrainingLegalBenchClassification","keyword":"monolingual","description":"\n  SCDBPTrainingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  provides training to employees on human trafficking and slavery? Broad policies such as ongoing dialogue on mitigating risks of human trafficking and slavery or increasing managers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPTrainingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDBPTrainingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Telugu"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_question","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"PDD-Extended-Bench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPDD-Extended-Bench\n\t\n\nLead and corresponding author: Inderjeet Singh\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTFDP evaluation benchmark consisting of minimally contrastive sentence pairs with single-token masks for auditing disparities in autoregressive LLMs.\nTwo topic groups included in this release: Climate Misinformation and Gender Equality, each with masked and original variants constructed for single-token prediction probes.\nEach record exposes ground-truth statements and masked counterpartsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu/PDD-Extended-Bench.","url":"https://huggingface.co/datasets/Fujitsu/PDD-Extended-Bench","creator_name":"Fujitsu Laboratories","creator_url":"https://huggingface.co/Fujitsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"TeluguAndhraJyotiNewsClassification","keyword":"monolingual","description":"\n  TeluguAndhraJyotiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Telugu dataset for 5-class classification of Telugu news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/AnushaMotamarri/Telugu-Newspaper-Article-Dataset\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TeluguAndhraJyotiNewsClassification\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TeluguAndhraJyotiNewsClassification.","url":"https://huggingface.co/datasets/mteb/TeluguAndhraJyotiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/telugu_news_classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Manipuri"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfCustomersLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNoSolicitOfCustomersLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party from contracting or soliciting customers or partners of the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ToxiMol-benchmark","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tToxiMol: A Benchmark for Structure-Level Molecular Detoxification\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nToxiMol is the first comprehensive benchmark for molecular toxicity repair tailored to general-purpose Multimodal Large Language Models (MLLMs). This is the dataset repository for the paper \"Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?\".\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n\t\n\t\t\n\t\tðŸ§¬ Comprehensive Dataset\n\t\n\n\n560 representative toxic molecules spanning diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeepYoke/ToxiMol-benchmark.","url":"https://huggingface.co/datasets/DeepYoke/ToxiMol-benchmark","creator_name":"DeepYoke","creator_url":"https://huggingface.co/DeepYoke","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","multi-class-classification","tabular-single-column-regression","monolingual"],"keywords_longer_than_N":true},
	{"name":"my_dataset_repo","keyword":"monolingual","description":"talmahmud/my_dataset_repo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/talmahmud/my_dataset_repo","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"escher-kitchen-action","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-kitchen-action\n\t\n\nMPII and YouCook2 dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/mair-lab/escher-kitchen-action","creator_name":"MAIR Lab","creator_url":"https://huggingface.co/mair-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V2\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nClarify objective and style\nShow examples dialogue and best-case summary\nInclude Chain-of-Thought Guidance (show individual subtasks)\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quickâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"AutoRAGRetrieval","keyword":"monolingual","description":"\n  AutoRAGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset enables the evaluation of Korean RAG performance across various domainsâ€”finance, public sector, healthcare, legal, and commerceâ€”by providing publicly accessible documents, questions, and answers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Medical, Legal, Social, Financial\n\n\nReference\nhttps://arxiv.org/abs/2410.20878\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AutoRAGRetrieval.","url":"https://huggingface.co/datasets/mteb/AutoRAGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Gujarati"],"keywords_longer_than_N":true},
	{"name":"RAG-Evaluation-Dataset-KO","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Reconstructed RAG Evaluation Dataset (KO)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\në³¸ ë°ì´í„°ì…‹ì€ allganize/RAG-Evaluation-Dataset-KOë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDF íŒŒì¼ì„ í¬í•¨í•˜ë„ë¡ ìž¬êµ¬ì„±í•œ í•œêµ­ì–´ í‰ê°€ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œëŠ” PDF íŒŒì¼ì˜ ê²½ë¡œë§Œ ì œê³µë˜ì–´ ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ëŠ” ë¶ˆíŽ¸í•¨ì´ ìžˆì—ˆê³ , ì¼ë¶€ PDF íŒŒì¼ì˜ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ì œë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ PDF íŒŒì¼ì„ í¬í•¨í•œ ë°ì´í„°ì…‹ì„ ìž¬êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nRAG Evaluation: ë³¸ ë°ì´í„°ëŠ” í•œêµ­ì–´ RAG íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ E2E Evaluationì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Korean (ko).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO.","url":"https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO","creator_name":"DongWook Kim","creator_url":"https://huggingface.co/datalama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","human-annotated","monolingual","extended|allganize/RAG-Evaluation-Dataset-KO","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"human-optic-nerve-fibroblasts-snRNAseq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Fibroblasts (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Data Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on fibroblasts from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cell atlas. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-optic-nerve-fibroblasts-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/human-optic-nerve-fibroblasts-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Oriya"],"keywords_longer_than_N":true},
	{"name":"counterfactual_history_reasoning","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Counterfactual History Reasoning Dataset\n\t\n\nThe Counterfactual History Reasoning Dataset contains 100 examples of counterfactual reasoning applied to historical events. Each example presents a historical event, poses a \"what if\" counterfactual premise, provides a step-by-step reasoning trace exploring the implications across multiple domains, and concludes with an alternative historical outcome. The reasoning traces and conclusions were generated using DeepSeek-R1, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning.","url":"https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning","creator_name":"Alex Strick van Linschoten","creator_url":"https://huggingface.co/strickvl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"histoires_morales","keyword":"monolingual","description":"Together with the Moral Stories dataset, Histoires Morales can be used for:\n\nCommonsense reasoning / social reasoning / moral reasoning The dataset can help evaluate whether pretrained language models can reason about actions that are consistent or inconsistent with social norms, the consequences of actions, and the norms that may motivate those actions. A Mistral model or Mistral-Instruct can be used for this purpose.\n\nText classification This dataset can be used to train models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LabHC/histoires_morales.","url":"https://huggingface.co/datasets/LabHC/histoires_morales","creator_name":"Laboratoire Hubert Curien","creator_url":"https://huggingface.co/LabHC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multiple-choice","text-generation","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"dsir-pile-1m-filtered-no-github-or-dm_mathematics","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMy_Downsampled_Dataset\n\t\n\nThis dataset contains 1,000,000 examples from timaeus/dsir-pile-13m-filtered-no-github-or-dm_mathematics, downsampled for efficient processing.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"path/to/my_downsampled_dataset\")\n\n","url":"https://huggingface.co/datasets/timaeus/dsir-pile-1m-filtered-no-github-or-dm_mathematics","creator_name":"Timaeus","creator_url":"https://huggingface.co/timaeus","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"ECDBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tECDBench: A Benchmark for Evaluating MLLM Chart Understanding\n\t\n\nThis repository hosts ECDBench, a high-quality benchmark dataset for evaluating the chart understanding capabilities of Multimodal Large Language Models (MLLMs), as presented in the paper Effective Training Data Synthesis for Improving MLLM Chart Understanding.\nThe full code for data generation, model fine-tuning, and evaluation can be found on the GitHub repository.\n\n\t\n\t\t\n\t\n\t\n\t\tâœ¨ Abstract\n\t\n\nBeing able to effectivelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChartFoundation/ECDBench.","url":"https://huggingface.co/datasets/ChartFoundation/ECDBench","creator_name":"Chart Foundation Research","creator_url":"https://huggingface.co/ChartFoundation","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","visual-question-answering","expert/gpt-4o-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"pxhere","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for pxhere Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a large collection of high-quality photographs sourced from pxhere.com, a free stock photo website. The dataset includes approximately 1,100,000 images in full resolution covering a wide range of subjects including nature, people, urban environments, objects, animals, and landscapes. All images are provided under the Creative Commons Zero (CC0) license, making them freely available for personal andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pxhere.","url":"https://huggingface.co/datasets/nyuuzyou/pxhere","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"monolingual","description":"\n\n\n    \n\n\n\n\n\n\n\n    1.5K Steam Reviews Binary Labeled for Constructiveness\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\n\nAlso available asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k.","url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"code-urbanisme","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'urbanisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"emotional-dataset-chile","keyword":"monolingual","description":"Este dataset contiene ejemplos en espaÃ±ol chileno etiquetados con valencia o arousal emocional en formato de regresiÃ³n continua (-1.0 a 1.0). Incluye dos configuraciones independientes: 'valencia' y 'arousal'.","url":"https://huggingface.co/datasets/cypher-256/emotional-dataset-chile","creator_name":"cypher 256","creator_url":"https://huggingface.co/cypher-256","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","manual","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"actuary-enough-qa-dataset","keyword":"monolingual","description":"\n  \n\n\n\t\n\t\t\n\t\tðŸ‘‹ Connect with me on LinkedIn!\n\t\n\n  \n  Manuel Caccone - Actuarial Data Scientist & Open Source Educator\n  Let's discuss actuarial science, AI, and open source projects!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŽ¯ Actuary Enough - Actuarial Question Simplification Dataset\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš© Dataset Description\n\t\n\nThe Actuary Enough Dataset contains examples of complex actuarial and insurance questions that have been simplified and rephrased to improve clarity and accessibility. This dataset is designed toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset.","url":"https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-simplification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"MC-III-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr_500_250406","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n500 lignes de GSM8K traduit en franÃ§ais Ã  l'aide de quickmt/quickmt-en-fr. Les questions sont rÃ©duites Ã  moins de 256 tokens et les rÃ©ponses Ã  moins de 768 tokens (tokenizer de Phi-4).\n500 lines of the GSM8K dataset translated to french using quickmt/quickmt-en-fr. Trimmed so questions are smaller than 256 tokens and responses smaller than 768 tokens (Phi-4 tokenizer).\n","url":"https://huggingface.co/datasets/cmh/gsm8k_fr_500_250406","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","French","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"talemaader_pc","keyword":"monolingual","description":"\n  TalemaaderPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Danish Language and Literature Society has developed a dataset for evaluating language models in Danish.\nThe dataset contains a total of 1000 Danish idioms and fixed expressions with transferred meanings based on the Danish Dictionary's collection of fixed expressions with associated definitions.\nFor each of the 1000 idioms and fixed expressions, three false definitions have also been prepared.\nThe dataset can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/talemaader_pc.","url":"https://huggingface.co/datasets/mteb/talemaader_pc","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Danish"],"keywords_longer_than_N":true},
	{"name":"myface","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tZurag Dataset with Prompts\n\t\n\nThis dataset contains a collection of face images with corresponding text descriptions (prompts). It is inspired by the structure of Temka/myface and is designed for applications such as:\n\nFine-tuning diffusion models (e.g., Stable Diffusion, LoRA)\nFace recognition\nText-to-image generation\n\n\n\t\n\t\t\n\t\tðŸ§¾ Dataset Structure\n\t\n\n\nimages/ â€” folder containing all the .jpg image files.\nmetadata.csv â€” a CSV file with the following columns:\nfile_name: name of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Temka/myface.","url":"https://huggingface.co/datasets/Temka/myface","creator_name":"Temka Serge","creator_url":"https://huggingface.co/Temka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-to-image","manually-created","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DalajClassification","keyword":"monolingual","description":"\n  DalajClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for linguistic acceptability. Available as a part of Superlim.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/superlim\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DalajClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DalajClassification.","url":"https://huggingface.co/datasets/mteb/DalajClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","expert-annotated","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"financial_news_sentiment_mixte_with_phrasebank_75","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"financial_news_sentiment_mixte_with_phrasebank_75\"\n\t\n\nThis is a customized version of the phrasebank dataset in which I kept only sentences validated by at least 75% annotators.In addition I added ~2000 articles of Canadian news where sentiment was validated manually.\nThe dataset also include a column topic which contains one of the following value:\n\nacquisition\nother\nquaterly financial release\nappointment to new position\ndividend\ncorporate update\ndrillings resultsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment_mixte_with_phrasebank_75.","url":"https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment_mixte_with_phrasebank_75","creator_name":"JB Polle","creator_url":"https://huggingface.co/Jean-Baptiste","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"sec-material-contracts-qa","keyword":"monolingual","description":"800+ EDGAR contracts with PDF images and key information extracted by the OpenAI GPT-4o model.\nThe key information is defined as follows:\nclass KeyInformation(BaseModel):\n    agreement_date : str = Field(description=\"Agreement signing date of the contract. (date)\")\n    effective_date : str = Field(description=\"Effective date of the contract. (date)\")\n    expiration_date : str = Field(description=\"Service end date or expiration date of the contract. (date)\")\n    party_address : str =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/sec-material-contracts-qa.","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","document-question-answering","visual-question-answering","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Relic-Test","keyword":"monolingual","description":"\n  BIRCO-Relic\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the RELIC dataset from BIRCO. This dataset contains 100 queries which are excerpts from literary analyses with a missing quotation (indicated by [masked sentence(s)]). Each query has a candidate pool of 50 passages. The objective is to retrieve the passage that best completes the literary analysis.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCOâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Relic-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-Relic-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"PoemSentimentClassification","keyword":"monolingual","description":"\n  PoemSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2011.02686\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PoemSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PoemSentimentClassification.","url":"https://huggingface.co/datasets/mteb/PoemSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RLAIF/mbpp.","url":"https://huggingface.co/datasets/RLAIF/mbpp","creator_name":"RLAIF","creator_url":"https://huggingface.co/RLAIF","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas-english-neucodec","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for NeuCodec Emilia-YODAS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe NeuCodec Emilia-YODAS dataset is an English-language dataset containing >30M audio samples (>78k hours), taken from the English-language subset of Emilia-YODAS and compressed with NeuCodec.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport torch\nfrom datasets import load_dataset\nfrom neucodec import NeuCodec\n\n# load dataset and model\ndataset = load_dataset(\"neuphonic/emilia-yodas-english-neucodec\", split=\"train\", streaming=True)\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neuphonic/emilia-yodas-english-neucodec.","url":"https://huggingface.co/datasets/neuphonic/emilia-yodas-english-neucodec","creator_name":"Neuphonic","creator_url":"https://huggingface.co/neuphonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","amphion/Emilia-YODAS","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"HET_Transfer_Orbit_Efficiency","keyword":"monolingual","description":"Data on the impact of space weather on Hall Effect Thrusters (HETs) efficiency, used in spacecraft transfer orbits","url":"https://huggingface.co/datasets/Taylor658/HET_Transfer_Orbit_Efficiency","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsDeEnPC","keyword":"monolingual","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC.","url":"https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Assamese"],"keywords_longer_than_N":true},
	{"name":"ImageNet-Think","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tImageNet-Think 250K\n\t\n\nA 250k-image dataset with JSONL/Parquet metadata providing prompts and answers for multimodal reasoning tasks.\n\n\t\n\t\t\n\t\tLoad\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"krishnateja95/ImageNet-Think\", split=\"train\")\nds[0]\n\n","url":"https://huggingface.co/datasets/krishnateja95/ImageNet-Think","creator_name":"Krishna Teja Chitty-Venkata","creator_url":"https://huggingface.co/krishnateja95","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","synthetic","machine-generated","monolingual","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Climate-Change-NER","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Climate Change NER\n\t\n\nThe Climate Change NER is an English-language dataset containing 534 abstracts of climate-related papers. They have been sourced from the Semantic Scholar Academic Graph \"abstracts\" dataset. The abstracts have been manually annotated by classifying climate-related tokens in a set of 13 categories.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWe introduce a comprehensive dataset for developing and evaluating NLP models tailored towardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/Climate-Change-NER.","url":"https://huggingface.co/datasets/ibm-research/Climate-Change-NER","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoTouche2020.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoTouche2020-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoTouche2020","French"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (14/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeMoussel/LEGI.","url":"https://huggingface.co/datasets/LeMoussel/LEGI","creator_name":"LeMoussel","creator_url":"https://huggingface.co/LeMoussel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Urdu"],"keywords_longer_than_N":true},
	{"name":"legal_summarization","keyword":"monolingual","description":"\n  LegalSummarization\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consistes of 439 pairs of contracts and their summarizations from https://tldrlegal.com and https://tosdr.org/.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lauramanor/legal_summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legal_summarization.","url":"https://huggingface.co/datasets/mteb/legal_summarization","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BLUR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap \n\t\n\nThe BLUR dataset expands on existing unlearning benchmarks by providing harder evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on BLUR, with simple approaches performing better on average than more recent methods.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/forgelab/BLUR.","url":"https://huggingface.co/datasets/forgelab/BLUR","creator_name":"Forge Lab","creator_url":"https://huggingface.co/forgelab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","closed-domain-qa","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"code-defense","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de la dÃ©fense, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"code-travail-maritime","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du travail maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithEmployeesLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLISharingWithEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some of Receiving Party's employees.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYouâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"monolingual","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"airportwebcams","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Airport Webcams\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 2,508 airport webcams extracted from airportwebcams.net. Each entry includes source URLs, embedded YouTube video links where available, and URLs to external webcam feeds.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nsource_url: URL of the airportwebcams.net page (string)\nyoutube_embeds: List of embedded YouTube video URLs, if anyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/airportwebcams.","url":"https://huggingface.co/datasets/nyuuzyou/airportwebcams","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["other","found","monolingual","original","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoLicensingLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLINoLicensingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Agreement shall not grant Receiving Party any right to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Oriya"],"keywords_longer_than_N":true},
	{"name":"RISCBAC","keyword":"monolingual","description":"RISCBAC was created using [RISC](https://github.com/GRAAL-Research/risc), an open-source Python package data \ngenerator. RISC generates look-alike automobile insurance contracts based on the Quebec regulatory insurance \nform in French and English.\n\nIt contains 10,000 English and French insurance contracts generated using the same seed. Thus, contracts share \nthe same deterministic synthetic data (RISCBAC can be used as an aligned dataset). RISC can be used to generate \nmore data for RISCBAC.","url":"https://huggingface.co/datasets/davebulaval/RISCBAC","creator_name":"David","creator_url":"https://huggingface.co/davebulaval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","question-answering","translation","monolingual","aligned"],"keywords_longer_than_N":true},
	{"name":"escher-aurora-kubric","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-aurora-kubric\n\t\n\nAurora-Kubric dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-aurora-kubric","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"entrenamiento-intents-luca","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset de clasificaciÃ³n de intents conversacionales en espaÃ±ol\n\t\n\nEste dataset contiene ejemplos en espaÃ±ol para entrenar un modelo de clasificaciÃ³n de intents. EstÃ¡ diseÃ±ado para sistemas conversacionales que ejecutan acciones basadas en entradas del usuario, como consultas, creaciÃ³n o modificaciÃ³n de entidades, planificaciÃ³n o control de operaciones.\n\n\t\n\t\t\n\t\tFormato\n\t\n\nCada entrada incluye:\n\ntext: mensaje en lenguaje natural.\nintent: clase que representa la intenciÃ³n del usuarioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QV-AI-Training/entrenamiento-intents-luca.","url":"https://huggingface.co/datasets/QV-AI-Training/entrenamiento-intents-luca","creator_name":"QV-AI-Training","creator_url":"https://huggingface.co/QV-AI-Training","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","team","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"turkish-sentiment-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTurkish Sentiment Dataset ðŸ‡¹ðŸ‡·\n\t\n\nThis dataset includes 30 Turkish sentences labeled with 3 sentiment classes: positive, negative, and neutral.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext (string): the sentence\nlabel (class): one of positive, negative, neutral\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Zeyustun/turkish-sentiment-dataset\")\n\n","url":"https://huggingface.co/datasets/Zeyustun/turkish-sentiment-dataset","creator_name":"Zeynep ÃœstÃ¼n","creator_url":"https://huggingface.co/Zeyustun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","manual","monolingual","Turkish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025.","url":"https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025","creator_name":"iclr2026-anonymous","creator_url":"https://huggingface.co/iclr2026-anonymous","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"mb-frost_cls","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-frost_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: frost\n1: non_frost\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 30124 images\ntest: 12249 images\nval: 11415 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 images\nfew_shot_train_10_shot:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-frost_cls.","url":"https://huggingface.co/datasets/Mirali33/mb-frost_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CUADVolumeRestrictionLegalBenchClassification","keyword":"monolingual","description":"\n  CUADVolumeRestrictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a fee increase or consent requirement, etc. if one party's use of the product/services exceeds certain threshold.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adaptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"cdg-continued-fractions-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Continued Fractions QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Continued Fractions QA dataset is a synthetic question-answering corpus focused on continued fractions and their theoretical and applied connections in mathematics and neural network interpretability. Each entry includes a question and an answer, occasionally embedding LaTeX-styled mathematical expressions within <math> tags for clarity.\nTopics covered include:\n\nSimple and generalized continued fractionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahlen/cdg-continued-fractions-qa.","url":"https://huggingface.co/datasets/cahlen/cdg-continued-fractions-qa","creator_name":"Cahlen Humphreys","creator_url":"https://huggingface.co/cahlen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wise-data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe wise-data and wise-data-preferences datasets are synthetically created collections of values-laden conversations, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. These datasets were specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data.","url":"https://huggingface.co/datasets/meaningalignment/wise-data","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","multi-class-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"BC-IV-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-IV-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"omim","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_mendelian_traits_chr11_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/omim.","url":"https://huggingface.co/datasets/Bgoood/omim","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"llmops-database","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tThe ZenML LLMOps Database\n\t\n\n\nTo learn more about ZenML and our open-source MLOps framework, visit\nzenml.io.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LLMOps Database is a comprehensive collection of over 500 real-world\ngenerative AI implementations that showcases how organizations are successfully\ndeploying Large Language Models (LLMs) in production. The case studies have been\ncarefully curated to focus on technical depth and practical problem-solving,\nwith an emphasis on implementation detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database.","url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-classification","text-generation","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"machine-paraphrase-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia","keyword":"monolingual","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","DBPedia","English"],"keywords_longer_than_N":true},
	{"name":"wmdp_chem_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWMDP-Chem Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-chem.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_chem_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_chem_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mb-atmospheric_dust_cls_edr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-atmospheric_dust_cls_edr\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: dusty\n1: not_dusty\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 9817 images\ntest: 5214 images\nval: 4969 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_edr.","url":"https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_edr","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"basic_mathematical-scientific-notation-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMathematical and Scientific Notation Parallel Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in mathematical and scientific contexts. It contains identical mathematical content expressed in four different notation styles, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison: Compare how different tokenizers (BPE, SentencePieceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/basic_mathematical-scientific-notation-parallel.","url":"https://huggingface.co/datasets/Malikeh1375/basic_mathematical-scientific-notation-parallel","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval","keyword":"monolingual","description":"\n  GermanQuAD-Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContext Retrieval for German Question Answering\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction, Web\n\n\nReference\nhttps://huggingface.co/datasets/deepset/germanquad\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GermanQuAD-Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval.","url":"https://huggingface.co/datasets/mteb/germanquad-retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"TOFUCr1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCr1.","url":"https://huggingface.co/datasets/kimperyang/TOFUCr1","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"code-impots","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode gÃ©nÃ©ral des impÃ´ts, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_context","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"tofu_ext1","keyword":"monolingual","description":"talmahmud/tofu_ext1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/talmahmud/tofu_ext1","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqsRetrieval","keyword":"monolingual","description":"\n  JaGovFaqsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJaGovFaqs is a dataset consisting of FAQs manully extracted from the website of Japanese bureaus. The dataset consists of 22k FAQs, where the queries (questions) and corpus (answers) have been shuffled, and the goal is to match the answer with the question.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval.","url":"https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"grouse","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GroUSE\n\t\n\nGroUSE (Grounded QA Unitary Scoring of Evaluators) is a dataset designed to assess the performance of Grounded QA evaluators. Its purpose is to evaluate whether an LLM, when used as a grounded QA evaluator, delivers the expected scores across six metrics when presented with both good and imperfect answers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEach sample is of the following form :\n{\n    \"references\": [\n        \"[Content of the 1stâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/illuin/grouse.","url":"https://huggingface.co/datasets/illuin/grouse","creator_name":"Illuin Technology","creator_url":"https://huggingface.co/illuin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"big-patent","keyword":"monolingual","description":"\n  BigPatentClustering.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of documents from the Big Patent dataset. Test set only includes documentsbelonging to a single category, with a total of 9 categories.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/NortheasternUniversity/big_patent\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/big-patent.","url":"https://huggingface.co/datasets/mteb/big-patent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","jinaai/big-patent-clustering","English"],"keywords_longer_than_N":true},
	{"name":"escher-aurora-ag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-aurora-ag\n\t\n\nAurora-AG dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-aurora-ag","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Maithili"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 21525\nFiltered size: 21408\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_answer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columnsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"Twin-2K-500","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwin-2K-500 Dataset\n\t\n\nThis dataset Twin-2K-500 contains comprehensive persona information from a representative sample of 2,058 US participants, providing rich demographic and psychological data. The dataset is specifically designed for building digital twins for LLM simulations.\n\nMore information on how to use this dataset can be found in our Documentation and GitHub repository.\nDetails on how the dataset was generated are available in our Paper.\n\n\n\t\n\t\n\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLM-Digital-Twin/Twin-2K-500.","url":"https://huggingface.co/datasets/LLM-Digital-Twin/Twin-2K-500","creator_name":"Digital-Twin@Columbia-Business-School","creator_url":"https://huggingface.co/LLM-Digital-Twin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","multi-class-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna","keyword":"monolingual","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","English"],"keywords_longer_than_N":true},
	{"name":"ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that Confidential Information may include verbally conveyed information.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KemSU","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸŽ“ Kemerovo State University Instructional QA Dataset (NodeLinker/KemSU)\n\t\n\n\n  \n     \n  \n\n\n  \n    \n  \n  \n    \n  \n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“ Dataset Overview & Splits\n\t\n\nThis dataset provides instructional question-answer (Q&A) pairs meticulously crafted for Kemerovo State University (ÐšÐµÐ¼Ð“Ð£, KemSU), Russia. Its primary purpose is to facilitate the fine-tuning of Large Language Models (LLMs), enabling them to function as knowledgeable and accurate assistants on a wide array of topics concerningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NodeLinker/KemSU.","url":"https://huggingface.co/datasets/NodeLinker/KemSU","creator_name":"Ilya Pereverzin","creator_url":"https://huggingface.co/NodeLinker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"neet-biology-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNEET Biology Questions Dataset\n\t\n\nA comprehensive collection of NEET (National Eligibility cum Entrance Test) Biology questions designed to help students prepare for medical entrance examinations.\n\n\t\n\t\t\n\t\tAbout This Dataset\n\t\n\nThis dataset contains 793 carefully crafted multiple-choice questions covering essential Biology topics that appear in NEET exams. Each question follows the standard NEET format with four answer choices and one correct answer.\n\n\t\n\t\t\n\t\tWhat's Inside\n\t\n\n\nQuestions:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sweatSmile/neet-biology-qa.","url":"https://huggingface.co/datasets/sweatSmile/neet-biology-qa","creator_name":"amitk17","creator_url":"https://huggingface.co/sweatSmile","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"CIFAR10","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ–¼ï¸ CIFAR10 (Extracted from PyTorch Vision)\n\t\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n\n\t\n\t\t\n\t\tâ„¹ï¸ Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Dataset Description\n\t\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The classes are completely mutually exclusive. There is noâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/CIFAR10.","url":"https://huggingface.co/datasets/p2pfl/CIFAR10","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Maithili"],"keywords_longer_than_N":true},
	{"name":"AILA_casedocs","keyword":"monolingual","description":"\n  AILACasedocs\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to retrieve the case document that most closely matches or is most relevant to the scenario described in the provided query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\nReference\nhttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILACasedocs\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_casedocs.","url":"https://huggingface.co/datasets/mteb/AILA_casedocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-V-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-V-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"monolingual","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"agentic-rag-redteam-bench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAgentic RAG Red Teaming Dataset v1.0.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTest-only corpus of successful adversarial prompts and scenarios targeting agentic RAG systems (multimodal where applicable).\nOne file per attack type; no consolidated master file is provided.\nExisting, per-type schemas are vendorized locally and left unmodified relative to the record structures used in this work.\nThis dataset was not used to train any model. It is intended strictly for evaluation, diagnostics, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu/agentic-rag-redteam-bench.","url":"https://huggingface.co/datasets/Fujitsu/agentic-rag-redteam-bench","creator_name":"Fujitsu Laboratories","creator_url":"https://huggingface.co/Fujitsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-generation","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hepha_bucket_to_bin","keyword":"monolingual","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSimulated robot control episodes for learning from pixels and interaction.\n\nHomepage: https://github.com/huggingface/lerobot\nPaper: [More Information Needed]\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nEpisodes contain RGB camera data and robot state.\nData is stored in Parquet files.\nVideo files are MP4 compressed per camera.\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nBibTeX:\n@misc{lerobot2024,\n  author = {HuggingFace Robotics Team},\n  title =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tmeynier/hepha_bucket_to_bin.","url":"https://huggingface.co/datasets/tmeynier/hepha_bucket_to_bin","creator_name":"Tristan","creator_url":"https://huggingface.co/tmeynier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["no-annotation","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"monolingual","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"Cybersec-Mutli-domain","keyword":"monolingual","description":"Creator: Zain NadeemRole: Python Django Developer | Software Engineer | Prompt Engineer | Ethical HackerLicense: CC BY 4.0Records: ~220,000Format: JSONLLanguage: English\n\n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nThe CyberSec Multi-Domain Dataset is a structured collection of synthetic and open-source cybersecurity data across five important domains. It is designed for building, testing, and benchmarking machine learning models in cybersecurity, threat intelligence, and automation systems.\nThis dataset helpsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain.","url":"https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain","creator_name":"Zain Nadeem","creator_url":"https://huggingface.co/ZainNadeem7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","text-retrieval","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedQADiagRetrieval","keyword":"monolingual","description":"\n  R2MEDMedQADiagRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedQA-Diag retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedQA-Diag\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedQADiagRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedQA-Diag"],"keywords_longer_than_N":true},
	{"name":"CUADPriceRestrictionsLegalBenchClassification","keyword":"monolingual","description":"\n  CUADPriceRestrictionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause places a restriction on the ability of a party to raise or reduce prices of technology, goods, or services provided.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ‰ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tðŸš€ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that Africanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"vep_clinvar_chr1_split","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_clinvar_chr8_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_clinvar_chr8_split\n   cdâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/vep_clinvar_chr1_split.","url":"https://huggingface.co/datasets/Bgoood/vep_clinvar_chr1_split","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"imdb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"imdb\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 84.13 MB\nSize of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/imdb.","url":"https://huggingface.co/datasets/pt-sk/imdb","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","sentiment-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"commonsenseqa-bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the Bangla translated version of the CommonsenseQA dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST). This method combines both Google Machine Translation and LLM-based rewriting of the translation to enhance the expressiveness and semantic accuracy of the translated content.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData instances\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDefaults\n\t\n\nAn example of a 'train' looks as follows:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/commonsenseqa-bn.","url":"https://huggingface.co/datasets/hishab/commonsenseqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_qa\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 3,320,898 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and targetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa.","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"AfriHist-CoT","keyword":"monolingual","description":"\n\n\t\n\t\t\n\t\tAfriHist-CoT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nAfriHist-CoT is a dataset of question-answer pairs derived from African history books, created using a Chain-of-Thought (CoT) reasoning approach with the Gemini language model via OpenRouter. The dataset supports training and evaluating question-answering models, with a focus on African history and CoT reasoning. It is available in English and French, catering to both monolingual and multilingual applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/AfriHist-CoT.","url":"https://huggingface.co/datasets/Svngoku/AfriHist-CoT","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","ai-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"BLURB","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BLURB\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBLURB is a collection of resources for biomedical natural language processing. In general domains, such as newswire and the Web, comprehensive benchmarks and leaderboards such as GLUE have greatly accelerated progress in open-domain NLP. In biomedicine, however, such resources are ostensibly scarce. In the past, there have been a plethora of shared tasks in biomedical NLP, such as BioCreative, BioNLP Shared Tasks, SemEval, and BioASQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMBO/BLURB.","url":"https://huggingface.co/datasets/EMBO/BLURB","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","token-classification","sentence-similarity","text-classification","closed-domain-qa"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"java-8m-methods-v1","keyword":"monolingual","description":"anjandash/java-8m-methods-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v1","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","mit","1M - 10M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"audiocaps-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\taudiocaps-ru\n\t\n\nTranslated version of d0rj/audiocaps into Russian.\n","url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","translated","monolingual","d0rj/audiocaps","Russian"],"keywords_longer_than_N":true},
	{"name":"synQA","keyword":"monolingual","description":"SynQA is a Reading Comprehension dataset created in the work \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\" (https://aclanthology.org/2021.emnlp-main.696/).\nIt consists of 314,811 synthetically generated questions on the passages in the SQuAD v1.1 (https://arxiv.org/abs/1606.05250) training set.\n\nIn this work, we use a synthetic adversarial data generation to make QA models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA (https://adversarialqa.github.io/) dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation to show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8% of the time on average, compared to 17.6% for a model trained without synthetic data.\n\nFor full details on how the dataset was created, kindly refer to the paper.","url":"https://huggingface.co/datasets/mbartolo/synQA","creator_name":"Max Bartolo","creator_url":"https://huggingface.co/mbartolo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","generated","found"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"monolingual","description":"Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008).","url":"https://huggingface.co/datasets/varox34/demo","creator_name":"Varun Shah","creator_url":"https://huggingface.co/varox34","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Gameplay_Images","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGameplay Images\n\t\n\nA dataset from kaggle.\nThis is a dataset of 10 very famous video games in the world.\nThese include\n\nAmong Us\nApex Legends\nFortnite\nForza Horizon\nFree Fire\nGenshin Impact\nGod of War\nMinecraft\nRoblox\nTerraria\n\nThere are 1000 images per class and all are sized 640 x 360. They are in the .png format.\nThis Dataset was made by saving frames every few seconds from famous gameplay videos on Youtube.\nâ€» This dataset was uploaded in January 2022. Game content updated after thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/Gameplay_Images.","url":"https://huggingface.co/datasets/Bingsu/Gameplay_Images","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","monolingual","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"zeroth-korean","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\n\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Koreanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean.","url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","monolingual","extended|kresnik/zeroth_korean","Korean"],"keywords_longer_than_N":true},
	{"name":"wikitablequestions-wtq","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for WikiTableQuestions-wtq\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiTableQuestions-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nquestion-answering, table-question-answering\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq.","url":"https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq","creator_name":"Dan Jarvis","creator_url":"https://huggingface.co/danwakeem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","wikitablequestions"],"keywords_longer_than_N":true},
	{"name":"cerpen-corpus","keyword":"monolingual","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","url":"https://huggingface.co/datasets/jakartaresearch/cerpen-corpus","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ZINC-canonicalized","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdataset description\n\t\n\nWe downloaded ZINC dataset from here and canonicalized it.\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\nfrom rdkit import Chem\ndef canonicalize(mol):\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\n    return mol \n\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\n","url":"https://huggingface.co/datasets/sagawa/ZINC-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"proof-pile","keyword":"monolingual","description":"A dataset of high quality mathematical text.","url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"poem_sentiment","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Gutenberg Poem Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\nThis dataset can be used for tasks such as sentiment classification or style transfer for poems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExample of one instance in the dataset.\n{'id': 0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/poem_sentiment.","url":"https://huggingface.co/datasets/google-research-datasets/poem_sentiment","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"ptparl","keyword":"monolingual","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament.","url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"LuÃ­s Tavares","creator_url":"https://huggingface.co/luist18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"msr_zhen_translation_parity","keyword":"monolingual","description":"Translator Human Parity Data\n\nHuman evaluation results and translation output for the Translator Human Parity Data release,\nas described in https://blogs.microsoft.com/ai/machine-translation-news-test-set-human-parity/.\nThe Translator Human Parity Data release contains all human evaluation results and translations\nrelated to our paper \"Achieving Human Parity on Automatic Chinese to English News Translation\",\npublished on March 14, 2018.","url":"https://huggingface.co/datasets/microsoft/msr_zhen_translation_parity","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"squadshifts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"squadshifts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSquadShifts consists of four new test sets for the Stanford Question Answering Dataset (SQuAD) from four different domains: Wikipedia articles, New York Times articles, Reddit comments, and Amazon product reviews. Each dataset was generated using the same data generating pipeline, Amazon Mechanical Turk interface, and data cleaning code as the original SQuAD v1.1 dataset. The \"new-wikipedia\" dataset measures overfitting onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ludwigschmidt/squadshifts.","url":"https://huggingface.co/datasets/ludwigschmidt/squadshifts","creator_name":"Ludwig Schmidt","creator_url":"https://huggingface.co/ludwigschmidt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"reddit-nonewnormal-complete","keyword":"monolingual","description":"This corpus contains the complete data for the activity on subreddit /r/NoNewNormal for the entire duration of its existence.","url":"https://huggingface.co/datasets/SocialGrep/reddit-nonewnormal-complete","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"polsum","keyword":"monolingual","description":"Polish Summaries Corpus: the corpus of Polish news summaries.","url":"https://huggingface.co/datasets/maciej-ogrodniczuk/polsum","creator_name":"Maciej Ogrodniczuk","creator_url":"https://huggingface.co/maciej-ogrodniczuk","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"monolingual","description":"ThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath,\nThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs\nwritten by journalists.","url":"https://huggingface.co/datasets/nakhun/thaisum","creator_name":"Nakhun Chumpolsathien","creator_url":"https://huggingface.co/nakhun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"RoSTSC","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tRO-STS-Cupidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nRoSTSC is a Romanian Semantic Textual Similarity (STS) dataset designed for evaluating and training sentence embedding models. It contains pairs of Romanian sentences along with similarity scores that indicate the degree of semantic equivalence between them.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nsentence1: The first sentence in the pair.\nsentence2: The second sentence in the pair.\nscore: A numerical value representing the semantic similarity between theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BlackKakapo/RoSTSC.","url":"https://huggingface.co/datasets/BlackKakapo/RoSTSC","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","monolingual","Romanian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"meddocan","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"meddocan\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA personal upload of the SPACC_MEDDOCAN corpus. The tokenization is made with the help of a custom spaCy pipeline.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nName Entity Recognition\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all splits.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\n\t\n\t\t\nname\ntrain\nvalidation\ntestâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GuiGel/meddocan.","url":"https://huggingface.co/datasets/GuiGel/meddocan","creator_name":"Guillaume Gelabert","creator_url":"https://huggingface.co/GuiGel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SciQA","keyword":"monolingual","description":"    SciQA contains 2,565 SPARQL query - question pairs along with answers fetched from the open research knowledge graph (ORKG)     via a Virtuoso SPARQL endpoint, it is a collection of both handcrafted and autogenerated questions and queries.     The dataset is split into 70% training, 10% validation and 20% test examples. The dataset is available as JSON files.","url":"https://huggingface.co/datasets/orkg/SciQA","creator_name":"The Open Research Knowledge Graph","creator_url":"https://huggingface.co/orkg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","auto-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"narrativeqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Narrative QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNarrativeQA is an English-lanaguage dataset of stories and corresponding questions designed to test reading comprehension, especially on long documents.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is used to test reading comprehension. There are 2 tasks proposed in the paper: \"summaries only\" and \"stories only\", depending on whether the human-generated summary or the full story text is used to answer the question.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/narrativeqa.","url":"https://huggingface.co/datasets/deepmind/narrativeqa","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["abstractive-qa","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wiki_split","keyword":"monolingual","description":"One million English sentences, each split into two sentences that together preserve the original meaning, extracted from Wikipedia\nGoogle's WikiSplit dataset was constructed automatically from the publicly available Wikipedia revision history. Although\nthe dataset contains some inherent noise, it can serve as valuable training data for models that split or merge sentences.","url":"https://huggingface.co/datasets/google-research-datasets/wiki_split","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["machine-generated","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"glucose","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUCOSE: GeneraLized and COntextualized Story Explanations, is a novel conceptual framework and dataset for commonsense reasoning. Given a short story and a sentence X in the story, GLUCOSE captures ten dimensions of causal explanation related to X. These dimensions, inspired by human cognitive psychology, cover often-implicit causes and effects of X, including events, location, possession, and other attributes.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/glucose.","url":"https://huggingface.co/datasets/community-datasets/glucose","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-jokes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-jokes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts from /r/jokes.\nPosts are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.\n'subreddit.id': the base-36 Reddit IDâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes.","url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"blimp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"blimp\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBLiMP is a challenge set for evaluating what language models (LMs) know about\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\nmorphology, or semantics. The data is automatically generated according to\nexpert-crafted grammars.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/blimp.","url":"https://huggingface.co/datasets/nyu-mll/blimp","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"selqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SelQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSelQA: A New Benchmark for Selection-Based Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion Answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example from the answer selection set:\n{\n        \"section\": \"Museums\",\n        \"question\": \"Where are Rockefeller Museum and LA Mayer Institute for Islamic Art?\",\n        \"article\": \"Israel\",\n        \"is_paraphrase\": trueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/selqa.","url":"https://huggingface.co/datasets/community-datasets/selqa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"HatefulMemesT2IRetrieval","keyword":"monolingual","description":"\n  HatefulMemesT2IRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve captions based on memes to assess OCR abilities.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nEncyclopaedic\n\n\nReference\nhttps://arxiv.org/pdf/2005.04790\n\n\n\t\n\nSource datasets:\n\nAhren09/MMSoc_HatefulMemes\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"HatefulMemesT2IRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HatefulMemesT2IRetrieval.","url":"https://huggingface.co/datasets/mteb/HatefulMemesT2IRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"med-safety-bench-reproduced","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMed Safety Bench Dataset\n\t\n\nThis dataset is a collection of harmful medical requests and safe responses, originally sourced from the AI4LIFE-GROUP/med-safety-bench GitHub repository.\nThe dataset is intended for research purposes related to the safety of medical AI models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nThe dataset contains the following columns:\n\nharmful_medical_request: The harmful medical request.\nsafe_response: The safe response to the request.\nsource: Indicates whether the dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/israel-adewuyi/med-safety-bench-reproduced.","url":"https://huggingface.co/datasets/israel-adewuyi/med-safety-bench-reproduced","creator_name":"Israel Adewuyi","creator_url":"https://huggingface.co/israel-adewuyi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["human","human","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"VidoreShiftProjectRetrieval","keyword":"monolingual","description":"\n  VidoreShiftProjectRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/shiftproject_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreShiftProjectRetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreShiftProjectRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreShiftProjectRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"xcopa_mt","keyword":"monolingual","description":"  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages. All the details about the\ncreation of XCOPA and the implementation of the baselines are available in the paper.\\n","url":"https://huggingface.co/datasets/juletxara/xcopa_mt","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"althingi_asr","keyword":"monolingual","description":"Althingi Parliamentary Speech consists of approximately 542 hours of recorded speech from Althingi, the Icelandic Parliament. Speeches date from 2005-2016.","url":"https://huggingface.co/datasets/language-and-voice-lab/althingi_asr","creator_name":"Language and Voice Laboratory (ReykjavÃ­k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"lsoie","keyword":"monolingual","description":"The Large Scale Open Information Extraction Dataset (LSOIE), is a dataset 20 \ntimes larger than the next largest human-annotated Open Information Extraction\n(OIE) dataset. LSOIE is a built upon the QA-SRL 2.0 dataset.","url":"https://huggingface.co/datasets/wardenga/lsoie","creator_name":"Robert Wardenga","creator_url":"https://huggingface.co/wardenga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","machine-generated","found","monolingual","extended|qa_srl"],"keywords_longer_than_N":true},
	{"name":"roman_urdu_hate_speech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for roman_urdu_hate_speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Roman Urdu Hate-Speech and Offensive Language Detection (RUHSOLD) dataset is a Roman Urdu dataset of tweets annotated by experts in the relevant language. The authors develop the gold-standard for two sub-tasks. First sub-task is based on binary labels of Hate-Offensive content and Normal content (i.e., inoffensive language). These labels are self-explanatory. The authors refer to this sub-task as coarse-grainedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech.","url":"https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands","keyword":"monolingual","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","url":"https://huggingface.co/datasets/google/speech_commands","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki_movies","keyword":"monolingual","description":"The WikiMovies dataset consists of roughly 100k (templated) questions over 75k entities based on questions with answers in the open movie database (OMDb).","url":"https://huggingface.co/datasets/facebook/wiki_movies","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki_summary","keyword":"monolingual","description":"\\\r\nThe dataset extracted from Persian Wikipedia into the form of articles and highlights and cleaned the dataset into pairs of articles and highlights and reduced the articles' length (only version 1.0.0) and highlights' length to a maximum of 512 and 128, respectively, suitable for parsBERT.","url":"https://huggingface.co/datasets/m3hrdadfi/wiki_summary","creator_name":"Mehrdad Farahani","creator_url":"https://huggingface.co/m3hrdadfi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","question-answering","summarization","abstractive-qa","explanation-generation"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\talpaca-cleaned-ru\n\t\n\nTranslated version of yahma/alpaca-cleaned into Russian.\n","url":"https://huggingface.co/datasets/d0rj/alpaca-cleaned-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translated","monolingual","yahma/alpaca-cleaned","Russian"],"keywords_longer_than_N":true},
	{"name":"newspop","keyword":"monolingual","description":"This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.\nThe collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine.\nThis data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation.","url":"https://huggingface.co/datasets/liaad/newspop","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-scoring","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"sd-nlp","keyword":"monolingual","description":"    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.","url":"https://huggingface.co/datasets/EMBO/sd-nlp","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","named-entity-recognition","parsing","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mnist-outlier","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"mnist-outlier\"\n\t\n\nðŸ“š This dataset is an enriched version of the MNIST Dataset.\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\n\n\t\n\t\t\n\t\tExplore the Dataset\n\t\n\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/mnist-outlier.\n\nOr you can explorer it locally:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/renumics/mnist-outlier.","url":"https://huggingface.co/datasets/renumics/mnist-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"evidence_inference","keyword":"monolingual","description":"The dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple\ntreatments. Each of these articles will have multiple questions, or 'prompts' associated with them.\nThese prompts will ask about the relationship between an intervention and comparator with respect to an outcome,\nas reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared\nto placebo on the duration of headaches. For the sake of this task, we assume that a particular article\nwill report that the intervention of interest either significantly increased, significantly decreased\nor had significant effect on the outcome, relative to the comparator.","url":"https://huggingface.co/datasets/bigbio/evidence_inference","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Tabular"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"monolingual","description":"This Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton.\nThe corpus was recorded in south Levantine Arabic\n(Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/halabi2016/arabic_speech_corpus","creator_name":"halabi2016","creator_url":"https://huggingface.co/halabi2016","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"newsqa","keyword":"monolingual","description":"NewsQA is a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text from the corresponding articles.","url":"https://huggingface.co/datasets/Maluuba/newsqa","creator_name":"Maluuba","creator_url":"https://huggingface.co/Maluuba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"sofc_materials_articles","keyword":"monolingual","description":"The SOFC-Exp corpus consists of 45 open-access scholarly articles annotated by domain experts.\nA corpus and an inter-annotator agreement study demonstrate the complexity of the suggested\nnamed entity recognition and slot filling tasks as well as high annotation quality is presented\nin the accompanying paper.","url":"https://huggingface.co/datasets/boschresearch/sofc_materials_articles","creator_name":"boschresearch","creator_url":"https://huggingface.co/boschresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","named-entity-recognition"],"keywords_longer_than_N":true},
	{"name":"quoteli3","keyword":"monolingual","description":"This dataset is a representation of Muzny et al.'s QuoteLi3 dataset as a Huggingface dataset. It can be best used for \nquote attribution.","url":"https://huggingface.co/datasets/Felix-ML/quoteli3","creator_name":"Felix","creator_url":"https://huggingface.co/Felix-ML","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"common_gen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"common_gen\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCommonGen is a constrained text generation task, associated with a benchmark dataset,\nto explicitly test machines for the ability of generative commonsense reasoning. Given\na set of common concepts; the task is to generate a coherent sentence describing an\neveryday scenario using these concepts.\nCommonGen is challenging because it inherently requires 1) relational reasoning using\nbackground commonsense knowledge, and 2)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/common_gen.","url":"https://huggingface.co/datasets/allenai/common_gen","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kor_sarcasm","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Korean Sarcasm Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: ì—­ì„¤, ì•„ë¬´ë§, ìš´ìˆ˜ì¢‹ì€ë‚ , ç¬‘, ë­ëž˜ ì•„ë‹™ë‹ˆë‹¤, ê·¸ëŸ´ë¦¬ì—†ë‹¤, ì–´ê·¸ë¡œ, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of the userâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm.","url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"red_caps","keyword":"monolingual","description":"RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\nImages and captions from Reddit depict and describe a wide variety of objects and scenes.\nThe data is collected from a manually curated set of subreddits (350 total),\nwhich give coarse image labels and allow steering of the dataset composition\nwithout labeling individual instances.","url":"https://huggingface.co/datasets/kdexd/red_caps","creator_name":"Karan Desai","creator_url":"https://huggingface.co/kdexd","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-to-text","image-captioning","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cosmos_qa","keyword":"monolingual","description":"Cosmos QA is a large-scale dataset of 35.6K problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. It focuses on reading between the lines over a diverse collection of people's everyday narratives, asking questions concerning on the likely causes or effects of events that require reasoning beyond the exact text spans in the context","url":"https://huggingface.co/datasets/allenai/cosmos_qa","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"piaf","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Piaf\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPiaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 1.31 MB\nSize of the generated dataset: 3.18 MB\nTotal amount of disk used: 4.49 MB\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/piaf.","url":"https://huggingface.co/datasets/AgentPublic/piaf","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qg_frquad_dummy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"lmqg/qg_frquad\"\n\t\n\nIMPORTANT: This is a dummy dataset for lmqg/qg_frquad. The original FRQuAD requires to fill a form (https://fquad.illuin.tech/) to get the data, and our lmqg/qg_frquad follows FQuAD's license. If you need lmqg/qg_frquad, please first request the access to FQuAD on their website https://fquad.illuin.tech/ . Once you obtain the access, we will add you to our lmqg group so that you can access https://huggingface.co/datasets/lmqg/qg_frquad.\nLeave aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lmqg/qg_frquad_dummy.","url":"https://huggingface.co/datasets/lmqg/qg_frquad_dummy","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","fquad","French","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"readability-es-hackathon-pln-public","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [readability-es-sentences]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompilation of short Spanish articles for readability assessment.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources: \n\nCoh-Metrix-Esp corpus (Quispesaravia, et al., 2016): collection of 100 parallel texts with simple and complex variants in Spanish. These textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public.","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public","creator_name":"I Hackathon Somos NLP: PLN en EspaÃ±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"glue","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/severo/glue","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"common-voice","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice.","url":"https://huggingface.co/datasets/DTU54DL/common-voice","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"monolingual","description":"The CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents.","url":"https://huggingface.co/datasets/CSTR-Edinburgh/vctk","creator_name":"Centre for Speech Technology Research - University of Edinburgh","creator_url":"https://huggingface.co/CSTR-Edinburgh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"thainer","keyword":"monolingual","description":"ThaiNER (v1.3) is a 6,456-sentence named entity recognition dataset created from expanding the 2,258-sentence\n[unnamed dataset](http://pioneer.chula.ac.th/~awirote/Data-Nutcha.zip) by\n[Tirasaroj and Aroonmanakun (2012)](http://pioneer.chula.ac.th/~awirote/publications/).\nIt is used to train NER taggers in [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp).\nThe NER tags are annotated by [Tirasaroj and Aroonmanakun (2012)]((http://pioneer.chula.ac.th/~awirote/publications/))\nfor 2,258 sentences and the rest by [@wannaphong](https://github.com/wannaphong/).\nThe POS tags are done by [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp)'s `perceptron` engine trained on `orchid_ud`.\n[@wannaphong](https://github.com/wannaphong/) is now the only maintainer of this dataset.","url":"https://huggingface.co/datasets/wannaphong/thainer","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","part-of-speech","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"hatecheck","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHateCheck is a suite of functional test for hate speech detection models. \nThe dataset contains 3,728 validated test cases in 29 functional tests.\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\nThis allows for targeted diagnostic insights into model performance.\nIn our ACL paper, we found critical weaknesses in all commercial and academic hateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck.","url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wnut_17","keyword":"monolingual","description":"WNUT 17: Emerging and Rare entity recognition\n\nThis shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\nNamed entities form the basis of many modern approaches to other tasks (like event clustering and summarisation),\nbut recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms.\nTake for example the tweet â€œso.. kktny in 30 mins?â€ - even human experts find entity kktny hard to detect and resolve.\nThis task will evaluate the ability to detect and classify novel, emerging, singleton named entities in noisy text.\n\nThe goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities.","url":"https://huggingface.co/datasets/leondz/wnut_17","creator_name":"Leon Derczynski","creator_url":"https://huggingface.co/leondz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"norec_agg","keyword":"monolingual","description":"Aggregated NoRec_fine: A Fine-grained Sentiment Dataset for Norwegian\nThis dataset was created by the Nordic Language Processing Laboratory by\naggregating the fine-grained annotations in NoReC_fine and removing sentences\nwith conflicting or no sentiment.","url":"https://huggingface.co/datasets/NbAiLab/norec_agg","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CONDAQA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nData from the EMNLP 2022 paper by Ravichander et al.: \"CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\". \nIf you use this dataset, we would appreciate you citing our work:\n@inproceedings{ravichander-et-al-2022-condaqa,\n  title={CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lasha-nlp/CONDAQA.","url":"https://huggingface.co/datasets/lasha-nlp/CONDAQA","creator_name":"Abhilasha Ravichander","creator_url":"https://huggingface.co/lasha-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"MSCOCO","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MSCOCO\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nCOCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n\nObject segmentation\nRecognition in context\nSuperpixel stuff segmentation\n330K images (>200K labeled)\n1.5 million object instances\n80 object categories\n91 stuff categories\n5 captions per image\n250,000 people with keypoints\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shunk031/MSCOCO.","url":"https://huggingface.co/datasets/shunk031/MSCOCO","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","object-detection","other","instance-segmentation","semantic-segmentation"],"keywords_longer_than_N":true},
	{"name":"NOAA-Buoy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNOAA Buoy meterological data\n\t\n\nNOAA Buoy Data was downloaded, processed, and cleaned for tasks pertaining to tabular data. The data consists of meteorological measurements. There are two datasets\n\nFrom 1980 through 2022 (denoted with \"years\" in file names)\nFrom Jan 2023 through end of Sept 2023 (denoted with \"2023\" in file names)\n\nThe original intended use is for anomaly detection in tabular data. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains weatherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qdrant/NOAA-Buoy.","url":"https://huggingface.co/datasets/Qdrant/NOAA-Buoy","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","tabular-classification","time-series-forecasting","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"duorc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for duorc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DuoRC dataset is an English language dataset of questions and answers gathered from crowdsourced AMT workers on Wikipedia and IMDb movie plots. The workers were given freedom to pick answer from the plots or synthesize their own answers. It contains two sub-datasets - SelfRC and ParaphraseRC. SelfRC dataset is built on Wikipedia movie plots solely. ParaphraseRC has questions written from Wikipedia movie plots and the answers areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/duorc.","url":"https://huggingface.co/datasets/ibm-research/duorc","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","abstractive-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"narrativeqa_manual","keyword":"monolingual","description":"The Narrative QA Manual dataset is a reading comprehension dataset, in which the reader must answer questions about stories by reading entire books or movie scripts. The QA tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience.\\THIS DATASET REQUIRES A MANUALLY DOWNLOADED FILE! Because of a script in the original repository which downloads the stories from original URLs everytime, The links are sometimes broken or invalid.  Therefore, you need to manually download the stories for this dataset using the script provided by the authors (https://github.com/deepmind/narrativeqa/blob/master/download_stories.sh). Running the shell script creates a folder named \"tmp\" in the root directory and downloads the stories there. This folder containing the storiescan be used to load the dataset via `datasets.load_dataset(\"narrativeqa_manual\", data_dir=\"<path/to/folder>\")`.","url":"https://huggingface.co/datasets/deepmind/narrativeqa_manual","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["abstractive-qa","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"docprompting-conala","keyword":"monolingual","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"azkurs","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Azkurs.org\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 566,713 pages of educational content in Azerbaijani language extracted from azkurs.org website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Azerbaijani (az) only.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/azkurs.","url":"https://huggingface.co/datasets/nyuuzyou/azkurs","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"nlm_gene","keyword":"monolingual","description":"NLM-Gene consists of 550 PubMed articles, from 156 journals, and contains more than 15 thousand unique gene names, corresponding to more than five thousand gene identifiers (NCBI Gene taxonomy). This corpus contains gene annotation data from 28 organisms. The annotated articles contain on average 29 gene names, and 10 gene identifiers per article. These characteristics demonstrate that this article set is an important benchmark dataset to test the accuracy of gene recognition algorithms both on multi-species and ambiguous data. The NLM-Gene corpus will be invaluable for advancing text-mining techniques for gene identification tasks in biomedical text.","url":"https://huggingface.co/datasets/bigbio/nlm_gene","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"cuad_qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CUAD\n\t\n\nThis is a modified version of original CUAD which trims the question to its label form.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions.\nCUAD is curated and maintained by The Atticus Project, Inc.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/cuad_qa.","url":"https://huggingface.co/datasets/chenghao/cuad_qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"edgar-corpus","keyword":"monolingual","description":"The dataset contains annual filings (10K) of all publicly traded firms from 1993-2020. The table data is stripped but all text is retained.\nThis dataset allows easy access to the EDGAR-CORPUS dataset based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round (See References in README.md for details).","url":"https://huggingface.co/datasets/c3po-ai/edgar-corpus","creator_name":"C3PO-AI","creator_url":"https://huggingface.co/c3po-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","no-annotation","other","monolingual","extended|other"],"keywords_longer_than_N":true},
	{"name":"xtreme_en_token_drift","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/xtreme_en_token_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"utcd","keyword":"monolingual","description":"UTCD is a compilation of 18 classification datasets spanning 3 categories of Sentiment, \nIntent/Dialogue and Topic classification. UTCD focuses on the task of zero-shot text classification where the \ncandidate labels are descriptive of the text being classified. UTCD consists of ~ 6M/800K train/test examples.","url":"https://huggingface.co/datasets/claritylab/utcd","creator_name":"Clarity Lab (University of Michigan)","creator_url":"https://huggingface.co/claritylab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","no-annotation","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"lld","keyword":"monolingual","description":"Designing a logo for a new brand is a lengthy and tedious back-and-forth process between a designer and a client. In this paper we explore to what extent machine learning can solve the creative task of the designer. For this, we build a dataset -- LLD -- of 600k+ logos crawled from the world wide web. Training Generative Adversarial Networks (GANs) for logo synthesis on such multi-modal data is not straightforward and results in mode collapse for some state-of-the-art methods. We propose the use of synthetic labels obtained through clustering to disentangle and stabilize GAN training. We are able to generate a high diversity of plausible logos and we demonstrate latent space exploration techniques to ease the logo design task in an interactive manner. Moreover, we validate the proposed clustered GAN training on CIFAR 10, achieving state-of-the-art Inception scores when using synthetic labels obtained via clustering the features of an ImageNet classifier. GANs can cope with multi-modal data by means of synthetic labels achieved through clustering, and our results show the creative potential of such techniques for logo synthesis and manipulation.","url":"https://huggingface.co/datasets/diwank/lld","creator_name":"Diwank Tomer","creator_url":"https://huggingface.co/diwank","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"moral_stories","keyword":"monolingual","description":"Moral Stories is a crowd-sourced dataset of structured, branching narratives for the study of grounded, goal-oriented \nsocial reasoning. For detailed information, see https://aclanthology.org/2021.emnlp-main.54.pdf.","url":"https://huggingface.co/datasets/demelin/moral_stories","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","text-classification","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"mdk_gov_data_titles_clf","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MDK\n\t\n\nThis dataset was created as part of the Bertelsmann Foundation's \nMusterdatenkatalog (MDK) project. The MDK provides an overview of Open Data in municipalities in Germany. It is intended to help municipalities in Germany, as well as data analysts and journalists, to get an overview of the topics and the extent to which cities have already published data sets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset is an annotated corpus ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf.","url":"https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf","creator_name":"&effect data solutions GmbH","creator_url":"https://huggingface.co/and-effect","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","extended","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"readability-es-caes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [readability-es-caes]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources:\n\nCAES corpus (MartÃ­nez et al., 2019): the \"Corpus de Aprendices del EspaÃ±ol\" is a collection of texts produced by Spanish L2 learners from Spanish learning centers and universities. These text are produced by studentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes.","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes","creator_name":"I Hackathon Somos NLP: PLN en EspaÃ±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_full_sent","keyword":"monolingual","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"tofu_resplit","keyword":"monolingual","description":"talmahmud/tofu_resplit dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/talmahmud/tofu_resplit","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"soda_synthetic_dialogue","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ðŸ¥¤SODA Synthetic Dialogue\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ¥¤SODA Synthetic Dialogue is a set of synthetic dialogues between Assistant and\nUser. In each conversation, User asks Assistant to perform summarization or\nstory generation tasks based on a snippet of an existing dialogue, story, or\nfrom a title or theme.\nThis data was created by synthesizing the dialogues in\nðŸ¥¤Soda and applying a set of\ntemplates to generate the conversation. The original research paper can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue.","url":"https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue","creator_name":"Jeffrey Quesnelle","creator_url":"https://huggingface.co/emozilla","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","no-annotation","machine-generated","monolingual","extended|allenai/soda"],"keywords_longer_than_N":true},
	{"name":"clearance","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for clearance\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nclearance is a dataset included in Chemberta-2 benchmarking. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget:\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10 train/valid/test split using scaffold split. \n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\nData wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clearance.","url":"https://huggingface.co/datasets/zpn/clearance","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"cen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCEN\n\t\n\n","url":"https://huggingface.co/datasets/clarin-knext/cen","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"recept","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Recept\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/recept.","url":"https://huggingface.co/datasets/amcoff/recept","creator_name":"Ã…ke Amcoff","creator_url":"https://huggingface.co/amcoff","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_mean","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_mean.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"squad_v2_sv","keyword":"monolingual","description":"SQuAD_v2_sv is a Swedish version of SQuAD2.0. Translation was done automatically by using Google Translate API but it is not so straightforward because;\n\n1. the span which determines the start and the end of the answer in the context may vary after translation,\n2. tne translated context may not contain the translated answer if we translate both independently.\n\nMore details on how to handle these will be provided in another blog post.","url":"https://huggingface.co/datasets/susumu2357/squad_v2_sv","creator_name":"Susumu Okazawa","creator_url":"https://huggingface.co/susumu2357","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","Swedish"],"keywords_longer_than_N":true},
	{"name":"qrecc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for QReCC: Question Rewriting in Conversational Context\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQReCC (Question Rewriting in Conversational Context) is an end-to-end open-domain question answering dataset comprising of 14K conversations with 81K question-answer pairs. The goal of this dataset is to provide a challenging benchmark for end-to-end conversational question answering that includes the individual subtasks of question rewriting, passage retrieval and reading comprehension.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/svakulenk0/qrecc.","url":"https://huggingface.co/datasets/svakulenk0/qrecc","creator_name":"Svitlana","creator_url":"https://huggingface.co/svakulenk0","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tox21_srp53","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for tox21_srp53\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ntox21_srp53 is a dataset included in MoleculeNet. It is the p53 stress-response pathway activation (SR-p53) task from Tox21.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: clinical trial toxicity (or absence of toxicity)\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/tox21_srp53.","url":"https://huggingface.co/datasets/zpn/tox21_srp53","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"fashionpedia_4_categories","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia_4_categories\n\t\n\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\n\nIt contains only 4 categories:\nClothing\nShoes\nBags\nAccessories\n\n\nNew splits were created:\nTrain: 90% of the images\nVal: 5%\nTest 5%\n\n\n\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories.","url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","monolingual","fashionpedia","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_oracle","keyword":"monolingual","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original numberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_oracle.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-paraphrase","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-paraphrase is an open source dataset of instruct-style records generated from the Telugu split of ai4bharat/IndicXParaphrase dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"laion2b_multi_korean_subset_with_image","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tlaion2b_multi_korean_subset_with_image\n\t\n\nimg2datasetì„ í†µí•´ ë‹¤ìš´ë¡œë“œì— ì„±ê³µí•œ Bingsu/laion2B-multi-korean-subset ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•œ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤.\nì´ë¯¸ì§€ëŠ” 9,800,137ìž¥ìž…ë‹ˆë‹¤.\nì´ë¯¸ì§€ëŠ” ì§§ì€ ìª½ ê¸¸ì´ê°€ 256ì´ ë˜ë„ë¡ ë¦¬ì‚¬ì´ì¦ˆ ë˜ì—ˆìœ¼ë©°, í’ˆì§ˆ 100ì¸ webpíŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\t1. datasets\n\t\n\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"Bingsu/laion2b_multi_korean_subset_with_image\", streaming=True, split=\"train\")\n\n>>> dataset.features\n{'image': Image(decode=True, id=None),\n 'text': Value(dtype='string', id=None)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image.","url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","extended|laion/laion2B-multi"],"keywords_longer_than_N":true},
	{"name":"mc4_nl_cleaned","keyword":"monolingual","description":"A thoroughly cleaned version of the Dutch portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.","url":"https://huggingface.co/datasets/yhavinga/mc4_nl_cleaned","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"source_code","keyword":"monolingual","description":"çº¯æ–‡æœ¬æ•°æ®ï¼Œå†…å®¹ï¼šé«˜è´¨é‡ç¼–ç¨‹æºä»£ç ï¼ŒåŒ…æ‹¬Pythonï¼ŒJavaï¼ŒCPPæºä»£ç ","url":"https://huggingface.co/datasets/shibing624/source_code","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"UnibQuAD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Squad-UNIB]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset create by own colecting for NLP task individual\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n    \"answers\": {\n        \"answer_start\": [1],\n        \"text\": [\"This is a test text\"]\n    },\n    \"context\": \"This is a test context.\",\n    \"id\": \"1\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fedryanto/UnibQuAD.","url":"https://huggingface.co/datasets/fedryanto/UnibQuAD","creator_name":"Fedryanto Dartiko","creator_url":"https://huggingface.co/fedryanto","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"java-8m-methods-v2","keyword":"monolingual","description":"anjandash/java-8m-methods-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v2","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","mit","1M - 10M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malteos/test2.","url":"https://huggingface.co/datasets/malteos/test2","creator_name":"malteos","creator_url":"https://huggingface.co/malteos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"wikitablequestions","keyword":"monolingual","description":"This WikiTableQuestions dataset is a large-scale dataset for the task of question answering on semi-structured tables.","url":"https://huggingface.co/datasets/stanfordnlp/wikitablequestions","creator_name":"Stanford NLP","creator_url":"https://huggingface.co/stanfordnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    â”œâ”€â”€ binary     : binaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"monolingual","description":"\n\t\n\t\t\n\t\taudiocaps\n\t\n\nHuggingFace mirror of official data repo.\n","url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"golf-courses","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary: golf-course\n\t\n\nThis dataset (bethecloud/golf-courses) includes 21 unique images of golf courses pulled from Unsplash.  \nThe dataset is a collection of photographs taken at various golf courses around the world. The images depict a variety of scenes, including fairways, greens, bunkers, water hazards, and clubhouse facilities. The images are high resolution and have been carefully selected to provide a diverse range of visual content for fine-tuning a machine learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bethecloud/golf-courses.","url":"https://huggingface.co/datasets/bethecloud/golf-courses","creator_name":"Kevin Leffew (GTM @ Replit)","creator_url":"https://huggingface.co/bethecloud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"latvian-text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tLatvian text dataset\n\t\n\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\n\n\t\n\t\t\n\t\tData sources used\n\t\n\n\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\nEuropean Parliament Proceedings Parallel Corpus -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text.","url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|tilde_model"],"keywords_longer_than_N":true},
	{"name":"math_qa","keyword":"monolingual","description":"Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.","url":"https://huggingface.co/datasets/allenai/math_qa","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-food-recipes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-food-recipes is an open source dataset of instruct-style records generated by webscraping a Telugu food recipes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_full","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/unpredictable/unpredictable_full","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"real-toxicity-prompts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":falseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/real-toxicity-prompts.","url":"https://huggingface.co/datasets/allenai/real-toxicity-prompts","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","original","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Category-classification","keyword":"monolingual","description":"This file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015). The original dataset is processed and cleaned of single word texts, English only sentences etc. \nIf you use this dataset, please cite {Nisansa de Silva, Sinhala Text Classification: Observations fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"COVID-19-vaccine-attitude-tweets","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-19-vaccine-attitude-tweets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 2564 manually annotated tweets related to COVID-19 vaccines. The dataset can be used to discover the attitude expressed in the tweet towards the subject of COVID-19 vaccines. Tweets are in English. The dataset was curated in such a way as to maximize the likelihood of tweets with a strong emotional tone. We have assumed the existence of three classes:\n\nPRO (label 0): positive, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets.","url":"https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets","creator_name":"webimmunization","creator_url":"https://huggingface.co/webimmunization","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","intent-classification","crowdsourced","other"],"keywords_longer_than_N":true},
	{"name":"soda","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ðŸ¥¤SODA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authoredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/soda.","url":"https://huggingface.co/datasets/allenai/soda","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","machine-generated","monolingual","original","extended|Atomic10x"],"keywords_longer_than_N":true},
	{"name":"big_patent_sample","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters in length, making the dataset good for training on lengths up to 250,000 tokens.\n\n\t\n\t\t\n\t\tDataset Card for Big Patent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents along with humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_sample.","url":"https://huggingface.co/datasets/Trelis/big_patent_sample","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMoroccan Darija YouTube Subtitles Dataset\n\t\n\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\n\nvideo_id: The unique identifier ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles.","url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRDocQAEnergyRetrieval","keyword":"monolingual","description":"\n  JinaVDRDocQAEnergyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve energy industry documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/docqa_energy_beir\n\n\n\t\n\nSource datasets:\n\njinaai/docqa_energy_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRDocQAEnergyRetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRDocQAEnergyRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRDocQAEnergyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRArxivQARetrieval","keyword":"monolingual","description":"\n  JinaVDRArxivQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve figures from scientific papers from arXiv based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/arxivqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/arxivqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRArxivQARetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRArxivQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRArxivQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreInfoVQARetrieval","keyword":"monolingual","description":"\n  VidoreInfoVQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/infovqa_test_subsampled_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreInfoVQARetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreInfoVQARetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreInfoVQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRTatQARetrieval","keyword":"monolingual","description":"\n  JinaVDRTatQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve financial reports based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/tatqa_beir\n\n\n\t\n\nSource datasets:\n\njinaai/tatqa_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRTatQARetrieval\")\nevaluator = mteb.MTEB([task])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRTatQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRTatQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreTatdqaRetrieval","keyword":"monolingual","description":"\n  VidoreTatdqaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/tatdqa_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"VidoreTatdqaRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreTatdqaRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreTatdqaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"cogtext","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CogText PubMed Abstracts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CogText dataset is a curated collection of abstracts about cognitive tasks and constructs from PubMed.\nThis dataset contains the original abstracts and their corresponding embeddings.\nPlease visit CogText on GitHub for the details and codes.\n\nHomepage: https://github.com/morteza/cogtext\nRepository: https://github.com/morteza/cogtext\nPoint of Contact: Morteza Ansarinia\nPaper: https://arxiv.org/abs/2203.11016â€¦ See the full description on the dataset page: https://huggingface.co/datasets/morteza/cogtext.","url":"https://huggingface.co/datasets/morteza/cogtext","creator_name":"Morteza Ansarinia","creator_url":"https://huggingface.co/morteza","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","semantic-similarity-classification","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"elsevier-oa-cc-by","keyword":"monolingual","description":"Elsevier OA CC-By is a corpus of 40k (40, 091) open access (OA) CC-BY articles\nfrom across Elsevierâ€™s journals and include the full text of the article, the metadata,\nthe bibliographic information for each reference, and author highlights.","url":"https://huggingface.co/datasets/orieg/elsevier-oa-cc-by","creator_name":"Nicolas Brousse","creator_url":"https://huggingface.co/orieg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","summarization","text-classification","masked-language-modeling","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"qg_squadshifts","keyword":"monolingual","description":"[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_squadshifts","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","subjqa","English"],"keywords_longer_than_N":true},
	{"name":"ipm_nel","keyword":"monolingual","description":"This data is for the task of named entity recognition and linking/disambiguation over tweets. It comprises\nthe addition of an entity URI layer on top of an NER-annotated tweet dataset. The task is to detect entities\nand then provide a correct link to them in DBpedia, thus disambiguating otherwise ambiguous entity surface\nforms; for example, this means linking \"Paris\" to the correct instance of a city named that (e.g. Paris, \nFrance vs. Paris, Texas).\n\nThe data concentrates on ten types of named entities: company, facility, geographic location, movie, musical\nartist, person, product, sports team, TV show, and other.\n\nThe file is tab separated, in CoNLL format, with line breaks between tweets.\nData preserves the tokenisation used in the Ritter datasets.\nPoS labels are not present for all tweets, but where they could be found in the Ritter\ndata, they're given. In cases where a URI could not be agreed, or was not present in\nDBpedia, there is a NIL. See the paper for a full description of the methodology.\n\nFor more details see http://www.derczynski.com/papers/ner_single.pdf or https://www.sciencedirect.com/science/article/abs/pii/S0306457314001034","url":"https://huggingface.co/datasets/strombergnlp/ipm_nel","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fashion_mnist_corrupted","keyword":"monolingual","description":"Fashion-MNIST is dataset of fashion images, indended as a drop-in replacement for the MNIST dataset.\nThis dataset (Fashion-Mnist-Corrupted) provides out-of-distribution data for the Fashion-Mnist\ndataset. Fashion-Mnist-Corrupted is based on a similar project for MNIST, called MNIST-C, by Mu et. al.","url":"https://huggingface.co/datasets/mweiss/fashion_mnist_corrupted","creator_name":"Michael Weiss","creator_url":"https://huggingface.co/mweiss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","expert-generated","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"movie_recommendation","keyword":"monolingual","description":"Movie recommendation task based on the Movielens dataset","url":"https://huggingface.co/datasets/sileod/movie_recommendation","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","open-domain-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"gov_report","keyword":"monolingual","description":"GovReport long document summarization dataset.\n\nThere are three configs:\n  - plain_text: plain text document-to-summary pairs\n  - plain_text_with_recommendations: plain text doucment-summary pairs, with \"What GAO recommends\" included in the summary\n  - structure: data with section structure","url":"https://huggingface.co/datasets/launch/gov_report","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NextGenBench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Next Generation Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a multitask test consisting of only questions (some are MCQ) from various branches of knowledge. Specifically the following topics:\nAbstract Algebra\nAnatomy\nAstronomy\nBusiness Ethics\nClinical Knowledge\nPrimary School Biology\nPrimary School Chemistry\nPrimary School Physics\nPrimary School Math\nPrimary School English\nPrimary School Science\nPrimary School Computer Science\nComputer Security\nDaily Economyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/NextGenBench.","url":"https://huggingface.co/datasets/KaraKaraWitch/NextGenBench","creator_name":"KaraKaraWitch","creator_url":"https://huggingface.co/KaraKaraWitch","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"id-paraphrase-detection","keyword":"monolingual","description":"This dataset is built as a playground for sequence to sequence classification","url":"https://huggingface.co/datasets/jakartaresearch/id-paraphrase-detection","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","found","found","monolingual","extended|msrp"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_hard_dummy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Hard set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR methodâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy.","url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"codequeries","keyword":"monolingual","description":"CodeQueries Ideal setup.","url":"https://huggingface.co/datasets/thepurpleowl/codequeries","creator_name":"Surya Prakash Sahu","creator_url":"https://huggingface.co/thepurpleowl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bold","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Bias in Open-ended Language Generation Dataset (BOLD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBias in Open-ended Language Generation Dataset (BOLD) is a dataset to evaluate fairness in open-ended language generation in English language. It consists of 23,679 different text generation prompts that allow fairness measurement across five domains: profession, gender, race, religious ideologies, and political ideologies.\n Some examples of prompts in BOLD are as follows:\n\nManyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/bold.","url":"https://huggingface.co/datasets/AmazonScience/bold","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"go_emotions-es-mt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGoEmotions Spanish\n\t\n\n\n\t\n\t\t\n\t\tA Spanish translation (using EasyNMT) of the GoEmotions dataset.\n\t\n\n\n\t\n\t\t\n\t\tFor more information check the official Model Card\n\t\n\n","url":"https://huggingface.co/datasets/mrm8488/go_emotions-es-mt","creator_name":"Manuel Romero","creator_url":"https://huggingface.co/mrm8488","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"COCO","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [COCO]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Luka-Wang/COCO.","url":"https://huggingface.co/datasets/Luka-Wang/COCO","creator_name":"Wang Yanghao","creator_url":"https://huggingface.co/Luka-Wang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"incivility-arizona-daily-star-comments","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for incivility-arizona-daily-star-comments\n\t\n\nThis is a collection of more than 6000 comments on Arizona Daily Star news articles from 2011 that have been manually annotated for various forms of incivility including aspersion, namecalling, sarcasm, and vulgarity.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach instance in the dataset corresponds to a single comment from a single commenter.\nAn instance's text field contains the text of the comment with any quotes of other commentersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments.","url":"https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments","creator_name":"Civility Lab","creator_url":"https://huggingface.co/civility-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"the-reddit-irl-dataset","keyword":"monolingual","description":"Data from the humour subreddits /r/meirl and /r/me_irl, up to Apr 1 2022","url":"https://huggingface.co/datasets/SocialGrep/the-reddit-irl-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Marketing-Budget-and-Actual-Sales-Dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for tweet_eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTweetEval consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. The tasks include - irony, hate, offensive, stance, emoji, emotion, and sentiment. All tasks have been unified into the same benchmark, with each dataset presented in the same format and with fixed training, validation and test splits.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext_classification: The dataset can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dianalogan/Marketing-Budget-and-Actual-Sales-Dataset.","url":"https://huggingface.co/datasets/dianalogan/Marketing-Budget-and-Actual-Sales-Dataset","creator_name":"Diana Logan","creator_url":"https://huggingface.co/dianalogan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["intent-classification","multi-class-classification","sentiment-classification","diana_logan","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm-hard","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the harder version of gsm8k math reasoning dataset (https://huggingface.co/datasets/gsm8k).\nWe construct this dataset by replacing the numbers in the questions of GSM8K with larger numbers that are less common.\n\u0001\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is used to evaluate math reasoning\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish - Numbers\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ndataset = load_dataset(\"reasoning-machines/gsm-hard\")\nDatasetDict({\n    train: Dataset({â€¦ See the full description on the dataset page: https://huggingface.co/datasets/reasoning-machines/gsm-hard.","url":"https://huggingface.co/datasets/reasoning-machines/gsm-hard","creator_name":"Reasoning Machines","creator_url":"https://huggingface.co/reasoning-machines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","gsm8k (https://huggingface.co/datasets/gsm8k)","code"],"keywords_longer_than_N":true},
	{"name":"enwik8","keyword":"monolingual","description":"The dataset is based on the Hutter Prize (http://prize.hutter1.net) and contains the first 10^8 bytes of English Wikipedia in 2006 in XML","url":"https://huggingface.co/datasets/LTCB/enwik8","creator_name":"Large Text Compression Benchmark","creator_url":"https://huggingface.co/LTCB","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_v2","keyword":"monolingual","description":"Paper: Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision\nAuthors: Wanyu Du*, Zae Myung Kim*, Vipul Raheja, Dhruv Kumar, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\nWatch our system demonstration below!\n\n","url":"https://huggingface.co/datasets/wanyu/IteraTeR_v2","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"ara-stance","keyword":"monolingual","description":"The AraStance dataset contains true and false claims, where each claim is paired with one or more documents. Each claimâ€“article pair has a stance label: agree, disagree, discuss, or unrelated.","url":"https://huggingface.co/datasets/strombergnlp/ara-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SeeTRUE","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SeeTRUE\n\t\n\n\nDataset Description\nSupported Tasks and Leaderboards\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nLicensing Information\nCitation Information\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe SeeTRUE dataset is a diverse benchmark for meta-evaluation of image-text alignment methods, covering the 4-way combinations of real and synthetic text-and-image pairs. It addresses limitations in current benchmarks, which mainly focus on natural imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yonatanbitton/SeeTRUE.","url":"https://huggingface.co/datasets/yonatanbitton/SeeTRUE","creator_name":"Yonatan","creator_url":"https://huggingface.co/yonatanbitton","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"drugprot","keyword":"monolingual","description":"The DrugProt corpus consists of a) expert-labelled chemical and gene mentions, and (b) all binary relationships between them corresponding to a specific set of biologically relevant relation types.","url":"https://huggingface.co/datasets/bigbio/drugprot","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"unpredictable_cluster14","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster14","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_baseball-fantasysports-yahoo-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_baseball-fantasysports-yahoo-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"cifar10-lt","keyword":"monolingual","description":"The CIFAR-10-LT imbalanced dataset is comprised of under 60,000 color images, each measuring 32x32 pixels, \ndistributed across 10 distinct classes.  \nThe dataset includes 10,000 test images, with 1000 images per class, \nand fewer than 50,000 training images.\nThe number of samples within each class of the train set decreases exponentially with factors of 10, 20, 50, 100, or 200.","url":"https://huggingface.co/datasets/tomas-gajarsky/cifar10-lt","creator_name":"Tomas Gajarsky","creator_url":"https://huggingface.co/tomas-gajarsky","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","crowdsourced","found","monolingual","cifar10"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for NevIR: Negation in Neural Information Retrieval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nData from the paper: \"NevIR: Negation in Neural Information Retrieval\". \nIf you use this dataset, we would appreciate you citing our work:\n@inproceedings{weller-et-al-2023-nevir,\n  title={NevIR: Negation in Neural Information Retrieval},\n  author={Weller, Orion and Lawrie, Dawn, and Van Durme, Benjamin},\n  year={2023},\n  eprint={2305.07614},\n  archivePrefix={arXiv},\n  year={2023}\n}\n\nPleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/NevIR.","url":"https://huggingface.co/datasets/orionweller/NevIR","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","monolingual","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster10","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster10","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"nouns","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Nouns auto-captioned\n\t\n\nDataset used to train Nouns text to image model\nAutomatically generated captions for Nouns from their attributes, colors and items. Help on the captioning script appreciated!\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite it as:\n@misc{piedrafita2022nouns,\n      author =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/m1guelpf/nouns.","url":"https://huggingface.co/datasets/m1guelpf/nouns","creator_name":"Miguel Piedrafita","creator_url":"https://huggingface.co/m1guelpf","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"pmc_open_access_xml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PMC Open Access XML\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe XML Open Access includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TomTBT/pmc_open_access_xml.","url":"https://huggingface.co/datasets/TomTBT/pmc_open_access_xml","creator_name":"Tom Boissonnet","creator_url":"https://huggingface.co/TomTBT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","other","no-annotation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"chizuru-ichinose","keyword":"monolingual","description":"This dataset is extracted from the Anime \"Rent-A-Girlfriend\" as posted on Kaggle by xandercubbin.\nPlease refer to the chizuru_dialog_dataset.ipynb file to see how the dataset was pre-processed.\n","url":"https://huggingface.co/datasets/alexandreteles/chizuru-ichinose","creator_name":"Alexandre Teles","creator_url":"https://huggingface.co/alexandreteles","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"arcalive_220506","keyword":"monolingual","description":"[ì•„ì¹´ë¼ì´ë¸Œ ë² ìŠ¤íŠ¸ ë¼ì´ë¸Œ ì±„ë„](https://arca.live/b/live)ì˜ 2021ë…„ 8ì›” 16ì¼ë¶€í„° 2022ë…„ 5ì›” 6ì¼ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬, ëŒ“ê¸€ë§Œ ê³¨ë¼ë‚¸ ë°ì´í„°ìž…ë‹ˆë‹¤.","url":"https://huggingface.co/datasets/Bingsu/arcalive_220506","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"brwac_tiny","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for BrWac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny.","url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ProsocialDialog Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/prosocial-dialog.","url":"https://huggingface.co/datasets/allenai/prosocial-dialog","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"dgen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdgen\n\t\n\nDGen is a cloze questions dataset which covers multiple domains including science, vocabulary, common sense and trivia. It is compiled from a wide variety of datasets including SciQ, MCQL, AI2 Science Questions, etc. The detail of DGen dataset is shown below.\n\n\t\n\t\t\nDGen dataset\nTrain\nValid\nTest\nTotal\n\n\n\t\t\nNumber of questions\n2321\n300\n259\n2880\n\n\n\t\n\nSource: https://github.com/DRSY/DGen\n","url":"https://huggingface.co/datasets/AndyChiang/dgen","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","monolingual","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ted_descriptions","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TED descriptions\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/gigant/ted_descriptions","creator_name":"ThÃ©o Gigant","creator_url":"https://huggingface.co/gigant","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tldr-17","keyword":"monolingual","description":"This corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.","url":"https://huggingface.co/datasets/webis/tldr-17","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"hh-rlhf-ru\"\n\t\n\nThis is translated version of Anthropic/hh-rlhf dataset into Russian.\n","url":"https://huggingface.co/datasets/d0rj/hh-rlhf-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translated","monolingual","Anthropic/hh-rlhf","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"vegetable","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tè”¬èœå›¾åƒæ•°æ®é›†\n\t\n\n\n\t\n\t\t\n\t\tèƒŒæ™¯\n\t\n\næœ€åˆçš„å®žéªŒæ˜¯ç”¨ä¸–ç•Œå„åœ°å‘çŽ°çš„15ç§å¸¸è§è”¬èœè¿›è¡Œçš„ã€‚å®žéªŒé€‰æ‹©çš„è”¬èœæœ‰ï¼šè±†ç±»ã€è‹¦ç“œã€è‘«èŠ¦ã€èŒ„å­ã€è¥¿å…°èŠ±ã€å·å¿ƒèœã€è¾£æ¤’ã€èƒ¡èåœã€èŠ±æ¤°èœã€é»„ç“œã€æœ¨ç“œã€åœŸè±†ã€å—ç“œã€èåœå’Œç•ªèŒ„ã€‚å…±ä½¿ç”¨äº†æ¥è‡ª15ä¸ªç±»çš„21000å¼ å›¾åƒï¼Œå…¶ä¸­æ¯ä¸ªç±»åŒ…å«1400å¼ å°ºå¯¸ä¸º224Ã—224ã€æ ¼å¼ä¸º*.jpgçš„å›¾åƒã€‚æ•°æ®é›†ä¸­70%ç”¨äºŽåŸ¹è®­ï¼Œ15%ç”¨äºŽéªŒè¯ï¼Œ15%ç”¨äºŽæµ‹è¯•ã€‚\n\n\t\n\t\t\n\t\tç›®å½•\n\t\n\næ­¤æ•°æ®é›†åŒ…å«ä¸‰ä¸ªæ–‡ä»¶å¤¹ï¼š\n\ntrain (15000 å¼ å›¾åƒ)\ntest (3000 å¼ å›¾åƒ)\nvalidation (3000 å¼ å›¾åƒ)\n\n\n\t\n\t\t\n\t\tæ•°æ®æ”¶é›†\n\t\n\nè¿™ä¸ªæ•°æ®é›†ä¸­çš„å›¾åƒæ˜¯æˆ‘ä»¬ä¸ºä¸€ä¸ªé¡¹ç›®ä»Žè”¬èœå†œåœºå’Œå¸‚åœºæ”¶é›†çš„ã€‚\n\n\t\n\t\t\n\t\tåˆ¶ä½œå…ƒæ•°æ®æ–‡ä»¶\n\t\n\nè¿è¡Œä¸‹é¢pythonçš„ä»£ç ï¼Œå°±å¯ä»¥åœ¨æ¡Œé¢ç”Ÿæˆä¸‰ä¸ªcsvæ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ã€ä¸€ä¸ªåˆ†ç±»æ•°æ®æ–‡ä»¶ï¼ˆéœ€è¦æ”¾å…¥åˆ°æ•°æ®æ–‡ä»¶ä¸­ï¼‰\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\n1.ä¸‹è½½çš„æ•°æ®æ–‡ä»¶ Vegetable Images.zip ï¼Œå¹¶è§£åŽ‹åˆ°æ¡Œé¢â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cc92yy3344/vegetable.","url":"https://huggingface.co/datasets/cc92yy3344/vegetable","creator_name":"é™ˆè¶…","creator_url":"https://huggingface.co/cc92yy3344","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"copa-sse","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COPA-SSE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nCOPA-SSE contains crowdsourced explanations for the Balanced COPA dataset, a variant of the Choice of Plausible Alternatives (COPA) benchmark. The explanations are formatted as a set of triple-like common sense statements with ConceptNet relations but freely written concepts.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nCan be used to train a model for explain+predict or predict+explain settings. Suited for both text-based andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anab/copa-sse.","url":"https://huggingface.co/datasets/anab/copa-sse","creator_name":"Ana Brassard","creator_url":"https://huggingface.co/anab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","explanation-generation","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"docee-event-classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DocEE Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDocEE dataset is an English-language dataset containing more than 27k news and Wikipedia articles. Dataset is primarily annotated and collected for large-scale document-level event extraction.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntitle: TODO\ntext: TODO\nevent_type: TODO\ndate: TODO\nmetadata: TODO\n\nNote: this repo contains only event detection portion of the dataset.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset has 2 splits: train and test. Trainâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fkdosilovic/docee-event-classification.","url":"https://huggingface.co/datasets/fkdosilovic/docee-event-classification","creator_name":"Filip Karlo DoÅ¡iloviÄ‡","creator_url":"https://huggingface.co/fkdosilovic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"xtreme_en","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/xtreme_en","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_sittercity-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_sittercity-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"s3_spyder","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Spider\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard can be seen at https://yale-lily.github.io/spider\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amitdanin/s3_spyder.","url":"https://huggingface.co/datasets/amitdanin/s3_spyder","creator_name":"Amit Danin","creator_url":"https://huggingface.co/amitdanin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["expert-generated","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster00","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster00","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster22","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster22","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster25","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster25","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"hatecheck-french","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french.","url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-medium","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-medium","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster15","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster15","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"asvspoof2019","keyword":"monolingual","description":"This is a database used for the Third Automatic Speaker Verification Spoofing\nand Countermeasuers Challenge, for short, ASVspoof 2019 (http://www.asvspoof.org)\norganized by Junichi Yamagishi, Massimiliano Todisco, Md Sahidullah, HÃ©ctor\nDelgado, Xin Wang, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Ville Vestman,\nand Andreas Nautsch in 2019.","url":"https://huggingface.co/datasets/LanceaKing/asvspoof2019","creator_name":"LanceaKing","creator_url":"https://huggingface.co/LanceaKing","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["audio-classification","other","other","monolingual","extended|vctk"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster09","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster09","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_qg","keyword":"monolingual","description":"Reddit question generation dataset.","url":"https://huggingface.co/datasets/launch/reddit_qg","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster19","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster19","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"wino_bias","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Wino_Bias dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWinoBias, a Winograd-schema dataset for coreference resolution focused on gender bias.\nThe corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe underlying task is coreference resolution. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/wino_bias.","url":"https://huggingface.co/datasets/uclanlp/wino_bias","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","coreference-resolution","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\talpaca-cleaned-ru\n\t\n\nconverter for autotrain from d0rj/alpaca-cleaned-ru\nTranslated version of yahma/alpaca-cleaned into Russian.\n","url":"https://huggingface.co/datasets/ASIDS/alpaca-cleaned-ru","creator_name":"Greed","creator_url":"https://huggingface.co/ASIDS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","translated","monolingual","yahma/alpaca-cleaned","Russian"],"keywords_longer_than_N":true},
	{"name":"JinaVDRMPMQARetrieval","keyword":"monolingual","description":"\n  JinaVDRMPMQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve product manuals based on human annotated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/mpmqa_small_beir\n\n\n\t\n\nSource datasets:\n\njinaai/mpmqa_small_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRMPMQARetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRMPMQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRMPMQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FinQARetrieval","keyword":"monolingual","description":"\n  FinQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on FinQA dataset containing numerical reasoning questions over financial documents. Each query is a financial question requiring numerical computation (e.g., 'What is the percentage change in operating expenses from 2019 to 2020?'), and the corpus contains financial document text with tables and numerical data. The task is to retrieve the correct financial information that enablesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinQARetrieval.","url":"https://huggingface.co/datasets/mteb/FinQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDRShiftProjectRetrieval","keyword":"monolingual","description":"\n  JinaVDRShiftProjectRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve documents with graphs from the Shift Project based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/shiftproject_beir\n\n\n\t\n\nSource datasets:\n\njinaai/shiftproject_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRShiftProjectRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRShiftProjectRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"VidoreSyntheticDocQAAIRetrieval","keyword":"monolingual","description":"\n  VidoreSyntheticDocQAAIRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/syntheticDocQA_artificial_intelligence_test_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAAIRetrieval.","url":"https://huggingface.co/datasets/mteb/VidoreSyntheticDocQAAIRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"dn_dataset","keyword":"monolingual","description":"adeaven/dn_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/adeaven/dn_dataset","creator_name":"hexiuwen","creator_url":"https://huggingface.co/adeaven","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["text-to-image","image-to-text","object-detection","zero-shot-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"commonvoice_benchmark_catalan_accents","keyword":"monolingual","description":"A new presentation of the corpus Catalan Common Voice v17.0 - metadata annotated version with the splits redefined to benchmark ASR models with various Catalan accent","url":"https://huggingface.co/datasets/projecte-aina/commonvoice_benchmark_catalan_accents","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","audio-to-audio","audio-language-identification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"genai_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/samyakmohelay/genai_dataset.","url":"https://huggingface.co/datasets/samyakmohelay/genai_dataset","creator_name":"Samyak Mohelay","creator_url":"https://huggingface.co/samyakmohelay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fake_news_en_opensources","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"Fake News Opensources\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/FakeNewsDataset\nRepository: https://github.com/AndyTheFactory/FakeNewsDataset\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na consolidated and cleaned up version of the opensources Fake News dataset\nFake News Corpus comprises 8,529,090 individual articles, classified into 12 classes: reliable, unreliable, political, bias, fake, conspiracyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/andyP/fake_news_en_opensources.","url":"https://huggingface.co/datasets/andyP/fake_news_en_opensources","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","fact-checking","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"tm2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Taskmaster-2\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020\nPaper: https://arxiv.org/pdf/1909.05358.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm2')\nontology = load_ontology('tm2')\ndatabase =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm2.","url":"https://huggingface.co/datasets/ConvLab/tm2","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","arxiv:1909.05358"],"keywords_longer_than_N":true},
	{"name":"camrest","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Camrest\n\t\n\n\nRepository: https://www.repository.cam.ac.uk/handle/1810/260970\nPaper: https://aclanthology.org/D16-1233/\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('camrest')\nontology = load_ontology('camrest')\ndatabase = load_database('camrest')â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/camrest.","url":"https://huggingface.co/datasets/ConvLab/camrest","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"FeedbackQARetrieval","keyword":"monolingual","description":"\n  FeedbackQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nUsing Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Government, Medical, Written\nReference\nhttps://arxiv.org/abs/2204.03025\n\n\n\t\n\nSource datasets:\n\nlt2c/fqa\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FeedbackQARetrieval.","url":"https://huggingface.co/datasets/mteb/FeedbackQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"pile-detoxify","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The Pile, which is English text.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify.","url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","hate-speech-detection","text-scoring"],"keywords_longer_than_N":true},
	{"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des pensions de retraite des marins franÃ§ais du commerce, de pÃªche ou de plaisance, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"chinese-poetry","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tå”è©©ä¸‰ç™¾é¦– Dataset\n\t\n\nA structured JSON dataset of 320 classical Tang Dynasty poems, sourced from ç¶­åŸºæ–‡åº«ï¼ˆWikisourceï¼‰.\nThis dataset provides clean, machine-readable text data suitable for natural language processing (NLP), classical Chinese analysis, digital humanities, and poetry generation tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“˜ Overview\n\t\n\n\nTotal entries: 320\nSource: Wikisource (Traditional Chinese)\nFormat: JSON Lines (.jsonl)\nEncoding: UTF-8\nLanguage: Classical Chinese (ç¹é«”ä¸­æ–‡)\n\nEach entry corresponds to oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZoneTwelve/chinese-poetry.","url":"https://huggingface.co/datasets/ZoneTwelve/chinese-poetry","creator_name":"ZoneTwelve","creator_url":"https://huggingface.co/ZoneTwelve","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","human-annotated","found"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_mean","keyword":"monolingual","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_mean.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"naab","keyword":"monolingual","description":"Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word Ù†Ø§Ø¨ which means pure and high-grade.","url":"https://huggingface.co/datasets/SLPL/naab","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"multi_lexsum","keyword":"monolingual","description":"Multi-LexSum is a multi-doc summarization dataset for civil rights litigation lawsuits with summaries of three granularities.","url":"https://huggingface.co/datasets/allenai/multi_lexsum","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wildfire_tweets","keyword":"monolingual","description":"rubrix/wildfire_tweets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubrix/wildfire_tweets","creator_name":"rubrix","creator_url":"https://huggingface.co/rubrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ludwig","keyword":"monolingual","description":"TODO","url":"https://huggingface.co/datasets/UCL-DARK/ludwig","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"twitter-financial-news-topic","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their topic.\n\nThe dataset holds 21,107 documents annotated with 20 labels:\n\ntopics = {\n    \"LABEL_0\": \"Analyst Update\",\n    \"LABEL_1\": \"Fed | Central Banks\",\n    \"LABEL_2\": \"Company | Product News\",\n    \"LABEL_3\": \"Treasuries | Corporate Debt\",\n    \"LABEL_4\": \"Dividend\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic.","url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"DEFT2023","keyword":"monolingual","description":"FrenchMedMCQA","url":"https://huggingface.co/datasets/DEFT-2023/DEFT2023","creator_name":"DEFT-2023","creator_url":"https://huggingface.co/DEFT-2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","multiple-choice","multiple-choice-qa","open-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"UTS_Text","keyword":"monolingual","description":"UTSText","url":"https://huggingface.co/datasets/undertheseanlp/UTS_Text","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","no-annotation","monolingual","Vietnamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"poem-tweets","keyword":"monolingual","description":"This dataset is built for text generation task in context of poem tweets in Bahasa.","url":"https://huggingface.co/datasets/jakartaresearch/poem-tweets","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT","keyword":"monolingual","description":"The LXMERT text train data used to train BERT-base baselines and adapt vision-and-language models to text-only tasks in the paper \"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\".\nThe data has been created from the data made available by the LXMERT repo.\n","url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"UTS_Dictionary","keyword":"monolingual","description":"UTSText","url":"https://huggingface.co/datasets/undertheseanlp/UTS_Dictionary","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","no-annotation","monolingual","Vietnamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MyspeechASR","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automaticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sidd2899/MyspeechASR.","url":"https://huggingface.co/datasets/Sidd2899/MyspeechASR","creator_name":"Siddhant Kadam","creator_url":"https://huggingface.co/Sidd2899","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"VaccinChatNL","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for VaccinChatNL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPoint of Contact:  Jeska Buhmann\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVaccinChatNL is a Flemish Dutch FAQ dataset on the topic of COVID-19 vaccinations in Flanders. It consists of 12,833 user questions divided over 181 answer labels, thus providing large groups of semantically equivalent paraphrases (a many-to-one mapping of user questions to answer labels). VaccinChatNL is the first Dutch many-to-one FAQ dataset of this size.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/clips/VaccinChatNL.","url":"https://huggingface.co/datasets/clips/VaccinChatNL","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\n","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD). Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy.","url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"rlhf-reward-datasets-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"rlhf-reward-datasets-ru\"\n\t\n\nThis is translated version of yitingxie/rlhf-reward-datasets dataset into Russian.\n","url":"https://huggingface.co/datasets/d0rj/rlhf-reward-datasets-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translated","monolingual","yitingxie/rlhf-reward-datasets","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"openpi_v2","keyword":"monolingual","description":"TEMPORARY DESCRIPTION","url":"https://huggingface.co/datasets/abhinavk/openpi_v2","creator_name":"Abhinav Kommula","creator_url":"https://huggingface.co/abhinavk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-classification","entity-linking-classification","natural-language-inference","expert-generated"],"keywords_longer_than_N":true},
	{"name":"twi-trigrams-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 166156 parallel speech-text pairs for Twi, a language spoken primarily in Ghana. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi - twi\nTask: Speech Recognition, Text-to-Speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"saf_communication_networks_english","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_communication_networks_english\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 31 English questions covering a range of college-level communication networks topics -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english.","url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"DebateSum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDebateSum\n\t\n\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \"DebateSum: A large-scale argument mining and summarization dataset\"\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\nVideo of presentation at COLING 2020:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum.","url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-retrieval","text-generation","abstractive-qa"],"keywords_longer_than_N":true},
	{"name":"tab_fact","keyword":"monolingual","description":"The problem of verifying whether a textual hypothesis holds the truth based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are restricted to dealing with unstructured textual evidence (e.g., sentences and passages, a pool of passages), while verification using structured forms of evidence, such as tables, graphs, and databases, remains unexplored. TABFACT is large scale dataset with 16k Wikipedia tables as evidence for 118k human annotated statements designed for fact verification with semi-structured evidence. The statements are labeled as either ENTAILED or REFUTED. TABFACT is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning.","url":"https://huggingface.co/datasets/wenhu/tab_fact","creator_name":"Wenhu Chen","creator_url":"https://huggingface.co/wenhu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-jokes","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-jokes is an open source dataset of instruct-style records generated by webscraping a Telugu Jokes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\naya-telugu-jokes is a corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"crypto_data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCryptoData Dataset\n\t\n\nThe CryptoData dataset is a comprehensive collection of cryptocurrency market data, designed to support various analyses, including price prediction, market trend analysis, and the study of the impact of various indicators on cryptocurrency prices.\nThis dataset has been configured to provide flexibility in selecting specific types of market data through the use of different dataset configurations. Depending on the analysis needs, users can select one of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sebdg/crypto_data.","url":"https://huggingface.co/datasets/sebdg/crypto_data","creator_name":"Sebastien De Greef","creator_url":"https://huggingface.co/sebdg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["time-series-forecasting","monolingual","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"qa-pt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for QA-Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese preprocessed split from MQA dataset.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is Portuguese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt.","url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"hmd-erwt-training","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ERWT Hertiage Made Digital Newspapers training data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text extracted at the page level from historic digitised newspapers from the Heritage Made Digital newspaper digitisation program. The newspapers in the dataset were published between 1800 and 1870.\nThe data was primarily created as a dataset for training 'time-aware' language models.\nThe dataset contains text generated from Optical Character Recognition software onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training.","url":"https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training","creator_name":"Living with Machines","creator_url":"https://huggingface.co/Livingwithmachines","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"resh-edu","keyword":"monolingual","description":"This is a dataset of lessons and tests scraped from resh.edu.ru","url":"https://huggingface.co/datasets/its5Q/resh-edu","creator_name":"its5Q","creator_url":"https://huggingface.co/its5Q","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","open-domain-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ke-products","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Kazanexpress products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace Kazanexpress. It includes all information from the product card and metadata from the API. The dataset was collected by processing around 3 million products, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Please note that the data returned by the APIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ke-products.","url":"https://huggingface.co/datasets/nyuuzyou/ke-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"mayosrs","keyword":"monolingual","description":"MayoSRS consists of 101 clinical term pairs whose relatedness was determined by nine medical coders and three physicians from the Mayo Clinic.","url":"https://huggingface.co/datasets/bigbio/mayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"hausa_voa_ner","keyword":"monolingual","description":"The Hausa VOA NER dataset is a labeled dataset for named entity recognition in Hausa. The texts were obtained from\nHausa Voice of America News articles https://www.voahausa.com/ . We concentrate on\nfour types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n\nThe Hausa VOA NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\nthere is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\nis the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\nof type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\nhave tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n\nFor more details, see https://www.aclweb.org/anthology/2020.emnlp-main.204/","url":"https://huggingface.co/datasets/UdS-LSV/hausa_voa_ner","creator_name":"LSV @ Saarland University","creator_url":"https://huggingface.co/UdS-LSV","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"sem_eval_2014_task_1","keyword":"monolingual","description":"The SemEval-2014 Task 1 focuses on Evaluation of Compositional Distributional Semantic Models\non Full Sentences through Semantic Relatedness and Entailment. The task was designed to\npredict the degree of relatedness between two sentences and to detect the entailment\nrelation holding between them.","url":"https://huggingface.co/datasets/SemEvalWorkshop/sem_eval_2014_task_1","creator_name":"SemEval","creator_url":"https://huggingface.co/SemEvalWorkshop","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-scoring","natural-language-inference","semantic-similarity-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"laroseda","keyword":"monolingual","description":"        LaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian, of which 7,500 are positive and 7,500 negative.\n        Star ratings of 1 and 2 and of 4 and 5 are provided for negative and positive reviews respectively.\n        The current dataset uses star rating as the label for multi-class classification.","url":"https://huggingface.co/datasets/universityofbucharest/laroseda","creator_name":"University of Bucharest","creator_url":"https://huggingface.co/universityofbucharest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wave-energy","keyword":"monolingual","description":"cmudrc/wave-energy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cmudrc/wave-energy","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","feature-extraction","image-to-image","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"curation-corpus","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tcuration-corpus\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nData from this official repo with downloaded news articles content.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{curationcorpusbase:2020,\n  title={Curation Corpus Base},\n  author={Curation},\n  year={2020}\n}\n\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"generics_kb","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Generics KB\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDataset contains a large (3.5M+ sentence) knowledge base of generic sentences.  This is the first large resource to contain naturally occurring generic sentences, rich in high-quality, general, semantically complete statements. All GenericsKB sentences are annotated with their topical term, surrounding context (sentences), and a (learned) confidence. We also release GenericsKB-Best (1M+ sentences), containing the best-qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/generics_kb.","url":"https://huggingface.co/datasets/community-datasets/generics_kb","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cantemist-ner","keyword":"monolingual","description":"https://temu.bsc.es/cantemist/","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/cantemist-ner","creator_name":"Plan de TecnologÃ­as del Lenguaje - Gobierno de EspaÃ±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"discovery","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Discovery\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDiscourse marker prediction with 174 markers\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ninput : sentence1, sentence2, \nlabel: marker originally between sentence1 and sentence2\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain/Val/Test\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sileod/discovery.","url":"https://huggingface.co/datasets/sileod/discovery","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-proc-whisper","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-proc-whisper.","url":"https://huggingface.co/datasets/DTU54DL/common-proc-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bn_hate_speech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Bengali Hate Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text. The dataset was created to provide greater support for under-resourced languages like Bengali on NLP tasks, and serves as a benchmark for multiple types of classification tasks. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rezacsedu/bn_hate_speech.","url":"https://huggingface.co/datasets/rezacsedu/bn_hate_speech","creator_name":"Rezaul Karim, PhD.","creator_url":"https://huggingface.co/rezacsedu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"zest","keyword":"monolingual","description":"ZEST tests whether NLP systems can perform unseen tasks in a zero-shot way, given a natural language description of\nthe task. It is an instantiation of our proposed framework \"learning from task descriptions\". The tasks include\nclassification, typed entity extraction and relationship extraction, and each task is paired with 20 different\nannotated (input, output) examples. ZEST's structure allows us to systematically test whether models can generalize\nin five different ways.","url":"https://huggingface.co/datasets/allenai/zest","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","token-classification","closed-domain-qa","extractive-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"covid_qa_deepset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOVID-QA is a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19.\nA total of 147 scientific articles from the CORD-19 dataset were annotated by 15 experts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepset/covid_qa_deepset.","url":"https://huggingface.co/datasets/deepset/covid_qa_deepset","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"germaner","keyword":"monolingual","description":"GermaNER is a freely available statistical German Named Entity Tagger based on conditional random fields(CRF). The tagger is trained and evaluated on the NoSta-D Named Entity dataset, which was used in the GermEval 2014 for named entity recognition. The tagger comes close to the performance of the best (proprietary) system in the competition with 77% F-measure (this is the latest result; the one reported in the paper is 76%) test set performance on the four standard NER classes (PERson, LOCation, ORGanisation and OTHer).\n\nWe describe a range of features and their influence on German NER classification and provide a comparative evaluation and some analysis of the results. The software components, the training data and all data used for feature generation are distributed under permissive licenses, thus this tagger can be used in academic and commercial settings without restrictions or fees. The tagger is available as a command-line tool and as an Apache UIMA component.","url":"https://huggingface.co/datasets/tudarmstadt-lt/germaner","creator_name":"Language Technology Group, TU Darmstadt) ","creator_url":"https://huggingface.co/tudarmstadt-lt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bioinfer","keyword":"monolingual","description":"A corpus targeted at protein, gene, and RNA relationships which serves as a\nresource for the development of information extraction systems and their\ncomponents such as parsers and domain analyzers. Currently, the corpus contains\n1100 sentences from abstracts of biomedical research articles annotated for\nrelationships, named entities, as well as syntactic dependencies.","url":"https://huggingface.co/datasets/bigbio/bioinfer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"nsmc","keyword":"monolingual","description":"This is a movie review dataset in the Korean language. Reviews were scraped from Naver movies. The dataset construction is based on the method noted in Large movie review dataset from Maas et al., 2011.","url":"https://huggingface.co/datasets/e9t/nsmc","creator_name":"Lucy Park","creator_url":"https://huggingface.co/e9t","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"psytar","keyword":"monolingual","description":"The \"Psychiatric Treatment Adverse Reactions\" (PsyTAR) dataset contains 891 drugs\nreviews posted by patients on \"askapatient.com\", about the effectiveness and adverse\ndrug events associated with Zoloft, Lexapro, Cymbalta, and Effexor XR.\n\nThis dataset can be used for (multi-label) sentence classification of Adverse Drug\nReaction (ADR), Withdrawal Symptoms (WDs), Sign/Symptoms/Illness (SSIs), Drug\nIndications (DIs), Drug Effectiveness (EF), Drug Infectiveness (INF) and Others, as well\nas for recognition of 5 different types of named entity (in the categories ADRs, WDs,\nSSIs and DIs)","url":"https://huggingface.co/datasets/bigbio/psytar","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"smartdata","keyword":"monolingual","description":"DFKI SmartData Corpus is a dataset of 2598 German-language documents\nwhich has been annotated with fine-grained geo-entities, such as streets,\nstops and routes, as well as standard named entity types. It has also\nbeen annotated with a set of 15 traffic- and industry-related n-ary\nrelations and events, such as Accidents, Traffic jams, Acquisitions,\nand Strikes. The corpus consists of newswire texts, Twitter messages,\nand traffic reports from radio stations, police and railway companies.\nIt allows for training and evaluating both named entity recognition\nalgorithms that aim for fine-grained typing of geo-entities, as well\nas n-ary relation extraction systems.","url":"https://huggingface.co/datasets/dfki-nlp/smartdata","creator_name":"dfki-nlp","creator_url":"https://huggingface.co/dfki-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-voice-test16k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test16k.","url":"https://huggingface.co/datasets/DTU54DL/common-voice-test16k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"clinc_oos","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CLINC150\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTask-oriented dialog systems need to know when a query falls outside their range of supported intents, but current text classification corpora only define label sets that cover every example. We introduce a new dataset that includes queries that are out-of-scope (OOS), i.e., queries that do not fall into any of the system's supported intents. This poses a new challenge because models cannot assume that every query at inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clinc/clinc_oos.","url":"https://huggingface.co/datasets/clinc/clinc_oos","creator_name":"Clinc: Conversational AI Technology","creator_url":"https://huggingface.co/clinc","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"lama","keyword":"monolingual","description":"LAMA is a dataset used to probe and analyze the factual and commonsense knowledge contained in pretrained language models. See https://github.com/facebookresearch/LAMA.","url":"https://huggingface.co/datasets/facebook/lama","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"osiris","keyword":"monolingual","description":"The OSIRIS corpus is a set of MEDLINE abstracts manually annotated\nwith human variation mentions. The corpus is distributed under the terms\nof the Creative Commons Attribution License\nCreative Commons Attribution 3.0 Unported License,\nwhich permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work is properly cited (Furlong et al, BMC Bioinformatics 2008, 9:84).","url":"https://huggingface.co/datasets/bigbio/osiris","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc-by-3.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"kor_ner","keyword":"monolingual","description":"Korean named entity recognition dataset","url":"https://huggingface.co/datasets/nlp-kmu/kor_ner","creator_name":"Korea Maritime and Ocean University","creator_url":"https://huggingface.co/nlp-kmu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-br-20240325","keyword":"monolingual","description":"A corpus of sentences extracted for the Breton Wikipedia (cirrus dump).\nThe sentences were filtered so that only Breton sentences were kept.\nPlease note that the sentence splitting algorithm is far from perfect, so many sentences will appear incorrect or incomplete.\n","url":"https://huggingface.co/datasets/gweltou/wikipedia-br-20240325","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Breton","apache-2.0","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"nanomind_1m","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNanomind 1M Pretraining Dataset\n\t\n\nA filtered and processed dataset for language model pretraining, containing 262,227 documents derived from web text and educational sources.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDocuments: 262,227\nLanguage: English\nFormat: JSONL with text field\nSize: 143 MB compressed\n\n\n\t\n\t\t\n\t\tSource Datasets\n\t\n\nDerived from:\n\nnampdn-ai/tiny-webtext (MIT License)\nnampdn-ai/tiny-textbooks (Apache-2.0 License)\n\n\n\t\n\t\t\n\t\tProcessing\n\t\n\nCreated using  with the following filters:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ethanker/nanomind_1m.","url":"https://huggingface.co/datasets/ethanker/nanomind_1m","creator_name":"Ethan KERDELHUE","creator_url":"https://huggingface.co/ethanker","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","text-classification","token-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"kd_conv_with_kb","keyword":"monolingual","description":"KdConv is a Chinese multi-domain Knowledge-driven Conversionsation dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics, while the corpus can also used for exploration of transfer learning and domain adaptation.\\","url":"https://huggingface.co/datasets/thu-coai/kd_conv_with_kb","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"beans","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Beans\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBeans leaf dataset with images of diseased and health leaves.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nimage-classification: Based on a leaf image, the goal of this task is to predict the disease type (Angular Leaf Spot and Bean Rust), if any.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA sample from the training set is provided below:\n{\n    'image_file_path':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Lab-Makerere/beans.","url":"https://huggingface.co/datasets/AI-Lab-Makerere/beans","creator_name":"Makerere AI Lab","creator_url":"https://huggingface.co/AI-Lab-Makerere","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"greek_legal_code","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Greek Legal Code\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGreek_Legal_Code (GLC) is a dataset consisting of approx. 47k legal resources from Greek legislation. The origin of GLC is â€œPermanent Greek Legislation Code - Raptarchisâ€, a collection of Greek legislative documents classified into multi-level (from broader to more specialized) categories.\nTopics\nGLC consists of 47 legislative volumes and each volume corresponds to a main thematic topic. Each volume is divided intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-team-UoA/greek_legal_code.","url":"https://huggingface.co/datasets/AI-team-UoA/greek_legal_code","creator_name":"AI Team - University of Athens","creator_url":"https://huggingface.co/AI-team-UoA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","topic-classification","found","found"],"keywords_longer_than_N":true},
	{"name":"uz-crawl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for UzCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release UzCrawl dataset, a web and telegram crawl corpus consisting of materials from nearly 1.2 million unique sources in the Uzbek Language. \nPlease refer to our blogpost for further details.\nP.S. We updated the dataset with 2nd version that extends the scope to new topics as well as being up to date to March 2024.\nTo load and use dataset, run this script:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-crawl.","url":"https://huggingface.co/datasets/tahrirchi/uz-crawl","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"mile_dataset","keyword":"monolingual","description":"IISc-MILE Tamil ASR Corpus contains transcribed speech corpus for training ASR systems for Tamil language. It contains ~150 hours of read speech data collected from 531 speakers in a noise-free recording environment with high quality USB microphones.","url":"https://huggingface.co/datasets/parambharat/mile_dataset","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"salom-ladino-articles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tÅžalom Ladino articles text corpus\n\t\n\nText corpus compiled from 397 articles from the Judeo-Espanyol section of Åžalom newspaper. Original sentences and articles belong to Åžalom. \nSize: 176,843 words\nOffical link\nPaper on ArXiv\nCitation:\nPreparing an endangered language for the digital age: The Case of Judeo-Spanish. Alp Ã–ktem, Rodolfo Zevallos, Yasmin Moslem, GÃ¼neÅŸ Ã–ztÃ¼rk, Karen Åžarhon. \nWorkshop on Resources and Technologies for Indigenous, Endangered and Lesser-resourced Languages inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/salom-ladino-articles.","url":"https://huggingface.co/datasets/collectivat/salom-ladino-articles","creator_name":"ColÂ·lectivaT","creator_url":"https://huggingface.co/collectivat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mmlu_ita","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tItalian Version of the MMLU DATASET\n\t\n\nBased on the version released by: FreedomIntelligence/MMLU_Italian\nIncludes minor fixes.\n\n\t\n\t\t\n\t\tCitations\n\t\n\nThis version:\n@misc{basile2023llamantino,\n      title={LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language}, \n      author={Pierpaolo Basile and Elio Musacchio and Marco Polignano and Lucia Siciliani and Giuseppe Fiameni and Giovanni Semeraro},\n      year={2023},\n      eprint={2312.09993}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/swap-uniba/mmlu_ita.","url":"https://huggingface.co/datasets/swap-uniba/mmlu_ita","creator_name":"SWAP Research Group@UNIBA","creator_url":"https://huggingface.co/swap-uniba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"pile-pii-scrubadub","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the personal idenfitiable information (PII) in each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the percentage of words in it that are classified as PII by Scrubadub.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis dataset is taken from Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub.","url":"https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"text2image-multi-prompt","keyword":"monolingual","description":"###è½¬è½½ pszemraj/text2image-multi-prompt\n\n\t\n\t\t\n\t\ttext2image multi-prompt(s): a dataset collection\n\t\n\n\ncollection of several text2image prompt datasets\ndata was cleaned/normalized with the goal of removing \"model specific APIs\" like the \"--ar\" for Midjourney and so on\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\n\n\n\t\n\t\t\n\t\tcontents\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'src_dataset'],\n        num_rows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt.","url":"https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt","creator_name":"JohnTeddy3","creator_url":"https://huggingface.co/JohnTeddy3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","bartman081523/stable-diffusion-discord-prompts","succinctly/midjourney-prompts","Gustavosta/Stable-Diffusion-Prompts","English"],"keywords_longer_than_N":true},
	{"name":"newyorker_caption_contest","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for New Yorker Caption Contest Benchmarks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee capcon.dev for more!\nData from:\nDo Androids Laugh at Electric Sheep? Humor \"Understanding\" Benchmarks from The New Yorker Caption Contest\n@inproceedings{hessel2023androids,\n  title={Do Androids Laugh at Electric Sheep? {Humor} ``Understanding''\n         Benchmarks from {The New Yorker Caption Contest}},\n  author={Hessel, Jack and Marasovi{\\'c}, Ana and Hwang, Jena D. and Lee, Lillian\n          andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jmhessel/newyorker_caption_contest.","url":"https://huggingface.co/datasets/jmhessel/newyorker_caption_contest","creator_name":"Jack Hessel","creator_url":"https://huggingface.co/jmhessel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multiple-choice","text-classification","text-generation","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"ICC","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ICC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Icelandic Crawled Corpus (ICC) contains approximately 930M tokens which have been scraped from a selection of Icelandic websites, including news sites, government websites and forums. The scraped text is presented in its original form, unannotated, untokenized and without deduplication.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe ICC is primarily intended for use in training language models. It can be combined with otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jonfd/ICC.","url":"https://huggingface.co/datasets/jonfd/ICC","creator_name":"JÃ³n FriÃ°rik DaÃ°ason","creator_url":"https://huggingface.co/jonfd","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-native","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native.","url":"https://huggingface.co/datasets/DTU54DL/common-native","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mobie","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"MobIE\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis script is for loading the MobIE dataset from https://github.com/dfki-nlp/mobie. \nMobIE is a German-language dataset which is human-annotated with 20 coarse- and fine-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and traffic reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge base. Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DFKI-SLT/mobie.","url":"https://huggingface.co/datasets/DFKI-SLT/mobie","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","named-entity-recognition","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"clinic150-sur","keyword":"monolingual","description":"dataset_info:\n  features:\n\nname: intent\ndtype: string\nname: user_utterance\ndtype: string\nname: origin\ndtype: string\n\n\n\t\n\t\t\n\t\tDataset Card for \"clinic150-SUR\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Clinic150-SUR dataset is a novel and augmented dataset designed to simulate natural human behavior during interactions with customer service-like centers.\nExtending the Clinic150 dataset, it incorporates two augmentation techniques, including IBM's LAMBADA and Parrot models and carefully curatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/clinic150-sur.","url":"https://huggingface.co/datasets/ibm-research/clinic150-sur","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","extended|clinic150","English","mit"],"keywords_longer_than_N":true},
	{"name":"kannada_asr_corpus","keyword":"monolingual","description":"The corpus contains roughly 360 hours of audio and transcripts in Kannada language. The transcripts have beed de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/kannada_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"RoITD","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We introduce a  Romanian IT Dataset (RoITD) resembling SQuAD 1.1.  RoITD consists of 9575 Romanian  QA pairs formulated by crowd workers. QA pairs are based on 5043 articles from Romanian Wikipedia articles describing IT and household products.  Of the total number of questions, 5103 are possible (i.e. the correct answer can be found within the paragraph) and 4472 are not possible (i.e. the given answer is a \"plausible answer\" and not correct)\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dragosnicolae555/RoITD.","url":"https://huggingface.co/datasets/dragosnicolae555/RoITD","creator_name":"Constantin Nicolae","creator_url":"https://huggingface.co/dragosnicolae555","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"DocBank","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DocBank\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nDocument AI (text and layout)\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maveriq/DocBank.","url":"https://huggingface.co/datasets/maveriq/DocBank","creator_name":"Haris Jabbar","creator_url":"https://huggingface.co/maveriq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["machine-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"sharif_emotional_speech_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSharif Emotional Speech Dataset (ShEMO)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used to decideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset.","url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","radio-plays"],"keywords_longer_than_N":true},
	{"name":"bace_classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for bace_classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbace_classification is a dataset included in MoleculeNet. This dataset consists of qualitative (binary label) binding binding results for a set of inhibitors of human Î²-secretase 1(BACE-1).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: the binary label binding results\n\n\n\t\n\t\t\n\t\tData Splitsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_classification.","url":"https://huggingface.co/datasets/zpn/bace_classification","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"delaney","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for delaney\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ndelaney (aka. ESOL) is a dataset included in MoleculeNet. Water solubility data(log solubility in mols per litre) for common organic small molecules.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: log solubility in mols per litre\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/delaney.","url":"https://huggingface.co/datasets/zpn/delaney","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"3d-printed-or-not","keyword":"monolingual","description":"\n\t\n\t\t\n\t\t3d-printed-or-not: An Image Dataset of 3D-printed Prototypes\n\t\n\nThis dataset is a collection of images that are particularly relevant to engineering and design, consisting of two categories: 3D-printed prototypes, and non-3D-printed prototypes This data was collected through a hybrid approach that entailed both web scraping and direct collection from engineering labs and workspaces at Penn State University. The initial data was then augmented using several data augmentation techniquesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmudrc/3d-printed-or-not.","url":"https://huggingface.co/datasets/cmudrc/3d-printed-or-not","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sentihood","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [SentiHood]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCreated as a part of the paper \"SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods\" by Saeidi et al. \n\n\t\n\t\t\n\t\tAbstract\n\t\n\nIn this paper, we introduce the task of targeted aspect-based sentiment analysis. The goal is to extract fine-grained information with respect to entities mentioned in user comments. This work extends both aspect-based sentiment analysis that assumes a single entity perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bhavnicksm/sentihood.","url":"https://huggingface.co/datasets/bhavnicksm/sentihood","creator_name":"Bhavnick Minhas","creator_url":"https://huggingface.co/bhavnicksm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","multi-class-classification","natural-language-inference","monolingual"],"keywords_longer_than_N":true},
	{"name":"LongSumEt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"LongSumEt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLongSumEt is an estonian language long summarization dataset with pages filtered from CulturaX dataset. The dataset consists of the page text, and machine generated short summary, long summary and bulletpoints.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEstonian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nMore Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/LongSumEt.","url":"https://huggingface.co/datasets/TalTechNLP/LongSumEt","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","machine-generated","monolingual","original","Estonian"],"keywords_longer_than_N":true},
	{"name":"open_question_type","keyword":"monolingual","description":"Open-ended question type annotated dataset.","url":"https://huggingface.co/datasets/launch/open_question_type","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twitter-sentiment-analysis","keyword":"monolingual","description":"The Twitter Sentiment Analysis Dataset contains 1,578,627 classified tweets, each row is marked as 1 for positive sentiment and 0 for negative sentiment.\nThe dataset is based on data from the following two sources:\n\nUniversity of Michigan Sentiment Analysis competition on Kaggle\nTwitter Sentiment Corpus by Niek Sanders\n\nFinally, I randomly selected a subset of them, applied a cleaning process, and divided them between the test and train subsets, keeping a balance between\nthe number of positive and negative tweets within each of these subsets.","url":"https://huggingface.co/datasets/carblacac/twitter-sentiment-analysis","creator_name":"Miguel Carlos Blanco CacharrÃ³n","creator_url":"https://huggingface.co/carblacac","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"LIFD_Magnetic_Field_Data","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LFID Magnetic Field Data\n\t\n\nYou will need the package\nhttps://chaosmagpy.readthedocs.io/en/master/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA description of the dataset:\nThe gufm1 model is a global geomagnetic model based on spherical harmonics, covering the period 1590 - 1990, and is described in the publication:\nAndrew Jackson, Art R. T. Jonkers and Matthew R. Walker (2000), â€œFour centuries of geomagnetic secular variation from historical recordsâ€, Phil. Trans. R. Soc.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Magnetic_Field_Data.","url":"https://huggingface.co/datasets/cemachelen/LIFD_Magnetic_Field_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","image-to-image","time-series-forecasting","object-detection","unconditional-image-generation"],"keywords_longer_than_N":true},
	{"name":"twitter_pos_vcb","keyword":"monolingual","description":"Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis data is the vote-constrained bootstrapped data generate to support state-of-the-art results.\n\nThe data is about 1.5 million English tweets annotated for part-of-speech using Ritter's extension of the PTB tagset.\nThe tweets are from 2012 and 2013, tokenized using the GATE tokenizer and tagged\njointly using the CMU ARK tagger and Ritter's T-POS tagger. Only when both these taggers' outputs\nare completely compatible over a whole tweet, is that tweet added to the dataset.\n\nThis data is recommend for use a training data **only**, and not evaluation data.\n\nFor more details see https://gate.ac.uk/wiki/twitter-postagger.html and https://aclanthology.org/R13-1026.pdf","url":"https://huggingface.co/datasets/strombergnlp/twitter_pos_vcb","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","part-of-speech","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-voice-kinyarwanda-text-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for DigitalUmuganda/common-voice-kinyarwanda-text-dataset\n\t\n\n","url":"https://huggingface.co/datasets/DigitalUmuganda/common-voice-kinyarwanda-text-dataset","creator_name":"Digital Umuganda","creator_url":"https://huggingface.co/DigitalUmuganda","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["crowd-sourced","Digital Umuganda","monolingual","original","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"textvqa","keyword":"monolingual","description":"TextVQA requires models to read and reason about text in images to answer questions about them.\nSpecifically, models need to incorporate a new modality of text present in the images and reason\nover it to answer TextVQA questions. TextVQA dataset contains 45,336 questions over 28,408 images\nfrom the OpenImages dataset.","url":"https://huggingface.co/datasets/facebook/textvqa","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"my-issues-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary in English\n\t\n\nThis customized dataset is made of a corpus of commun Github issues, typically utilized for tracking bugs or features within a repositories. This self-constructed corpus can serve multiple purposes, such as analyzing the time taken to resolve open issues or pull requests, training a classifier to tag issues based on their descriptions (e.g., \"bug,\" \"enhancement,\" \"question\"), or developing a semantic search engineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/devopsmarc/my-issues-dataset.","url":"https://huggingface.co/datasets/devopsmarc/my-issues-dataset","creator_name":"Marcello Barretto","creator_url":"https://huggingface.co/devopsmarc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOpenOrca-ru\n\t\n\nThis is translated version of Open-Orca/OpenOrca into Russian.\n","url":"https://huggingface.co/datasets/d0rj/OpenOrca-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"QA2D","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for QA2D\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we showâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D.","url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-simplification","machine-generated","crowdsourced","found","machine-generated"],"keywords_longer_than_N":true},
	{"name":"qg_dequad","keyword":"monolingual","description":"[GermanSQuAD](https://huggingface.co/datasets/deepset/germanquad) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_dequad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","deepset/germanquad","German"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","description":"BANKING77 dataset provides a very fine-grained set of intents in a banking domain.\nIt comprises 13,083 customer service queries labeled with 77 intents.\nIt focuses on fine-grained single-domain intent detection.","url":"https://huggingface.co/datasets/PolyAI/banking77","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Orchid","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOrchid: Understanding LLM-based Code Generation under Ambiguous Requirements\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nOrchid is a comprehensive benchmark dataset designed to evaluate the robustness of Large Language Models (LLMs) in handling ambiguity during code generation tasks. It extends the HumanEval dataset with four carefully crafted ambiguity types, providing a systematic way to assess how well models can identify and handle ambiguous requirements.\n\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nðŸ”¤ Lexicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SII-YDD/Orchid.","url":"https://huggingface.co/datasets/SII-YDD/Orchid","creator_name":"SII-YDD","creator_url":"https://huggingface.co/SII-YDD","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-annotated","machine-generated","monolingual","HumanEval","English"],"keywords_longer_than_N":true},
	{"name":"fake_news_filipino_parquet","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFake News Filipino (Parquet version)\n\t\n\nThis is a Parquet version of the Fake News Filipino dataset by Cruz et al., 2020.\nIt contains 3,206 Filipino-language news articles, half labeled fake (1) and half real (0).The dataset is widely used for benchmarking fake-news detection and fact-checking models in low-resource languages.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§© Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"renshhhh/fake_news_filipino_parquet\", data_files=\"train.parquet\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/renshhhh/fake_news_filipino_parquet.","url":"https://huggingface.co/datasets/renshhhh/fake_news_filipino_parquet","creator_name":"Gabriel Mari Flores","creator_url":"https://huggingface.co/renshhhh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"minimayosrs","keyword":"monolingual","description":"MiniMayoSRS is a subset of the MayoSRS and consists of 30 term pairs on which a higher inter-annotator agreement was\nachieved. The average correlation between physicians is 0.68. The average correlation between medical coders is 0.78.","url":"https://huggingface.co/datasets/bigbio/minimayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","< 1K","Tabular"],"keywords_longer_than_N":true},
	{"name":"medmentions","keyword":"monolingual","description":"MedMentions is a new manually annotated resource for the recognition of biomedical concepts.\nWhat distinguishes MedMentions from other annotated biomedical corpora is its size (over 4,000\nabstracts and over 350,000 linked mentions), as well as the size of the concept ontology (over\n3 million concepts from UMLS 2017) and its broad coverage of biomedical disciplines.\n\nCorpus: The MedMentions corpus consists of 4,392 papers (Titles and Abstracts) randomly selected\nfrom among papers released on PubMed in 2016, that were in the biomedical field, published in\nthe English language, and had both a Title and an Abstract.\n\nAnnotators: We recruited a team of professional annotators with rich experience in biomedical\ncontent curation to exhaustively annotate all UMLSÂ® (2017AA full version) entity mentions in\nthese papers.\n\nAnnotation quality: We did not collect stringent IAA (Inter-annotator agreement) data. To gain\ninsight on the annotation quality of MedMentions, we randomly selected eight papers from the\nannotated corpus, containing a total of 469 concepts. Two biologists ('Reviewer') who did not\nparticipate in the annotation task then each reviewed four papers. The agreement between\nReviewers and Annotators, an estimate of the Precision of the annotations, was 97.3%.","url":"https://huggingface.co/datasets/bigbio/medmentions","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","arxiv:1902.09476","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"nota","keyword":"monolingual","description":"Nota lyd- og tekstdata\nDatasÃ¦ttet indeholder bÃ¥de tekst- og taledata fra udvalgte dele af Nota's lydbogsbiblotek. DatasÃ¦ttet bestÃ¥r af \nover 500 timers oplÃ¦sninger og medfÃ¸lgende transkriptioner pÃ¥ dansk. Al lyddata er i .wav-format, mens tekstdata \ner i .txt-format.\n\nI data indgÃ¥r indlÃ¦sninger af Notas eget blad \"Inspiration\" og \"Radio/TV\", som er udgivet i perioden 2007 til 2022.\nNota krediteres for arbejdet med at strukturere data, sÃ¥ledes at tekst og lyd stemmer overens.\n\nNota er en institution under Kulturministeriet, der gÃ¸r trykte tekster tilgÃ¦ngelige i digitale formater til personer \nmed synshandicap og lÃ¦sevanskeligheder, fx via produktion af lydbÃ¸ger og oplÃ¦sning af aviser, magasiner, mv.","url":"https://huggingface.co/datasets/arpelarpe/nota","creator_name":"Rasmus Arpe Fogh EgebÃ¦k","creator_url":"https://huggingface.co/arpelarpe","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Danish","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"plsc","keyword":"monolingual","description":"PLSC - Polish Library of Science Corpus\n","url":"https://huggingface.co/datasets/rafalposwiata/plsc","creator_name":"RafaÅ‚ PoÅ›wiata","creator_url":"https://huggingface.co/rafalposwiata","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","multi-label-classification","monolingual"],"keywords_longer_than_N":true},
	{"name":"million-headlines","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Million Headlines\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis contains data of news headlines published over a period of eighteen years.  Sourced from the reputable Australian news source ABC (Australian Broadcasting Corporation) \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nFor each instance, there is a integer for the data, a string for news headline.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\npublish date: a integer that represents the data\nheadline: a string for the news headlineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rajistics/million-headlines.","url":"https://huggingface.co/datasets/rajistics/million-headlines","creator_name":"Rajiv Shah","creator_url":"https://huggingface.co/rajistics","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"kote","keyword":"monolingual","description":"50k Korean online comments labeled for 44 emotion categories.","url":"https://huggingface.co/datasets/searle-j/kote","creator_name":"Jeon Duyoung","creator_url":"https://huggingface.co/searle-j","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"video_tags","keyword":"monolingual","description":"The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\nimages per class. There are 60,000 training images and 10,000 test images.","url":"https://huggingface.co/datasets/filwsyl/video_tags","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"resd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for resd\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRussian dataset of emotional speech dialogues. This dataset was assembled from ~3.5 hours of live speech by actors who voiced pre-distributed emotions in the dialogue for ~3 minutes each.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/resd.","url":"https://huggingface.co/datasets/Aniemore/resd","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"central_de_fatos","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCentral de Fatos\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking agencies.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos.","url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sd-nlp-non-tokenized","keyword":"monolingual","description":"    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.","url":"https://huggingface.co/datasets/EMBO/sd-nlp-non-tokenized","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","text-classification","multi-class-classification","named-entity-recognition","parsing"],"keywords_longer_than_N":true},
	{"name":"jd21","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/kuroneko5943/jd21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"rumoureval_2019","keyword":"monolingual","description":"\nStance prediction task in English. The goal is to predict whether a given reply to a claim either supports, denies, questions, or simply comments on the claim. Ran as a SemEval task in 2019.","url":"https://huggingface.co/datasets/strombergnlp/rumoureval_2019","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"stock11","keyword":"monolingual","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_mgoblog-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_mgoblog-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"xtreme_en_language_drift_es","keyword":"monolingual","description":"This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.","url":"https://huggingface.co/datasets/arize-ai/xtreme_en_language_drift_es","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster16","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster16","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cappex-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cappex-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_unique","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_unique","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"chartve_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ChartVE's Training Data\n\t\n\n\nDataset Description\nPaper Information\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nChartVE (Chart Visual Entailment) is a visual entailment model introduced in the paper \"Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning\" for evaluating the factuality of a generated caption sentence with regard to the input chart. The model takes in a chart figure and a caption sentence as input, and outputs anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/chartve_dataset.","url":"https://huggingface.co/datasets/khhuang/chartve_dataset","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"spellcheck_punctuation_benchmark","keyword":"monolingual","description":"Russian Spellcheck Benchmark is a new benchmark for spelling correction in Russian language.\n                It includes four datasets, each of which consists of pairs of sentences in Russian language. \n                Each pair embodies sentence, which may contain spelling errors, and its corresponding correction. \n                Datasets were gathered from various sources and domains including social networks, internet blogs, github commits, \n                medical anamnesis, literature, news, reviews and more.","url":"https://huggingface.co/datasets/ai-forever/spellcheck_punctuation_benchmark","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"Dataset2","keyword":"monolingual","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.","url":"https://huggingface.co/datasets/MajdTannous/Dataset2","creator_name":"Majd Tannous","creator_url":"https://huggingface.co/MajdTannous","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"canarim","keyword":"monolingual","description":"\n  \n\n\n\n  [ðŸ± GitHub]\n\n\n\n\n\n\n\t\n\t\t\n\t\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim.","url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"Alpaca-cnn-dailymail","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tData Summary\n\t\n\nData set Alpaca-cnn-dailymail is a data set version format changed by ccdv/cnn_dailymail to meet Alpaca fine-tuning Llama2. Only versions 3.0.0 and 2.0.0 were used for merging and as a key data set for the summary extraction task.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe Alpaca-cnn-dailymail dataset version 1.0.0 is released under the Apache-2.0 License.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{see-etal-2017-get,\n    title = \"Get To The Point: Summarization withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail.","url":"https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail","creator_name":"Zhongsheng Wang","creator_url":"https://huggingface.co/ZhongshengWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_support-google-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"scitail","keyword":"monolingual","description":"The SciTail dataset is an entailment dataset created from multiple-choice science exams and\nweb sentences. Each question and the correct answer choice are converted into an assertive\nstatement to form the hypothesis. We use information retrieval to obtain relevant text from\na large text corpus of web sentences, and use these sentences as a premise P. We crowdsource\nthe annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order\nto create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with\nentails label and 16,925 examples with neutral label.","url":"https://huggingface.co/datasets/bigbio/scitail","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"unpredictable_5k","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_5k","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"NERDE","keyword":"monolingual","description":"(pt) NERDE Ã© um dataset para NER a partir de documentos jurÃ­dicos da defesa econÃ´mica em portuguÃªs do Brasil, foi criado em colaboraÃ§Ã£o com o Cade e o laboratÃ³rio LATITUDE/UnB.\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory.","url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","description":"The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\nprogramming problems, designed to be solvable by entry level programmers, covering programming\nfundamentals, standard library functionality, and so on. Each problem consists of a task\ndescription, code solution and 3 automated test cases.","url":"https://huggingface.co/datasets/Muennighoff/mbpp","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster27","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster27","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_wkdu-org","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_wkdu-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster12","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster12","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cram-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_cram-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit-r-bitcoin-data-for-jun-2022","keyword":"monolingual","description":"Lite version of our Reddit /r/Bitcoin dataset - CSV of all posts & comments to the /r/Bitcoin subreddit over Jun 2022.","url":"https://huggingface.co/datasets/SocialGrep/reddit-r-bitcoin-data-for-jun-2022","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"unpredictable_dummies-com","keyword":"monolingual","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","url":"https://huggingface.co/datasets/MicPie/unpredictable_dummies-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"one-year-of-tsla-on-reddit","keyword":"monolingual","description":"This dataset contains all the posts and comments mentioning the term \"TSLA\", spanning from July 5th, 2021 to July 4th, 2022.","url":"https://huggingface.co/datasets/SocialGrep/one-year-of-tsla-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"code-penitentiaire","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode pÃ©nitentiaire, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode des pensions militaires d'invaliditÃ© et des victimes de guerre, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"japan_diet_q_and_a_sessions_20k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tJapan Diet Q&A Sessions Dataset\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nThis dataset was created by scraping the parliamentary questions and answers webpage. \nAs of March 27, 2024, it includes 216 sessions.\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Consists of three parts. \nThe initial alphabet indicates whether it is a question (a) or an answer (b).\nThe next three digits represent the session number of the parliament.\nThe last three digits are the question number within the parliament session.\n\n\ntitle: The titleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k.","url":"https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k","creator_name":"takashi miwa","creator_url":"https://huggingface.co/notoxicpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","Japanese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AttaQ","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tAttaQ Dataset Card\n\t\n\nThe AttaQ red teaming dataset, consisting of 1402 carefully crafted adversarial questions, is designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses. \nIt may serve as a benchmark to assess the potential harm of responses produced by LLMs. \nThe dataset is categorized into seven distinct classes of questions: deception, discrimination, harmful information, substance abuse, sexual content, personallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ.","url":"https://huggingface.co/datasets/ibm-research/AttaQ","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","extended|Anthropic/hh-rlhf","English","mit"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-poems","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-poems is an open source dataset of instruct-style records generated by webscraping a Telugu poems website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\naya-telugu-poems is a corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CHOCOLATE","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CHOCOLATE\n\t\n\n\nDataset Description\nPaper Information\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nCHOCOLATE is a benchmark for detecting and correcting factual inconsistency in generated chart captions. It consists of captions produced by six most advanced models, which are categorized into three subsets:\n\nLVLM: GPT-4V, Bard (before Gemini)\nLLM-based Pipeline: DePlot + GPT-4\nFine-tuned Model: ChartT5, MatCha, UniChart\n\nThe charts are from two datasets: VisText and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/CHOCOLATE.","url":"https://huggingface.co/datasets/khhuang/CHOCOLATE","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","found","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"kpwr-ner","keyword":"monolingual","description":"KPWR-NER tagging dataset.","url":"https://huggingface.co/datasets/clarin-pl/kpwr-ner","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["other","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"germanquad","keyword":"monolingual","description":"In order to raise the bar for non-English QA, we are releasing a high-quality, human-labeled German QA dataset consisting of 13 722 questions, incl. a three-way annotated test set.\nThe creation of GermanQuAD is inspired by insights from existing datasets as well as our labeling experience from several industry projects. We combine the strengths of SQuAD, such as high out-of-domain performance, with self-sufficient questions that contain all relevant information for open-domain QA as in the NaturalQuestions dataset. Our training and test datasets do not overlap like other popular datasets and include complex questions that cannot be answered with a single entity or only a few words.","url":"https://huggingface.co/datasets/deepset/germanquad","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"cococon","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for CoCoCON\n\t\n\n\nDataset Description\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nConsiderations for Using the Data\nLicensing Information\nCitation Information\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nCocoCON is a challenging dataset for evaluating cross-task consistency in vision-and-language models. We use contrast sets created by modifying COCO test instances for multiple tasks in small but semantically meaningful ways to change the gold label, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adymaharana/cococon.","url":"https://huggingface.co/datasets/adymaharana/cococon","creator_name":"Adyasha Maharana","creator_url":"https://huggingface.co/adymaharana","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"lipo","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for lipo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nlipo is a dataset included in MoleculeNet. It measures the experimental results of octanol/water distribution coefficient(logD at pH 7.4)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: octanol/water distribution coefficient(logD at pH 7.4)\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zpn/lipo.","url":"https://huggingface.co/datasets/zpn/lipo","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"tamil_asr_corpus","keyword":"monolingual","description":"The corpus contains roughly 1000 hours of audio and trasncripts in Tamil language. The transcripts have beedn de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/tamil_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"ancora-ca-ner","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AnCora-Ca-NER\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for Named Entity Recognition (NER) in Catalan. It adapts AnCora corpus for Machine Learning and Language Model evaluation purposes.\nThis dataset was developed by BSC TeMU as part of the Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNamed Entities Recognition, Language Model\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe dataset is in Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/ancora-ca-ner.","url":"https://huggingface.co/datasets/projecte-aina/ancora-ca-ner","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","Catalan","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"squad_v2_pt","keyword":"monolingual","description":"combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers\n to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but\n also determine when no answer is supported by the paragraph and abstain from answering.","url":"https://huggingface.co/datasets/cjaniake/squad_v2_pt","creator_name":"Christian Janiake","creator_url":"https://huggingface.co/cjaniake","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"SeeTRUE-Feedback","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for SeeTRUE-Feedback\n\t\n\n\nDataset Description\nSupported Tasks and Leaderboards\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nLicensing Information\nCitation Information\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe SeeTRUE-Feedback dataset is a diverse benchmark for the meta-evaluation of image-text matching/alignment feedback. It aims to overcome limitations in current benchmarks, which primarily focus on predicting a matching score between 0-1. SeeTRUEâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback.","url":"https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback","creator_name":"mismatch-quest","creator_url":"https://huggingface.co/mismatch-quest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Marathon","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Marathon\n\t\n\n\n\t\n\t\t\n\t\tRelease\n\t\n\n\n[2024/05/15] ðŸ”¥ Marathon is accepted by ACL 2024 Main Conference.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMarathon benchmark is a new long-context multiple-choice benchmark, mainly based on LooGLE, with some original data from LongBench. The context length can reach up to 200K+. Marathon benchmark comprises six tasks: Comprehension and Reasoning, Multiple Information Retrieval, Timeline Reorder, Computation, Passage Retrieval, and Short Dependencyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lemoncoke/Marathon.","url":"https://huggingface.co/datasets/Lemoncoke/Marathon","creator_name":"Lei Zhang","creator_url":"https://huggingface.co/Lemoncoke","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","no-annotation","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"CUADInsuranceLegalBenchClassification","keyword":"monolingual","description":"\n  CUADInsuranceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if clause creates a requirement for insurance that must be maintained by one party for the benefit of the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCTreatmentRetrieval","keyword":"monolingual","description":"\n  R2MEDPMCTreatmentRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Treatment retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Treatment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCTreatmentRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Treatment"],"keywords_longer_than_N":true},
	{"name":"rutube-channels","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Rutube channels\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from channel pages on the Russian video-sharing platform Rutube. It includes all information from the channel card. The dataset was collected by processing 36 million channels, starting from the first one. At the time the dataset was collected, it is assumed that these were all the channels available on this platform. Some fields may be empty, but the string is expected to contain some data, emptyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rutube-channels.","url":"https://huggingface.co/datasets/nyuuzyou/rutube-channels","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"babelbox_voice","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Babelbox Voice\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis database was created by Nordic Language Technology for the development of automatic speech recognition and dictation in Swedish. \nIt is redistributed as a Hugging Face dataset for convienience.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSwedish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/babelbox/babelbox_voice.","url":"https://huggingface.co/datasets/babelbox/babelbox_voice","creator_name":"BabelBox","creator_url":"https://huggingface.co/babelbox","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"catalan_government_crawling","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Catalan Government Crawling\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Catalan Government Crawling Corpus is a 39-million-token web corpus of Catalan built from the web. It has been obtained by crawling the .gencat domain and subdomains, belonging to the Catalan Government during September and October 2020. It consists of 39,117,909 tokens, 1,565,433 sentences and 71,043 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_government_crawling.","url":"https://huggingface.co/datasets/projecte-aina/catalan_government_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MNLP_M2_mcqa_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M2 MCQA Dataset\n\t\n\nThe MNLP M2 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~26,000 MCQA questions\n7 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-android","keyword":"monolingual","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackAndroidRetrieval\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-android.","url":"https://huggingface.co/datasets/mteb/cqadupstack-android","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"InsurancePolicyInterpretationLegalBenchClassification","keyword":"monolingual","description":"\n  InsurancePolicyInterpretationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven an insurance claim and policy, determine whether the claim is covered by the policy.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"crater_binary_segmentation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tcrater_binary_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Crater\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/crater_binary_segmentation.","url":"https://huggingface.co/datasets/gremlin97/crater_binary_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Urdu"],"keywords_longer_than_N":true},
	{"name":"GR-III-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"IndonesianIdClickbaitClassification","keyword":"monolingual","description":"\n  IndonesianIdClickbaitClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\nReference\nhttp://www.sciencedirect.com/science/article/pii/S2352340920311252\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification.","url":"https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"domars16k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdomars16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-12\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: aec\n1: ael\n2: cli\n3: cra\n4: fse\n5: fsf\n6: fsg\n7: fss\n8: mix\n9: rid\n10: rou\n11: sfe\n12: sfx\n13: smo\n14: tex\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 1639 images\ntest: 234 images\nval: 469 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/domars16k.","url":"https://huggingface.co/datasets/gremlin97/domars16k","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SciVer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSCIVER: A Benchmark for Multimodal Scientific Claim Verification\n\t\n\n\n  ðŸŒ Github â€¢\n  ðŸ“– Paper â€¢\n  ðŸ¤— Data\n\n\n\n\n\t\n\t\t\n\t\tðŸ“° News\n\t\n\n\n[May 15, 2025] SciVer has been accepted by ACL 2025 Main!\n\n\n\t\n\t\t\n\t\tðŸ‘‹ Overview\n\t\n\n\nSCIVER is the first benchmark specifically designed to evaluate the ability of foundation models to verify scientific claims across text, charts, and tables. It challenges models to reason over complex, multimodal contexts with fine-grained entailment labels andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengyewang/SciVer.","url":"https://huggingface.co/datasets/chengyewang/SciVer","creator_name":"chengyewang","creator_url":"https://huggingface.co/chengyewang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"SFT_54k_reasoning","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/SFT_54k_reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/SFT_54k_reasoning is a processed version of the XuHu6736/s1_54k_filter_with_isreasoning dataset, specifically reformatted for instruction fine-tuning (SFT) of language models.\nThe original question and solution pairs have been converted into an instruction-following format. Critically, the isreasoning_score and isreasoning labels from the parent dataset are preserved, allowing for targeted SFT onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning.","url":"https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["XuHu6736 (formatting and derivation)","derived from XuHu6736/s1_54k_filter_with_isreasoning","derived from source datasets","monolingual","XuHu6736/s1_54k_filter_with_isreasoning"],"keywords_longer_than_N":true},
	{"name":"BC-II-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"COVID-QA-el-small","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-QA-el-small\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe COVID-QA-el-small dataset is a Greek-language subset of 826 examples derived from the COVID-QA-el dataset, translated using machine translation. The dataset follows the SQuADv1.1 fashion style. \nThe original dataset, COVID-QA: A Question Answering Dataset for COVID-19  (ACL 2020) contains 2,019 question-answer pairs annotated by volunteer biomedical experts on scientific literature about COVID-19.\n\n\t\n\t\t\n\t\n\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-QA-el-small.","url":"https://huggingface.co/datasets/panosgriz/COVID-QA-el-small","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","monolingual","deepset/covid_qa_deepset"],"keywords_longer_than_N":true},
	{"name":"DBPedia_test_top_250_only_w_correct-v2","keyword":"monolingual","description":"\n  DBPediaHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2.","url":"https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","mteb/dbpedia","English"],"keywords_longer_than_N":true},
	{"name":"synthetic_dropout_dataset_vietnam_100k_final_lhu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tStudent Dropout Prediction Dataset (Lac Hong University - Synthetic)\n\t\n\nThis dataset is a synthetically generated dataset representing student academic and behavioral data at Lac Hong University.\nIt is intended for machine learning tasks that predict student dropout risks.\n\n\t\n\t\t\n\t\tðŸ“Š Features\n\t\n\n\nStudentID: Unique student identifier (format: 1YYxxxxxx)\nLUC: Lack of University Commitment (Likert 1â€“5)\nDCC: Degree Commitment Conflict (Likert 1â€“5)\nITM: Ineffective Time Management (Likertâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LHUThacSi/synthetic_dropout_dataset_vietnam_100k_final_lhu.","url":"https://huggingface.co/datasets/LHUThacSi/synthetic_dropout_dataset_vietnam_100k_final_lhu","creator_name":"LHU Thac Si","creator_url":"https://huggingface.co/LHUThacSi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mnist","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\nHalf of the image were drawn by Census Bureau employees and the other half by high school studentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minpeter/mnist.","url":"https://huggingface.co/datasets/minpeter/mnist","creator_name":"minpeter","creator_url":"https://huggingface.co/minpeter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"BornholmBitextMining","keyword":"monolingual","description":"\n  BornholmBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Bornholmsk Parallel Corpus. Bornholmsk is a Danish dialect spoken on the island of Bornholm, Denmark. Historically it is a part of east Danish which was also spoken in Scania and Halland, Sweden.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nWeb, Social, Fiction, Written\n\n\nReference\nhttps://aclanthology.org/W19-6138/\n\n\n\t\n\nSource datasets:\n\nstrombergnlp/bornholmsk_parallel\n\n\n\t\n\t\t\n\t\tHow to evaluate on this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BornholmBitextMining.","url":"https://huggingface.co/datasets/mteb/BornholmBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","monolingual","strombergnlp/bornholmsk_parallel","Danish"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset_2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_2.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_2","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Tree_Images_PT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸŒ³ Tree Images Dataset\n\t\n\nThis dataset contains labeled images of the three most common Mediterranean tree species in Portugal:\n\nEucalyptus globulus\nPinus pinaster\nQuercus suber\n\nThese images were scrapped from GBIF\nAll images pretain to Portugal\nAll images have CC_BY_4_0 or CC0\n","url":"https://huggingface.co/datasets/Diogo-Janice-Rafael/Tree_Images_PT","creator_name":"Diogo Janice e Rafael","creator_url":"https://huggingface.co/Diogo-Janice-Rafael","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multi-class-classification","monolingual","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"192-Youtube-Channel-Views-Count","keyword":"monolingual","description":"\n\t\n\t\t\n\t\t192 YouTube Channel Views Count\n\t\n\nThis project compiles and analyzes data from 192 YouTube channels, totaling approximately 166,411 videos. The dataset includes information such as video titles, view counts, publish dates, and authors.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe 192 YouTube Channel Views Count project aims to provide insights and analytics on video performance across 192 different YouTube channels. By aggregating data such as video titles, view counts, publish dates, and authorsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count.","url":"https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count","creator_name":"Muhammad Suleman","creator_url":"https://huggingface.co/leodeveloper2000","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"wikinews-fr-100_fr_prompt_data_to_text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\twikinews-fr-100_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwikinews-fr-100_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 3,000 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text.","url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/wikinews-fr-100"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"logical","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Satyam-Singh/logical.","url":"https://huggingface.co/datasets/Satyam-Singh/logical","creator_name":"Satyam Singh","creator_url":"https://huggingface.co/Satyam-Singh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"CUADEffectiveDateLegalBenchClassification","keyword":"monolingual","description":"\n  CUADEffectiveDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the agreement becomes effective.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, UniversitÃ¤t Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"corpus-carolina","keyword":"monolingual","description":"Carolina is an Open Corpus for Linguistics and Artificial Intelligence with a\nrobust volume of texts of varied typology in contemporary Brazilian Portuguese\n(1970-).","url":"https://huggingface.co/datasets/carolina-c4ai/corpus-carolina","creator_name":"Carolina C4AI","creator_url":"https://huggingface.co/carolina-c4ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Urdu"],"keywords_longer_than_N":true},
	{"name":"allocine_fr_prompt_sentiment_analysis","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tallocine_fr_prompt_sentiment_analysis\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nallocine_fr_prompt_sentiment_analysis is a subset of the Dataset of French Prompts (DFP).It contains 5,600,000 rows that can be used for a binary sentiment analysis task.The original data (without prompts) comes from the dataset allocine by Blard.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis.","url":"https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","allocine"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"mathlibretrieval","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tInformalized Mathlib4 Retrieval Dataset\n\t\n\nThe goal is to retrieve relevant mathlib4 theorems based on informal mathematical queries. Sourced from https://huggingface.co/datasets/hcju/leansearch_bench/\n","url":"https://huggingface.co/datasets/hcju/mathlibretrieval","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","leansearch","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Assamese"],"keywords_longer_than_N":true},
	{"name":"aircraft-images","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for High-Resolution Aircraft Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 165,340 high-resolution aircraft images collected from the internet, along with machine-generated captions. The captions were generated using Gemini Flash 1.5 AI model and are stored in separate text files matching the image filenames.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All image captions are in English\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/aircraft-images.","url":"https://huggingface.co/datasets/nyuuzyou/aircraft-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"rule34lol-webm","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Rule34.lol WebM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about WebM files from Rule34.lol, a booru-style imageboard. The dataset includes metadata for 22,733 WebM files, including URLs, tags, and file information. The actual WebM files are stored in zip archives, with each archive containing 500 WebM files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset metadata is primarily in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rule34lol-webm.","url":"https://huggingface.co/datasets/nyuuzyou/rule34lol-webm","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ambientcg","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AmbientCG Textures and HDRIs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 14,202 high-quality texture images and HDRI environments from ambientcg.com. It includes a comprehensive collection of materials such as fabric, metal, wood, stone, concrete, nature elements, and HDRI skyboxes for 3D rendering and computer graphics applications. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compressionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ambientcg.","url":"https://huggingface.co/datasets/nyuuzyou/ambientcg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"programmerhumor","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ProgrammerHumor.io Memes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains programming-related memes and humor content collected from programmerhumor.io, along with associated metadata such as titles, categories, tags, and image captions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All meme content and descriptions are primarily in English\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nThe dataset consists of:\n\nImage files (stored inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/programmerhumor.","url":"https://huggingface.co/datasets/nyuuzyou/programmerhumor","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringS2S.v2","keyword":"monolingual","description":"\n  PlscClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2.","url":"https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-s2s"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Telugu"],"keywords_longer_than_N":true},
	{"name":"bioinfo-bench_preprocess","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBioinfo Bench Preprocessed Dataset\n\t\n\nThis dataset is a pre-processed and automatically evaluated version ofQiyuan04/bioinfo-bench.\n\n\t\n\t\t\n\t\tPre-processing Summary\n\t\n\n\nFlexible loading â€“ handled inconsistent columns with pandas.\nFix missing answers â€“ inferred Correct Answer from \"Option D\" when necessary.\nFilter invalid rows â€“ kept only rows whose answer âˆˆ {A, B, C, D}.\nFormat options â€“ prefixed each choice with A:, B:, â€¦ .\nCombine for SFT â€“ joined question + options into question;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/bioinfo-bench_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/bioinfo-bench_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"HunSum2AbstractiveRetrieval","keyword":"monolingual","description":"\n  HunSum2AbstractiveRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHunSum-2-abstractive is a Hungarian dataset containing news articles along with lead, titles and metadata.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.03555\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HunSum2AbstractiveRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval.","url":"https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Hungarian"],"keywords_longer_than_N":true},
	{"name":"Diversity3LegalBenchClassification","keyword":"monolingual","description":"\n  Diversity3LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 3).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"RomanianReviewsSentiment","keyword":"monolingual","description":"\n  RomanianReviewsSentiment\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2101.04197\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RomanianReviewsSentiment\")\nevaluator = mteb.MTEB([task])\n\nmodelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RomanianReviewsSentiment.","url":"https://huggingface.co/datasets/mteb/RomanianReviewsSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lighteval/mmlu.","url":"https://huggingface.co/datasets/lighteval/mmlu","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"clone-of-gretel-financial-risk-analysis-v1","keyword":"monolingual","description":"\nâš ï¸ðŸ”´ IMPORTANT NOTICE ðŸ”´âš ï¸\nThis dataset is directly cloned from gretelai/gretel-financial-risk-analysis-v1 on Hugging Face. No modifications have been made to the original dataset, it is only for archival.\n\n\n\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated using differential privacy guarantees, trained on 14,306 SEC (10-K, 10-Q, and 8-k) filings from 2023-2024. The dataset is designed for training models to extractâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"monolingual","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V1 dataset (last update 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"NFR_Spanish_requirements_classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nReSpaN(Spanish Dataset for non-functional requirements classification): Published version of dataset used for paper 'Towards a FAIR Dataset for non-functional requirements'.This dataset was created following the FAIR principles. \n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nIn the dataset_structure file.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tInitial Data Collection and Normalization\n\t\n\nThis dataset was createdâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification.","url":"https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"cms_iom_500","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcdsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_500.","url":"https://huggingface.co/datasets/evekhm/cms_iom_500","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","https://www.cms.gov/medicare-coverage-database","https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms"],"keywords_longer_than_N":true},
	{"name":"conequest_detection","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tconequest_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: cone\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/conequest_detection.","url":"https://huggingface.co/datasets/gremlin97/conequest_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MNIST","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ–¼ï¸ MNIST (Extracted from PyTorch Vision)\n\t\n\nMNIST is a classic dataset of handwritten digits, widely used for image classification tasks in machine learning.\n\n\t\n\t\t\n\t\tâ„¹ï¸ Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Dataset Description\n\t\n\nThe MNIST database of handwritten digits is a commonly used benchmark dataset in machine learning. It consists of 70,000 grayscale images of handwritten digits (0-9), each with a size of 28x28 pixels. The dataset is split into 60,000 training images and 10,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/MNIST.","url":"https://huggingface.co/datasets/p2pfl/MNIST","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"techcrunch-articles","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTechCrunch News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 10,265 high-quality news articles scraped from TechCrunch, one of the leading technology news websites. The dataset includes comprehensive article content, metadata, and quality assessments suitable for various NLP tasks including text classification, sentiment analysis, summarization, and content generation.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\n10,265 articles with full text content\nHigh-quality filteringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/techcrunch-articles.","url":"https://huggingface.co/datasets/abhilash88/techcrunch-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"OMIM_from_GPA-MSA","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_mendelian_traits_chr11_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/OMIM_from_GPA-MSA.","url":"https://huggingface.co/datasets/Bgoood/OMIM_from_GPA-MSA","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"NorwegianParliamentClassification","keyword":"monolingual","description":"\n  NorwegianParliamentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNorwegian parliament speeches annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nGovernment, Spoken\n\n\nReference\nhttps://huggingface.co/datasets/NbAiLab/norwegian_parliament\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NorwegianParliamentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianParliamentClassification.","url":"https://huggingface.co/datasets/mteb/NorwegianParliamentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Norwegian BokmÃ¥l","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADThirdPartyBeneficiaryLegalBenchClassification","keyword":"monolingual","description":"\n  CUADThirdPartyBeneficiaryLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that that there a non-contracting party who is a beneficiary to some or all of the clauses in the contract and therefore can enforce its rights against a contracting party.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MiniF2F","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tminif2f Dataset\n\t\n\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F.","url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","explanation-generation","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"RUParaPhraserSTS","keyword":"monolingual","description":"\n  RUParaPhraserSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nParaPhraser is a news headlines corpus with precise, near and non-paraphrases.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://aclanthology.org/2020.ngt-1.6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RUParaPhraserSTS\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RUParaPhraserSTS.","url":"https://huggingface.co/datasets/mteb/RUParaPhraserSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","merionum/ru_paraphraser"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"monolingual","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"CUADMostFavoredNationLegalBenchClassification","keyword":"monolingual","description":"\n  CUADMostFavoredNationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a third party gets better terms on the licensing or sale of technology/goods/services described in the contract, the buyer of such technology/goods/services under the contract shall be entitled to those better terms.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"iris-clase","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"iris\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Iris dataset is one of the most classic datasets in machine learning, often used for classification and clustering tasks. It contains 150 samples of iris flowers, each described by four features: sepal length, sepal width, petal length, and petal width. The task is to classify the samples into one of three species: Iris setosa, Iris versicolor, or Iris virginica.\nThis dataset is especially useful for:\n\nSupervised learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aegarciaherrera/iris-clase.","url":"https://huggingface.co/datasets/aegarciaherrera/iris-clase","creator_name":"AndrÃ©s Eduardo GarcÃ­a Herrera","creator_url":"https://huggingface.co/aegarciaherrera","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","multi-class-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"CUADUncappedLiabilityLegalBenchClassification","keyword":"monolingual","description":"\n  CUADUncappedLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party's liability is uncapped upon the breach of its obligation in the contract. This also includes uncap liability for a particular type of breach such as IP infringement or breach of confidentiality obligation.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"TamilNewsClassification","keyword":"monolingual","description":"\n  TamilNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Tamil dataset for 6-class classification of Tamil news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/vanangamudi/tamil-news-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TamilNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TamilNewsClassification.","url":"https://huggingface.co/datasets/mteb/TamilNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/tamil_news_classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adaptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"formatted_miromind-1000","keyword":"monolingual","description":"mssfj/formatted_miromind-1000 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mssfj/formatted_miromind-1000","creator_name":"Masashi Fujimoto","creator_url":"https://huggingface.co/mssfj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"haitian-creole-synthetic-v1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHaitian Creole Synthetic Dataset v2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a synthetic dataset of Haitian Creole text samples across multiple domains, including legal, medical, education, business, technology, daily life, and culture. The dataset is designed for natural language processing tasks such as text classification, language modeling, and machine translation.\n\n\t\n\t\t\n\t\tDataset Splits\n\t\n\n\n\t\n\t\t\nSplit\nSamples\nDescription\n\n\n\t\t\nTrain\n908\nTraining set\n\n\nValidation\n113\nValidation setâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vladimirht/haitian-creole-synthetic-v1.","url":"https://huggingface.co/datasets/Vladimirht/haitian-creole-synthetic-v1","creator_name":"VladVador","creator_url":"https://huggingface.co/Vladimirht","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","language-modeling","synthetic"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval","keyword":"monolingual","description":"\n  NLPJournalAbsArticleRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Maithili"],"keywords_longer_than_N":true},
	{"name":"iris-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIris Dataset\n\t\n\nThe classic Iris dataset in .parquet format. Useful for ML demos, classification tasks, and model testing.\n","url":"https://huggingface.co/datasets/DmytroSerbeniuk/iris-dataset","creator_name":"Dmytro Serbeniuk","creator_url":"https://huggingface.co/DmytroSerbeniuk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","monolingual","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TextualismToolDictionariesLegalBenchClassification","keyword":"monolingual","description":"\n  TextualismToolDictionariesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a paragraph from a judicial opinion is applying a form textualism that relies on the dictionary meaning of terms.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TextualismToolDictionariesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/TextualismToolDictionariesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"LMTuberEval","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for LMTuberEval\n\t\n\nTraining LLMs to convincingly emulate VTubers requires rigorous evaluation of their knowledge, encompassing both specific VTuber details and the broader VTuber landscape.  Current LLMs often struggle with factuality, particularly regarding lesser-known VTubers, frequently resorting to hallucination and generating incorrect information. This benchmark addresses the critical need for objective measurement of this specialized knowledge, which is currentlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shadowlilac/LMTuberEval.","url":"https://huggingface.co/datasets/shadowlilac/LMTuberEval","creator_name":"ShadowLilac","creator_url":"https://huggingface.co/shadowlilac","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","ai-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mars-seg_mer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmars-seg_mer\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-seg_mer.","url":"https://huggingface.co/datasets/gremlin97/mars-seg_mer","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringS2S.v2","keyword":"monolingual","description":"\n  CLSClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringS2S.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2.","url":"https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringS2S"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"monolingual","description":"\n  AmazonPolarityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAmazon Polarity Classification Dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/amazon_polarity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonPolarityClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_polarity.","url":"https://huggingface.co/datasets/mteb/amazon_polarity","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"github-issues-updated","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“Š GitHub Issues Dataset (HuggingFace/datasets Repository)\n\t\n\nThis dataset contains structured GitHub issues scraped from the huggingface/datasets repository. It is intended for NLP tasks, topic modeling, issue classification, and software engineering research.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Œ Dataset Summary\n\t\n\n\nRepository Source: huggingface/datasets\nScraped via: GitHub REST API v3\nTotal Issues: ~7,465\nCollected On: June 25, 2025\nFormat: JSONL â†’ loaded via Arrow for Hugging Face\nLanguage: Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rIsHu009/github-issues-updated.","url":"https://huggingface.co/datasets/rIsHu009/github-issues-updated","creator_name":"Naman Chanana","creator_url":"https://huggingface.co/rIsHu009","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","extractive-qa","unknown","found"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Urdu"],"keywords_longer_than_N":true},
	{"name":"taln-archives_fr_prompt_data_to_text","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttaln-archives_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntaln-archives_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 35,370 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text.","url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/taln-archives"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Oriya"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNFCorpus.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNFCorpus-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNFCorpus","French"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-tex","keyword":"monolingual","description":"\n  CQADupstackTexRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackTexRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-tex.","url":"https://huggingface.co/datasets/mteb/cqadupstack-tex","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"xlam-function-calling-60k-raw-augmented","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tXLAM Function Calling 60k Raw Augmented Dataset\n\t\n\nThis dataset includes augmented train and test splits derived from product-science/xlam-function-calling-60k-raw.\n\nTrain split size: Original size plus augmented data\nTest split size: Original size plus augmented data\n\n\n\t\n\t\t\n\t\n\t\n\t\tAugmentation Details\n\t\n\nThis dataset has been augmented by modifying function names in the original data. Randomly selected function names have underscores replaced with periods at random positionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented.","url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","language-modeling","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"R2MEDIIYiClinicalRetrieval","keyword":"monolingual","description":"\n  R2MEDIIYiClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIIYi-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/IIYi-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDIIYiClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/IIYi-Clinical"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset\n\t\n\nThis dataset contains image data and explanations for deepfake detection analysis. It includes:\n\nOriginal images\nCAM (Class Activation Map) visualizations\nDetailed technical and non-technical explanations\nConfidence scores and labels\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\ncombined_dataset.csv: The main dataset file containing all information including:\nImage paths\nLabels\nConfidence scores\nTechnical and non-technical explanations for each query\n\n\nimages/: Directoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset.","url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"wikipedia-paragraph-sft","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tWikipedia Paragraph Supervised Finetuning Dataset\n\t\n\n\n\t\n\t\t\n\t\tModel Description\n\t\n\nThis dataset is designed for training language models to generate supervised finetuning data from raw text. It consists of text passages and corresponding question-answer pairs in JSONLines format.\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\nThe primary purpose of this dataset is to enable large language models (LLMs) to generate high-quality supervised finetuning data from raw text inputs, useful for creating customâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/wikipedia-paragraph-sft.","url":"https://huggingface.co/datasets/agentlans/wikipedia-paragraph-sft","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","abstractive-qa","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may independently develop information similar to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cuebench","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCUEBench: Contextual Unobserved Entity Benchmark\n\t\n\nCUEBench is a neurosymbolic benchmark that emphasizes contextual entity prediction in autonomous driving scenes. Unlike traditional detection tasks, CUEBench focuses on reasoning over unobserved entities â€” objects that may be occluded, out-of-frame, or affected by sensor failures.\n\n\t\n\t\t\n\t\tTask\n\t\n\nInput: A scene ID and a set of observed_classes present in the scene\nOutput: Predict the target_classes that were present but unobservedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ishwarbb23/cuebench.","url":"https://huggingface.co/datasets/ishwarbb23/cuebench","creator_name":"Ishwar B","creator_url":"https://huggingface.co/ishwarbb23","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","human-annotated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ECD-10k-Images","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEffective Training Data Synthesis for Improving MLLM Chart Understanding\n\t\n\nThe Effective Chart Dataset (ECD-10k-Images) is a high-quality, multimodal dataset designed to enhance chart understanding capabilities in Multimodal Large Language Models (MLLMs). This dataset includes over 10,000 synthetic chart images and 321,544 QA pairs (both descriptive and reasoning) spanning 29 chart types, 25 themes, and 252 unique chart combinations. By addressing data realism, complexity, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChartFoundation/ECD-10k-Images.","url":"https://huggingface.co/datasets/ChartFoundation/ECD-10k-Images","creator_name":"Chart Foundation Research","creator_url":"https://huggingface.co/ChartFoundation","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","GPT-4o-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"My","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMy Face Dataset\n\t\n\nThis dataset contains a collection of face images with corresponding text descriptions (prompts). It is designed for applications such as:\n\nFine-tuning diffusion models (e.g., Stable Diffusion, LoRA)\nFace recognition\nText-to-image generation\n\n\n\t\n\t\t\n\t\tðŸ§¾ Dataset Structure\n\t\n\n\ntrain/ â€” folder containing all the .jpg image files.\nmetadata.jsonl â€” a JSON Lines file where each line is a JSON object with the following fields:\nfile_name: name of the image file.\ntext: aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ochir04075143/My.","url":"https://huggingface.co/datasets/Ochir04075143/My","creator_name":"Ochir","creator_url":"https://huggingface.co/Ochir04075143","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-to-image","manually-created","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"my-cosmopedia-dataset","keyword":"monolingual","description":"ðŸ§¾ Dataset Description\nThe Pre-processed and Cleaned Cosmopedia Dataset is a ready-to-use derivative of the original HuggingFaceTB/cosmopedia\n collection.\nCosmopedia is a large-scale synthetic dataset consisting of high-quality textbooks, blog posts, stories, tutorials, and forum discussions generated by Mixtral-8x7B. While the raw dataset is incredibly rich, it requires significant preprocessing before it can be used effectively for supervised fine-tuning (SFT) or other instruction-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/blah7/my-cosmopedia-dataset.","url":"https://huggingface.co/datasets/blah7/my-cosmopedia-dataset","creator_name":"blah","creator_url":"https://huggingface.co/blah7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","monolingual","HuggingFaceTB/cosmopedia","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"openclipart","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OpenClipart.org SVG Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 178,604 public domain SVG vector clipart images collected from OpenClipart.org. OpenClipart.org is a community-driven platform where artists share vector clip art explicitly released into the public domain (CC0). The dataset includes the SVG content along with comprehensive metadata such as titles, descriptions, artist names, creation dates, tags, and image URLs. The SVG files in thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/openclipart.","url":"https://huggingface.co/datasets/nyuuzyou/openclipart","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"causal-news-corpus-v2","keyword":"monolingual","description":"\n[!NOTE]This repository integrates the Causal News Corpus v2 (aka. RECESS) dataset into hf datasets. It is in conformance with Causal News Corpus v2's CC0 1.0 license. Please find the original dataset\nhere. Please see the citations at the end of this README.\n\n\n[!IMPORTANT]\nThe Causal News Corpus v2 does not include labels for the test set.\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCausality Detection\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"webis/causal-news-corpus-v2\", \"causalityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thagen/causal-news-corpus-v2.","url":"https://huggingface.co/datasets/thagen/causal-news-corpus-v2","creator_name":"Tim Hagen","creator_url":"https://huggingface.co/thagen","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020Retrieval","keyword":"monolingual","description":"\n  NanoTouche2020Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoTouche2020 is a smaller subset of TouchÃ© Task 1: Argument Retrieval for Controversial Questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReferencehttps://webis.de/events/touche-20/shared-task-1.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoTouche2020Retrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval.","url":"https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"ai2_arc_ita","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Ai2 ARC (ita)\n\t\n\n\n\nThis dataset is a machine-translated version of Ai2 ARC into Italian.\n\nLicensed under CC-BY 4.0\nTranslated with TowerInstruct-7B-v0.2\nMore details and code used for translation will follow shortly.\n\nThe rest of the page is WIP :)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita.","url":"https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","monolingual","Italian"],"keywords_longer_than_N":true},
	{"name":"myelography-imaging","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMyelography Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 750 synthetic myelography examination records representing a wide spectrum of spinal pathologies and patient experiences. Each record includes:\n\nPatient demographics: Age and sex.\nClinical symptoms prompting the procedure: Detailed and verbose descriptions.\nProcedural details: Contrast medium type, injection site, and imaging modality used.\nVerbose findings: Observations such as spinal cord compressionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/myelography-imaging.","url":"https://huggingface.co/datasets/Taylor658/myelography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","named-entity-recognition","news-articles-summarization","synthetic","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"grade_labeled_wiki_paragraphs","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGrade-Labeled Wiki Paragraphs (GPT-4.1 Nano)\n\t\n\nThis dataset contains Wikipedia paragraphs simplified to different grade reading levels (targeting Grade 1-12) using the GPT-4.1 Nano model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of pairs of original Wikipedia paragraphs and their machine-generated simplified versions. The simplification aims to make the text understandable for readers at specific US grade levels while preserving the coreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs.","url":"https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-simplification","machine","machine","monolingual","agentlans/wikipedia-paragraphs"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API costâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"SimpleToM","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimpleToM Dataset and Evaluation data\n\t\n\nThe SimpleToM dataset of stories with associated questions are described in the paper \n\"SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs\"\nAssociated evaluation data for the models analyzed in the paper can be found in the\nseparate dataset: coming soon.\n\n\t\n\t\t\n\t\tQuestion sets\n\t\n\nThere are three question sets in the SimpleToM dataset:\n\nmental-state-qa questions about information awareness of characterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/SimpleToM.","url":"https://huggingface.co/datasets/allenai/SimpleToM","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["found","found","monolingual","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Telugu"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 41012\nFiltered size: 38772\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"QASports2","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQASports is the first large sports-themed question answering dataset counting over 1 million questions and answers about 124k preprocessed wiki pages, using as documents the wiki of 20 of the most popular sports in the world, like Soccer, American Football, Basketball, Cricket, and so on. Each sport can be downloaded individually as a subset, with the train, test and validation splits, or all subsets can be downloaded together.\n\nðŸ”§ Processing scripts:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/leomaurodesenv/QASports2.","url":"https://huggingface.co/datasets/leomaurodesenv/QASports2","creator_name":"Leonardo Mauro","creator_url":"https://huggingface.co/leomaurodesenv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"R2MEDBiologyRetrieval","keyword":"monolingual","description":"\n  R2MEDBiologyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBiology retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Biology\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBiologyRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Biology"],"keywords_longer_than_N":true},
	{"name":"Eyedoctor","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEye Disease QA Dataset\n\t\n\nThis dataset is designed for training and evaluating large language models (LLMs) in the field of ophthalmology. It consists of a structured disease knowledge base and question-answer (QA) pairs derived from that knowledge. The dataset can be used for supervised fine-tuning, testing, and knowledge-enhanced retrieval tasks.\n\n\t\n\t\t\n\t\tðŸ“‚ Files Included\n\t\n\n\neye_disease_knowledge_base.json\nA curated knowledge base covering common eye diseases such as glaucomaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI4Bread/Eyedoctor.","url":"https://huggingface.co/datasets/AI4Bread/Eyedoctor","creator_name":"AI4Bread","creator_url":"https://huggingface.co/AI4Bread","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Eason_TOFU","keyword":"monolingual","description":"EasonZhong/Eason_TOFU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EasonZhong/Eason_TOFU","creator_name":"Yisheng Zhong","creator_url":"https://huggingface.co/EasonZhong","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S","keyword":"monolingual","description":"\n  AlloProfClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.","url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Gujarati"],"keywords_longer_than_N":true},
	{"name":"NYSJudicialEthicsLegalBenchClassification","keyword":"monolingual","description":"\n  NYSJudicialEthicsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions on judicial ethics from the New York State Unified Court System Advisory Committee.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"MalayalamNewsClassification","keyword":"monolingual","description":"\n  MalayalamNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Malayalam dataset for 3-class classification of Malayalam news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-malyalam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MalayalamNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MalayalamNewsClassification.","url":"https://huggingface.co/datasets/mteb/MalayalamNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"SCDBPAuditsLegalBenchClassification","keyword":"monolingual","description":"\n  SCDBPAuditsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  performs any type of audit, or reserves the right to audit?'\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPAuditsLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDBPAuditsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"truthfull_qa-tr","keyword":"monolingual","description":"This Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\n\n\t\n\t\t\n\t\tDataset Card for truthful_qa-tr\n\t\n\nmalhajar/truthful_qa-tr is a translated version of truthful_qa aimed specifically to be used in the OpenLLMTurkishLeaderboard \nDeveloped by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a benchmark to measure whether a language model isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/truthfull_qa-tr.","url":"https://huggingface.co/datasets/malhajar/truthfull_qa-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"CUADNonDisparagementLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNonDisparagementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires a party not to disparage the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"cpath-mcgill-ubc","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCanadian Universities Q&A Dataset (CPath)\n\t\n\nA comprehensive question-answering dataset focused on Canadian universities' programs, admissions, and academic information, specifically covering McGill University and the University of British Columbia (UBC).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains carefully curated question-answer pairs extracted from official university websites and documentation. It is designed to serve as a reliable resource for understanding academicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc.","url":"https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc","creator_name":"Houcine Bdk","creator_url":"https://huggingface.co/houcine-bdk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"diet-planning-evaluation-20250531-140238","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDiet Planning Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains evaluation results for diet planning model responses.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains a model response and its evaluation metrics.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nFull Prompt: object\nModel Response: object\nDesired Response: object\nNormalized_Edit_Distance: float64â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140238.","url":"https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140238","creator_name":"Alex Jihun Kim","creator_url":"https://huggingface.co/alexjk1m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"twi_words","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Words Dataset\n\t\n\nThe Twi Words Dataset is a curated list of over 50,000 unique words in Twi, a major language spoken in Ghana. This dataset aims to support Natural Language Processing (NLP) tasks in Twi, particularly for low-resource language modeling, classification, and lexicon development.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is created to support:\n\nNLP development for low-resource African languages\nSpell checkers and autocorrect models\nText-to-speech and speech-to-text trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_words.","url":"https://huggingface.co/datasets/michsethowusu/twi_words","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","language-identification","self-annotated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoArguAnaRetrieval","keyword":"monolingual","description":"\n  NanoArguAnaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoArguAna is a smaller subset of ArguAna, a dataset for argument retrieval in debate contexts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReferencehttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoArguAnaRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/arguana","English"],"keywords_longer_than_N":true},
	{"name":"Orchid","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tOrchid: Understanding LLM-based Code Generation under Ambiguous Requirements\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nOrchid is a comprehensive benchmark dataset designed to evaluate the robustness of Large Language Models (LLMs) in handling ambiguity during code generation tasks. It extends the HumanEval dataset with four carefully crafted ambiguity types, providing a systematic way to assess how well models can identify and handle ambiguous requirements.\n\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nðŸ”¤ Lexicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SII-YDD/Orchid.","url":"https://huggingface.co/datasets/SII-YDD/Orchid","creator_name":"SII-YDD","creator_url":"https://huggingface.co/SII-YDD","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["expert-annotated","machine-generated","monolingual","HumanEval","English"],"keywords_longer_than_N":true},
	{"name":"ShamNER","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tShamNER â€“ SpokenÂ Arabic Namedâ€‘Entity Recognition Corpus (Levantine v1.1)\n\t\n\nShamNER is a curated corpus of Levantineâ€‘Arabic sentences annotated for NamedÂ Entities, plus dual annotation to check for consisetency (agreement) across human annotators. \n\nRoundsÂ : pilot, round1â€“round5 (manual, as a rule quality improved across rounds) and round6 (synthetic, postâ€‘edited). The sythentic data is done by sampling label-rich annotated spans from an MSA project and writing it with an LLM whileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ShamNER.","url":"https://huggingface.co/datasets/HebArabNlpProject/ShamNER","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-annotated","monolingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"fun_rec","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tsmall demo learning how to use dataset in huggingface\n\t\n\n","url":"https://huggingface.co/datasets/ykckevin/fun_rec","creator_name":"kevin","creator_url":"https://huggingface.co/ykckevin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Gujarati"],"keywords_longer_than_N":true},
	{"name":"code-expropriation-utilite-publique","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'expropriation pour cause d'utilitÃ© publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the developmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wbigger/sentiment-analysis-test.","url":"https://huggingface.co/datasets/wbigger/sentiment-analysis-test","creator_name":"Claudio Capobianco","creator_url":"https://huggingface.co/wbigger","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mars-seg_msl","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmars-seg_msl\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-seg_msl.","url":"https://huggingface.co/datasets/gremlin97/mars-seg_msl","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PIQA-eu","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for PIQA-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPIQA-eu is the professional translation to Basque of the PIQA's \n(Bisk et al., 2020) validation partition. \nPIQA is a commonsense QA benchmark for naive physics reasoning focusing on how we interact with everyday\nobjects in everyday situations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nPIQA-eu examples look like this:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/PIQA-eu.","url":"https://huggingface.co/datasets/HiTZ/PIQA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","natural-language-inference","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"ro-offense-news","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-news.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-news","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MAUDLegalBenchClassification","keyword":"monolingual","description":"\n  MAUDLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the MAUD dataset, which consists of over 47,000 labels across 152 merger agreements annotated to identify 92 questions in each agreement used by the 2021 American Bar Association (ABA) Public Target Deal Points Study. Each dataset is formatted as a series of multiple-choice questions, where given a segment of the merger agreement and a Deal Point question, the model is toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_as","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Magahi"],"keywords_longer_than_N":true},
	{"name":"OpenHermes-2.5-ru","keyword":"monolingual","description":"\n\t\n\t\t\n\t\td0rj/OpenHermes-2.5-ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is translated version of teknium/OpenHermes-2.5 into Russian using Google Translate.\n","url":"https://huggingface.co/datasets/d0rj/OpenHermes-2.5-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"uk_pv","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUK PV dataset\n\t\n\nDomestic solar photovoltaic (PV) power generation data from Great Britain.\nThis dataset contains data from over 30,000 solar PV systems. The dataset spans 2010 to 2025. \nThe nominal generation capacity per PV system ranges from 0.47 kilowatts to 250 kilowatts.\nThe dataset is updated with new data every few months.\nAll PV systems in this dataset report cumulative energy generation every 30 minutes. This data represents a true accumulation of the total energy generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/James-EPL/uk_pv.","url":"https://huggingface.co/datasets/James-EPL/uk_pv","creator_name":"James Martin","creator_url":"https://huggingface.co/James-EPL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","multivariate-time-series-forecasting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"humaneval_splits","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for HumanEval with Splits\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe programming problems are written in Python and contain English natural text in comments and docstrings.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iskhare/humaneval_splits.","url":"https://huggingface.co/datasets/iskhare/humaneval_splits","creator_name":"Ishan Khare","creator_url":"https://huggingface.co/iskhare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset_support","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_support.","url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_support","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact","keyword":"monolingual","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SciFact","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"PSC","keyword":"monolingual","description":"\n  PSC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Summaries Corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/1211_Paper.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PSC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PSC.","url":"https://huggingface.co/datasets/mteb/PSC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"JGLUE","keyword":"monolingual","description":"JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.","url":"https://huggingface.co/datasets/llm-book/JGLUE","creator_name":"å¤§è¦æ¨¡è¨€èªžãƒ¢ãƒ‡ãƒ«å…¥é–€","creator_url":"https://huggingface.co/llm-book","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","sentence-similarity","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-programmers","keyword":"monolingual","description":"\n  CQADupstackProgrammersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-programmers.","url":"https://huggingface.co/datasets/mteb/cqadupstack-programmers","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SnomedCT","keyword":"monolingual","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from SnomedCT's subsumption hierarchy (TBox) for training and evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/SnomedCT","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NorwegianCourtsBitextMining","keyword":"monolingual","description":"\n  NorwegianCourtsBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNynorsk and BokmÃ¥l parallel corpus from Norwegian courts. Norwegian courts have two standardised written languages. BokmÃ¥l is a variant closer to Danish, while Nynorsk was created to resemble regional dialects of Norwegian.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://opus.nlpl.eu/index.php\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining.","url":"https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","monolingual","Norwegian Nynorsk","Norwegian BokmÃ¥l"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"modup","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMathOverflow Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/mathoverflow.net.7z\n","url":"https://huggingface.co/datasets/hcju/modup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mo","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQ","keyword":"monolingual","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NQ","English"],"keywords_longer_than_N":true},
	{"name":"HeadlineClassification","keyword":"monolingual","description":"\n  HeadlineClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHeadline rubric classification based on the paraphraser plus dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://aclanthology.org/2020.ngt-1.6/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HeadlineClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HeadlineClassification.","url":"https://huggingface.co/datasets/mteb/HeadlineClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"TabularDataHW1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TabularDataHW1\n\t\n\nThis dataset contains tabular data describing classical music pieces by Beethoven and Mozart, for classification by composer.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original split consists of 30 classical piano pieces, for prediction of whether the composer is either Mozart or Beethoven.\nThe five parameters measured were number of right hand notes, number of left hand notes, number of measures, key center, and marking data.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emkessle/TabularDataHW1.","url":"https://huggingface.co/datasets/emkessle/TabularDataHW1","creator_name":"Ethan Kessler","creator_url":"https://huggingface.co/emkessle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gdz4you","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GDZ4You.com Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 18,037 educational materials from the gdz4you.com platform, a resource for teachers and students providing multimedia presentations and other educational content. The dataset includes information such as material titles, URLs, download links, ratings, and slide-by-slide content with images where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gdz4you.","url":"https://huggingface.co/datasets/nyuuzyou/gdz4you","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"klingai","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for KLING AI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 12,782 AI-generated media items (images and videos) created using KLING AI's generative tools. The content includes metadata and original files for various AI generations, encompassing both still images and motion videos created through text-to-image and image-to-video transformations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en), with prompts and metadata in English.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/klingai.","url":"https://huggingface.co/datasets/nyuuzyou/klingai","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-video","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"noise-dataset-de","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tGerman Noise-Augmented Speech Demo Dataset\n\t\n\nThis dataset provides German speech samples augmented with realistic noise scenarios such as office noise, street noise, white noise, echo, and lowpass filtering.It is designed for testing and improving the robustness of ASR (Automatic Speech Recognition) systems.\n\n\t\n\t\t\n\t\tðŸ’¡ Source\n\t\n\n\nOriginal voice samples: Mozilla Common Voice (CC0)\nNoise layers: custom augmented (see noise.rolgor.de)\n\n\n\t\n\t\t\n\t\tâš ï¸ Privacy\n\t\n\nPlease respect speakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rolgor/noise-dataset-de.","url":"https://huggingface.co/datasets/rolgor/noise-dataset-de","creator_name":"rol gor","creator_url":"https://huggingface.co/rolgor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["keyword-spotting","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per L'analisi dei sentimenti\n\t\n\nil dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tuttiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felipeit/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Felipeit/sentiment-analysis-test","creator_name":"Felipe Simoes Campos","creator_url":"https://huggingface.co/Felipeit","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Panjabi"],"keywords_longer_than_N":true},
	{"name":"CEDRClassification","keyword":"monolingual","description":"\n  CEDRClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClassification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Social, Blog, Written\n\nReference\nhttps://www.sciencedirect.com/science/article/pii/S1877050921013247\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CEDRClassification.","url":"https://huggingface.co/datasets/mteb/CEDRClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"crud-code-tests","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ› ï¸ Code Fixing & Generation Dataset (Alpaca Format)\n\t\n\n\n\t\n\t\t\n\t\tCode Fixing & Generation Dataset (Alpaca Format)\n\t\n\nThis dataset is designed to fine-tune open-source large language models (LLMs) to automatically fix buggy code and generate accurate code completions based on real-world inputs.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nThe dataset follows the Alpaca-style format:\n[\n  {\n    \"instruction\": \"<SYSTEM_PROMPT + TASK_DESCRIPTION>\",\n    \"input\": \"<CODE_SNIPPET>\",\n    \"output\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kramster/crud-code-tests.","url":"https://huggingface.co/datasets/kramster/crud-code-tests","creator_name":"Karthik Ram","creator_url":"https://huggingface.co/kramster","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["language-modeling","human-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"amr-3-parsed","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for AMR 3.0 Parsed\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains parsed Abstract Meaning Representation (AMR) annotations from the LDC2020T02 release, formatted as instruction-following conversations. Each example consists of a sentence and its corresponding AMR graph representation.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks: Semantic parsing, specifically generating AMR graphs from English sentences\nLeaderboards: AMR Parsing\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hoshuhan/amr-3-parsed.","url":"https://huggingface.co/datasets/hoshuhan/amr-3-parsed","creator_name":"hoshuhan","creator_url":"https://huggingface.co/hoshuhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","machine-generated","expert-generated","monolingual","ldc2020t02"],"keywords_longer_than_N":true},
	{"name":"gr00t-g1-palm-pose-augmented","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tUnitree G1 Fruits Pick & Place â€” Palm Pose Augmented (FK Traces)\n\t\n\nTL;DR. This dataset mirrors NVIDIAâ€™s PhysicalAI-Robotics-GR00T-Teleop-G1 release and adds four forward-kinematics (FK) signals per frame: left_palm_pose, right_palm_pose, and their short-horizon future traces. These compact, goal-centric features make downstream imitation learning and planning/MPC easier, without replaying full videos.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy this augmented version?\n\t\n\nMost real-robot teleoperation sets exposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nirav-Madhani/gr00t-g1-palm-pose-augmented.","url":"https://huggingface.co/datasets/Nirav-Madhani/gr00t-g1-palm-pose-augmented","creator_name":"Nirav Madhani","creator_url":"https://huggingface.co/Nirav-Madhani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["robotics","monolingual","nvidia/PhysicalAI-Robotics-GR00T-Teleop-G1","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-3.0","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 3.0 (CC-BY-3.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): Allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fisda","keyword":"monolingual","description":"jamsran/fisda dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jamsran/fisda","creator_name":"Myngan","creator_url":"https://huggingface.co/jamsran","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsource","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-webmasters","keyword":"monolingual","description":"\n  CQADupstackWebmastersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWebmastersRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-webmasters.","url":"https://huggingface.co/datasets/mteb/cqadupstack-webmasters","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"synthetic_call_center_summaries","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nExtensive evaluation metrics and attributes such as conciseness, formatting, contextual relevance, tone, and actionability.\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntendedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries.","url":"https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"MixBench25-visual","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"piqa-bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the translated version of the PIQA LLM evaluation dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST), which combines Google Translation with LLM-based rewriting. PIQA introduces the task of physical commonsense reasoning and provides a corresponding benchmark for understanding physical interactions in everyday situations. It focuses on atypical solutions to practical problems, inspired by instructional guidesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/piqa-bn.","url":"https://huggingface.co/datasets/hishab/piqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","monolingual","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"ibge-cidades","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tibge-cidades\n\t\n\nDados dos municÃ­pios no Portal Cidades@ recuperados da API do IBGE\n\n\t\n\t\t\n\t\tFonte\n\t\n\nOs dados em questÃ£o sÃ£o disponibilizados pelo IBGE no Portal Cidades@ (https://cidades.ibge.gov.br/brasil/panorama). Os dados foram coletados por chamadas Ã  API em 21-22 de maio de 2025.\n\n\t\n\t\t\n\t\tDados no dataset\n\t\n\nO dataset contÃ©m dados de 5.565 localidades no Brasil (Cidades, Povoados, Vilarejos, etc.) coletados pelo IBGE, organizados por ano.\nNo total, sÃ£o 40 indicadores que tÃªm seusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Saint-Clair/ibge-cidades.","url":"https://huggingface.co/datasets/Saint-Clair/ibge-cidades","creator_name":"Lima","creator_url":"https://huggingface.co/Saint-Clair","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleCopyLegalBenchClassification","keyword":"monolingual","description":"\n  ContractNLIPermissibleCopyLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may create a copy of some Confidential Information in some circumstances.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Awadhi"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_answer","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"mb-landmark_cls","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-landmark_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: oth\n1: cra\n2: ddu\n3: sst\n4: bdu\n5: ime\n6: sch\n7: spi\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 6997 images\ntest: 1793 images\nval: 2025 images\nfew_shot_train_2_shot: 16 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-landmark_cls.","url":"https://huggingface.co/datasets/Mirali33/mb-landmark_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"domarks16k","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tdomarks16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-09\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: aec\n1: ael\n2: cli\n3: cra\n4: fse\n5: fsf\n6: fsg\n7: fss\n8: mix\n9: rid\n10: rou\n11: sfe\n12: sfx\n13: smo\n14: tex\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 11305 images\ntest: 1614 images\nval: 3231 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/domarks16k.","url":"https://huggingface.co/datasets/gremlin97/domarks16k","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"chichewa-trigrams-speech-text-parallel","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tChichewa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 132549 parallel speech-text pairs for Chichewa, a language spoken primarily in Malawi. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Chichewa - ny\nTask: Speech Recognitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Chichewa"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-sequences.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-sequences","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"hle_math_pythics_278_with_prompt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHumanity's Last Exam Dataset\n\t\n\nHumanity's Last Exam Datasetã®Mathã¨Pysicsã®è¨­å•ã‹ã‚‰ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒå¿…è¦ãªå•é¡Œã‚’é™¤å¤–ã—ã€ãƒ©ãƒ³ãƒ€ãƒ ã«278å•æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ§‹é€ åŒ–ã•ã‚ŒãŸå›žç­”ã‚’ä¿ƒã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’questionã«è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/hle_math_pythics_278_with_prompt","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsSourceClassification","keyword":"monolingual","description":"\n  SinhalaNewsSourceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK, Newsfirst, World Socialist Web Site-Sinhala).\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification.","url":"https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Source-classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Panjabi"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackST","keyword":"monolingual","description":"\n  CodeFeedbackST\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"CodeFeedbackST\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackST.","url":"https://huggingface.co/datasets/mteb/CodeFeedbackST","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"SquadES_Ex1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDocumentation translated in Catalan\n\t\n\n\n\t\n\t\t\n\t\tCarta de presentaciÃ³ sobre el dataset Squad-ES\n\t\n\n\n\t\n\t\t\n\t\tTaula de continguts\n\t\n\n\nDescripcio del dataset\nEstructura del dataset\nCamps\nParticionament de les dades\nInformacio sobre la llicencia\nCitacions\nContribucions\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDescripcio del dataset\n\t\n\nAquest dataset Ã©s una traducciÃ³ automÃ tica a l'espanyol del famÃ³s conjunt de dades Stanford Question Answering Dataset (SQuAD).\nEstÃ  dissenyat per a tasques de preguntes i respostesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/itorrento/SquadES_Ex1.","url":"https://huggingface.co/datasets/itorrento/SquadES_Ex1","creator_name":"Iker TorrentÃ³","creator_url":"https://huggingface.co/itorrento","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"rocky_mountain_snowpack","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tRocky Mountain Snowpack Dataset\n\t\n\nThe Rocky Mountain Snowpack dataset contains ~2,341 samples of snowpack imagery collected in the Colorado Rocky Mountains during the 2024â€“2025 winter season.Each sample segment of snow includes three types of images:\n\nMagnified crystal images (close-up snow snow crystal profile photography)\nSnowpack profile images (non-magnified snow crystal profiles photography)\nCore segment images (snow cores sampled with a apple corer)\n\nFor each segment thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RMDig/rocky_mountain_snowpack.","url":"https://huggingface.co/datasets/RMDig/rocky_mountain_snowpack","creator_name":"Rocky Mountain Digerati","creator_url":"https://huggingface.co/RMDig","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-classification","manual","monolingual","None"],"keywords_longer_than_N":true},
	{"name":"CUADIPOwnershipAssignmentLegalBenchClassification","keyword":"monolingual","description":"\n  CUADIPOwnershipAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that intellectual property created by one party become the property of the counterparty, either per the terms of the contract or upon the occurrence of certain events.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"smartlab-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Smart-lab.ru Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Smart-lab.ru, a Russian platform for discussing up-to-date stock exchange information, market news, investment ideas, and trading methods. Each entry in the dataset represents a post from the website, including its title, content, author, and a unique identifier.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, though some posts may contain content in other languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/smartlab-posts.","url":"https://huggingface.co/datasets/nyuuzyou/smartlab-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"bordaru-posts","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Borda.ru Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Borda.ru, a Russian platform for hosting various discussion forums on a wide range of topics. Each entry in the dataset represents a post from the website, including its content, author, URL, and other relevant information. The dataset contains 5,251,346 unique messages. The dataset was deduplicated based on the \"content\" value, which removed spam and other low-quality data, keepingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/bordaru-posts.","url":"https://huggingface.co/datasets/nyuuzyou/bordaru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"SCDDAccountabilityLegalBenchClassification","keyword":"monolingual","description":"\n  SCDDAccountabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer maintains internal accountability standards and procedures for employees or contractors failing to meet company standards regarding slavery and trafficking?'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDAccountabilityLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDDAccountabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"faquad-nli","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of 900â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli.","url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-mmls","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-mmls\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Landslide\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  â”œâ”€â”€ train/\n  â”‚   â”œâ”€â”€ images/  # Image files\n  â”‚   â””â”€â”€ masks/   # Segmentation masks\n  â”œâ”€â”€ val/\n  â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mmls.","url":"https://huggingface.co/datasets/Mirali33/mb-mmls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"monolingual","description":"\n\t\n\t\t\n\t\ttest\n\t\n\ntest1\n","url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v3","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V3\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nAdapted prompt from yourbench\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"tiny-truthful-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 790 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rahmanidashti/tiny-truthful-qa.","url":"https://huggingface.co/datasets/rahmanidashti/tiny-truthful-qa","creator_name":"Hossein A. (Saeed) Rahmani","creator_url":"https://huggingface.co/rahmanidashti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"proofwikiqa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProofWiki Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the ProofWiki dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/proofwikiqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"SunDataset","keyword":"monolingual","description":"\n  \n\n\n\n\t\n\t\t\n\t\tDataset Labels\n\t\n\n['sun']\n\n\n\t\n\t\t\n\t\tNumber of Images\n\t\n\n{'valid': 374, 'test': 184, 'train': 4047}\n\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\n\nInstall datasets:\n\npip install datasets\n\n\nLoad the dataset:\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"SamuelM0422/SunDataset\", name=\"full\")\nexample = ds['train'][0]\n\n\n\t\n\t\t\n\t\tRoboflow Dataset Page\n\t\n\nhttps://universe.roboflow.com/samuelm0422/sundetection-bwqjs/dataset/1\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SamuelM0422/SunDataset.","url":"https://huggingface.co/datasets/SamuelM0422/SunDataset","creator_name":"Samuel Silva","creator_url":"https://huggingface.co/SamuelM0422","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"zelensky-speeches","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"zelenskiy-speeches\"\n\t\n\nSpeeches given by the president of Ukraine Volodymyr ZelenskyLanguages: Ukrainian, EnglishSource: president.gov.uaAuto-updated daily by Github Actions of zelensky-speech-fetcherLicense: CC BY-NC-ND 4.0 Deed\n","url":"https://huggingface.co/datasets/slava-medvedev/zelensky-speeches","creator_name":"Viacheslav Medvediev","creator_url":"https://huggingface.co/slava-medvedev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"monolingual","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues-PlusÂ \n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech â†’ text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"escher-human-edit","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-human-edit\n\t\n\nHuman Edit dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-human-edit","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ‰ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tðŸš€ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that Africanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"code_civil","keyword":"monolingual","description":"Hunterlige/code_civil dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hunterlige/code_civil","creator_name":"Denis","creator_url":"https://huggingface.co/Hunterlige","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","original","French","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"code-travail","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du travail, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cv17_es_other_automatically_verified","keyword":"monolingual","description":"Split called -other- of the Spanish Common Voice v17.0 that was automatically verified\nusing various ASR system.","url":"https://huggingface.co/datasets/projecte-aina/cv17_es_other_automatically_verified","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","mozilla-foundation/common_voice_17_0"],"keywords_longer_than_N":true},
	{"name":"code-organisation-judiciaire","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode de l'organisation judiciaire, non-instruct (2025-05-31)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"FoodOn","keyword":"monolingual","description":"This dataset is a collection of Mixed-hop Prediction datasets created from FoodOn's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/FoodOn","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_answer_and_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context.","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"cultural-dimension-cover-letters","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for cultural-dimension-cover-letters\n\t\n\nThe cultural-dimension-cover-letters dataset contains cover letters modified to reflect different cultural dimensions based on Hofstede's framework. Created for evaluating implicit cultural preferences in large language models (LLMs) through job application assessment tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset features cover letters adapted to represent six cultural dimensions: Individualism/Collectivism, Power Distanceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akhan02/cultural-dimension-cover-letters.","url":"https://huggingface.co/datasets/akhan02/cultural-dimension-cover-letters","creator_name":"Ariba Khan","creator_url":"https://huggingface.co/akhan02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentiment-classification","text-scoring","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"CodeMMLU","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities\n\t\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ“Œ CodeMMLU\n\t\n\nCodeMMLU is a comprehensive benchmark designed to evaluate the capabilities of large language models (LLMs) in coding and software knowledge. \nIt builds upon the structure of multiple-choice question answering (MCQA) to cover a wide range of programming tasks and domains, including code generation, defect detection, software engineering principles, and much more.\n\n\t\n\t\t\n\t\tðŸ“„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU.","url":"https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"SCDDVerificationLegalBenchClassification","keyword":"monolingual","description":"\n  SCDDVerificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer engages in verification of product supply chains to evaluate and address risks of human trafficking and slavery? If the company conducts verification], the disclosureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDVerificationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDDVerificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"CUADGoverningLawLegalBenchClassification","keyword":"monolingual","description":"\n  CUADGoverningLawLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies which state/countryâ€™s law governs the contract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"my_image_caption_dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMy image-caption dataset\n\t\n\nThis dataset contains images with English descriptions (captions).\n","url":"https://huggingface.co/datasets/hongin9812/my_image_caption_dataset","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NibirMandal/IRRISIGHT.","url":"https://huggingface.co/datasets/NibirMandal/IRRISIGHT","creator_name":"Nibir Mandal","creator_url":"https://huggingface.co/NibirMandal","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"sec-material-contracts-qa-splitted","keyword":"monolingual","description":"Mixed and filtered version of chenghao/sec-material-contracts-qa and jordyvl/DUDE_subset_100val.\n","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa-splitted","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","document-question-answering","visual-question-answering","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_8b","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 500,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-8B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 500,000 samples with embeddings\nQueryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_8b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_8b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"monolingual","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"checking","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHumaniBench: A Human-Centric Visual QA Dataset\n\t\n\nHumaniBench is a dataset for evaluating visual question answering models on tasks that involve human-centered attributes such as gender, age, and occupation.\nEach data point includes:\n\nID: Unique identifier\nAttribute: A social attribute (e.g., gender, race)\nQuestion: A visual question related to the image\nAnswer: The ground-truth answer\nimage: Embedded image in base64 or file format for visual preview\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample Entry\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shainaraza/checking.","url":"https://huggingface.co/datasets/shainaraza/checking","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ug-normativity","keyword":"monolingual","description":"Rivert97/ug-normativity dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Rivert97/ug-normativity","creator_name":"Roberto Garcia Guzman","creator_url":"https://huggingface.co/Rivert97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","original","Spanish"],"keywords_longer_than_N":true},
	{"name":"faquad-nli-parquet","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\nTHIS IS A TEMPORARY COPY OF THE ORIGINAL ruanchaves/faquad-nli.\nWHY? As of datasets==4.0, loading scripts and trust_remote_code are no longer supported. \nThis breaks things, like the lm-evaluation-harness-pt, which people who work with Portuguese LLMs need for running evals.\nAs soon as ruanchaves updates his version, I'll delete this copy.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/faquad-nli-parquet.","url":"https://huggingface.co/datasets/nicholasKluge/faquad-nli-parquet","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"monolingual","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"MC-II-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/MC-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-II-100","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/GR-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"filtered_articles_by_year","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered Articles by Year\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Filtered Articles by Year dataset contains yearly-segmented web articles from the FineWeb dataset, specifically filtered and processed for temporal language analysis and Word2Vec model training. This dataset spans 21 years (2005-2025) and serves as the foundation for research into semantic change, concept emergence, and language evolution over time.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adameubanks/filtered_articles_by_year.","url":"https://huggingface.co/datasets/adameubanks/filtered_articles_by_year","creator_name":"Adam Eubanks","creator_url":"https://huggingface.co/adameubanks","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","language-modeling","text-scoring","monolingual"],"keywords_longer_than_N":true},
	{"name":"testrtt","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","url":"https://huggingface.co/datasets/hongin9812/testrtt","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"afrixnli-translate-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrixnli","Amharic"],"keywords_longer_than_N":true},
	{"name":"ruforum","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Russian Forum Messages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 58,112,681 messages collected from Russian online forums. Each entry represents a message posted by a user, including metadata such as message ID, timestamp, and the message text. The dataset contains data from approximately 2010 to 04.2025.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ruforum.","url":"https://huggingface.co/datasets/nyuuzyou/ruforum","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","sentiment-classification","found"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringP2P.v2","keyword":"monolingual","description":"\n  PlscClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles+abstracts from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2.","url":"https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-p2p"],"keywords_longer_than_N":true},
	{"name":"jupyter-agent-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tJupyter Agent Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset uses real Kaggle notebooks processed through a multi-stage pipeline to de-duplicate, fetch referenced datasets, score educational quality, filter to data-analysisâ€“relevant content, generate dataset-grounded questionâ€“answer (QA) pairs, and produce executable reasoning traces by running notebooks. The resulting examples include natural questions about a dataset/notebook, verified answers, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jupyter-agent/jupyter-agent-dataset.","url":"https://huggingface.co/datasets/jupyter-agent/jupyter-agent-dataset","creator_name":"Jupyter Agent","creator_url":"https://huggingface.co/jupyter-agent","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","monolingual","code"],"keywords_longer_than_N":true},
	{"name":"hle-math_pysics-278","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tHumanity's Last Exam Dataset\n\t\n\nHumanity's Last Exam Datasetã®Mathã¨Pysicsã®è¨­å•ã‹ã‚‰ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒå¿…è¦ãªå•é¡Œã‚’é™¤å¤–ã—ã€ãƒ©ãƒ³ãƒ€ãƒ ã«278å•æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚Mathã¨Pysicsã®è¨­å•æ•°ã¯ã€HLEã®é…åˆ†ã«åˆã‚ã›ã€278å•ä¸­ã€Math82ï¼…ï¼ˆ228å•ï¼‰:Pysics18ï¼…ï¼ˆ50å•ï¼‰ã¨ã—ã¦ã„ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/hle-math_pysics-278","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"CICMalDroid","keyword":"monolingual","description":"builetrongduc/CICMalDroid dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/builetrongduc/CICMalDroid","creator_name":"BÃ¹i LÃª Trá»ng Äá»©c","creator_url":"https://huggingface.co/builetrongduc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["user-generated","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset Ã¨ stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effetuate coorelando le risposte testuali ad indicatori di gradimento.\nIl dataaset Ã¨ stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'IA.\nGrazie a tutti per laâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test","creator_name":"Marrocco Marco","creator_url":"https://huggingface.co/Cocciadipollo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoMSMARCO.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoMSMARCO-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoMSMARCO","French"],"keywords_longer_than_N":true},
	{"name":"gsm8k-tr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\nmalhajar/GSM8K-tr is a translated version of GSM8K aimed specifically to be used in the OpenLLMTurkishLeaderboard \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math wordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/gsm8k-tr.","url":"https://huggingface.co/datasets/malhajar/gsm8k-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tofu_ext2_rp","keyword":"monolingual","description":"talmahmud/tofu_ext2_rp dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/talmahmud/tofu_ext2_rp","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MoroccanSocialMedia-MultiGen","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for MoroccanSocialMedia-MultiGen (MSM-MG)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMoroccanSocialMedia-MultiGen (MSM-MG) is a dataset of 12,973 pairs of native Darija social media posts (tweets and YouTube comments) and their synthetic counterparts. The dataset supports six tasks: Continuation, Reply, Summarization, Rephrasing, Explanation, and Safe Response. The synthetic generations were created by prompting Claude 3.5 Sonnet to perform each of these tasks based on the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen.","url":"https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","machine-generated","machine-translated","monolingual","qadi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"books","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBooks\n\t\n\nThe books dataset consists of a diverse collection of books organized into 9 categories, it splitted to train, validation where the train contains 40 books, and the validation 9 books.\nThis dataset is cleaned well and designed to support various natural language processing (NLP) tasks, including text generation and masked language modeling.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nThe dataset contains 4 columns:\n\ntitle: The tilte of the book.\nauthor: The author of the book.\ncategory: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/books.","url":"https://huggingface.co/datasets/IsmaelMousa/books","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","IsmaelMousa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"spm_jsonresume_resumed","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tspm\n\t\n\nSmall Package Model is a method for creating micro llms trained to be an expert on a single software project. The goal is to generate fine tuned models that are so small they can be saved as a package, loaded as a dependency, and run locally. The advantage of this method is that the model can give accurate and up to date information on the particular code being run without needing external tools, it stays up to date with latest changes and understands the specific implementationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ajaxdavis/spm_jsonresume_resumed.","url":"https://huggingface.co/datasets/ajaxdavis/spm_jsonresume_resumed","creator_name":"Thomas Davis","creator_url":"https://huggingface.co/ajaxdavis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Awadhi"],"keywords_longer_than_N":true},
	{"name":"my-awesome-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Axion004/my-awesome-dataset.","url":"https://huggingface.co/datasets/Axion004/my-awesome-dataset","creator_name":"Matthew Kehoe","creator_url":"https://huggingface.co/Axion004","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"vibeeval_greek","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Vibe-Eval Greek\n\t\n\nThe Vibe-Eval Greek dataset is a benchmark of 269 examples for evaluating multimodal chat models, including especially challenging examples. It has been manually translated into Greek from the VibeEval dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nEach example has the following fields:\n\nmedia_url: a URL where the file is hosted publicly\nexample_id: a unique ID for the example\ncategory: the category that this example belongs to, either difficulty-normal orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/vibeeval_greek.","url":"https://huggingface.co/datasets/ilsp/vibeeval_greek","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-classification","monolingual","Greek","English"],"keywords_longer_than_N":true},
	{"name":"MovieReviewSentimentClassification","keyword":"monolingual","description":"\n  MovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe AllocinÃ© dataset is a French-language dataset for sentiment analysis that contains movie reviews produced by the online community of the AllocinÃ©.fr website.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification.","url":"https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"stock_market_asx_audio","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Stock Market ASX Audio\n\t\n\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nsentence_id (string): An id for the sentence used for the recording.\nvoice_id (string): An id for which client (voice) made the recording.\naudio (dict): A dictionary containing the path to the downloaded audio file.\nsentence (string): The sentence the user wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio.","url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sdeering","google translate","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"EmpathicConversations","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tEmpathicConversations\n\t\n\nEmpathicConversations is a human-curated dataset designed to train and evaluate conversational AI systems that offer emotionally intelligent, supportive, and non-judgmental responses in therapeutic settings.\n\n\t\n\t\t\n\t\tðŸ§  Purpose\n\t\n\nThis dataset serves as a foundation for building AI therapy assistants and mental wellness chatbots. It emphasizes empathy, active listening, and emotional support, aiming to make AI more compassionate and context-aware in sensitiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/samdak93/EmpathicConversations.","url":"https://huggingface.co/datasets/samdak93/EmpathicConversations","creator_name":"Samdak","creator_url":"https://huggingface.co/samdak93","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","human-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-WTB-Test","keyword":"monolingual","description":"\n  BIRCO-WTB\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the WhatsThatBook dataset from BIRCO. This dataset contains 100 queries where each query is an ambiguous description of a book. Each query has a candidate pool of 50 book descriptions. The objective is to retrieve the correct book description.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-WTB-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-WTB-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GermanGovServiceRetrieval","keyword":"monolingual","description":"\n  GermanGovServiceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLHM-Dienstleistungen-QA is a German question answering dataset for government services of the Munich city administration. It associates questions with a textual context containing the answer\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval.","url":"https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"time_series_datasets","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTourism Monthly Time Series Dataset with Economic and Static Covariates\n\t\n\nThis dataset, originally sourced from Athanasopoulos et al. (2011), focuses on the tourism industry with a monthly frequency and has been enhanced with economic covariates (e.g., CPI, Inflation Rate, GDP) from official Australian government sources. We also perform some preprocessing to further increase the usability of the dataset with dynamic start dates for each series and static covariates for in-depth timeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zaai-ai/time_series_datasets.","url":"https://huggingface.co/datasets/zaai-ai/time_series_datasets","creator_name":"ZAAI","creator_url":"https://huggingface.co/zaai-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","univariate-time-series-forecasting","multivariate-time-series-forecasting","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hne","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Contract_Clause_SampleDataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“¦ Contract Clause Dataset (Sample Preview)\n\t\n\nðŸ”— To purchase the full dataset (66,813 clauses), visit:  âž¡ï¸ https://asapworks.gumroad.com/l/wtave\nSupport: Asapuaiworks@gmail.com\n\nThis file provides a 200-record preview of the full Contract Clause Dataset v1.0 â€” a high-quality, enriched legal dataset containing clauses extracted from 10+ years of SEC contract filings.\nThe dataset is designed for legal AI, NLP research, and clause-based retrieval systems.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ What's Insideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/asapworks/Contract_Clause_SampleDataset.","url":"https://huggingface.co/datasets/asapworks/Contract_Clause_SampleDataset","creator_name":"Siddharth shankar Asapu","creator_url":"https://huggingface.co/asapworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nlile/mbpp.","url":"https://huggingface.co/datasets/nlile/mbpp","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mb-conequest_det","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tmb-conequest_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 10 splits: train, val, test, 0.01x_partition, 0.02x_partition, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.01x_partition, 0.02x_partitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-conequest_det.","url":"https://huggingface.co/datasets/Mirali33/mb-conequest_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"conversation_data_mcp_100","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ“š Conversation Data MCP 100\n\t\n\nA conversational dataset consisting of 100 high-quality multi-turn dialogues for use in fine-tuning and evaluating conversational models.\n\n\t\n\t\t\n\t\tðŸ“Œ Dataset Summary\n\t\n\nThis dataset contains 100 multi-turn conversations structured in a JSON format. It is designed to support research and development in areas such as:\n\nChatbot development\nDialogue modeling\nConversational AI evaluation\nNLP fine-tuning for custom agents\n\nEach conversation featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yashsoni78/conversation_data_mcp_100.","url":"https://huggingface.co/datasets/yashsoni78/conversation_data_mcp_100","creator_name":"Yash Soni","creator_url":"https://huggingface.co/yashsoni78","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"cybersecurity_alarm_analysis_508","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Security Alert Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nè¯¥æ•°æ®é›†åŒ…å«å®‰å…¨å‘Šè­¦æ—¥å¿—æ•°æ®ï¼Œç”¨äºŽè®­ç»ƒå¤§æ¨¡åž‹åˆ¤æ–­å®‰å…¨å‘Šè­¦æ˜¯çœŸå®žæ”»å‡»è¿˜æ˜¯è¯¯æŠ¥ã€‚æ•°æ®é›†é‡‡ç”¨Alpacaæ ¼å¼ï¼ŒåŒ…å«instructionã€inputå’Œoutputä¸‰ä¸ªå­—æ®µã€‚\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTask: å®‰å…¨å‘Šè­¦åˆ†ç±»\nTask Type: æ–‡æœ¬åˆ†ç±»\nLanguages: ä¸­æ–‡\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\næ•°æ®é›†ä¸­çš„æ–‡æœ¬ä¸ºä¸­æ–‡ã€‚\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\næ¯ä¸ªæ ·æœ¬åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\ninstruction: ä»»åŠ¡è¯´æ˜Žï¼ŒæŒ‡å¯¼æ¨¡åž‹ä½œä¸ºç½‘ç»œå®‰å…¨å‘Šè­¦åˆ†æžä¸“å®¶åˆ†æžå®‰å…¨å‘Šè­¦æ—¥å¿—\ninput: å‘Šè­¦æ—¥å¿—æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼ŒåŒ…å«å¤šç§å®‰å…¨å‘Šè­¦çš„è¯¦ç»†ä¿¡æ¯\noutput: æ ‡ç­¾ï¼ˆ\"æ”»å‡»\"æˆ–\"è¯¯æŠ¥\"ï¼‰\n\n\n\t\n\t\t\n\t\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis_508.","url":"https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis_508","creator_name":"zheng tian","creator_url":"https://huggingface.co/tiangler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TERRa","keyword":"monolingual","description":"\n  TERRa\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTextual Entailment Recognition for Russian. This task requires to recognize, given two text fragments, whether the meaning of one text is entailed (can be inferred) from the other text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://arxiv.org/pdf/2010.15925\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TERRa.","url":"https://huggingface.co/datasets/mteb/TERRa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","ai-forever/terra-pairclassification"],"keywords_longer_than_N":true},
	{"name":"ProbaEstructura","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JJFrancisco/ProbaEstructura.","url":"https://huggingface.co/datasets/JJFrancisco/ProbaEstructura","creator_name":"jose javier francisco marini","creator_url":"https://huggingface.co/JJFrancisco","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-generated","monolingual","Galician","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"emojis","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for Emojis.com\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 3,264,372 AI-generated emoji images from Emojis.com. Each entry represents an emoji with associated metadata including prompt text and image URLs.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nslug: Unique identifier for the emoji (string)\nid: Internal ID (string) \nnoBackgroundUrl:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/emojis.","url":"https://huggingface.co/datasets/nyuuzyou/emojis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-classification","multi-class-image-classification","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"AssistantGPT","keyword":"monolingual","description":"kingj233414/AssistantGPT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kingj233414/AssistantGPT","creator_name":"Jake P","creator_url":"https://huggingface.co/kingj233414","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"telugu-summarization-generation","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation.","url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"traffic-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tFHWA Traffic Signal Timing Q&A Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n4,368 Q&A pairs on traffic signal timing topics.  \nAI-generated using Google's Gemini model.  \nStructured for training and fine-tuning AI models.  \nBased on official FHWA documentation.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nQuestion: Traffic signal timing question.  \nAnswer: Detailed technical answer.  \nSection ID: Reference to the original source section.  \nChapter: Chapterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paulelliotco/traffic-qa.","url":"https://huggingface.co/datasets/paulelliotco/traffic-qa","creator_name":"Paul Elliot","creator_url":"https://huggingface.co/paulelliotco","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SCDBPCertificationLegalBenchClassification","keyword":"monolingual","description":"\n  SCDBPCertificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  performs any type of audit, or reserves the right to audit?'\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPCertificationLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/SCDBPCertificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"german-ler","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for \"German LER\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of Legal Documents from German federal court decisions for Named Entity Recognition. The dataset is human-annotated with 19 fine-grained entity classes. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities. NER tags use the BIO tagging scheme. \nThe dataset includes two different versions of annotations, one with a set of 19 fine-grained semantic classes (ner_tags) and another oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/german-ler.","url":"https://huggingface.co/datasets/elenanereiss/german-ler","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"code-service-national","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tCode du service national, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"LegalQuAD","keyword":"monolingual","description":"\n  LegalQuAD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of questions and legal documents in German.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/Christoph911/AIKE2021_Appendix\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LegalQuAD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalQuAD.","url":"https://huggingface.co/datasets/mteb/LegalQuAD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"CUADLiquidatedDamagesLegalBenchClassification","keyword":"monolingual","description":"\n  CUADLiquidatedDamagesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause awards either party liquidated damages for breach or a fee upon the termination of a contract (termination fee).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jwst-quality-analysis-dataset","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tJWST Quality Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains comprehensive quality analysis for 2,709 JWST (James Webb Space Telescope) NIRCam images from the MAST archive. Each image has been automatically analyzed for quality metrics, artifact detection, and noise characteristics.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSize: 2,709 images\nFormat: JSONL (JSON Lines)\nSource: JWST NIRCam observations from MAST\nTargets: M16, NGC 3132, NGC 3324, SMACS 0723, Stephan's Quintetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/norbertm/jwst-quality-analysis-dataset.","url":"https://huggingface.co/datasets/norbertm/jwst-quality-analysis-dataset","creator_name":"Norbert M","creator_url":"https://huggingface.co/norbertm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset Ã¨ stato creato con un questionario online in cu isi chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset Ã¨ stato stato realizzato all'interno di un corsp pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Smatteux/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Smatteux/sentiment-analysis-test","creator_name":"daniele matteucci","creator_url":"https://huggingface.co/Smatteux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"escher-omniedit","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for escher-omniedit\n\t\n\nOmniEdit dataset\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains:\n\nsource_image: The original image\nedited_image: The edited version of the image\nedit_instruction: The instruction used to edit the image\nsource_image_caption: Caption for the source image\ntarget_image_caption: Caption for the edited image\nAdditional metadata fields\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n{}\n\n","url":"https://huggingface.co/datasets/Image-editing/escher-omniedit","creator_name":"Image-editing","creator_url":"https://huggingface.co/Image-editing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-inpainting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"BIRCO-ClinicalTrial-Test","keyword":"monolingual","description":"\n  BIRCO-ClinicalTrial\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the Clinical-Trial dataset from BIRCO. This dataset contains 50 queries that are patient case reports. Each query has a candidate pool comprising 30-110 clinical trial descriptions. Relevance is graded (0, 1, 2), where 1 and 2 are considered relevant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_pa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Panjabi"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_4b","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-4B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_4b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_4b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-I-50","keyword":"monolingual","description":"Welcome to the Friend or Foe Collection!\n","url":"https://huggingface.co/datasets/powidla/BC-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"CUADTerminationForConvenienceLegalBenchClassification","keyword":"monolingual","description":"\n  CUADTerminationForConvenienceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that one party can terminate this contract without cause (solely by giving a notice and allowing a waiting period to expire).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"TOFU","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/locuslab/TOFU.","url":"https://huggingface.co/datasets/locuslab/TOFU","creator_name":"Locus Lab","creator_url":"https://huggingface.co/locuslab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna-fr","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoArguAna.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoArguAna-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoArguAna","French"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"monolingual","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"LccSentimentClassification","keyword":"monolingual","description":"\n  LccSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe leipzig corpora collection, annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://github.com/fnielsen/lcc-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LccSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LccSentimentClassification.","url":"https://huggingface.co/datasets/mteb/LccSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"vep_mendelian_traits_chr11_split","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nå­—æ®µ: ref, alt, label, chromosome, position\nåˆ’åˆ†: chromosome=1ä¸ºtestï¼Œå…¶ä½™ä¸ºtrain\næ”¯æŒè‡ªåŠ¨ç”Ÿæˆref/altåºåˆ—\n\n\n\t\n\t\t\n\t\tç”¨æ³•\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_mendelian_traits_chr11_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ä¸Šä¼ åˆ° HuggingFace\n\n1. **åˆå§‹åŒ–git repoï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_split.","url":"https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_split","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"ruschatgpt-qa","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for ruschatgpt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains question-answer pairs collected from ruschatgpt.ru, a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 190,281 unique question-answer pairs covering various topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa.","url":"https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"danish-dynaword","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tðŸ§¨ Danish Dynaword\n\t\n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\nVersion\n1.2.12 (Changelog)\n\n\nLanguage\ndan, dansk, Danish\n\n\nLicense\nOpenly Licensed, See the respective dataset\n\n\nModels\nFor model trained used this data see danish-foundation-models\n\n\nContact\nIf you have question about this project please create an issue here\n\n\n\t\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nNumber of samples: 5.61M\nNumber of tokens (Llama 3): 5.89B\nAverage document length in tokens (min, max): 1.05K (2, 9.81M)\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danish-foundation-models/danish-dynaword.","url":"https://huggingface.co/datasets/danish-foundation-models/danish-dynaword","creator_name":"Danish Foundation Models","creator_url":"https://huggingface.co/danish-foundation-models","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (Peopleâ€™s Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"glue-ci","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained analysis of systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evaluate/glue-ci.","url":"https://huggingface.co/datasets/evaluate/glue-ci","creator_name":"evaluate","creator_url":"https://huggingface.co/evaluate","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"CUADNonTransferableLicenseLegalBenchClassification","keyword":"monolingual","description":"\n  CUADNonTransferableLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause limits the ability of a party to transfer the license being granted to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification.","url":"https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_second_iteration","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API costâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-Direct","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning ðŸ¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Direct.","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Direct","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true},
	{"name":"mars-multi-label-classification","keyword":"monolingual","description":"\n\t\n\t\t\n\t\tMER - Mars Exploration Rover Dataset\n\t\n\nA multi-label classification dataset containing Mars images from the Mars Exploration Rover (MER) mission for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-10\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset uses multi-label classification, meaning each image can have multiple class labels.\nThe dataset contains the following classes:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-multi-label-classification.","url":"https://huggingface.co/datasets/gremlin97/mars-multi-label-classification","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true}
]
;
