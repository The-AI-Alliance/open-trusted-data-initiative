const data_for_modality_monolingual = 
[
	{"name":"DOID","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/DOID","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from DOID's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SnomedCT","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/SnomedCT","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from SnomedCT's subsumption hierarchy (TBox) for training and evaluating hierarchy embedding models.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"text_meme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/text_meme","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\ttext_meme\n\t\n\n–°–æ—Å–∫—Ä–∞–ø–µ–Ω–æ —Å –æ—Ç–ª–∏—á–Ω–æ–≥–æ Telegram –∫–∞–Ω–∞–ª–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ–º—ã.\n","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","monolingual","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations_cleaned","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset (cleaned)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"pxhere","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/pxhere","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for pxhere Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a large collection of high-quality photographs sourced from pxhere.com, a free stock photo website. The dataset includes approximately 1,100,000 images in full resolution covering a wide range of subjects including nature, people, urban environments, objects, animals, and landscapes. All images are provided under the Creative Commons Zero (CC0) license, making them freely available for personal and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pxhere.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"mb-frost_cls","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-frost_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-frost_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: frost\n1: non_frost\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 30124 images\ntest: 12249 images\nval: 11415 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 images\nfew_shot_train_10_shot:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-frost_cls.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"check","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shainaraza/check","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","description":"shainaraza/check dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"RoSTSC","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlackKakapo/RoSTSC","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","description":"\n\t\n\t\t\n\t\tRO-STS-Cupidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nRoSTSC is a Romanian Semantic Textual Similarity (STS) dataset designed for evaluating and training sentence embedding models. It contains pairs of Romanian sentences along with similarity scores that indicate the degree of semantic equivalence between them.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nsentence1: The first sentence in the pair.\nsentence2: The second sentence in the pair.\nscore: A numerical value representing the semantic similarity between the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlackKakapo/RoSTSC.","first_N":5,"first_N_keywords":["sentence-similarity","monolingual","Romanian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"my_dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wkdnev/my_dataset","creator_name":"Neil Rainsforth","creator_url":"https://huggingface.co/wkdnev","description":"\n\t\n\t\t\n\t\tTest Sentiment Dataset\n\t\n\nA small sample dataset for text classification tasks, specifically binary sentiment analysis (positive or negative). Useful for testing, demos, or building and validating pipelines with Hugging Face Datasets.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short text samples labeled as either positive or negative. It is intended for testing purposes and includes:\n\n10 training samples\n4 test samples\n\nEach example includes:\n\ntext: A short sentence or review‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wkdnev/my_dataset.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"merged_valid","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1g0rrr/merged_valid","creator_name":"Igor","creator_url":"https://huggingface.co/1g0rrr","description":"\n\t\n\t\t\n\t\tDataset Card for 1g0rrr/merged_valid\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LeRobot v2.1 format with the following structure:\n\nmeta/info.json: Dataset metadata and configuration\nmeta/episodes.jsonl: Episode information including tasks and lengths\nmeta/tasks.jsonl: Task descriptions and indices\nmeta/episodes_stats.jsonl: Per-episode statistics\ndata/chunk_*/episode_*.parquet: Episode data files\nvideos/chunk_*/video_key_*/episode_*.mp4: Video files (if present)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1g0rrr/merged_valid.","first_N":5,"first_N_keywords":["robotics","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mb-conequest_det","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-conequest_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-conequest_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 10 splits: train, val, test, 0.01x_partition, 0.02x_partition, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.01x_partition, 0.02x_partition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-conequest_det.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PubMedQA-MetaGenBlendedRAG","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG","creator_name":"Shivam Raj Solanki","creator_url":"https://huggingface.co/Shivam6693","description":"\n\t\n\t\t\n\t\tPubMedQA-MetaGen: Metadata-Enriched PubMedQA Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPubMedQA-MetaGen is a metadata-enriched version of the PubMedQA biomedical question-answering dataset, created using the MetaGenBlendedRAG enrichment pipeline. The dataset contains both the original and enriched versions of the corpus, enabling direct benchmarking of retrieval-augmented and semantic search approaches in biomedical NLP.\n\n\n\t\n\t\t\n\t\tFiles Provided\n\t\n\n\nPubMedQA_original_corpus.csv\nThis file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG.","first_N":5,"first_N_keywords":["text-retrieval","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"BACE-V-SMILES-2","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChemVision/BACE-V-SMILES-2","creator_name":"ChemVisionLanguage","creator_url":"https://huggingface.co/ChemVision","description":"\n\t\n\t\t\n\t\tBACE Dataset\n\t\n\nThis dataset contains BACE molecule images generated from SMILES strings.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nQuestion: The question associated with the molecule\nAnswer: The answer associated with the molecule\nTargetMolecule: SMILES representation of the molecule\nSampleMethod: Method used for sampling\nSampleNum: Sample number\nSampleRep: Sample representation\nfile_name: The file path to the molecule image\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChemVision/BACE-V-SMILES-2.","first_N":5,"first_N_keywords":["image-classification","monolingual","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mb-atmospheric_dust_cls_edr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_edr","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-atmospheric_dust_cls_edr\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: dusty\n1: not_dusty\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 9817 images\ntest: 5214 images\nval: 4969 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_edr.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_seg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-boulder_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-boulder_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Boulder\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks\n  ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-boulder_seg.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-crater_binary_seg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-crater_binary_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-crater_binary_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Crater\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-crater_binary_seg.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-conequest_seg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-conequest_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-conequest_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Cone\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks\n  ‚îú‚îÄ‚îÄ val/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-conequest_seg.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/IRRISIGHT","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-crater_multi_seg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-crater_multi_seg","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-crater_multi_seg\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Other\n2: Layered\n3: Buried\n4: Secondary\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-crater_multi_seg.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"melange_visual_bbq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDfree/melange_visual_bbq","creator_name":"no_ID","creator_url":"https://huggingface.co/IDfree","description":"\n\t\n\t\t\n\t\tMelange Visual Bias Benchmark\n\t\n\nA visual multiple-choice benchmark for evaluating social bias and reasoning in vision-language models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMelange Visual Bias Benchmark is a multimodal extension of the BBQ (Bias Benchmark for Question Answering) dataset, designed to probe social bias and fairness in VLMs (Vision-Language Models). Instead of relying on textual context, this dataset grounds each multiple-choice question in one or more scene images that depict the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IDfree/melange_visual_bbq.","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","visual-question-answering","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mb-mmls","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-mmls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-mmls\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Landslide\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks\n  ‚îú‚îÄ‚îÄ val/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mmls.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"my_dataset_repo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/talmahmud/my_dataset_repo","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","description":"talmahmud/my_dataset_repo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"myface","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Temka/myface","creator_name":"Temka Serge","creator_url":"https://huggingface.co/Temka","description":"\n\t\n\t\t\n\t\tZurag Dataset with Prompts\n\t\n\nThis dataset contains a collection of face images with corresponding text descriptions (prompts). It is inspired by the structure of Temka/myface and is designed for applications such as:\n\nFine-tuning diffusion models (e.g., Stable Diffusion, LoRA)\nFace recognition\nText-to-image generation\n\n\n\t\n\t\t\n\t\tüßæ Dataset Structure\n\t\n\n\nimages/ ‚Äî folder containing all the .jpg image files.\nmetadata.csv ‚Äî a CSV file with the following columns:\nfile_name: name of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Temka/myface.","first_N":5,"first_N_keywords":["image-classification","text-to-image","manually-created","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"deepseek-svg-description","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShahzebKhoso/deepseek-svg-description","creator_name":"Shahzeb Khoso","creator_url":"https://huggingface.co/ShahzebKhoso","description":"\n\t\n\t\t\n\t\tSVG Reasoning and Generation Dataset\n\t\n\nA rich dataset containing SVG graphics, structured reasoning, and generated descriptions.Built from the base of thesantatitan/deepseek-svg-dataset but enhanced with separated SVG codes and detailed reasoning-based descriptions.\n\n\t\n\t\t\n\t\n\t\n\t\tDescription Generation Process\n\t\n\nThe dataset has been enhanced by using the reasoning part from the original completion to generate longer, detailed descriptions. The SVG code part of the completion is ignored‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShahzebKhoso/deepseek-svg-description.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"first-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yarinkos/first-dataset","creator_name":"Yarin Kos","creator_url":"https://huggingface.co/yarinkos","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yarinkos/first-dataset.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"WixQA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wix/WixQA","creator_name":"Wix","creator_url":"https://huggingface.co/Wix","description":"\n\t\n\t\t\n\t\tWixQA: Enterprise RAG Question-Answering Benchmark\n\t\n\nüìÑ Full Paper Available: For comprehensive details on dataset design, methodology, evaluation results, and analysis, please see our complete research paper:\nWixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation\nCohen et al. (2025) - arXiv:2505.08643\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nWixQA is a three-config collection for evaluating and training Retrieval-Augmented Generation (RAG) systems in enterprise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wix/WixQA.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","open-domain-qa","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"warrungu-dictionary","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warrungu/warrungu-dictionary","creator_name":"Christopher morganson","creator_url":"https://huggingface.co/warrungu","description":"This dataset contains cleaned dictionary and grammar resources for the Warrungu language, compiled from structured CSV files for use in language revitalisation apps and AI tutors.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nCleaned_Warrungu_Dictionary.csv\nwarrungu_flashcards.csv\nwarrungu_suffix_table.csv\n/images/ (Warrungu flashcard images)\n/audio/ (Warrungu flashcard audio)\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution 4.0 International (CC BY 4.0)\n\n\t\n\t\t\n\t\tContact\n\t\n\nMaintained by the Warrungu project team.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warrungu/warrungu-dictionary.","first_N":5,"first_N_keywords":["translation","human-annotated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-2.0","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 2.0 (GPL-2.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-3.0","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 3.0 (GPL-3.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, and textures along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset descriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cdg-neural-math-qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahlen/cdg-neural-math-qa","creator_name":"Cahlen Humphreys","creator_url":"https://huggingface.co/cahlen","description":"\n\t\n\t\t\n\t\tNeural Math QA Dataset\n\t\n\nThis directory contains the neural_math_qa.jsonl dataset, used for fine-tuning models for question-answering related to neural networks and pure mathematics.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of question-answer pairs focused on the intersection of neural networks and pure mathematics concepts. It was generated synthetically using an LLM.\nTopics include:\n\nLinear algebra foundations\nTopology in network spaces\nDifferentiable manifolds\nMeasure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahlen/cdg-neural-math-qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"grade_labeled_wiki_paragraphs","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","description":"\n\t\n\t\t\n\t\tGrade-Labeled Wiki Paragraphs (GPT-4.1 Nano)\n\t\n\nThis dataset contains Wikipedia paragraphs simplified to different grade reading levels (targeting Grade 1-12) using the GPT-4.1 Nano model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of pairs of original Wikipedia paragraphs and their machine-generated simplified versions. The simplification aims to make the text understandable for readers at specific US grade levels while preserving the core‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs.","first_N":5,"first_N_keywords":["text-simplification","machine","machine","monolingual","agentlans/wikipedia-paragraphs"],"keywords_longer_than_N":true},
	{"name":"publicdomainfiles","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/publicdomainfiles","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for PublicDomainFiles.com Collection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains various public domain media files collected from PublicDomainFiles.com. The website hosts a diverse collection of user-shared content explicitly released into the public domain, including images, fonts, clip art, artwork, video clips, TV shows, and pictures. While images are the predominant file type, the dataset encompasses a wide range of multimedia formats. Each item includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/publicdomainfiles.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"DCLM_German","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faidrap/DCLM_German","creator_name":"Faidra Patsatzi","creator_url":"https://huggingface.co/faidrap","description":"\n\t\n\t\t\n\t\tDCLM German Dataset\n\t\n\nThis dataset contains German language data processed for LLM pretraining, filtered using FastText language detection.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the entire dataset\ndataset = load_dataset(\"faidrap/DCLM_German\")\n\n# Stream for large datasets (recommended)\ndataset = load_dataset(\"faidrap/DCLM_German\", streaming=True)\n\n# Access the data\nfor example in dataset['train']:\n    print(example['text'][:100])  # Print first 100 chars‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faidrap/DCLM_German.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"MixBench25-visual","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mixed-modality-search/MixBench2025","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench2025.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset_support","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_support","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_support.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ClevelandMuseumArt","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tCleveland Museum of Art Open Access Dataset\n\t\n\nThis dataset contains the complete Cleveland Museum of Art Open Access collection data, originally sourced from the ClevelandMuseumArt/openaccess GitHub repository and reuploaded for broader distribution, Parquet generation for high-performance analytics, and seamless integration with data science workflows.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Cleveland Museum of Art provides open access to information on more than 61,000 artworks in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","image-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"entrenamiento-intents-luca","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QV-AI-Training/entrenamiento-intents-luca","creator_name":"QV-AI-Training","creator_url":"https://huggingface.co/QV-AI-Training","description":"\n\t\n\t\t\n\t\tDataset de clasificaci√≥n de intents conversacionales en espa√±ol\n\t\n\nEste dataset contiene ejemplos en espa√±ol para entrenar un modelo de clasificaci√≥n de intents. Est√° dise√±ado para sistemas conversacionales que ejecutan acciones basadas en entradas del usuario, como consultas, creaci√≥n o modificaci√≥n de entidades, planificaci√≥n o control de operaciones.\n\n\t\n\t\t\n\t\tFormato\n\t\n\nCada entrada incluye:\n\ntext: mensaje en lenguaje natural.\nintent: clase que representa la intenci√≥n del usuario‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QV-AI-Training/entrenamiento-intents-luca.","first_N":5,"first_N_keywords":["text-classification","intent-classification","team","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cuebench","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ishwarbb23/cuebench","creator_name":"Ishwar B","creator_url":"https://huggingface.co/ishwarbb23","description":"\n\t\n\t\t\n\t\tCUEBench: Contextual Unobserved Entity Benchmark\n\t\n\nCUEBench is a neurosymbolic benchmark that emphasizes contextual entity prediction in autonomous driving scenes. Unlike traditional detection tasks, CUEBench focuses on reasoning over unobserved entities ‚Äî objects that may be occluded, out-of-frame, or affected by sensor failures.\n\n\t\n\t\t\n\t\tTask\n\t\n\nInput: A scene ID and a set of observed_classes present in the scene\nOutput: Predict the target_classes that were present but unobserved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ishwarbb23/cuebench.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","human-annotated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"twi-fante-sentences-parts-of-speech-pos-10m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-fante-sentences-parts-of-speech-pos-10m","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tAkan POS Tagging Dataset - 10 Million Sentences\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes sentences and part-of-speech tags and is aimed at supporting the development of POS tagging models for the Akan language.\nThis work demonstrates that data limitations for low-resource languages can be overcome using artificial data generation techniques.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nsentence: The Akan sentence text\npos_sequence: Part-of-speech tags for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-fante-sentences-parts-of-speech-pos-10m.","first_N":5,"first_N_keywords":["text-classification","token-classification","part-of-speech","synthetic","machine-generated"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoDBPedia-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoDBPedia.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoDBPedia","French"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFEVER.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFEVER","French"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoMSMARCO-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoMSMARCO.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoMSMARCO","French"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoQuoraRetrieval-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoQuoraRetrieval.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoQuoraRetrieval","French"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoSCIDOCS-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSCIDOCS.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSCIDOCS","French"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoArguAna-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoArguAna.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoArguAna","French"],"keywords_longer_than_N":true},
	{"name":"yuxiaowang-prompts-2025","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/languagehub-ai/yuxiaowang-prompts-2025","creator_name":"Yuxiaowang ¬∑ ËØ≠Ë®ÄÂ≠¶Ê†°Êï∞ÊçÆ‰∏≠ÂøÉ","creator_url":"https://huggingface.co/languagehub-ai","description":"\n\t\n\t\t\n\t\tYuxiaowang Semantic Dataset ¬∑ Hugging Face Version\n\t\n\n\n\t\n\t\t\n\t\tüß† English Summary\n\t\n\n\n\t\n\t\t\n\t\tYuxiaowang ¬∑ Semantic Dataset for Japanese Language Schools (Chinese)\n\t\n\nThis project provides structured semantic definitions and prompt examples for the domain of Japanese language schools in China.It aims to serve as a grounding corpus for large language models (LLMs) to understand terms like \"ËØ≠Ê†°\", \"ËØ≠Ê†°ÁΩë\", and related concepts.\n\nSource platform: https://www.yuxiaowang.comAll prompts and term‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/languagehub-ai/yuxiaowang-prompts-2025.","first_N":5,"first_N_keywords":["text-generation","question-answering","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Kiali","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kiali/Kiali","creator_name":"Kiali","creator_url":"https://huggingface.co/Kiali","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Kiali Chatbot Q&A Dataset is a collection of question-answer pairs focused on Kiali, an observability console for Istio service meshes, and related Istio concepts. This dataset is specifically designed to facilitate the training of conversational AI models (chatbots) aimed at assisting users with understanding and troubleshooting the Kiali interface and core Istio functionalities.\nThe dataset includes questions and answers derived‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kiali/Kiali.","first_N":5,"first_N_keywords":["question-answering","document-question-answering","conversational","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"cc0-textures","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cc0-textures","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for CC0 Textures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 18,785 texture images from cc0-textures.com. It includes textures of wood, metal, concrete, fabric, stone, ceramic, and other materials. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while keeping good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): Texture titles and tags‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cc0-textures.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"eli-why","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/eli-why","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tüìò ELI-Why\n\t\n\n\n\t\n\t\t\n\t\tüß† Dataset Summary\n\t\n\nELI-Why is a benchmark for evaluating how well large language models (LLMs) explain \"Why\" questions to people across different educational levels.This full release contains over 13,000 diverse ‚ÄúWhy‚Äù questions with:\n\nüìö Domain and Discipline metadata\nüåê A web-retrieved explanation\nü§ñ 16 model-generated explanations from 4 LLMs:\nGPT-4\nLLaMA 3.2\nQwen 2.5\nR1-Distilled LLaMA\n\n\n\nEach model responds at four educational levels: üßí elementary school‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why.","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"eli-why-manually-web-retrieved","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tüìö ELI-Why Manually Web-Retrieved Explanations\n\t\n\n\n\t\n\t\t\n\t\tüß† Dataset Summary\n\t\n\nThis dataset contains high-quality, manually curated explanations for \"Why\" questions, retrieved from the web to serve as educationally appropriate references.Each explanation is annotated with:\n\nA corresponding question\nA fine-grained topic and domain label (e.g., STEM / Physics)\nThe intended educational level (Elementary, High School, Graduate)\nThe original source URL from which the explanation was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved.","first_N":5,"first_N_keywords":["expert-verified","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"NewsClassification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/1509.01626\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NorwegianParliamentClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NorwegianParliamentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorwegianParliamentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNorwegian parliament speeches annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nGovernment, Spoken\n\n\nReference\nhttps://huggingface.co/datasets/NbAiLab/norwegian_parliament\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NorwegianParliamentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianParliamentClassification.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Norwegian Bokm√•l","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"OverrulingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OverrulingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task consists of classifying whether or not a particular sentence of case law overturns the decision of a previous case.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PersonalJurisdictionLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PersonalJurisdictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a fact pattern describing the set of contacts between a plaintiff, defendant, and forum, determine if a court in that forum could excercise personal jurisdiction over the defendant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PoemSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PoemSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PoemSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2011.02686\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PoemSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PoemSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-OUT","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-OUT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-OUT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-OUT task is to predict the sentiment of out-of-domain (products and school) reviews using models train on reviews from medicine and hotels domains.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-OUT.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PpcPC","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PpcPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PpcPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Paraphrase Corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction, Non-fiction, Web, Written, Spoken, Social, News\n\n\nReference\nhttps://arxiv.org/pdf/2207.12759.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PpcPC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PpcPC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"counterfactual_history_reasoning","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning","creator_name":"Alex Strick van Linschoten","creator_url":"https://huggingface.co/strickvl","description":"\n\t\n\t\t\n\t\tDataset Card for Counterfactual History Reasoning Dataset\n\t\n\nThe Counterfactual History Reasoning Dataset contains 100 examples of counterfactual reasoning applied to historical events. Each example presents a historical event, poses a \"what if\" counterfactual premise, provides a step-by-step reasoning trace exploring the implications across multiple domains, and concludes with an alternative historical outcome. The reasoning traces and conclusions were generated using DeepSeek-R1, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning.","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-license-plate-ocr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr","creator_name":"Nuttapong Chimwai","creator_url":"https://huggingface.co/morsetechlab","description":"\n\t\n\t\t\n\t\tThai License Plate OCR Dataset üáπüá≠\n\t\n\nüá∫üá∏ English Version\n\nTask: Optical Character Recognition (OCR)\nLanguage: Thai üáπüá≠  \n\nOCR dataset ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR-rec ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞\n‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\n\n\n‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö PaddleOCR-rec (‡πÑ‡∏°‡πà‡∏°‡∏µ detection / classification)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nthai-license-ocr-dataset/\n‚îú‚îÄ‚îÄ images/           # ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n‚îú‚îÄ‚îÄ train.txt         # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô\n‚îú‚îÄ‚îÄ val.txt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KLUE-STS","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KLUE-STS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KLUE-STS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHuman-annotated STS dataset of Korean reviews, news, and spoken word sets. Part of the Korean Language Understanding Evaluation (KLUE).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nReviews, News, Spoken, Written, Spoken\nReference\nhttps://arxiv.org/abs/2105.09680\n\n\n\t\n\nSource datasets:\n\nklue/klue\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KLUE-STS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","klue/klue"],"keywords_longer_than_N":true},
	{"name":"TTI-Set","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pointofnoreturn/TTI-Set","creator_name":"laura wagner","creator_url":"https://huggingface.co/pointofnoreturn","description":"\n\t\n\t\t\n\t\tText-to-Image Model Attribution Dataset\n\t\n\nThis dataset is distilled from two comprehensive sources:\n\nA 2-year snapshot of the CivitAI SFW (Safe-for-Work) image dataset, containing metadata for generated images.\nA complete export of all models published on CivitAI, including metadata such as model names, types, and version identifiers.\n\nBy matching image-level resourceIDs (used to generate each image) with the corresponding model version IDs from the model dataset, we identified and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pointofnoreturn/TTI-Set.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"domarks16k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/domarks16k","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tdomarks16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-09\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: aec\n1: ael\n2: cli\n3: cra\n4: fse\n5: fsf\n6: fsg\n7: fss\n8: mix\n9: rid\n10: rou\n11: sfe\n12: sfx\n13: smo\n14: tex\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 11305 images\ntest: 1614 images\nval: 3231 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/domarks16k.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dust-devil-detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/dust-devil-detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tdust-devil-detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-09\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: dust_devil\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/dust-devil-detection.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MMS-VPR","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR","creator_name":"Yiwei Ou","creator_url":"https://huggingface.co/Yiwei-Ou","description":"\n\t\n\t\t\n\t\tMMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset\n\t\n\nMultimodal Street-Level Visual Place Recognition Dataset (MMS-VPR) is a novel, open-access dataset designed to advance research in visual place recognition (VPR) and multimodal urban scene understanding. This dataset focuses on complex, fine-grained, and pedestrian-only urban environments, addressing a significant gap in existing VPR datasets that often rely on vehicle-based imagery from road networks and overlook‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.","first_N":5,"first_N_keywords":["image-classification","text-retrieval","multi-class-image-classification","human-annotated","found"],"keywords_longer_than_N":true},
	{"name":"medra-medical","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicoboss/medra-medical","creator_name":"Nico Bosshard","creator_url":"https://huggingface.co/nicoboss","description":"\n\t\n\t\t\n\t\tMedra Medical Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, provisionally named the \"Medra Medical Reasoning Dataset,\" is a curated and processed collection of various medical question answering, dialogue, and reasoning datasets. It has been specifically formatted to facilitate the training of large language models, such as Gemma 3 (code-named Medra in this project), to improve their medical knowledge, enhance their reasoning capabilities, and enable them to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicoboss/medra-medical.","first_N":5,"first_N_keywords":["question-answering","text-generation","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"mars-multi-label-classification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/mars-multi-label-classification","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tMER - Mars Exploration Rover Dataset\n\t\n\nA multi-label classification dataset containing Mars images from the Mars Exploration Rover (MER) mission for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-10\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset uses multi-label classification, meaning each image can have multiple class labels.\nThe dataset contains the following classes:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-multi-label-classification.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"My","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ochir04075143/My","creator_name":"Ochir","creator_url":"https://huggingface.co/Ochir04075143","description":"\n\t\n\t\t\n\t\tMy Face Dataset\n\t\n\nThis dataset contains a collection of face images with corresponding text descriptions (prompts). It is designed for applications such as:\n\nFine-tuning diffusion models (e.g., Stable Diffusion, LoRA)\nFace recognition\nText-to-image generation\n\n\n\t\n\t\t\n\t\tüßæ Dataset Structure\n\t\n\n\ntrain/ ‚Äî folder containing all the .jpg image files.\nmetadata.jsonl ‚Äî a JSON Lines file where each line is a JSON object with the following fields:\nfile_name: name of the image file.\ntext: a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ochir04075143/My.","first_N":5,"first_N_keywords":["image-classification","text-to-image","manually-created","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"crater_binary_segmentation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/crater_binary_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tcrater_binary_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Crater\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/crater_binary_segmentation.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"crater_multi_segmentation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/crater_multi_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tcrater_multi_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Other\n2: Layered\n3: Buried\n4: Secondary\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/crater_multi_segmentation.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mars-seg_mer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/mars-seg_mer","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tmars-seg_mer\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-seg_mer.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mars-seg_msl","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/mars-seg_msl","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tmars-seg_msl\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mars-seg_msl.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"conequest_detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/conequest_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tconequest_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: cone\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/conequest_detection.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"LearningPaper24","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vivianchen98/LearningPaper24","creator_name":"Shenghui Chen","creator_url":"https://huggingface.co/vivianchen98","description":"\n\t\n\t\t\n\t\tLearningPaper24 Dataset\n\t\n\nThis dataset contains video recordings and metadata from ICLR and NeurIPS 2024 conference talks. It includes both poster and oral presentations, along with their associated metadata such as titles, abstracts, keywords, and primary areas.\nThe paper list is originally sourced from Paperlists.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nlearningpaper24/\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ metadata/\n‚îÇ   ‚îî‚îÄ‚îÄ catalog.json\n‚îî‚îÄ‚îÄ video/\n    ‚îú‚îÄ‚îÄ {openreview_id}_{slideslive_id}.mp4\n    ‚îî‚îÄ‚îÄ ...‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vivianchen98/LearningPaper24.","first_N":5,"first_N_keywords":["summarization","video-text-to-text","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"mnist","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/minpeter/mnist","creator_name":"minpeter","creator_url":"https://huggingface.co/minpeter","description":"\n\t\n\t\t\n\t\tDataset Card for MNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\nHalf of the image were drawn by Census Bureau employees and the other half by high school students‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minpeter/mnist.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"diet-planning-evaluation-20250531-140238","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140238","creator_name":"Alex Jihun Kim","creator_url":"https://huggingface.co/alexjk1m","description":"\n\t\n\t\t\n\t\tDiet Planning Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains evaluation results for diet planning model responses.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance contains a model response and its evaluation metrics.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nFull Prompt: object\nModel Response: object\nDesired Response: object\nNormalized_Edit_Distance: float64‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140238.","first_N":5,"first_N_keywords":["text-generation","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"diet-planning-evaluation-20250531-140436","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjk1m/diet-planning-evaluation-20250531-140436","creator_name":"Alex Jihun Kim","creator_url":"https://huggingface.co/alexjk1m","description":"\n\t\n\t\t\n\t\tDiet Planning Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains evaluation results for diet planning model responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is stored in parquet format for efficient loading and pagination.\n","first_N":5,"first_N_keywords":["text-generation","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cybersecurity_alarm_analysis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis","creator_name":"zheng tian","creator_url":"https://huggingface.co/tiangler","description":"\n\t\n\t\t\n\t\tDataset Card for Security Alert Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ÂÆâÂÖ®ÂëäË≠¶Êó•ÂøóÊï∞ÊçÆÔºåÁî®‰∫éËÆ≠ÁªÉÂ§ßÊ®°ÂûãÂà§Êñ≠ÂÆâÂÖ®ÂëäË≠¶ÊòØÁúüÂÆûÊîªÂáªËøòÊòØËØØÊä•„ÄÇÊï∞ÊçÆÈõÜÈááÁî®AlpacaÊ†ºÂºèÔºåÂåÖÂê´instruction„ÄÅinputÂíåoutput‰∏â‰∏™Â≠óÊÆµ„ÄÇ\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTask: ÂÆâÂÖ®ÂëäË≠¶ÂàÜÁ±ª\nTask Type: ÊñáÊú¨ÂàÜÁ±ª\nLanguages: ‰∏≠Êñá\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊñáÊú¨‰∏∫‰∏≠Êñá„ÄÇ\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nÊØè‰∏™Ê†∑Êú¨ÂåÖÂê´‰ª•‰∏ãÂ≠óÊÆµÔºö\n\ninstruction: ‰ªªÂä°ËØ¥ÊòéÔºåÊåáÂØºÊ®°Âûã‰Ωú‰∏∫ÁΩëÁªúÂÆâÂÖ®ÂëäË≠¶ÂàÜÊûê‰∏ìÂÆ∂ÂàÜÊûêÂÆâÂÖ®ÂëäË≠¶Êó•Âøó\ninput: ÂëäË≠¶Êó•ÂøóÊï∞ÊçÆÔºàJSONÊ†ºÂºèÔºâÔºåÂåÖÂê´Â§öÁßçÂÆâÂÖ®ÂëäË≠¶ÁöÑËØ¶ÁªÜ‰ø°ÊÅØ\noutput: Ê†áÁ≠æÔºà\"ÊîªÂáª\"Êàñ\"ËØØÊä•\"Ôºâ\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis.","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"uk_pv","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/James-EPL/uk_pv","creator_name":"James Martin","creator_url":"https://huggingface.co/James-EPL","description":"\n\t\n\t\t\n\t\tUK PV dataset\n\t\n\nDomestic solar photovoltaic (PV) power generation data from Great Britain.\nThis dataset contains data from over 30,000 solar PV systems. The dataset spans 2010 to 2025. \nThe nominal generation capacity per PV system ranges from 0.47 kilowatts to 250 kilowatts.\nThe dataset is updated with new data every few months.\nAll PV systems in this dataset report cumulative energy generation every 30 minutes. This data represents a true accumulation of the total energy generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James-EPL/uk_pv.","first_N":5,"first_N_keywords":["time-series-forecasting","multivariate-time-series-forecasting","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V3\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nAdapted prompt from yourbench\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"iris-clase","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aegarciaherrera/iris-clase","creator_name":"Andr√©s Eduardo Garc√≠a Herrera","creator_url":"https://huggingface.co/aegarciaherrera","description":"\n\t\n\t\t\n\t\tDataset Card for \"iris\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Iris dataset is one of the most classic datasets in machine learning, often used for classification and clustering tasks. It contains 150 samples of iris flowers, each described by four features: sepal length, sepal width, petal length, and petal width. The task is to classify the samples into one of three species: Iris setosa, Iris versicolor, or Iris virginica.\nThis dataset is especially useful for:\n\nSupervised learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aegarciaherrera/iris-clase.","first_N":5,"first_N_keywords":["tabular-classification","multi-class-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmh/gsm8k_fr","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nGSM8K traduit en fran√ßais √† l'aide de quickmt/quickmt-en-fr.\nGSM8K dataset translated to french using quickmt/quickmt-en-fr.\n","first_N":5,"first_N_keywords":["monolingual","French","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Train_data","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-Mock-Interviewer/Train_data","creator_name":"AI-Mock-Interviewer","creator_url":"https://huggingface.co/AI-Mock-Interviewer","description":"AI-Mock-Interviewer/Train_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","dialogue-modeling","human-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"cybersecurity_alarm_analysis_508","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis_508","creator_name":"zheng tian","creator_url":"https://huggingface.co/tiangler","description":"\n\t\n\t\t\n\t\tDataset Card for Security Alert Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ÂÆâÂÖ®ÂëäË≠¶Êó•ÂøóÊï∞ÊçÆÔºåÁî®‰∫éËÆ≠ÁªÉÂ§ßÊ®°ÂûãÂà§Êñ≠ÂÆâÂÖ®ÂëäË≠¶ÊòØÁúüÂÆûÊîªÂáªËøòÊòØËØØÊä•„ÄÇÊï∞ÊçÆÈõÜÈááÁî®AlpacaÊ†ºÂºèÔºåÂåÖÂê´instruction„ÄÅinputÂíåoutput‰∏â‰∏™Â≠óÊÆµ„ÄÇ\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTask: ÂÆâÂÖ®ÂëäË≠¶ÂàÜÁ±ª\nTask Type: ÊñáÊú¨ÂàÜÁ±ª\nLanguages: ‰∏≠Êñá\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊñáÊú¨‰∏∫‰∏≠Êñá„ÄÇ\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nÊØè‰∏™Ê†∑Êú¨ÂåÖÂê´‰ª•‰∏ãÂ≠óÊÆµÔºö\n\ninstruction: ‰ªªÂä°ËØ¥ÊòéÔºåÊåáÂØºÊ®°Âûã‰Ωú‰∏∫ÁΩëÁªúÂÆâÂÖ®ÂëäË≠¶ÂàÜÊûê‰∏ìÂÆ∂ÂàÜÊûêÂÆâÂÖ®ÂëäË≠¶Êó•Âøó\ninput: ÂëäË≠¶Êó•ÂøóÊï∞ÊçÆÔºàJSONÊ†ºÂºèÔºâÔºåÂåÖÂê´Â§öÁßçÂÆâÂÖ®ÂëäË≠¶ÁöÑËØ¶ÁªÜ‰ø°ÊÅØ\noutput: Ê†áÁ≠æÔºà\"ÊîªÂáª\"Êàñ\"ËØØÊä•\"Ôºâ\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tiangler/cybersecurity_alarm_analysis_508.","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"BC-I-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-II-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-V-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-V-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MC-I-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Libra-Emo","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caskcsg/Libra-Emo","creator_name":" KCSG Knowledge Computing and Service Group, IIE, CAS","creator_url":"https://huggingface.co/caskcsg","description":"\n\t\n\t\t\n\t\tüé≠ Libra-Emo Dataset\n\t\n\n\nLibra-Emo is a large-scale multimodal fine-grained dataset for negative emotion detection. It includes video clips, subtitles, emotion labels, and corresponding explanations.\n\n\n\t\n\t\t\n\t\tüìä Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tüìù Sample Structure\n\t\n\nEach sample includes:\n\nüé• A video clip\nüí¨ The corresponding subtitle\nüè∑Ô∏è An emotion label\nüìã An explanation of why the label was assigned\n\n\n\t\n\t\t\n\t\tüéØ Emotion Categories\n\t\n\n\n\t\n\t\t\n\t\tüòä Positive Emotions\n\t\n\n\nExcited üòÜ: A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caskcsg/Libra-Emo.","first_N":5,"first_N_keywords":["video-classification","crowdsourced","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MC-II-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MC-III-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-III-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MC-III-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mb-domars16k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-domars16k","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-domars16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: ael\n1: rou\n2: cli\n3: aec\n4: tex\n5: smo\n6: fss\n7: rid\n8: fse\n9: sfe\n10: fsf\n11: fsg\n12: sfx\n13: cra\n14: mix\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 11305 images\ntest: 1614 images\nval: 3231 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-domars16k.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"GR-III-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-I-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-II-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-III-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-III-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"boulder_detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/boulder_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tboulder_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-16\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: boulder\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/boulder_detection.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"holps","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/holps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tHolStep\n\t\n\nPremise selection dataset for HOL.\nReference: http://cl-informatik.uibk.ac.at/cek/holstep/\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HolStep","English"],"keywords_longer_than_N":true},
	{"name":"msedup","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/msedup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tMathematics Stack Exchange Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/math.stackexchange.com.7z\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mse","English"],"keywords_longer_than_N":true},
	{"name":"isabelleps","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/isabelleps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tIsabelle Premise Selection\n\t\n\npremise selection evaluation dataset for Isabelle, sourced from MAPL (https://huggingface.co/datasets/Simontwice/premise_selection_in_isabelle).\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MACHINE-AUGMENTED PROOFS LIBRARY (MAPL)","English"],"keywords_longer_than_N":true},
	{"name":"mathlibretrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/mathlibretrieval","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tInformalized Mathlib4 Retrieval Dataset\n\t\n\nThe goal is to retrieve relevant mathlib4 theorems based on informal mathematical queries. Sourced from https://huggingface.co/datasets/hcju/leansearch_bench/\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","leansearch","English"],"keywords_longer_than_N":true},
	{"name":"custom_tofu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/talmahmud/custom_tofu","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","description":"talmahmud/custom_tofu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mseformula","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/mseformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tARQMath-Task-2\n\t\n\nMathematics Stack Exchange Formula Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"proofwikips","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/proofwikips","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tProofWiki Premise Selection Dataset, part of NaturalProofs Dataset\n\t\n\nSourced from NaturalProofs https://zenodo.org/records/4902289\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"stacksqa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/stacksqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tStacks Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the Stacks dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","stacks","English"],"keywords_longer_than_N":true},
	{"name":"enhanced-ud-syntax","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoBaLD/enhanced-ud-syntax","creator_name":"CoBaLD Annotation Project","creator_url":"https://huggingface.co/CoBaLD","description":"\n\t\n\t\t\n\t\tEnhanced Universal Dependencies (syntax only) dataset\n\t\n\nThis repo aggregates syntactic markup from UD_English-EWT and UD_English-GUM datasets.\nChanges made to the source datasets:\n\nOnly syntactic tags (head, deprel, deps) are preserved\nShort sentences (fewer than 3 tokens) are removed\n\nSource datasets:\n\nUD_English-EWT: https://github.com/UniversalDependencies/UD_English-EWT\nUD_English-GUM: https://github.com/UniversalDependencies/UD_English-GUM\n\n","first_N":5,"first_N_keywords":["token-classification","monolingual","UD_English-EWT","UD_English-GUM","English"],"keywords_longer_than_N":true},
	{"name":"clean-medqa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChakradharS/clean-medqa","creator_name":"Chakradhar","creator_url":"https://huggingface.co/ChakradharS","description":"\n\t\n\t\t\n\t\tü©∫ Clean MedQA Dataset\n\t\n\n\nImproving healthcare through language-based AI.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nThe Clean MedQA dataset is a refined version of data originally sourced from the MedQuAD (Medical Question Answering Dataset) ‚Äî a well-known resource for building question-answering systems in the healthcare domain.\nThis cleaned version is optimized for Natural Language Processing (NLP) tasks, particularly for training and evaluating models that need to understand or generate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChakradharS/clean-medqa.","first_N":5,"first_N_keywords":["question-answering","text-classification","summarization","token-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeMoussel/LEGI","creator_name":"LeMoussel","creator_url":"https://huggingface.co/LeMoussel","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (14/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeMoussel/LEGI.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wbigger/sentiment-analysis-test","creator_name":"Claudio Capobianco","creator_url":"https://huggingface.co/wbigger","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wbigger/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Loacky/sentiment-analysis-test","creator_name":"Lorenzo Adacher","creator_url":"https://huggingface.co/Loacky","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Loacky/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Felipeit/sentiment-analysis-test","creator_name":"Felipe Simoes Campos","creator_url":"https://huggingface.co/Felipeit","description":"\n\t\n\t\t\n\t\tProgetto scolastico per L'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felipeit/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test","creator_name":"Marrocco Marco","creator_url":"https://huggingface.co/Cocciadipollo","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effetuate coorelando le risposte testuali ad indicatori di gradimento.\nIl dataaset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'IA.\nGrazie a tutti per la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test","creator_name":"Fra Merlino","creator_url":"https://huggingface.co/Merlinooooo","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qwertychri/sentiment-analysis-test","creator_name":"Christian Scimenes","creator_url":"https://huggingface.co/qwertychri","description":"Il dataset √® stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tutti per la collaborazione ‚ù§Ô∏è\n","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Liux69/sentiment-analysis-test","creator_name":"Lorenzo Martirani Paolillo","creator_url":"https://huggingface.co/Liux69","description":"Liux69/sentiment-analysis-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/happycircus1/sentiment-analysis-test","creator_name":"tghrgg","creator_url":"https://huggingface.co/happycircus1","description":"#Sentiment analysi School project\nthe dataset was created with an online questionnaire in which an audience of students, teachers, administrative staff, and families were asked to answer some questions about their relationship with school.\nthe annotations were made by correlating the textual responses to satisfaction indicators.\nthe dataset was created within an afternoon course dedicated to artificial intelligence.\nthanks to everyone for their collaboration‚ù§Ô∏è.\n","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sjwsjw/github-issues","creator_name":"sjw","creator_url":"https://huggingface.co/sjwsjw","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sjwsjw/github-issues.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"recaptchav2-29k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k","creator_name":"Dennis J.","creator_url":"https://huggingface.co/nobodyPerfecZ","description":"\n\t\n\t\t\n\t\tReCAPTCHAv2-29k\n\t\n\nReCAPTCHAv2-29k is a dataset consisting of images derived from Google's ReCAPTCHA v2 system, which is widely used for online human verification.\nIt contains thousands of ReCAPTCHA images, each paired with corresponding labels indicating the presence of specific objects or features (e.g., bicycle, bus, car).\nThis dataset is intended for educational and research purposes and is particularly suited for tasks such as feature extraction and multi-label image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","found","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"clker-images","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/clker-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Clker.com Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 140,313 public domain clipart images collected from Clker.com. Clker.com hosts user-shared vector clip art that is explicitly released into the public domain (CC0). The dataset includes the images themselves along with metadata such as titles and tags associated with each image.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All image titles and tags are in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/clker-images.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-s5mars","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-s5mars","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-s5mars\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Hole\n3: Ridge\n4: Rock\n5: Rover\n6: Sand / Soil\n7: Sky\n8: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  #‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-s5mars.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"BLUR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/forgelab/BLUR","creator_name":"Forge Lab","creator_url":"https://huggingface.co/forgelab","description":"\n\t\n\t\t\n\t\tBLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap \n\t\n\nThe BLUR dataset expands on existing unlearning benchmarks by providing harder evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on BLUR, with simple approaches performing better on average than more recent methods.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/forgelab/BLUR.","first_N":5,"first_N_keywords":["question-answering","text-generation","closed-domain-qa","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_det","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/mb-boulder_det","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tmb-boulder_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 8 splits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/mb-boulder_det.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-boulder_det","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-boulder_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-boulder_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 8 splits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-16\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-boulder_det.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tofu_ext1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/talmahmud/tofu_ext1","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","description":"talmahmud/tofu_ext1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Contract_Clause_SampleDataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asapworks/Contract_Clause_SampleDataset","creator_name":"Siddharth shankar Asapu","creator_url":"https://huggingface.co/asapworks","description":"\n\t\n\t\t\n\t\tüì¶ Contract Clause Dataset (Sample Preview)\n\t\n\nüîó To purchase the full dataset (66,813 clauses), visit:  ‚û°Ô∏è https://asapworks.gumroad.com/l/wtave\nSupport: Asapuaiworks@gmail.com\n\nThis file provides a 200-record preview of the full Contract Clause Dataset v1.0 ‚Äî a high-quality, enriched legal dataset containing clauses extracted from 10+ years of SEC contract filings.\nThe dataset is designed for legal AI, NLP research, and clause-based retrieval systems.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ What's Inside‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asapworks/Contract_Clause_SampleDataset.","first_N":5,"first_N_keywords":["text-classification","topic-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mb-atmospheric_dust_cls_rdr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_rdr","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-atmospheric_dust_cls_rdr_upd\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-22\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: dusty\n1: not_dusty\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 9817 images\ntest: 5214 images\nval: 4969 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-atmospheric_dust_cls_rdr.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"complex_mathematical-scientific-notation-parallel","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/complex_mathematical-scientific-notation-parallel","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tMathematical and Scientific Notation Parallel Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in mathematical and scientific contexts. It contains identical mathematical content expressed in four different notation styles, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison: Compare how different tokenizers (BPE, SentencePiece‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/complex_mathematical-scientific-notation-parallel.","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"basic_mathematical-scientific-notation-parallel","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/basic_mathematical-scientific-notation-parallel","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tMathematical and Scientific Notation Parallel Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in mathematical and scientific contexts. It contains identical mathematical content expressed in four different notation styles, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison: Compare how different tokenizers (BPE, SentencePiece‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/basic_mathematical-scientific-notation-parallel.","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"TCP","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beanbagdzf/TCP","creator_name":"Zifeng Ding","creator_url":"https://huggingface.co/Beanbagdzf","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for the TCP dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTCP is a temporal constraint-based planning benchmark that specifically evaluates LLMs' ability in planning under interdependent temporal constraints.\n\nCurated by: Zifeng Ding\nLanguage(s) (NLP): English\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\nThe dataset is split into two categories of problems, i.e., short problems and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beanbagdzf/TCP.","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"ConstructiveBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sunjia72/ConstructiveBench","creator_name":"Jialiang Sun","creator_url":"https://huggingface.co/sunjia72","description":"\nüîç Enumerate‚ÄìConjecture‚ÄìProve: Formally Solving Answer-Construction Problems in Math Competitions\n\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\n\nBackground: We identify that current mathematical reasoning approaches either generate creative answers (LLMs) but fail to verify them formally, or verify rigorously (symbolic provers) but cannot efficiently generate answers.\nContribution: \nWe introduce ECP framework: a modular neuro-symbolic pipeline that integrates a feedback-driven autoformalization stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sunjia72/ConstructiveBench.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-train","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magichampz/medical-cyber-train","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 523\nNumber of unique topics: 9\nNumber of unique subtopics: 48\nLast updated: 2025-05-24\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-train.","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"QASports2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leomaurodesenv/QASports2","creator_name":"Leonardo Mauro","creator_url":"https://huggingface.co/leomaurodesenv","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQASports is the first large sports-themed question answering dataset counting over 1 million questions and answers about 124k preprocessed wiki pages, using as documents the wiki of 20 of the most popular sports in the world, like Soccer, American Football, Basketball, Cricket, and so on. Each sport can be downloaded individually as a subset, with the train, test and validation splits, or all subsets can be downloaded together.\n\nüîß Processing scripts:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leomaurodesenv/QASports2.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"MNLP_M2_mcqa_dataset_2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset_2","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M2 MCQA Dataset 2\n\t\n\nThe MNLP M2 MCQA Dataset 2 is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~25,000 MCQA questions\n7 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset_2.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"chesspiece-detection-yolo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/acapitani/chesspiece-detection-yolo","creator_name":"Andrea Capitani","creator_url":"https://huggingface.co/acapitani","description":"\n\t\n\t\t\n\t\tChess Pieces Detection Dataset (YOLO format)\n\t\n\n\n\t\n\t\t\n\t\tüì¶ Overview\n\t\n\nThis dataset is designed for object detection of chess pieces on a chessboard using YOLOv5/YOLOv10.\n\nClasses: 12 (6 white + 6 black pieces)\nFormat: YOLO (txt annotations)\nSplit: Train/Validation\nImage count: ~2208 images\n\n\n\t\n\t\t\n\t\tüóÇÔ∏è Structure\n\t\n\nimages/train/\nimages/val/\nlabels/train/\nlabels/val/\ndataset.yaml\n\n\n\t\n\t\t\n\t\tüè∑Ô∏è Class Names\n\t\n\n0 = white pawn\n1 = white rook\n2 = white knight\n3 = white bishop\n4 = white queen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/acapitani/chesspiece-detection-yolo.","first_N":5,"first_N_keywords":["object-detection","manual","monolingual","original","extended"],"keywords_longer_than_N":true},
	{"name":"GravityBench","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GravityBench/GravityBench","creator_name":"GravityBench","creator_url":"https://huggingface.co/GravityBench","description":"\n\t\n\t\t\n\t\tGravity-Bench Dataset\n\t\n\n   \nThis dataset contains the benchmark data for Gravity-Bench, a benchmark for evaluating AI agents on discovering gravitational physics through iterative observation and data analysis.\n\n  \n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes 206 physics discovery tasks across various gravitational scenarios.\nEach task provides:\n\nTask prompt and expected units\nHigh-precision simulation data from two-body gravitational systems\nGround truth answers for evaluation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GravityBench/GravityBench.","first_N":5,"first_N_keywords":["table-question-answering","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"templatic_generation_tasks","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/microsoft/templatic_generation_tasks","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","description":"\n\t\n\t\t\n\t\tDataset Card for Active/Passive/Logical Transforms\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a synthetic dataset containing a set of templatic generation tasks using both English and random 2-letter words. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[TBD]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll data is in English or random 2-letter words.  \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of several subsets, or tasks. Each task contains a train split, a dev split, and a\ntest split, and multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/microsoft/templatic_generation_tasks.","first_N":5,"first_N_keywords":["machine-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"leanps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/leanps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tLean Premise Selection Dataset\n\t\n\nLeanDojo (https://zenodo.org/doi/10.5281/zenodo.8040109) premise selection dataset\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","lenandojo","English"],"keywords_longer_than_N":true},
	{"name":"modup","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/modup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tMathOverflow Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/mathoverflow.net.7z\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mo","English"],"keywords_longer_than_N":true},
	{"name":"mseqa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/mseqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tARQMath-Task-1\n\t\n\nMathematics Stack Exchange Answer Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"numbertheoryps","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/numbertheoryps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tNumber Theory Premise Selection Dataset, part of NaturalProofs Dataset\n\t\n\nSourced from NaturalProofs https://zenodo.org/records/4902289\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","number-theory","English"],"keywords_longer_than_N":true},
	{"name":"proofwikiqa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/proofwikiqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tProofWiki Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the ProofWiki dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"wikiformula","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hcju/wikiformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","description":"\n\t\n\t\t\n\t\tNTCIR-WFB\n\t\n\nWiki Formula Browsing Task from NTICR-12 (https://research.nii.ac.jp/ntcir/permission/ntcir-12/perm-en-MathIR.html)\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"openspaces-depth-aware-32-samples","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/srimoyee12/openspaces-depth-aware-32-samples","creator_name":"Srimoyee Mukhopadhyay","creator_url":"https://huggingface.co/srimoyee12","description":"\n\t\n\t\t\n\t\tOpenSpaces Depth-Aware Visual QA Dataset\n\t\n\nThis is a 32-sample visual question answering (VQA) dataset that includes:\n\nRGB images from the OpenSpaces dataset\nPredicted depth maps generated using Depth Anything\n3 depth-aware QA pairs per image:\nYes/No question (e.g., ‚ÄúIs there a person near the door?‚Äù)\nShort answer question (e.g., ‚ÄúWhat color is the man‚Äôs coat?‚Äù)\nSpatial sorting question (e.g., ‚ÄúSort the objects from closest to farthest‚Äù)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Use\n\t\n\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/srimoyee12/openspaces-depth-aware-32-samples.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","visual-question-answering","human-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S.v2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S.v2\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"AngryTweetsClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AngryTweetsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AngryTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.53/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AngryTweetsClassification\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AngryTweetsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ArmenianParaphrasePC","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ArmenianParaphrasePC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArmenianParaphrasePC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nasparius/Armenian-Paraphrase-PC\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/ivannikov-lab/arpa-paraphrase-corpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArmenianParaphrasePC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArmenianParaphrasePC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Armenian"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BulgarianStoreReviewSentimentClassfication","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BulgarianStoreReviewSentimentClassfication\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBulgarian online store review dataset for sentiment classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://doi.org/10.7910/DVN/TXIK9P\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BulgarianStoreReviewSentimentClassfication\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackMT","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CodeFeedbackMT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CodeFeedbackMT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2402.14658\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CodeFeedbackMT\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackMT.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"DalajClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DalajClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DalajClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for linguistic acceptability. Available as a part of Superlim.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/superlim\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DalajClassification\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DalajClassification.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","expert-annotated","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"EstonianValenceClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EstonianValenceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EstonianValenceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset containing annotated Estonian news data from the Postimees and √ïhtuleht newspapers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferencehttps://figshare.com/articles/dataset/Estonian_Valence_Corpus_Eesti_valentsikorpus/24517054\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EstonianValenceClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CUADEffectiveDateLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADEffectiveDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the agreement becomes effective.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADExpirationDateLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADExpirationDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the initial term expires.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADIrrevocableOrPerpetualLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a license grant that is irrevocable or perpetual.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfCustomersLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoSolicitOfCustomersLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party from contracting or soliciting customers or partners of the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfEmployeesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoSolicitOfEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party's soliciting or hiring employees and/or contractors from the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADTerminationForConvenienceLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADTerminationForConvenienceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that one party can terminate this contract without cause (solely by giving a notice and allowing a waiting period to expire).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADThirdPartyBeneficiaryLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADThirdPartyBeneficiaryLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that that there a non-contracting party who is a beneficiary to some or all of the clauses in the contract and therefore can enforce its rights against a contracting party.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADUncappedLiabilityLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADUncappedLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party's liability is uncapped upon the breach of its obligation in the contract. This also includes uncap liability for a particular type of breach such as IP infringement or breach of confidentiality obligation.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grants one party an ‚Äúenterprise,‚Äù ‚Äúall you can eat‚Äù or unlimited usage license.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADWarrantyDurationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADWarrantyDurationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a duration of any warranty against defects or errors in technology, products, or services provided under the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that Confidential Information may include verbally conveyed information.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLILimitedUseLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLILimitedUseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall not use any Confidential Information for any purpose other than the purposes stated in Agreement.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoLicensingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLINoLicensingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Agreement shall not grant Receiving Party any right to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may acquire information similar to Confidential Information from a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleCopyLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleCopyLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may create a copy of some Confidential Information in some circumstances.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may independently develop information similar to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may retain some Confidential Information even after the return or destruction of Confidential Information.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIReturnOfConfidentialInformationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIReturnOfConfidentialInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall destroy or return some Confidential Information upon the termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithEmployeesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISharingWithEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some of Receiving Party's employees.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISurvivalOfObligationsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISurvivalOfObligationsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that some obligations of Agreement may survive termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CorporateLobbyingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CorporateLobbyingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Corporate Lobbying task consists of determining whether a proposed Congressional bill may be relevant to a company based on a company's self-description in its SEC 10K filing.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DefinitionClassificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DefinitionClassificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DefinitionClassificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task consists of determining whether or not a sentence from a Supreme Court opinion offers a definition of a term.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DefinitionClassificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity2LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity2LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 2).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity3LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity3LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 3).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity4LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity4LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 4).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity5LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity5LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 5).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity6LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity6LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 6).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"EightTagsClustering.v2","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EightTagsClustering.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EightTagsClustering.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of headlines from social media posts in Polish belonging to 8 categories: film, history, food, medicine, motorization, work, sport and technology.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.207.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EightTagsClustering.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/8tags-clustering"],"keywords_longer_than_N":true},
	{"name":"FQuADRetrieval","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset has been built from the French SQuad dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/manu/fquad2_test\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FQuADRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FQuADRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"FilipinoShopeeReviewsClassification","keyword":"monolingual","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FilipinoShopeeReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Shopee reviews tl 15 dataset is constructed by randomly taking 2100 training samples and 450 samples for testing and validation for each review star from 1 to 5. In total, there are 10500 training samples and 2250 each in validation and testing samples.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://uijrt.com/articles/v4/i8/UIJRTV4I80009.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeoreviewClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeoreviewClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview classification (5-point scale) based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeorgianSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeorgianSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeorgianSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGoergian Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.173\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeorgianSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeorgianSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GreenNodeTableMarkdownRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GreenNodeTableMarkdownRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreenNodeTable documents\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFinancial, Encyclopaedic, Non-fiction\n\n\nReference\nhttps://huggingface.co/GreenNode\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreenNodeTableMarkdownRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"GujaratiNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GujaratiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GujaratiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Gujarati dataset for 3-class classification of Gujarati news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-gujarati\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GujaratiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GujaratiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Gujarati"],"keywords_longer_than_N":true},
	{"name":"HALClusteringS2S.v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HALClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HALClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from HAL (https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HALClusteringS2S.v2\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HALClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/clustering-hal-s2s","French"],"keywords_longer_than_N":true},
	{"name":"HagridRetrieval","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HagridRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HagridRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset)is a dataset for generative information-seeking scenarios. It consists of queriesalong with a set of manually labelled relevant passages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/project-miracl/hagrid\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HagridRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HinDialectClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HinDialectClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HinDialectClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHinDialect: 26 Hindi-related languages and dialects of the Indic Continuum in North India\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Spoken, Written\n\n\nReferencehttps://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4839\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HinDialectClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Angika"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IndonesianIdClickbaitClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndonesianIdClickbaitClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\nReference\nhttp://www.sciencedirect.com/science/article/pii/S2352340920311252\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification.","first_N":5,"first_N_keywords":["text-classification","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"InsurancePolicyInterpretationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InsurancePolicyInterpretationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven an insurance claim and policy, determine whether the claim is covered by the policy.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"IsiZuluNewsClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IsiZuluNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IsiZuluNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nisiZulu News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/dsfsi/za-isizulu-siswati-news\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IsiZuluNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IsiZuluNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Zulu"],"keywords_longer_than_N":true},
	{"name":"JCrewBlockerLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JCrewBlockerLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe J.Crew Blocker, also known as the J.Crew Protection, is a provision included in leveraged loan documents to prevent companies from removing security by transferring intellectual property (IP) into new subsidiaries and raising additional debt. The task consists of detemining whether the J.Crew Blocker is present in the document.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"JavaneseIMDBClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JavaneseIMDBClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JavaneseIMDBClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge Movie Review Dataset translated to Javanese. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/w11wo/nlp-datasets#javanese-imdb\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JavaneseIMDBClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KannadaNewsClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KannadaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KannadaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Kannada news dataset contains only the headlines of news article in three categories: Entertainment, Tech, and Sports. The data set contains around 6300 news article headlines which are collected from Kannada news websites. The data set has been cleaned and contains train and test set using which can be used to benchmark topic classification models in Kannada.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KannadaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Kannada"],"keywords_longer_than_N":true},
	{"name":"KlueMrcDomainClustering","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KlueMrcDomainClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KlueMrcDomainClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nthis dataset is a processed and redistributed version of the KLUE-MRC dataset. Domain: Game / Media / Automotive / Finance / Real Estate / Education\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KlueMrcDomainClustering.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"KlueYnatMrcCategoryClustering","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KlueYnatMrcCategoryClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KlueYnatMrcCategoryClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nthis dataset is a processed and redistributed version of the KLUE-Ynat & KLUE-MRC  dataset. News_category: IT/Science, Sports, Media/Culture, Ecomomy/Finance, Real Estate\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KlueYnatMrcCategoryClustering.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"KorFin","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorFin","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorFin\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe KorFin-ASC is an extension of KorFin-ABSA, which is a financial sentiment analysis dataset including 8818 samples with (aspect, polarity) pairs annotated. The samples were collected from KLUE-TC and analyst reports from Naver Finance.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written, Financial\n\n\nReference\nhttps://huggingface.co/datasets/amphora/korfin-asc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorFin.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorSarcasmClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorSarcasmClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorSarcasmClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original\n    meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These\n    tweets were gathered by querying for: irony sarcastic, and\n    sarcasm.\n    The dataset was created by gathering HTML data from Twitter. Queries for hashtags that include sarcasm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorSarcasmClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"KurdishSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KurdishSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KurdishSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nKurdish Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://link.springer.com/article/10.1007/s10579-023-09716-6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KurdishSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KurdishSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"LccSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LccSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LccSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe leipzig corpora collection, annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://github.com/fnielsen/lcc-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LccSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LccSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Moroco","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Moroco","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Moroco\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Moldavian and Romanian Dialectal Corpus. The MOROCO data set contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: (0) culture, (1) finance, (2) politics, (3) science, (4) sports, (5) tech\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/moroco\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Moroco.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Romanian"],"keywords_longer_than_N":true},
	{"name":"MovieReviewSentimentClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Allocin√© dataset is a French-language dataset for sentiment analysis that contains movie reviews produced by the online community of the Allocin√©.fr website.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NanoDBPediaRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoDBPediaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoDBPediaRetrieval is a small version of the standard test collection for entity search over the DBpedia knowledge base.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic\n\nReference\nhttps://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","topic-classification","expert-annotated","monolingual","mteb/dbpedia"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQARetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoHotpotQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoHotpotQARetrieval is a smaller subset of the HotpotQA dataset, which is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpusRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoNFCorpusRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNFCorpus is a smaller subset of NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\nReference\nhttps://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","expert-annotated","monolingual","mteb/nfcorpus"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoQuoraRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoQuoraRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoQuoraRetrieval is a smaller subset of the QuoraRetrieval dataset, which is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nSocial\n\n\nReference\nhttps://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoQuoraRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","mteb/quora","English"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCSRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoSCIDOCSRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/scidocs","English"],"keywords_longer_than_N":true},
	{"name":"Risk_Factor_Disclosure_SampleDataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asapworks/Risk_Factor_Disclosure_SampleDataset","creator_name":"Siddharth shankar Asapu","creator_url":"https://huggingface.co/asapworks","description":"\n\t\n\t\t\n\t\tüìä Sample Preview ‚Äì Risk Factor Disclosure Dataset v1.0\n\t\n\nüëâ This is a preview sample (100 records) of the full Risk Factor Disclosure Dataset v1.0.üîó To access the full dataset (1,869 enriched risk disclosures), visit:https://asapworks.gumroad.com/l/jbxtfd\n\n\n\t\n\t\t\n\t\tüì¶ About the Sample File\n\t\n\nThis sample contains 100 enriched Item 1A \"Risk Factor\" disclosures extracted from 10-K filings submitted by top public companies between 2010 and 2024.\nEach row represents a structured risk‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asapworks/Risk_Factor_Disclosure_SampleDataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","extractive-qa","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ibge-cidades","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saint-Clair/ibge-cidades","creator_name":"Lima","creator_url":"https://huggingface.co/Saint-Clair","description":"\n\t\n\t\t\n\t\tibge-cidades\n\t\n\nDados dos munic√≠pios no Portal Cidades@ recuperados da API do IBGE\n\n\t\n\t\t\n\t\tFonte\n\t\n\nOs dados em quest√£o s√£o disponibilizados pelo IBGE no Portal Cidades@ (https://cidades.ibge.gov.br/brasil/panorama). Os dados foram coletados por chamadas √† API em 21-22 de maio de 2025.\n\n\t\n\t\t\n\t\tDados no dataset\n\t\n\nO dataset cont√©m dados de 5.565 localidades no Brasil (Cidades, Povoados, Vilarejos, etc.) coletados pelo IBGE, organizados por ano.\nNo total, s√£o 40 indicadores que t√™m seus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Saint-Clair/ibge-cidades.","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"jokemachine","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pawneeranger/jokemachine","creator_name":"pawneeranger","creator_url":"https://huggingface.co/pawneeranger","description":"\n\t\n\t\t\n\t\tJokeMachine Dataset\n\t\n\nThe JokeMachine dataset contains short-form comedic responses generated in a stand-up comedy style. Each row consists of a prompt and a response, intended for training language models in humorous text generation.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFields:\n\nprompt: Always \"write a joke\" ‚Äî used as a standard prompt for consistency.\nresponse: The generated joke or humorous response (1+ sentences).\n\n\nSplit:\n\ntrain: All available rows are in the training set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pawneeranger/jokemachine.","first_N":5,"first_N_keywords":["text-generation","language-modeling","human","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OBH30/IRRISIGHT","creator_name":"Oishee Bintey Hoque","creator_url":"https://huggingface.co/OBH30","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\nDue to the space constraints, we uploaded the files across multiple repositories as follows:\nTo download Pennsylvania and Maryland, use the current repository (OBH30/IRRISIGHT). \nTo download Arizona, Arkansas, Florida, Georgia, New Jersey, North Carolina‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OBH30/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-change_cls_hirise","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-change_cls_hirise","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-change_cls_hirise\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-22\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: no_change\n1: change\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 6206 images\ntest: 1340 images\nval: 1340 images\nfew_shot_train_2_shot: 4 images\nfew_shot_train_1_shot: 2 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-change_cls_hirise.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NibirMandal/IRRISIGHT","creator_name":"Nibir Mandal","creator_url":"https://huggingface.co/NibirMandal","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NibirMandal/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"MixBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mixed-modality-search/MixBench","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"tofu_ext2_rp","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/talmahmud/tofu_ext2_rp","creator_name":"Tamim Al Mahmud","creator_url":"https://huggingface.co/talmahmud","description":"talmahmud/tofu_ext2_rp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MNLP_M2_mcqa_dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M2 MCQA Dataset\n\t\n\nThe MNLP M2 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~26,000 MCQA questions\n7 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M2_mcqa_dataset.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magichampz/medical-cyber-test","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 113\nNumber of unique topics: 9\nNumber of unique subtopics: 46\nLast updated: 2025-05-28\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-test.","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"geolayers","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arjunrao2000/geolayers","creator_name":"Arjun Rao","creator_url":"https://huggingface.co/arjunrao2000","description":"\n\t\n\t\t\n\t\tGeolayers-Data\n\t\n\n\n\n -->\nThis dataset card contains usage instructions and metadata for all data-products released with our paper:Using Multiple Input Modalities can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery. We release 3 modified versions of 3 benchmark datasets spanning land-cover segmentation, tree-cover regression, and multi-label land-cover classification tasks. These datasets are augmented with auxiliary, geographic inputs. A full list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arjunrao2000/geolayers.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","found","monolingual","SustainBench"],"keywords_longer_than_N":true},
	{"name":"elkarhizketak","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/elkarhizketak","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for ElkarHizketak\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nElkarHizketak is a low resource conversational Question Answering (QA) dataset in Basque created by Basque speaker volunteers. The dataset contains close to 400 dialogues and more than 1600 question and answers, and its small size presents a realistic low-resource scenario for conversational QA systems. The dataset is built on top of Wikipedia sections about popular people and organizations. The dialogues involve two crowd‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/elkarhizketak.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","no-annotation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"processed-jigsaw-toxic-comments","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Koushim/processed-jigsaw-toxic-comments","creator_name":"K Koushik Reddy","creator_url":"https://huggingface.co/Koushim","description":"\n\t\n\t\t\n\t\tProcessed Jigsaw Toxic Comments Dataset\n\t\n\nThis is a preprocessed and tokenized version of the original Jigsaw Toxic Comment Classification Challenge dataset, prepared for multi-label toxicity classification using transformer-based models like BERT.\n‚ö†Ô∏è Important Note: I am not the original creator of the dataset. This dataset is a cleaned and restructured version made for quick use in PyTorch deep learning models.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Features\n\t\n\nEach example contains:\n\ntext: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Koushim/processed-jigsaw-toxic-comments.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/gsm8k","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/gsm8k.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"PubMedQA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qiaojin/PubMedQA","creator_name":"Qiao Jin","creator_url":"https://huggingface.co/qiaojin","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe official leaderboard is available at: https://pubmedqa.github.io/.\n500 questions in the pqa_labeled are used as the test set. They can be found at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qiaojin/PubMedQA.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"go_emotions","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/go_emotions","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for GoEmotions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\nThe raw data is included as well as the smaller, simplified version of the dataset with predefined train/val/test\nsplits.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class, multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is in English.\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/go_emotions.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cais/mmlu","creator_name":"Center for AI Safety","creator_url":"https://huggingface.co/cais","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cais/mmlu.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"medmcqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openlifescienceai/medmcqa","creator_name":"Open Life Science AI","creator_url":"https://huggingface.co/openlifescienceai","description":"\n\t\n\t\t\n\t\tDataset Card for MedMCQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.\nEach sample contains a question, correct answer(s), and other options which require‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openlifescienceai/medmcqa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","multiple-choice-qa","open-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"narrativeqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/narrativeqa","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\n\t\n\t\t\n\t\tDataset Card for Narrative QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNarrativeQA is an English-lanaguage dataset of stories and corresponding questions designed to test reading comprehension, especially on long documents.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is used to test reading comprehension. There are 2 tasks proposed in the paper: \"summaries only\" and \"stories only\", depending on whether the human-generated summary or the full story text is used to answer the question.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/narrativeqa.","first_N":5,"first_N_keywords":["abstractive-qa","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openai_humaneval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/openai_humaneval","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tDataset Card for OpenAI HumanEval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe programming problems are written in Python and contain English natural text in comments and docstrings.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/openai_humaneval.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"squad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajpurkar/squad","creator_name":"Pranav R","creator_url":"https://huggingface.co/rajpurkar","description":"\n\t\n\t\t\n\t\tDataset Card for SQuAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\nSQuAD 1.1 contains 100,000+ question-answer pairs on 500+ articles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion Answering.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"stereoset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/stereoset","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for StereoSet\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStereoSet is a dataset that measures stereotype bias in language models. StereoSet consists of 17,000 sentences that measures model preferences across gender, race, religion, and profession.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nmultiple-choice question answering\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n#intersentence\n{'bias_type': 'race', 'context': 'Many people live in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/stereoset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"truthful_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/truthfulqa/truthful_qa","creator_name":"TruthfulQA","creator_url":"https://huggingface.co/truthfulqa","description":"\n\t\n\t\t\n\t\tDataset Card for truthful_qa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/truthfulqa/truthful_qa.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"real-toxicity-prompts","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/real-toxicity-prompts","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/real-toxicity-prompts.","first_N":5,"first_N_keywords":["monolingual","original","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"acronym_identification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amirveyseh/acronym_identification","creator_name":"amir veyseh","creator_url":"https://huggingface.co/amirveyseh","description":"\n\t\n\t\t\n\t\tDataset Card for Acronym Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the training, validation, and test data for the Shared Task 1: Acronym Identification of the AAAI-21 Workshop on Scientific Document Understanding.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports an acronym-identification task, where the aim is to predic which tokens in a pre-tokenized sentence correspond to acronyms. The dataset was released for a Shared Task which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amirveyseh/acronym_identification.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ai2_arc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ai2_arc","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14 million science sentences relevant to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ai2_arc.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","found","found"],"keywords_longer_than_N":true},
	{"name":"aqua_rat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/aqua_rat","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\n\t\n\t\t\n\t\tDataset Card for AQUA-RAT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA large-scale dataset consisting of approximately 100,000 algebraic word problems.\nThe solution to each question is explained step-by-step using natural language.\nThis data is used to train a program generation model that learns to generate the explanation,\nwhile generating the program that solves the question.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/aqua_rat.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"lambada","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cimec/lambada","creator_name":"CIMeC - Center for Mind/Brain Sciences, University of Trento","creator_url":"https://huggingface.co/cimec","description":"\n\t\n\t\t\n\t\tDataset Card for LAMBADA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LAMBADA evaluates the capabilities of computational models\nfor text understanding by means of a word prediction task.\nLAMBADA is a collection of narrative passages sharing the characteristic\nthat human subjects are able to guess their last word if\nthey are exposed to the whole passage, but not if they\nonly see the last sentence preceding the target word.\nTo succeed on LAMBADA, computational models cannot\nsimply rely on local‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cimec/lambada.","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","extended|bookcorpus","English"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/mbpp","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/mbpp.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mnist","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ylecun/mnist","creator_name":"Yann LeCun","creator_url":"https://huggingface.co/ylecun","description":"\n\t\n\t\t\n\t\tDataset Card for MNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\nHalf of the image were drawn by Census Bureau employees and the other half by high school students‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylecun/mnist.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"spider","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/spider","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\n\t\n\t\t\n\t\tDataset Card for Spider\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students.\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard can be seen at https://yale-lily.github.io/spider\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/spider.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"HuCOLA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuCOLA","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\n\t\n\t\t\n\t\tDataset Card for HuCOLA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian Corpus of Linguistic Acceptability (HuCOLA), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe BCP-47 code for Hungarian, the only represented language in this dataset, is hu-HU. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nFor each instance, there is aN id, a sentence and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuCOLA.","first_N":5,"first_N_keywords":["text-simplification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"P3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/P3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"\n\t\n\t\t\n\t\tDataset Card for P3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nP3 (Public Pool of Prompts) is a collection of prompted English datasets covering a diverse set of NLP tasks. A prompt is the combination of an input template and a target template. The templates are functions mapping a data example into natural language for the input and target sequences. For example, in the case of an NLI dataset, the data example would include fields for Premise, Hypothesis, Label. An input template would be If‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/P3.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"few-nerd","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/few-nerd","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":"Few-NERD is a large-scale, fine-grained manually annotated named entity recognition dataset, \nwhich contains 8 coarse-grained types, 66 fine-grained types, 188,200 sentences, 491,711 entities \nand 4,601,223 tokens. Three benchmark tasks are built, one is supervised: Few-NERD (SUP) and the \nother two are few-shot: Few-NERD (INTRA) and Few-NERD (INTER).","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"kobest_v1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skt/kobest_v1","creator_name":"SK Telecom","creator_url":"https://huggingface.co/skt","description":"\n\t\n\t\t\n\t\tDataset Card for KoBEST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nko-KR\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tKB-BoolQ\n\t\n\nAn example of a data point looks as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skt/kobest_v1.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","Korean"],"keywords_longer_than_N":true},
	{"name":"slither-audited-smart-contracts","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mwritescode/slither-audited-smart-contracts","creator_name":"Martina Rossini","creator_url":"https://huggingface.co/mwritescode","description":"This dataset contains source code and deployed bytecode for Solidity Smart Contracts that have been verified on Etherscan.io, along with a classification of their vulnerabilities according to the Slither static analysis framework.","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-label-classification","multi-input-text-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"CLIP-Kinetics700","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iejMac/CLIP-Kinetics700","creator_name":"Maciej Kilian","creator_url":"https://huggingface.co/iejMac","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for CLIP-Kinetics70\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nCLIP-Kinetics700 is a compressed version of the Kinetics700 dataset using OpenAI's CLIP model.\nThe original dataset is ~700 GB making it difficult to use and hold in memory on one machine. By downsampling each video to 1 FPS and encoding the frames using CLIP we we're able to compress the dataset to ~8 GB making it very memory-friendly and easy to use.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iejMac/CLIP-Kinetics700.","first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-hindi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/mbpp","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\nprogramming problems, designed to be solvable by entry level programmers, covering programming\nfundamentals, standard library functionality, and so on. Each problem consists of a task\ndescription, code solution and 3 automated test cases.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code_contests","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/code_contests","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\n\t\n\t\t\n\t\tDataset Card for CodeContests\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCodeContests is a competitive programming dataset for machine-learning. This\ndataset was used when training AlphaCode.\nIt consists of programming problems, from a variety of sources:\n\n\t\n\t\t\nSite\nURL\nSource\n\n\n\t\t\nAizu\nhttps://judge.u-aizu.ac.jp\nCodeNet\n\n\nAtCoder\nhttps://atcoder.jp\nCodeNet\n\n\nCodeChef\nhttps://www.codechef.com\ndescription2code\n\n\nCodeforces\nhttps://codeforces.com\ndescription2code and Codeforces\n\n\nHackerEarth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/code_contests.","first_N":5,"first_N_keywords":["translation","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"clinical_trial_reason_to_stop","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop","creator_name":"Open Targets","creator_url":"https://huggingface.co/opentargets","description":"\n\t\n\t\t\n\t\tDataset Card for Clinical Trials's Reason to Stop\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a curated classification of more than 5000 reasons why a clinical trial has suffered an early stop.\nThe text has been extracted from clinicaltrials.gov, the largest resource of clinical trial information. The text has been curated by members of the Open Targets organisation, a project aimed at providing data relevant to drug development.\nAll 17 possible classes have been carefully‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"openwebtext_20p","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/openwebtext_20p","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\topenwebtext_20p\n\t\n\nfirst 20% of openwebtext\n","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"nouns","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m1guelpf/nouns","creator_name":"Miguel Piedrafita","creator_url":"https://huggingface.co/m1guelpf","description":"\n\t\n\t\t\n\t\tDataset Card for Nouns auto-captioned\n\t\n\nDataset used to train Nouns text to image model\nAutomatically generated captions for Nouns from their attributes, colors and items. Help on the captioning script appreciated!\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite it as:\n@misc{piedrafita2022nouns,\n      author =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m1guelpf/nouns.","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MultiPL-E","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/MultiPL-E","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\n\t\n\t\t\n\t\tDataset Card for MultiPL-E\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPL-E is a dataset for evaluating large language models for code\ngeneration that supports 22 programming languages. It takes the OpenAI \nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\ntranslate them  to other languages. It is easy to add support for new languages \nand benchmarks.\nThe dataset is divided into several configurations named SRCDATA-LANG, where\nSRCDATA is either‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/MultiPL-E.","first_N":5,"first_N_keywords":["machine-generated","machine-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gutenberg-poetry-corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\n\t\n\t\t\n\t\tAllison Parrish's Gutenberg Poetry Corpus\n\t\n\nThis corpus was originally published under the CC0 license by Allison Parrish. Please visit Allison's fantastic accompanying GitHub repository for usage inspiration as well as more information on how the data was mined, how to create your own version of the corpus, and examples of projects using it.\nThis dataset contains 3,085,117 lines of poetry from hundreds of Project Gutenberg books. Each line has a corresponding gutenberg_id (1191‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/prosocial-dialog","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for ProsocialDialog Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/prosocial-dialog.","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pubhealth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/pubhealth","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"A dataset of 11,832 claims for fact- checking, which are related a range of health topics\nincluding biomedical subjects (e.g., infectious diseases, stem cell research), government healthcare policy\n(e.g., abortion, mental health, women‚Äôs health), and other public health-related stories","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"ScienceQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMulti-modal Multiple Choice\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExplore more samples here.\n{'image': Image,\n 'question': 'Which of these states is farthest north?',\n 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'],\n 'answer': 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","other","visual-question-answering","text-classification"],"keywords_longer_than_N":true},
	{"name":"GRIT","keyword":"monolingual","license":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":"en","dataset_url":"https://huggingface.co/datasets/zzliang/GRIT","creator_name":"zhiliang","creator_url":"https://huggingface.co/zzliang","description":"\n\t\n\t\t\n\t\tGRIT: Large-Scale Training Corpus of Grounded Image-Text Pairs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce GRIT, a large-scale dataset of Grounded Image-Text pairs, which is created based on image-text pairs from COYO-700M and LAION-2B. We construct a pipeline to extract and link text spans (i.e., noun phrases, and referring expressions) in the caption to their corresponding image regions. More details can be found in the paper.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nDuring the construction, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zzliang/GRIT.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","object-detection","zero-shot-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"sharegpt_gpt4","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShareGPT‰∏≠ÊåëÈÄâÂá∫ÁöÑGPT4Â§öËΩÆÈóÆÁ≠îÊï∞ÊçÆÔºåÂ§öËØ≠Ë®ÄÈóÆÁ≠î„ÄÇ\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nÊï∞ÊçÆÈõÜÊòØÂ§öËØ≠Ë®ÄÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊó•ÊñáÁ≠âÂ∏∏Áî®ËØ≠Ë®Ä„ÄÇ\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all splits.\n\nconversations: a List of string .\n\nhead -n 1 sharegpt_gpt4.jsonl\n\n{\"conversations\":[\n  {'from': 'human',\n   'value': 'Êé°Áî®ÂÑ™ÈõÖÁèæ‰ª£‰∏≠ÊñáÔºåÁî®‰∏≠ÊñáÁπÅÈ´îÂ≠óÂûãÔºåÂõûÁ≠î‰ª•‰∏ãÂïèÈ°å„ÄÇÁÇ∫ÊâÄÊúâÊ®ôÈ°åÊàñÂ∞àÁî®Â≠óË©ûÊèê‰æõÂ∞çÊáâÁöÑËã±Ë™ûÁøªË≠ØÔºöUsing scholarly style, summarize in detail James Barr\\'s book \"Semantics of Biblical Language\". Provide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-scoring","shibing624","shibing624"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\n\t\n\t\t\n\t\tDataset Card for MathVista\n\t\n\n\nDataset Description\nPaper Information\nDataset Examples\nLeaderboard\nDataset Usage\nData Downloading\nData Format\nData Visualization\nData Source\nAutomatic Evaluation\n\n\nLicense\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate logical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ChemBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jablonkagroup/ChemBench","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","description":"\n\t\n\t\t\n\t\tChemBench\n\t\n\n\n\n\n\n\n\n\n\n\nA manually curated benchmark for evaluating chemistry and materials capabilities of Large Language Models\n\n\n\n\n\t\n\t\t\n\t\t‚ö†Ô∏è IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tüö´ THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY üö´\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/ChemBench.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","language-modeling","natural-language-inference","expert-generated"],"keywords_longer_than_N":true},
	{"name":"chempile-reasoning","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jablonkagroup/chempile-reasoning","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","description":"\n\t\n\t\t\n\t\tChemPile-Reasoning\n\t\n\n\n\n\n\n\n\n\nA comprehensive collection of reasoning tasks for chemistry, spectral analysis, and scientific understanding\n\t\n\t\t\n\t\tüìã Dataset Summary\n\t\n\nChemPile-Reasoning is a dataset designed for reasoning tasks in the field of chemistry. It is part of the ChemPile project, which aims to create a comprehensive collection of chemistry-related data for training language models. This dataset includes a variety of reasoning tasks derived from scientific Stack Exchange‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/chempile-reasoning.","first_N":5,"first_N_keywords":["text-generation","question-answering","natural-language-inference","open-domain-qa","conversational"],"keywords_longer_than_N":true},
	{"name":"Wiki-zh-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-zh-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-zh-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Chinese‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Chinese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"adversarial_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCLNLP/adversarial_qa","creator_name":"UCL NLP","creator_url":"https://huggingface.co/UCLNLP","description":"\n\t\n\t\t\n\t\tDataset Card for adversarialQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe have created three new Reading Comprehension datasets constructed using an adversarial model-in-the-loop.\nWe use three different models; BiDAF (Seo et al., 2016), BERTLarge (Devlin et al., 2018), and RoBERTaLarge (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\nThe adversarial human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCLNLP/adversarial_qa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"allegro_reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/legacy-datasets/allegro_reviews","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAllegro Reviews is a sentiment analysis dataset, consisting of 11,588 product reviews written in Polish and extracted from Allegro.pl - a popular e-commerce marketplace. Each review contains at least 50 words and has a rating on a scale from one (negative review) to five (positive review).\nWe recommend using the provided train/dev/test split. The ratings for the test set reviews are kept hidden. You can evaluate your model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/allegro_reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-scoring","text-scoring","found","found"],"keywords_longer_than_N":true},
	{"name":"allocine","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tblard/allocine","creator_name":"Th√©ophile Blard","creator_url":"https://huggingface.co/tblard","description":"\n\t\n\t\t\n\t\tDataset Card for Allocin√©\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Allocin√© dataset is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the Allocin√©.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset can be used to train a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tblard/allocine.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fancyzhx/amazon_polarity","creator_name":"Xiang Zhang","creator_url":"https://huggingface.co/fancyzhx","description":"\n\t\n\t\t\n\t\tDataset Card for Amazon Review Polarity\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Amazon reviews dataset consists of reviews from amazon.\nThe data span a period of 18 years, including ~35 million reviews up to March 2013.\nReviews include product and user information, ratings, and a plaintext review.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset is mainly used for text classification: given the content and the title, predict the correct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fancyzhx/amazon_polarity.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"amttl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gavinxing/amttl","creator_name":"Gavin Xing","creator_url":"https://huggingface.co/gavinxing","description":"\n\t\n\t\t\n\t\tDataset Card for AMTTL\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gavinxing/amttl.","first_N":5,"first_N_keywords":["token-classification","parsing","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","description":"\n\t\n\t\t\n\t\tDataset Card for ArSarcasm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis\ndatasets (SemEval 2017\nand ASTD) and adds sarcasm and\ndialect labels to them.\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\nFor more details, please check the paper\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"arcd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hsseinmz/arcd","creator_name":"Hussein Mozannar","creator_url":"https://huggingface.co/hsseinmz","description":"\n\t\n\t\t\n\t\tDataset Card for \"arcd\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 1.94 MB\nSize of the generated dataset: 1.70 MB\nTotal amount of disk used: 3.64 MB\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hsseinmz/arcd.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"ascent_kb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tuanphong/ascent_kb","creator_name":"Tuan-Phong Nguyen","creator_url":"https://huggingface.co/tuanphong","description":"\n\t\n\t\t\n\t\tDataset Card for Ascent KB\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 8.9M commonsense assertions extracted  by the Ascent pipeline developed at the Max Planck Institute for Informatics.\nThe focus of this dataset is on everyday concepts such as elephant, car, laptop, etc.\nThe current version of Ascent KB (v1.0.0) is approximately 19 times larger  than ConceptNet (note that, in this comparison, non-commonsense knowledge in ConceptNet such as lexical relations is excluded).\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tuanphong/ascent_kb.","first_N":5,"first_N_keywords":["other","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"asset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/asset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for ASSET\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASSET (Alva-Manchego et al., 2020) is multi-reference dataset for the evaluation of sentence simplification in English. The dataset uses the same 2,359 sentences from TurkCorpus (Xu et al., 2016) and each sentence is associated with 10 crowdsourced simplifications. Unlike previous simplification datasets, which contain a single transformation (e.g., lexical paraphrasing in TurkCorpus or sentence\nsplitting in HSplit), the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/asset.","first_N":5,"first_N_keywords":["text-classification","text-simplification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/legacy-datasets/banking77","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for BANKING77\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n  Deprecated: Dataset \"banking77\" is deprecated and will be deleted. Use \"PolyAI/banking77\" instead.\n\n\nDataset composed of online banking queries annotated with their corresponding intents.\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain.\nIt comprises 13,083 customer service queries labeled with 77 intents. \nIt focuses on fine-grained single-domain intent detection.\n\n\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/banking77.","first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"bbc_hindi_nli","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","description":"\n\t\n\t\t\n\t\tDataset Card for BBC Hindi NLI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\nEntailment_label is of 2 types - entailed and not-entailed.\nDataset can be used to train models for Natural Language Inference tasks in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"beans","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-Lab-Makerere/beans","creator_name":"Makerere AI Lab","creator_url":"https://huggingface.co/AI-Lab-Makerere","description":"\n\t\n\t\t\n\t\tDataset Card for Beans\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBeans leaf dataset with images of diseased and health leaves.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nimage-classification: Based on a leaf image, the goal of this task is to predict the disease type (Angular Leaf Spot and Bean Rust), if any.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA sample from the training set is provided below:\n{\n    'image_file_path':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Lab-Makerere/beans.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"billsum","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FiscalNote/billsum","creator_name":"FiscalNote","creator_url":"https://huggingface.co/FiscalNote","description":"\n\t\n\t\t\n\t\tDataset Card for \"billsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBillSum, summarization of US Congressional and California state bills.\nThere are several features:\n\ntext: bill text.\nsummary: summary of the bills.\ntitle: title of the bills.\nfeatures for us bills. ca bills does not have.\ntext_len: number of chars in text.\nsum_len: number of chars in summary.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FiscalNote/billsum.","first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"biosses","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tabilab/biosses","creator_name":"BOUN Text Analytics and BIoInformatics Lab User","creator_url":"https://huggingface.co/tabilab","description":"\n\t\n\t\t\n\t\tDataset Card for BIOSSES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIOSSES is a benchmark dataset for biomedical sentence similarity estimation. The dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset containing articles from the biomedical domain. The sentence pairs in BIOSSES were selected from citing sentences, i.e. sentences that have a citation to a reference article. \nThe sentence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tabilab/biosses.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"blimp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyu-mll/blimp","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","description":"\n\t\n\t\t\n\t\tDataset Card for \"blimp\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBLiMP is a challenge set for evaluating what language models (LMs) know about\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\nmorphology, or semantics. The data is automatically generated according to\nexpert-crafted grammars.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/blimp.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"bn_hate_speech","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rezacsedu/bn_hate_speech","creator_name":"Rezaul Karim, PhD.","creator_url":"https://huggingface.co/rezacsedu","description":"\n\t\n\t\t\n\t\tDataset Card for Bengali Hate Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text. The dataset was created to provide greater support for under-resourced languages like Bengali on NLP tasks, and serves as a benchmark for multiple types of classification tasks. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rezacsedu/bn_hate_speech.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"casino","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kchawla123/casino","creator_name":"Kushal Chawla","creator_url":"https://huggingface.co/kchawla123","description":"\n\t\n\t\t\n\t\tDataset Card for Casino\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kchawla123/casino.","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cdt","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/ptaszynski/cdt","creator_name":"Michal Ptaszynski","creator_url":"https://huggingface.co/ptaszynski","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cyberbullying Detection task was part of 2019 edition of PolEval competition. The goal is to predict if a given Twitter message contains a cyberbullying (harmful) content.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nPolish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nsentence: an anonymized tweet in polish\ntarget: 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ptaszynski/cdt.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"cedr_v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagteam/cedr_v1","creator_name":"AI technology lab at NRC \"Kurchatov Institute\"","creator_url":"https://huggingface.co/sagteam","description":"\n\t\n\t\t\n\t\tDataset Card for [cedr]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Corpus for Emotions Detecting in Russian-language text sentences of different social sources (CEDR) contains 9410  comments labeled for 5 emotion categories (joy, sadness, surprise, fear, and anger). \nHere are 2 dataset configurations:\n\n\"main\" - contains \"text\", \"labels\", and \"source\" features;\n\"enriched\" - includes all \"main\" features and \"sentences\".\n\nDataset with predefined train/test splits.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sagteam/cedr_v1.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"cfq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/cfq","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for \"cfq\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Compositional Freebase Questions (CFQ) is a dataset that is specifically designed to measure compositional\ngeneralization. CFQ is a simple yet realistic, large dataset of natural language questions and answers that also\nprovides for each question a corresponding SPARQL query against the Freebase knowledge base. This means that CFQ can\nalso be used for semantic parsing.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/cfq.","first_N":5,"first_N_keywords":["question-answering","other","open-domain-qa","closed-domain-qa","no-annotation"],"keywords_longer_than_N":true},
	{"name":"circa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/circa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for CIRCA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Circa (meaning ‚Äòapproximately‚Äô) dataset aims to help machine learning systems to solve the problem of interpreting indirect answers to polar questions.\nThe dataset contains pairs of yes/no questions and indirect answers, together with annotations for the interpretation of the answer. The data is collected in 10 different social conversational situations (eg. food preferences of a friend).\nThe following are the situational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/circa.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cmrc2018","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2018","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\n\t\n\t\t\n\t\tDataset Card for \"cmrc2018\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA Span-Extraction dataset for Chinese machine reading comprehension to add language\ndiversities in this area. The dataset is composed by near 20,000 real questions annotated\non Wikipedia paragraphs by human experts. We also annotated a challenge set which\ncontains the questions that need comprehensive understanding and multi-sentence\ninference throughout the context.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2018.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abisee/cnn_dailymail","creator_name":"Abigail See","creator_url":"https://huggingface.co/abisee","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail.","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"coarse_discourse","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/coarse_discourse","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for \"coarse_discourse\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA large corpus of discourse annotations and relations on ~10K forum threads.\nWe collect and release a corpus of over 9,000 threads comprising over 100,000 comments manually annotated via paid crowdsourcing with discourse acts and randomly sampled from the site Reddit.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/coarse_discourse.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common_gen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/common_gen","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for \"common_gen\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCommonGen is a constrained text generation task, associated with a benchmark dataset,\nto explicitly test machines for the ability of generative commonsense reasoning. Given\na set of common concepts; the task is to generate a coherent sentence describing an\neveryday scenario using these concepts.\nCommonGen is challenging because it inherently requires 1) relational reasoning using\nbackground commonsense knowledge, and 2)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/common_gen.","first_N":5,"first_N_keywords":["crowdsourced","found","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"commonsense_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tau/commonsense_qa","creator_name":"Tel Aviv University","creator_url":"https://huggingface.co/tau","description":"\n\t\n\t\t\n\t\tDataset Card for \"commonsense_qa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tau/commonsense_qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"covid_qa_deepset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepset/covid_qa_deepset","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOVID-QA is a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19.\nA total of 147 scientific articles from the CORD-19 dataset were annotated by 15 experts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepset/covid_qa_deepset.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cs_restaurants","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/cs_restaurants","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Czech Restaurant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as a translation of the English San Francisco Restaurants dataset by Wen et al. (2015). The domain is restaurant information in Prague, with random/fictional values. It includes input dialogue acts and the corresponding outputs in Czech.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nother-intent-to-text:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/cs_restaurants.","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"discovery","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/discovery","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"\n\t\n\t\t\n\t\tDataset Card for Discovery\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDiscourse marker prediction with 174 markers\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ninput : sentence1, sentence2, \nlabel: marker originally between sentence1 and sentence2\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain/Val/Test\n\n\t\n\t\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sileod/discovery.","first_N":5,"first_N_keywords":["text-classification","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"disfl_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/disfl_qa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for DISFL-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDisfl-QA is a targeted dataset for contextual disfluencies in an information seeking  setting, namely question answering over Wikipedia passages.  Disfl-QA builds upon the SQuAD-v2 (Rajpurkar et al., 2018) dataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as a source of distractors.\nThe final dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/disfl_qa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"drop","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucinlp/drop","creator_name":"UCI NLP","creator_url":"https://huggingface.co/ucinlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"drop\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs.\n. DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a\nquestion, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or\n sorting). These operations require a much more comprehensive understanding of the content of paragraphs than‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucinlp/drop.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","abstractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"duorc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/duorc","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\n\t\n\t\t\n\t\tDataset Card for duorc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DuoRC dataset is an English language dataset of questions and answers gathered from crowdsourced AMT workers on Wikipedia and IMDb movie plots. The workers were given freedom to pick answer from the plots or synthesize their own answers. It contains two sub-datasets - SelfRC and ParaphraseRC. SelfRC dataset is built on Wikipedia movie plots solely. ParaphraseRC has questions written from Wikipedia movie plots and the answers are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/duorc.","first_N":5,"first_N_keywords":["question-answering","abstractive-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"dyk","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/dyk","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Did You Know (pol. Czy wiesz?) dataset consists of human-annotated question-answer pairs. The task is to predict if the answer is correct. We chose the negatives which have the largest token overlap with a question.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nPolish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nq_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/dyk.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"exams","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe languages in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fashion_mnist","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zalando-datasets/fashion_mnist","creator_name":"zalando-datasets","creator_url":"https://huggingface.co/zalando-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for FashionMNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashion-MNIST is a dataset of Zalando's article images‚Äîconsisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zalando-datasets/fashion_mnist.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"generics_kb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/generics_kb","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Generics KB\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDataset contains a large (3.5M+ sentence) knowledge base of generic sentences.  This is the first large resource to contain naturally occurring generic sentences, rich in high-quality, general, semantically complete statements. All GenericsKB sentences are annotated with their topical term, surrounding context (sentences), and a (learned) confidence. We also release GenericsKB-Best (1M+ sentences), containing the best-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/generics_kb.","first_N":5,"first_N_keywords":["other","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"glucose","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/glucose","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUCOSE: GeneraLized and COntextualized Story Explanations, is a novel conceptual framework and dataset for commonsense reasoning. Given a short story and a sentence X in the story, GLUCOSE captures ten dimensions of causal explanation related to X. These dimensions, inspired by human cognitive psychology, cover often-implicit causes and effects of X, including events, location, possession, and other attributes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/glucose.","first_N":5,"first_N_keywords":["fill-mask","text-generation","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"greek_legal_code","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-team-UoA/greek_legal_code","creator_name":"AI Team - University of Athens","creator_url":"https://huggingface.co/AI-team-UoA","description":"\n\t\n\t\t\n\t\tDataset Card for Greek Legal Code\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGreek_Legal_Code (GLC) is a dataset consisting of approx. 47k legal resources from Greek legislation. The origin of GLC is ‚ÄúPermanent Greek Legislation Code - Raptarchis‚Äù, a collection of Greek legislative documents classified into multi-level (from broader to more specialized) categories.\nTopics\nGLC consists of 47 legislative volumes and each volume corresponds to a main thematic topic. Each volume is divided into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-team-UoA/greek_legal_code.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","topic-classification","found","found"],"keywords_longer_than_N":true},
	{"name":"hebrew_this_world","keyword":"monolingual","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/hebrew_this_world","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for HebrewSentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHebrewThisWorld is a data set consists of 2028 issues of the newspaper 'This World' edited by Uri Avnery and were published between 1950 and 1989. Released under the AGPLv3 license.\nData Annotation: \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nLanguage modeling\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nHebrew\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ncsv file with \",\" delimeter\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nSample:\n{\n  \"issue_num\": 637,\n  \"page_count\": 16‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/hebrew_this_world.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"id_newspapers_2018","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/id_newspapers_2018","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Indonesian Newspapers 2018\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains around 500K articles (136M of words) from 7 Indonesian newspapers: Detik, Kompas, Tempo,\nCNN Indonesia, Sindo, Republika and Poskota. The articles are dated between 1st January 2018 and 20th August 2018\n(with few exceptions dated earlier). The size of uncompressed 500K json files (newspapers-json.tgz) is around 2.2GB,\nand the cleaned uncompressed in a big text file (newspapers.txt.gz) is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/id_newspapers_2018.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"irc_disentangle","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jkkummerfeld/irc_disentangle","creator_name":"Jonathan K. Kummerfeld","creator_url":"https://huggingface.co/jkkummerfeld","description":"\n\t\n\t\t\n\t\tDataset Card for IRC Disentanglement\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDisentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. This new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. The dataset is 16 times larger than all previously released datasets combined, the first to include‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jkkummerfeld/irc_disentangle.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"klue","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/klue/klue","creator_name":"KLUE Benchmark","creator_url":"https://huggingface.co/klue","description":"\n\t\n\t\t\n\t\tDataset Card for KLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKLUE is a collection of 8 tasks to evaluate natural language understanding capability of Korean language models. We delibrately select the 8 tasks, which are Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTopic Classification, Semantic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/klue/klue.","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","token-classification"],"keywords_longer_than_N":true},
	{"name":"kor_3i4k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wicho/kor_3i4k","creator_name":"Won Ik Cho","creator_url":"https://huggingface.co/wicho","description":"\n\t\n\t\t\n\t\tDataset Card for 3i4K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe 3i4K dataset is a set of frequently used Korean words (corpus provided by the Seoul National University Speech Language Processing Lab) and manually created questions/commands containing short utterances. The goal is to identify the speaker intention of a spoken utterance based on its transcript, and whether in some cases, requires using auxiliary acoustic features. The classification system decides whether the utterance is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wicho/kor_3i4k.","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"kor_nli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/kor_nli","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\n\t\n\t\t\n\t\tDataset Card for \"kor_nli\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKorean Natural Language Inference datasets.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tmulti_nli\n\t\n\n\nSize of downloaded dataset files: 42.11 MB\nSize of the generated dataset: 84.72 MB\nTotal amount of disk used: 126.85 MB\n\nAn example of 'train' looks as follows.\n\n\n\n\t\n\t\t\n\t\tsnli\n\t\n\n\nSize of downloaded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/kor_nli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"kor_sarcasm","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","description":"\n\t\n\t\t\n\t\tDataset Card for Korean Sarcasm Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: Ïó≠ÏÑ§, ÏïÑÎ¨¥Îßê, Ïö¥ÏàòÏ¢ãÏùÄÎÇ†, Á¨ë, Î≠êÎûò ÏïÑÎãôÎãàÎã§, Í∑∏Îü¥Î¶¨ÏóÜÎã§, Ïñ¥Í∑∏Î°ú, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of the user‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"lex_glue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/lex_glue","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\n\t\n\t\t\n\t\tDataset Card for \"LexGLUE\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nInspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018), the subsequent more difficult SuperGLUE (Wang et al., 2019), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018; McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a benchmark dataset to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/lex_glue.","first_N":5,"first_N_keywords":["question-answering","text-classification","multi-class-classification","multi-label-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"myanmar_news","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayehninnkhine/myanmar_news","creator_name":"Aye Hninn Khine","creator_url":"https://huggingface.co/ayehninnkhine","description":"\n\t\n\t\t\n\t\tDataset Card for Myanmar_News\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Myanmar news dataset contains article snippets in four categories:\nBusiness, Entertainment, Politics, and Sport.\nThese were collected in October 2017 by Aye Hninn Khine\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMyanmar/Burmese language\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext - text from article\ncategory - a topic: Business, Entertainment, Politic, or Sport (note spellings)\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nOne training set (8,116 total‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayehninnkhine/myanmar_news.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"nkjp-ner","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkjp/nkjp-ner","creator_name":"Narodowego Korpusu Jƒôzyka Polskiego","creator_url":"https://huggingface.co/nkjp","description":"\n\t\n\t\t\n\t\tDataset Card for NJKP NER\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA linguistic corpus is a collection of texts where one can find the typical use of a single word or a phrase, as well as their meaning and grammatical function. Nowadays, without access to a language corpus, it has become impossible to do linguistic research, to write dictionaries, grammars and language teaching books, to create search engines sensitive to Polish inflection, machine translation engines and software of advanced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nkjp/nkjp-ner.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"onestop_english","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iastate/onestop_english","creator_name":"Iowa State University","creator_url":"https://huggingface.co/iastate","description":"\n\t\n\t\t\n\t\tDataset Card for OneStopEnglish corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOneStopEnglish is a corpus of texts written at three reading levels, and demonstrates its usefulness for through two applications - automatic readability assessment and automatic text simplification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn instance example:\n{\n  \"text\": \"When you see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iastate/onestop_english.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","text-simplification","found","found"],"keywords_longer_than_N":true},
	{"name":"onestop_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malmaud/onestop_qa","creator_name":"Jonathan Malmaud","creator_url":"https://huggingface.co/malmaud","description":"\n\t\n\t\t\n\t\tDataset Card for OneStopQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOneStopQA is a multiple choice reading comprehension dataset annotated according to the STARC (Structured Annotations for Reading Comprehension) scheme. The reading materials are Guardian articles taken from the OneStopEnglish corpus. Each article comes in three difficulty levels, Elementary, Intermediate and Advanced. Each paragraph is annotated with three multiple choice reading comprehension questions. The reading‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malmaud/onestop_qa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"piaf","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AgentPublic/piaf","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\n\t\n\t\t\n\t\tDataset Card for Piaf\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPiaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 1.31 MB\nSize of the generated dataset: 3.18 MB\nTotal amount of disk used: 4.49 MB\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/piaf.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"poem_sentiment","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/poem_sentiment","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Gutenberg Poem Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\nThis dataset can be used for tasks such as sentiment classification or style transfer for poems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExample of one instance in the dataset.\n{'id': 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/poem_sentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"proto_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/proto_qa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is for studying computational models trained to reason about prototypical situations. It is anticipated that still would not lead to usage in a downstream task, but as a way of studying the knowledge (and biases) of prototypical situations already contained in pre-trained models. The data it is partially based on (Family Feud).\nUsing deterministic filtering a sampling from a larger set of all transcriptions was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/proto_qa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qasc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/qasc","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for \"qasc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice\nquestions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/qasc.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","extractive-qa","multiple-choice-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qasper","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/qasper","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"A dataset containing 1585 papers with 5049 information-seeking questions asked by regular readers of NLP papers, and answered by a separate set of NLP practitioners.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"quartz","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/quartz","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for \"quartz\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nQuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each\nquestion is paired with one of 405 different background sentences (sometimes short paragraphs).\nThe QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with\none of 405 different background sentences (sometimes short paragraphs).\nThe dataset is split into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/quartz.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"re_dial","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/re_dial","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for ReDial (Recommendation Dialogues)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReDial (Recommendation Dialogues) is an annotated dataset of dialogues, where users\nrecommend movies to each other. The dataset was collected by a team of researchers working at\nPolytechnique Montr√©al, MILA ‚Äì Quebec AI Institute, Microsoft Research Montr√©al, HEC Montreal, and Element AI.\nThe dataset allows research at the intersection of goal-directed dialogue systems\n(such as restaurant recommendation)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/re_dial.","first_N":5,"first_N_keywords":["other","text-classification","sentiment-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tldr-17","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/webis/tldr-17","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","description":"This corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.","first_N":5,"first_N_keywords":["summarization","no-annotation","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ronec","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/ronec","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for RONEC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRONEC, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities.\nThe corpus has the following classes and distribution in the train/valid/test splits:\n| Classes      \t| Total  \t    | Train  \t|         \t| Valid  \t|         \t| Test   \t|         \t|\n|-------------\t|:------:\t    |:------:\t|:-------:\t|:------:\t|:-------:\t|:------:\t|:-------:\t|\n|            \t|‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/ronec.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"ropes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ropes","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for ROPES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nROPES (Reasoning Over Paragraph Effects in Situations) is a QA dataset which tests a system's ability to apply knowledge from a passage of text to a new situation. A system is presented a background passage containing a causal or qualitative relation(s) (e.g., \"animal pollinators increase efficiency of fertilization in flowers\"), a novel situation that uses this background, and questions that require reasoning about effects of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ropes.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"selqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/selqa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for SelQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSelQA: A New Benchmark for Selection-Based Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion Answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example from the answer selection set:\n{\n        \"section\": \"Museums\",\n        \"question\": \"Where are Rockefeller Museum and LA Mayer Institute for Islamic Art?\",\n        \"article\": \"Israel\",\n        \"is_paraphrase\": true‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/selqa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"snips_built_in_intents","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents","creator_name":"sonos-nlu-benchmark","creator_url":"https://huggingface.co/sonos-nlu-benchmark","description":"\n\t\n\t\t\n\t\tDataset Card for Snips Built In Intents\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSnips' built in intents dataset was initially used to compare different voice assistants and released as a public dataset hosted at\nhttps://github.com/sonos/nlu-benchmark in folder 2016-12-built-in-intents. The dataset contains 328 utterances over 10 intent classes.\nA related Medium post is https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents.","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"snli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanfordnlp/snli","creator_name":"Stanford NLP","creator_url":"https://huggingface.co/stanfordnlp","description":"\n\t\n\t\t\n\t\tDataset Card for SNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stanfordnlp/snli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"squad_v1_pt","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad_v1_pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize of downloaded dataset files: 39.53 MB\nSize of the generated dataset: 96.72 MB\nTotal amount of disk used: 136.25 MB\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"squad_v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajpurkar/squad_v2","creator_name":"Pranav R","creator_url":"https://huggingface.co/rajpurkar","description":"\n\t\n\t\t\n\t\tDataset Card for SQuAD 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\nSQuAD 2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad_v2.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"swahili_news","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/swahili_news","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Swahili : News Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSwahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\nNews contributes to education, technology, and the economic growth of a country, and news in local languages plays an important cultural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swahili_news.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"swedish_medical_ner","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/swedish_medical_ner","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for swedish_medical_ner\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSwedMedNER is Named Entity Recognition dataset on medical text in Swedish. It consists three subsets which are in turn derived from three different sources respectively: the Swedish Wikipedia (a.k.a. wiki), L√§kartidningen (a.k.a. lt), and 1177 V√•rdguiden (a.k.a. 1177). While the Swedish Wikipedia and L√§kartidningen subsets in total contains over 790000 sequences with 60 characters each, the 1177 V√•rdguiden subset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swedish_medical_ner.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"tashkeela","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/tashkeela","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Tashkeela\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIt contains 75 million of fully vocalized words mainly\n97 books from classical and modern Arabic language.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is based on Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{'book':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tashkeela.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"turk","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/turk","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for TURK\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTURK is a multi-reference dataset for the evaluation of sentence simplification in English. The dataset consists of 2,359 sentences from the Parallel Wikipedia Simplification (PWKP) corpus. Each sentence is associated with 8 crowdsourced simplifications that focus on only lexical paraphrasing (no sentence splitting or deletion).\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNo Leaderboard for the task.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nTURK‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/turk.","first_N":5,"first_N_keywords":["text-simplification","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tweet_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucsbnlp/tweet_qa","creator_name":"UC Santa Barbara NLP Group","creator_url":"https://huggingface.co/ucsbnlp","description":"\n\t\n\t\t\n\t\tDataset Card for TweetQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWith social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effectiveness of many applications that rely on real-time knowledge. While previous question answering (QA) datasets have concentrated on formal text like news and Wikipedia, the first large-scale dataset for QA over social media data is presented. To make sure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucsbnlp/tweet_qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tweets_hate_speech_detection","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tweets-hate-speech-detection/tweets_hate_speech_detection","creator_name":"tweets-hate-speech-detection","creator_url":"https://huggingface.co/tweets-hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Tweets Hate Speech Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\nFormally, given a training sample of tweets and labels, where label ‚Äò1‚Äô denotes the tweet is racist/sexist and label ‚Äò0‚Äô denotes the tweet is not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tweets-hate-speech-detection/tweets_hate_speech_detection.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wino_bias","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/wino_bias","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\n\t\n\t\t\n\t\tDataset Card for Wino_Bias dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWinoBias, a Winograd-schema dataset for coreference resolution focused on gender bias.\nThe corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe underlying task is coreference resolution. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/wino_bias.","first_N":5,"first_N_keywords":["token-classification","coreference-resolution","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wisesight_sentiment","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/wisesight_sentiment","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for wisesight_sentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\nReleased to public domain under Creative Commons Zero v1.0 Universal license.\nLabels: {\"pos\": 0, \"neu\": 1, \"neg\": 2, \"q\": 3}\nSize: 26,737 messages\nLanguage: Central Thai\nStyle: Informal and conversational. With some news headlines and advertisement.\nTime period: Around 2016 to early 2019. With‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/wisesight_sentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wongnai_reviews","keyword":"monolingual","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wongnai/wongnai_reviews","creator_name":"Wongnai","creator_url":"https://huggingface.co/Wongnai","description":"\n\t\n\t\t\n\t\tDataset Card for Wongnai_Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Wongnai Review dataset contains restaurant reviews and ratings, almost entirely in Thai language.\nThe reviews are in 5 classes ranging from 1 to 5 stars.\nThis dataset was featured in a Kaggle challenge https://www.kaggle.com/c/wongnai-challenge-review-rating-prediction/overview\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nreview_body - text of review\nstar_rating - an integer star rating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wongnai/wongnai_reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube_caption_corrections","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/youtube_caption_corrections","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for YouTube Caption Corrections\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is built from pairs of YouTube captions where both an auto-generated and a manually-corrected caption are available for a single specified language. It currently only in English, but scripts at repo support other languages. The motivation for creating it was from viewing errors in auto-generated captions at a recent virtual conference, with the hope that there could be some way to help correct those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/youtube_caption_corrections.","first_N":5,"first_N_keywords":["other","text-generation","fill-mask","slot-filling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fanpage","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ARTeLab/fanpage","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","description":"\n\t\n\t\t\n\t\tDataset Card for fanpage\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFanpage dataset, containing news articles taken from Fanpage.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n Fanpage text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/fanpage.","first_N":5,"first_N_keywords":["summarization","monolingual","original","Italian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ilpost","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ARTeLab/ilpost","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","description":"\n\t\n\t\t\n\t\tDataset Card for ilpost\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIlPost dataset, containing news articles taken from IlPost.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n IlPost text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/ilpost.","first_N":5,"first_N_keywords":["summarization","monolingual","Italian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BAAD16","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD16","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD16 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by the authors of this paper. It was created by scraping text from an online Bangla e-library using custom web crawler and contains literary works of various famous Bangla writers. It contains novels, stories, series, and other works of 16 authors. Each sample document is created with 750 words. The dataset is imbalanced and resembles real-world scenarios more closely, where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD16.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"BAAD6","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD6","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD6 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by Hemayet et al [1]. The data was obtained from different online posts and blogs. This dataset is balanced among the 6 Authors with 350 sample texts per author. This is a relatively small dataset but is noisy given the sources it was collected from and its cleaning procedure. Nonetheless, it may help evaluate authorship attribution systems as it resembles texts often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD6.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fungi_diagnostic_chars_comparison_japanese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\n\t\n\t\t\n\t\tfungi_diagnostic_chars_comparison_japaneseÂ§ßËèåËº™„ÄåË≠òÂà•ÂΩ¢Ë≥™„Åæ„Å®„ÇÅ„Äç„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊúÄÁµÇÊõ¥Êñ∞Êó• / Last updated: 2025/5/2Ôºàup to R3-12744Ôºâ\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å / Overview\n\t\n\nAtsushi NakajimaÔºà‰∏≠Â≥∂Ê∑≥ÂøóÔºâ„ÅåÂÄã‰∫∫„ÅßÈÅãÂñ∂„Åó„Å¶„ÅÑ„ÇãWeb„Çµ„Ç§„ÉàÂ§ßËèåËº™„Åß„ÅØ„ÄÅÊï∞ÂçÉ‰ª∂‰ª•‰∏ä„ÅÆËèåÈ°ûÂàÜÈ°ûÂ≠¶Ë´ñÊñá„Çí„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Å®„ÅÑ„ÅÜÂΩ¢„ÅßË¶ÅÁ¥Ñ„Åä„Çà„Å≥Á¥¢Âºï‰ªò„ÅëÔºà„Ç§„É≥„Éá„Ç≠„Ç∑„É≥„Ç∞Ôºâ„Åó„ÅüÊÉÖÂ†±„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆ‰∏ÄÁí∞„Å®„Åó„Å¶„ÄÅ„ÅÇ„ÇãËèå„Å®Âà•„ÅÆËèå„ÅÆ„ÄåÂÖ±ÈÄö„Åô„Çã„Äç„ÅÇ„Çã„ÅÑ„ÅØ„ÄåÁï∞„Å™„Çã„ÄçË≠òÂà•ÂΩ¢Ë≥™ (diagnostic characters) „Å´Èñ¢„Åô„ÇãË®òËø∞„Çí‰∫∫Êâã„ÅßÊäΩÂá∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\nDaikinrin, a website personally operated by Atsushi Nakajima, provides summaries and indexing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fungi_indexed_mycological_papers_japanese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\n\t\n\t\t\n\t\tfungi_indexed_mycological_papers_japanese\nÂ§ßËèåËº™„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊúÄÁµÇÊõ¥Êñ∞Êó•Ôºö2025/5/2ÔºàR3-12744„Åæ„ÅßÔºâ  \n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å / Overview\n\t\n\nÂ§ßËèåËº™„ÅØ„ÄÅAtsushi NakajimaÔºà‰∏≠Â≥∂Ê∑≥ÂøóÔºâ„ÅåÂÄã‰∫∫„ÅßÈÅãÂñ∂„Åó„Å¶„ÅÑ„ÇãWeb„Çµ„Ç§„Éà„Åß„Åô„ÄÇ„Åì„Åì„Åß„ÅØ„ÄÅÊï∞ÂçÉ‰ª∂‰ª•‰∏ä„ÅÆËèåÈ°ûÂàÜÈ°ûÂ≠¶Ë´ñÊñá„Çí„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Å®„ÅÑ„ÅÜÂΩ¢„ÅßË¶ÅÁ¥Ñ„Åä„Çà„Å≥Á¥¢Âºï‰ªò„ÅëÔºà„Ç§„É≥„Éá„Ç≠„Ç∑„É≥„Ç∞Ôºâ„Åó„ÅüÊÉÖÂ†±„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\nDaikinrin is a website personally operated by Atsushi Nakajima. It provides summaries and indexing information for thousands of mycological taxonomy papers in the form of \"Three-line‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese.","first_N":5,"first_N_keywords":["other","monolingual","original","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"rebel-dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/rebel-dataset","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation","first_N":5,"first_N_keywords":["text-retrieval","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"parla_text_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Baybars/parla_text_corpus","creator_name":"Baybars K√ºlebi","creator_url":"https://huggingface.co/Baybars","description":"\n\t\n\t\t\n\t\tParlaTextCorpus\n\t\n\nSpoken text corpus for Catalan. Derived and cleaned from three sources. OpenSubtitles, Tv3Parla and Festcat.\n","first_N":5,"first_N_keywords":["language-modeling","no-annotation","various","monolingual","found"],"keywords_longer_than_N":true},
	{"name":"angry-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/angry-tweets","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\n\t\n\t\t\n\t\tDataset Card for AngryTweets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of anonymised Danish Twitter data that has been annotated for sentiment analysis through crowd-sourcing. All credits go to the authors of the following paper, who created the dataset: \nPauli, Amalie Brogaard, et al. \"DaNLP: An open-source toolkit for Danish Natural Language Processing.\" Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). 2021\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/angry-tweets.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"europarl","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/europarl","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\n\t\n\t\t\n\t\tDataset Card for DKHate\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of Danish data from the European Parliament that has been annotated for sentiment analysis by the Alexandra Institute - all credits go to them.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for sentiment analysis.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset has a document and an associated label.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/europarl.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"lcc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/lcc","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\n\t\n\t\t\n\t\tDataset Card for LCC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of Danish data from the Leipzig Collection that has been annotated for sentiment analysis by Finn √Örup Nielsen.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for sentiment analysis.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset has a document and an associated label.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nAn entry in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/lcc.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit-da","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/reddit-da","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\n\t\n\t\t\n\t\tDataset Card for SQuAD-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 1,908,887 Danish posts from Reddit. These are from this Reddit dump and have been filtered using this script, which uses FastText to detect the Danish posts. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is suitable for language modelling.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Danish.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEvery entry in the dataset contains short Reddit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/reddit-da.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki-entity-similarity","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Exr0n/wiki-entity-similarity","creator_name":"exr0n","creator_url":"https://huggingface.co/Exr0n","description":"\n\t\n\t\t\n\t\tWiki Entity Similarity\n\t\n\nUsage:\nfrom datasets import load_dataset\n\ncorpus = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20corpus', split='train')\nassert corpus[0] == {'article': 'A1000 road', 'link_text': 'A1000', 'is_same': 1}\n\npairs = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20pairs', split='train')\nassert corpus[0] == {'article': 'Rhinobatos', 'link_text': 'Ehinobatos beurleni', 'is_same': 1}\nassert len(corpus) == 4_793_180\n\n\n\t\n\t\t\n\t\tCorpus (name=*corpus)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Exr0n/wiki-entity-similarity.","first_N":5,"first_N_keywords":["found","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"DebateSum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\n\t\n\t\t\n\t\tDebateSum\n\t\n\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \"DebateSum: A large-scale argument mining and summarization dataset\"\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\nVideo of presentation at COLING 2020:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum.","first_N":5,"first_N_keywords":["question-answering","summarization","text-retrieval","text-generation","abstractive-qa"],"keywords_longer_than_N":true},
	{"name":"sucx3_ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KBLab/sucx3_ner","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","description":"    The dataset is a conversion of the venerable SUC 3.0 dataset into the\n    huggingface ecosystem. The original dataset does not contain an official\n    train-dev-test split, which is introduced here; the tag distribution for the\n    NER tags between the three splits is mostly the same.\n    \n    The dataset has three different types of tagsets: manually annotated POS,\n    manually annotated NER, and automatically annotated NER. For the\n    automatically annotated NER tags, only sentences were chosen, where the\n    automatic and manual annotations would match (with their respective\n    categories).\n    \n    Additionally we provide remixes of the same data with some or all sentences\n    being lowercased.","first_N":5,"first_N_keywords":["other","named-entity-recognition","part-of-speech","expert-generated","other"],"keywords_longer_than_N":true},
	{"name":"ILUR-news-text-classification-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Karavet/ILUR-news-text-classification-corpus","creator_name":"Karen Avetisyan","creator_url":"https://huggingface.co/Karavet","description":"\n\t\n\t\t\n\t\tNews Texts Dataset\n\t\n\nWe release a dataset of over 12000 news articles from iLur.am, categorized into 7 classes: sport, politics, weather, economy, accidents, art, society. The articles are split into train (2242k tokens) and test sets (425k tokens).\nFor more details, refer to the paper.\n","first_N":5,"first_N_keywords":["text-classification","monolingual","Armenian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"starter","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Langame/starter","creator_name":"Langa","creator_url":"https://huggingface.co/Langame","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Langame/starter.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES-titles","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES-titles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES-titles is a Spanish-language dataset for news titles generation. The text and titles comes from 2019 and 2020 CC-NEWS data (which is part of Common Crawl).\nIt contains 402.310 pairs of news title and body, splitted in :\n\nTrain: 370.125\n\nEval: 16.092\n\nTest: 16.092\n\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset can be used to train a model for news title‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles.","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES is a Spanish-language dataset of news. The corpus was generated by extracting the Spanish articles from CC-NEWS (news index of Common Crawl) of 2019. For doing that FastText model was used for language prediction.\nIt contains a total of 7,473,286 texts and 1,812,009,283 words distributed as follows:\n\n\t\n\t\t\ndomain\ntexts\nwords\n\n\n\t\t\nar\n532703\n1.45127e+08\n\n\nbo\n29557\n7.28996e+06\n\n\nbr\n107\n14207\n\n\ncl\n116661\n3.34633e+07\n\n\nco‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES.","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"monolingual-quechua-iic","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic","creator_name":"Llamacha","creator_url":"https://huggingface.co/Llamacha","description":"\n\t\n\t\t\n\t\tDataset Card for Monolingual-Quechua-IIC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We present Monolingual-Quechua-IIC, a monolingual corpus of Southern Quechua, which can be used to build language models using Transformers models. This corpus also includes the Wiki and OSCAR corpora. We used this corpus to build Llama-RoBERTa-Quechua, the first language model for Southern Quechua using Transformers.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSouthern‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic.","first_N":5,"first_N_keywords":["fill-mask","language-modeling","masked-language-modeling","no-annotation","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"HuCoPA","keyword":"monolingual","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuCoPA","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\n\t\n\t\t\n\t\tDataset Card for HuCoPA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian Choice of Plausible Alternatives Corpus (HuCoPA), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU. The corpus was created by translating and re-annotating the original English CoPA corpus (Roemmele et al., 2011).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n'commonsense reasoning'\n'question answering'\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe BCP-47 code for Hungarian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuCoPA.","first_N":5,"first_N_keywords":["other","found","found","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"HuRC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuRC","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for HuRC\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian Corpus for Reading Comprehension with Commonsense Reasoning (HuRC), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU.\nThe dataset contains 80 614 instances. Each instance is composed of a lead, a passage and a cloze-style query with a masked entity. The task is to select the named entity that is being masked in the query.\nThe data was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuRC.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","abstractive-qa","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"HuSST","keyword":"monolingual","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuSST","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\n\t\n\t\t\n\t\tDataset Card for HuSST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian version of the Stanford Sentiment Treebank. This dataset which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU. The corpus was created by translating and re-annotating the original SST (Roemmele et al., 2011).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n'sentiment classification'\n'sentiment scoring'\n\n\t\n\t\t\n\t\tLanguage\n\t\n\nThe BCP-47 code for Hungarian, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuSST.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","sentiment-scoring","text-scoring","found"],"keywords_longer_than_N":true},
	{"name":"HuWNLI","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuWNLI","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\n\t\n\t\t\n\t\tDataset Card for HuWNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset card for the Hungarian translation of the Winograd schemata formatted as an inference task. A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution (Levesque et al. 2012). This dataset is also part of the Hungarian Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuWNLI.","first_N":5,"first_N_keywords":["other","coreference-resolution","found","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"norwegian_parliament","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/norwegian_parliament","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a classification dataset created from a subset of the Talk of Norway. This dataset contains text phrases from the political parties Fremskrittspartiet and Sosialistisk Venstreparti. The dataset is annotated with the party the speaker, as well as a timestamp. The classification task is to, simply by looking at the text, being able to predict is the speech was done by a representative from Fremskrittspartiet or from SV.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/norwegian_parliament.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hatecheck","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHateCheck is a suite of functional test for hate speech detection models. \nThe dataset contains 3,728 validated test cases in 29 functional tests.\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\nThis allows for targeted diagnostic insights into model performance.\nIn our ACL paper, we found critical weaknesses in all commercial and academic hate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"cantemist-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PlanTL-GOB-ES/cantemist-ner","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"https://temu.bsc.es/cantemist/","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"pharmaconer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PlanTL-GOB-ES/pharmaconer","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje (Plan TL).\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"nepalitext-language-model-dataset","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset","creator_name":"Utsav Maskey","creator_url":"https://huggingface.co/Sakonii","description":"\n\t\n\t\t\n\t\tDataset Card for \"nepalitext-language-model-dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\"NepaliText\" language modeling dataset is a collection of over 13 million Nepali text sequences (phrases/sentences/paragraphs) extracted by combining the datasets: OSCAR , cc100 and a set of scraped Nepali articles on Wikipedia. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended to pre-train language models and word representations on Nepali Language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-confessions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-confessions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts from the following subreddits:\n\n/r/trueoffmychest\n/r/confession\n/r/confessions\n/r/offmychest\n\nPosts are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-jokes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-jokes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts from /r/jokes.\nPosts are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.\n'subreddit.id': the base-36 Reddit ID‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"one-million-reddit-questions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\n\t\n\t\t\n\t\tDataset Card for one-million-reddit-questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains a million posts on /r/AskReddit, annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit post.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.\n'subreddit.id': the base-36 Reddit ID of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"one-year-of-r-india","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-year-of-r-india","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This corpus contains the complete data for the activity of the subreddit /r/India from Sep 30, 2020 to Sep 30, 2021.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"reddit-crypto-aug-2021","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/reddit-crypto-aug-2021","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This corpus contains the complete data for the activity on seven major cryptocurrency subreddits for the entire month of August 2021.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"the-2022-trucker-strike-on-reddit","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\n\t\n\t\t\n\t\tDataset Card for the-2022-trucker-strike-on-reddit\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains all the comments under the /r/Ottawa convoy megathreads.\nComments are annotated with their score.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMainly English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA data point is a Reddit comment.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n'type': the type of the data point. Can be 'post' or 'comment'.\n'id': the base-36 Reddit ID of the data point. Unique when combined with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"the-reddit-covid-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-covid-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This dataset attempts to capture the full extent of COVID-19 discussion across the entire site of Reddit. All posts and comments found to mention the term 'COVID' as of 2021-10-25 have been gathered from the site.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"top-american-universities-on-reddit","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/top-american-universities-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This NLP dataset contains all the posts and comments in the subreddits of top 10 universities in the United States, chosen according to the 2019 Forbes ranking.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"klej-polemo2-in","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allegro/klej-polemo2-in","creator_name":"Allegro ML Research","creator_url":"https://huggingface.co/allegro","description":"\n\t\n\t\t\n\t\tklej-polemo2-in\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe PolEmo2.0 is a dataset of online consumer reviews from four domains: medicine, hotels, products, and university. It is human-annotated on a level of full reviews and individual sentences. It comprises over 8000 reviews, about 85% from the medicine and hotel domains.\nWe use the PolEmo2.0 dataset to form two tasks. Both use the same training dataset, i.e., reviews from medicine and hotel domains, but are evaluated on a different test set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allegro/klej-polemo2-in.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"klej-polemo2-out","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allegro/klej-polemo2-out","creator_name":"Allegro ML Research","creator_url":"https://huggingface.co/allegro","description":"\n\t\n\t\t\n\t\tklej-polemo2-out\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe PolEmo2.0 is a dataset of online consumer reviews from four domains: medicine, hotels, products, and university. It is human-annotated on a level of full reviews and individual sentences. It comprises over 8000 reviews, about 85% from the medicine and hotel domains.\nWe use the PolEmo2.0 dataset to form two tasks. Both use the same training dataset, i.e., reviews from medicine and hotel domains, but are evaluated on a different test set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allegro/klej-polemo2-out.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"scico","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/scico","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"        SciCo is a dataset for hierarchical cross-document coreference resolution\n        over scientific papers in the CS domain.","first_N":5,"first_N_keywords":["token-classification","coreference-resolution","domain experts","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"qg_squad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) evaluation set for the question generation (QG) models. The split \nof test and development set follows the [\"Neural Question Generation\"](https://arxiv.org/abs/1705.00106) work and is \ncompatible with the [leader board](https://paperswithcode.com/sota/question-generation-on-squad11).","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad","English"],"keywords_longer_than_N":true},
	{"name":"sentihood","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bhavnicksm/sentihood","creator_name":"Bhavnick Minhas","creator_url":"https://huggingface.co/bhavnicksm","description":"\n\t\n\t\t\n\t\tDataset Card for [SentiHood]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCreated as a part of the paper \"SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods\" by Saeidi et al. \n\n\t\n\t\t\n\t\tAbstract\n\t\n\nIn this paper, we introduce the task of targeted aspect-based sentiment analysis. The goal is to extract fine-grained information with respect to entities mentioned in user comments. This work extends both aspect-based sentiment analysis that assumes a single entity per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bhavnicksm/sentihood.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","multi-class-classification","natural-language-inference","monolingual"],"keywords_longer_than_N":true},
	{"name":"aspectemo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/aspectemo","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"AspectEmo dataset: Multi-Domain Corpus of Consumer Reviews for Aspect-Based \n                Sentiment Analysis","first_N":5,"first_N_keywords":["token-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"nkjp-pos","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/nkjp-pos","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"NKJP-POS tagging dataset.","first_N":5,"first_N_keywords":["other","part-of-speech","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"polemo2-official","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/polemo2-official","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"PolEmo 2.0:  Corpus of Multi-Domain Consumer Reviews, evaluation data for article presented at CoNLL.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"coda","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/corypaik/coda","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","description":"*The Color Dataset* (CoDa) is a probing dataset to evaluate the representation of visual properties in language models. CoDa consists of color distributions for 521 common objects, which are split into 3 groups: Single, Multi, and Any.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"prost","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/corypaik/prost","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","description":"*Physical Reasoning about Objects Through Space and Time* (PROST) is a probing dataset to evaluate the ability of pretrained LMs to understand and reason about the physical world. PROST consists of 18,736 cloze-style multiple choice questions from 14 manually curated templates, covering 10 physical reasoning concepts:  direction, mass, height, circumference, stackable, rollable, graspable, breakable, slideable, and bounceable.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","open-domain-qa","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aaac","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DebateLabKIT/aaac","creator_name":"DebateLab at KIT","creator_url":"https://huggingface.co/DebateLabKIT","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Artificial Argument Analysis Corpus (AAAC)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDeepA2 is a modular framework for deep argument analysis. DeepA2 datasets contain comprehensive logical reconstructions of informally presented arguments in short argumentative texts. This document describes two synthetic DeepA2 datasets for artificial argument analysis: AAAC01 and AAAC02.\n# clone\ngit lfs clone https://huggingface.co/datasets/debatelab/aaac\n\nimport pandas as pd\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DebateLabKIT/aaac.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","parsing","text-simplification"],"keywords_longer_than_N":true},
	{"name":"klexikon","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dennlinger/klexikon","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","description":"\n\t\n\t\t\n\t\tDataset Card for the Klexikon Dataset\n\t\n\n\n\t\n\t\t\n\t\tVersion History\n\t\n\n\nv0.3 (2022-09-01): Removing some five samples from the dataset due to duplication conflicts with other samples.\nv0.2 (2022-02-28): Updated the files to no longer contain empty sections and removing otherwise empty lines at the end of files. Also removing lines with some sort of coordinate.\nv0.1 (2022-01-19): Initial data release on Huggingface datasets.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Klexikon dataset is a German‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dennlinger/klexikon.","first_N":5,"first_N_keywords":["summarization","text-simplification","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"mobie","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/mobie","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":"\n\t\n\t\t\n\t\tDataset Card for \"MobIE\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis script is for loading the MobIE dataset from https://github.com/dfki-nlp/mobie. \nMobIE is a German-language dataset which is human-annotated with 20 coarse- and fine-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and traffic reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge base. A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DFKI-SLT/mobie.","first_N":5,"first_N_keywords":["text-classification","token-classification","named-entity-recognition","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"RoITD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dragosnicolae555/RoITD","creator_name":"Constantin Nicolae","creator_url":"https://huggingface.co/dragosnicolae555","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We introduce a  Romanian IT Dataset (RoITD) resembling SQuAD 1.1.  RoITD consists of 9575 Romanian  QA pairs formulated by crowd workers. QA pairs are based on 5043 articles from Romanian Wikipedia articles describing IT and household products.  Of the total number of questions, 5103 are possible (i.e. the correct answer can be found within the paragraph) and 4472 are not possible (i.e. the given answer is a \"plausible answer\" and not correct)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dragosnicolae555/RoITD.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Urban100","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eugenesiow/Urban100","creator_name":"Eugene Siow","creator_url":"https://huggingface.co/eugenesiow","description":"The Urban100 dataset contains 100 images of urban scenes. \nIt commonly used as a test set to evaluate the performance of super-resolution models.","first_N":5,"first_N_keywords":["other","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"java-cmpx-v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/giganticode/java-cmpx-v1","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","description":"giganticode/java-cmpx-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"java-cmpx","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/giganticode/java-cmpx","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","description":"giganticode/java-cmpx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ICC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonfd/ICC","creator_name":"J√≥n Fri√∞rik Da√∞ason","creator_url":"https://huggingface.co/jonfd","description":"\n\t\n\t\t\n\t\tDataset Card for ICC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Icelandic Crawled Corpus (ICC) contains approximately 930M tokens which have been scraped from a selection of Icelandic websites, including news sites, government websites and forums. The scraped text is presented in its original form, unannotated, untokenized and without deduplication.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe ICC is primarily intended for use in training language models. It can be combined with other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jonfd/ICC.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ManyTypes4TypeScript","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","description":"\n\t\n\t\t\n\t\tModels Trained On ManyTypes4TypeScript\n\t\n\n\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task similar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript.","first_N":5,"first_N_keywords":["found","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"my-awesome-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewtun/my-awesome-dataset","creator_name":"Lewis Tunstall","creator_url":"https://huggingface.co/lewtun","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewtun/my-awesome-dataset.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"long-covid-classification-data","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llangnickel/long-covid-classification-data","creator_name":"Lisa Langnickel","creator_url":"https://huggingface.co/llangnickel","description":"\n\t\n\t\t\n\t\tData Description\n\t\n\nLong-COVID related articles have been manually collected by information specialists.Please find further information here. \n\n\t\n\t\t\n\t\tSize\n\t\n\n\n\t\n\t\t\n\nTraining\nDevelopment\nTest\nTotal\n\n\n\t\t\nPositive Examples\n215\n76\n70\n345\n\n\nNegative Examples\n199\n62\n68\n345\n\n\nTotal\n414\n238\n138\n690\n\n\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{10.1093/database/baac048,author = {Langnickel, Lisa and Darms, Johannes and Heldt, Katharina and Ducks, Denise and Fluck, Juliane},title = \"{Continuous development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llangnickel/long-covid-classification-data.","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"icelandic-error-corpus-IceEC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mideind/icelandic-error-corpus-IceEC","creator_name":"Mi√∞eind ehf.","creator_url":"https://huggingface.co/mideind","description":"The Icelandic Error Corpus (IceEC) is a collection of texts in modern Icelandic annotated for mistakes related to spelling, grammar, and other issues. The texts are organized by genre. The current version includes sentences from student essays, online news texts and Wikipedia articles.\nSentences within texts in the student essays had to be shuffled due to the license which they were originally published under, but neither the online news texts nor the Wikipedia articles needed to be shuffled.","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","Icelandic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"medwiki","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tr-qnli","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpyeditepe/tr-qnli","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr-qnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","found","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tr_rte","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpyeditepe/tr_rte","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr_rte dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","found","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"sharif_emotional_speech_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","description":"\n\t\n\t\t\n\t\n\t\n\t\tSharif Emotional Speech Dataset (ShEMO)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","radio-plays"],"keywords_longer_than_N":true},
	{"name":"ancora-ca-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/ancora-ca-ner","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for AnCora-Ca-NER\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for Named Entity Recognition (NER) in Catalan. It adapts AnCora corpus for Machine Learning and Language Model evaluation purposes.\nThis dataset was developed by BSC TeMU as part of the Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNamed Entities Recognition, Language Model\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe dataset is in Catalan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/ancora-ca-ner.","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","Catalan","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"casum","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for CaSum\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (Ag√®ncia Catalana de Not√≠cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rouge score. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum.","first_N":5,"first_N_keywords":["summarization","machine-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"catalan_general_crawling","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_general_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for Catalan General Crawling\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Catalan General Crawling Corpus is a 435-million-token web corpus of Catalan built from the web. It has been obtained by crawling the 500 most popular .cat and .ad domains during July 2020. It consists of 434,817,705 tokens, 19,451,691 sentences and 1,016,114 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.\nThis work is licensed under a Creative Commons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_general_crawling.","first_N":5,"first_N_keywords":["fill-mask","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"catalan_government_crawling","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_government_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for Catalan Government Crawling\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Catalan Government Crawling Corpus is a 39-million-token web corpus of Catalan built from the web. It has been obtained by crawling the .gencat domain and subdomains, belonging to the Catalan Government during September and October 2020. It consists of 39,117,909 tokens, 1,565,433 sentences and 71,043 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_government_crawling.","first_N":5,"first_N_keywords":["fill-mask","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"catalan_textual_corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for Catalan Textual Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Catalan Textual Corpus is a 1760-million-token web corpus of Catalan built from several sources.\nIt consists of 1,758,388,896 tokens, 73,172,152 sentences, and 12,556,365 documents. Documents are separated by single new lines. These boundaries have been preserved as long as the license allowed it.\nThis work is licensed under a Creative Commons Attribution Share Alike 4.0 International license.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus.","first_N":5,"first_N_keywords":["fill-mask","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sts-ca","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/sts-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for STS-ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSTS-ca corpus is a benchmark for evaluating Semantic Text Similarity in Catalan. This dataset was developed by BSC TeMU as part of Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\nThis work is licensed under a Attribution-ShareAlike 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to build and score semantic similarity models in Catalan.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/sts-ca.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-scoring","text-scoring","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"vilaquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/vilaquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for VilaQuAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVilaQuAD, An extractive QA dataset for Catalan, from VilaWeb newswire text.\nThis dataset contains 2095 of Catalan language news articles along with 1 to 5 questions referring to each fragment (or context).\nVilaQuad articles are extracted from the daily VilaWeb and used under CC-BY-NC-SA-ND licence. \nThis dataset can be used to build extractive-QA and Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nExtractive-QA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/vilaquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"viquiquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/viquiquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia.\nThis dataset contains 3111 contexts extracted from a set of 597 high quality original (no translations) articles in the Catalan Wikipedia \"Viquip√®dia\", and 1 to 5 questions with their answer for each fragment.\nViquipedia articles are used under CC-by-sa licence. \nThis dataset can be used to fine-tune and evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/viquiquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wnli-ca","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/wnli-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tWNLI-ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\"A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution. The schema takes its name from Terry Winograd.\" Source: The Winograd Schema Challenge.\nThe Winograd NLI dataset presents 855 sentence pairs, in which the first sentence contains an ambiguity and the second one a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/wnli-ca.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"xquad-ca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/xquad-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for XQuAD-Ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProfessional translation into Catalan of XQuAD dataset.\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 (Rajpurkar, Pranav et al., 2016) together with their professional translations into ten language: Spanish, German, Greek‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/xquad-ca.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"quasar","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/sagnikrayc/quasar","creator_name":"sagnik ray choudhury","creator_url":"https://huggingface.co/sagnikrayc","description":"We present two new large-scale datasets aimed at evaluating systems designed to comprehend a natural language query and extract its answer from a large corpus of text. The Quasar-S dataset consists of 37000 cloze-style (fill-in-the-gap) queries constructed from definitions of software entity tags on the popular website Stack Overflow. The posts and comments on the website serve as the background corpus for answering the cloze questions. The Quasar-T dataset consists of 43000 open-domain trivia questions and their answers obtained from various internet sources. ClueWeb09 serves as the background corpus for extracting these answers. We pose these datasets as a challenge for two related subtasks of factoid Question Answering: (1) searching for relevant pieces of text that include the correct answer to a query, and (2) reading the retrieved text to answer the query.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"tripclick-training","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training","creator_name":"Sebastian Hofst√§tter","creator_url":"https://huggingface.co/sebastian-hofstaetter","description":"\n\t\n\t\t\n\t\tTripClick Baselines with Improved Training Data\n\t\n\nEstablishing Strong Baselines for TripClick Health Retrieval Sebastian Hofst√§tter, Sophia Althammer, Mete Sertkan and Allan Hanbury\nhttps://arxiv.org/abs/2201.00365\ntl;dr We create strong re-ranking and dense retrieval baselines (BERTCAT, BERTDOT, ColBERT, and TK) for TripClick (health ad-hoc retrieval). We improve the ‚Äì originally too noisy ‚Äì training data with a simple negative sampling policy. We achieve large gains over BM25 in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","other","clicks","other"],"keywords_longer_than_N":true},
	{"name":"nli_zh","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli_zh","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"Á∫ØÊñáÊú¨Êï∞ÊçÆÔºåÊ†ºÂºèÔºöÔºàsentence1Ôºå sentence2Ôºå labelÔºâ„ÄÇÂ∏∏ËßÅ‰∏≠ÊñáËØ≠‰πâÂåπÈÖçÊï∞ÊçÆÈõÜÔºåÂåÖÂê´ATEC„ÄÅBQ„ÄÅLCQMC„ÄÅPAWSX„ÄÅSTS-BÂÖ±5‰∏™‰ªªÂä°„ÄÇ","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"source_code","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/source_code","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"Á∫ØÊñáÊú¨Êï∞ÊçÆÔºåÂÜÖÂÆπÔºöÈ´òË¥®ÈáèÁºñÁ®ãÊ∫ê‰ª£Á†ÅÔºåÂåÖÊã¨PythonÔºåJavaÔºåCPPÊ∫ê‰ª£Á†Å","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Softcatala-Web-Texts-Dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\n\t\n\t\t\n\t\tDataset Card for Softcatala-Web-Texts-Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains Sofcatal√† web site content (articles and programs descriptions).\nDataset size:\n\narticles.json contains 623 articles with 373233 words.\nprogrames.json contains 330 program descriptions with 49868 words.\n\nThe license of the data is Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) or Universal Public Domain Dedication (CC0 1.0)\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ca_text_corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/ca_text_corpus","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\n\t\n\t\t\n\t\tDataset Card for ca-text-corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPublic domain corpus of Catalan text.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nCatalan (ca).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/ca_text_corpus.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"catalan-dictionary","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/catalan-dictionary","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\n\t\n\t\t\n\t\tDataset Card for ca-text-corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCatalan word lists with part of speech labeling curated by humans. Contains 1 180 773 forms including verbs, nouns, adjectives, names or toponyms. These word lists are used to build applications like Catalan spellcheckers or verb querying applications.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nCatalan (ca).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains 3 columns:\n\nForm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/catalan-dictionary.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"open-source-english-catalan-corpus","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\n\t\n\t\t\n\t\tDataset Card for open-source-english-catalan-corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTranslation memory built from more than 180 open source projects. These include LibreOffice, Mozilla, KDE, GNOME, GIMP, Inkscape and many others. It can be used as translation memory or as training corpus for neural translators.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nCatalan (ca)\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stevhliu/demo","creator_name":"Steven Liu","creator_url":"https://huggingface.co/stevhliu","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stevhliu/demo.","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"WikiConvert","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/usc-isi/WikiConvert","creator_name":"USC Information Sciences Institute","creator_url":"https://huggingface.co/usc-isi","description":"Language Modelling with Cardinal Number Annotations.","first_N":5,"first_N_keywords":["fill-mask","other","text-generation","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"lsoie","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wardenga/lsoie","creator_name":"Robert Wardenga","creator_url":"https://huggingface.co/wardenga","description":"The Large Scale Open Information Extraction Dataset (LSOIE), is a dataset 20 \ntimes larger than the next largest human-annotated Open Information Extraction\n(OIE) dataset. LSOIE is a built upon the QA-SRL 2.0 dataset.","first_N":5,"first_N_keywords":["text-retrieval","machine-generated","found","monolingual","extended|qa_srl"],"keywords_longer_than_N":true},
	{"name":"COVID-19-vaccine-attitude-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets","creator_name":"webimmunization","creator_url":"https://huggingface.co/webimmunization","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-19-vaccine-attitude-tweets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 2564 manually annotated tweets related to COVID-19 vaccines. The dataset can be used to discover the attitude expressed in the tweet towards the subject of COVID-19 vaccines. Tweets are in English. The dataset was curated in such a way as to maximize the likelihood of tweets with a strong emotional tone. We have assumed the existence of three classes:\n\nPRO (label 0): positive, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","intent-classification","crowdsourced","other"],"keywords_longer_than_N":true},
	{"name":"turkish-sentiment-analysis-dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset","creator_name":"Batuhan","creator_url":"https://huggingface.co/winvoker","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains positive , negative and notr sentences from several data sources given in the references. In the most sentiment models , there are only two labels; positive and negative. However , user input can be totally notr sentence. For such cases there were no data I could find. Therefore I created this dataset with 3 class. Positive and negative sentences are listed below. Notr examples are extraced from turkish wiki dump. In addition, added some random text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"annotated_reference_strings","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuanchuan/annotated_reference_strings","creator_name":"Yuan Chuan Kee","creator_url":"https://huggingface.co/yuanchuan","description":"A repository of reference strings annotated using CSL processor using citations obtained from various sources.","first_N":5,"first_N_keywords":["token-classification","parsing","other","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"finer-139","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpaueb/finer-139","creator_name":"AUEB NLP Group","creator_url":"https://huggingface.co/nlpaueb","description":"FiNER-139 is a named entity recognition dataset consisting of 10K annual \nand quarterly English reports (filings) of publicly traded companies \ndownloaded from the U.S. Securities and Exchange Commission (SEC) \nannotated with 139 XBRL tags in the IOB2 format.","first_N":5,"first_N_keywords":["named-entity-recognition","expert-generated","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"java-8m-methods-v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v1","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","description":"anjandash/java-8m-methods-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["monolingual","mit","1M - 10M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"the-antiwork-subreddit-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-antiwork-subreddit-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This dataset follows the notorious subreddit /r/Antiwork, a place for many Redditors to share resources and discuss grievances with the current labour market.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_full_sent","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_full_doc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_human_sent","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_human_doc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\n","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"java-8m-methods-v2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v2","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","description":"anjandash/java-8m-methods-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["monolingual","mit","1M - 10M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malteos/test2","creator_name":"malteos","creator_url":"https://huggingface.co/malteos","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malteos/test2.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"pmc_open_access_xml","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TomTBT/pmc_open_access_xml","creator_name":"Tom Boissonnet","creator_url":"https://huggingface.co/TomTBT","description":"\n\t\n\t\t\n\t\tDataset Card for PMC Open Access XML\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe XML Open Access includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TomTBT/pmc_open_access_xml.","first_N":5,"first_N_keywords":["text-classification","summarization","other","no-annotation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"roman_urdu_hate_speech","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for roman_urdu_hate_speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Roman Urdu Hate-Speech and Offensive Language Detection (RUHSOLD) dataset is a Roman Urdu dataset of tweets annotated by experts in the relevant language. The authors develop the gold-standard for two sub-tasks. First sub-task is based on binary labels of Hate-Offensive content and Normal content (i.e., inoffensive language). These labels are self-explanatory. The authors refer to this sub-task as coarse-grained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"adv_glue","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-Secure/adv_glue","creator_name":"Secure Learning Lab","creator_url":"https://huggingface.co/AI-Secure","description":"\n\t\n\t\t\n\t\tDataset Card for Adversarial GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAdversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. It covers five natural language understanding tasks from the famous GLUE tasks and is an adversarial version of GLUE benchmark.\nAdvGLUE considers textual adversarial attacks from different perspectives and hierarchies, including word-level transformations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Secure/adv_glue.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","sentiment-classification","other","machine-generated"],"keywords_longer_than_N":true},
	{"name":"psycholinguistic_eval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KevinZ/psycholinguistic_eval","creator_name":"Kevin Zhao","creator_url":"https://huggingface.co/KevinZ","description":"Psycholinguistic dataset from 'What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models'\nby Allyson Ettinger","first_N":5,"first_N_keywords":["multiple-choice","fill-mask","question-answering","zero-shot-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"multiwoz21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/multiwoz21","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MultiWOZ 2.1\n\t\n\n\nRepository: https://github.com/budzianowski/multiwoz\nPaper: https://aclanthology.org/2020.lrec-1.53\nLeaderboard: https://github.com/budzianowski/multiwoz\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('multiwoz21')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/multiwoz21.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"readability-es-caes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\n\t\n\t\t\n\t\tDataset Card for [readability-es-caes]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources:\n\nCAES corpus (Mart√≠nez et al., 2019): the \"Corpus de Aprendices del Espa√±ol\" is a collection of texts produced by Spanish L2 learners from Spanish learning centers and universities. These text are produced by students‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes.","first_N":5,"first_N_keywords":["text-classification","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"unam_tesis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card of \"unam_tesis\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nEl dataset unam_tesis cuenta con 1000 tesis de 5 carreras de la Universidad Nacional Aut√≥noma de M√©xico (UNAM), 200 por carrera. Se pretende seguir incrementando este dataset con las dem√°s carreras y m√°s tesis.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\ntext-classification\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nEspa√±ol (es)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\nLas instancias del dataset son de la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis.","first_N":5,"first_N_keywords":["text-classification","language-modeling","MajorIsaiah","Ximyer","clavel"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pragnakalp/squad_v2_french_translated","creator_name":"Pragnakalp Techlabs","creator_url":"https://huggingface.co/pragnakalp","description":"Using Google Translation, we have translated SQuAD 2.0 dataset into multiple languages. \nHere is the translated dataset of SQuAD 2.0 in French language.\nShared by Pragnakalp Techlabs\n","first_N":5,"first_N_keywords":["monolingual","translation","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"readability-es-hackathon-pln-public","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\n\t\n\t\t\n\t\tDataset Card for [readability-es-sentences]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompilation of short Spanish articles for readability assessment.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources: \n\nCoh-Metrix-Esp corpus (Quispesaravia, et al., 2016): collection of 100 parallel texts with simple and complex variants in Spanish. These texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public.","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"monolingual_ab","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nart/monolingual_ab","creator_name":"Danial Zakaria","creator_url":"https://huggingface.co/Nart","description":"\n\t\n\t\t\n\t\tDataset Card for \"monolingual_ab\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Abkhaz language monolingual dataset is a collection of 1,470,480 sentences extracted from  different sources. The dataset is available under the Creative Commons Universal Public Domain License. Part of it is also available as part of Common Voice, another part is from the Abkhaz National Corpus\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nHere is a link to the source of a large part of the data on github‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nart/monolingual_ab.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"the-reddit-dataset-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-dataset-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"A meta dataset of Reddit's own /r/datasets community.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"the-reddit-place-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-place-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"The written history or /r/Place, in posts and comments.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Ukr-Synth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ukr-models/Ukr-Synth","creator_name":"Volodymyr Kurnosov","creator_url":"https://huggingface.co/ukr-models","description":"Large silver standard Ukrainian corpus annotated with morphology tags, syntax trees and PER, LOC, ORG NER-tags.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","parsing","part-of-speech","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Category-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015). The original dataset is processed and cleaned of single word texts, English only sentences etc. \nIf you use this dataset, please cite {Nisansa de Silva, Sinhala Text Classification: Observations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Source-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK,\nNewsfirst, World Socialist Web Site-Sinhala). This is a processed version of the corpus created by Sachintha, D., Piyarathna, L., Rajitha, C., and Ranathunga, S. (2021). Exploiting parallel corpora to improve multilingual embedding based document and sentence alignment. Single word sentences, invalid characters have been removed from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"smithsonian_butterflies","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ceyda/smithsonian_butterflies","creator_name":"Ceyda Cinarel","creator_url":"https://huggingface.co/ceyda","description":"\n\t\n\t\t\n\t\tDataset Card for [Smithsonian Butterflies]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHigh-res images from Smithsonian \"Education and Outreach\" & \"NMNH - Entomology Dept.\" collections. Crawled\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIncludes metadata about the scientific name of butterflies, but there maybe missing values. Might be good for classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tExample data\n\t\n\n{'image_url':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ceyda/smithsonian_butterflies.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"pesp","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/apjanco/pesp","creator_name":"Andy Janco","creator_url":"https://huggingface.co/apjanco","description":"\n\t\n\t\t\n\t\tPages of Early Soviet Performance (PESP)\n\t\n\nThis dataset was created as part of the Pages of Early Soviet Performance project at Princeton and provides text and image research data from a previously scanned collection of illustrated periodicals held by Princeton University's Slavic Collections. The project was a partnership with ITMO University in Saint Petersburg. Our work focused on document segmentation and the prediction of image, text, title, and mixedtext regions in the document‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/apjanco/pesp.","first_N":5,"first_N_keywords":["other","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"APEACH","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jason9693/APEACH","creator_name":"Kichang Yang","creator_url":"https://huggingface.co/jason9693","description":"\n\t\n\t\t\n\t\tDataset for project: kor_hate_eval(APEACH)\n\t\n\n\n\n\t\n\t\t\n\t\tSample Code\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Descritpion\n\t\n\nKorean Hate Speech Evaluation Datasets : trained with BEEP! and evaluate with APEACH\n\nRepository: Korean HateSpeech Evaluation Dataset\nPaper: APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\nPoint of Contact: Kichang Yang\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nko-KR\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\n\t\n\t\tData Instances\n\t\n\nA sample from this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jason9693/APEACH.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowd-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PLOD-filtered","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-filtered","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"This is the dataset repository for PLOD Dataset accepted to be published at LREC 2022.\nThe dataset can help build sequence labelling models for the task Abbreviation Detection.","first_N":5,"first_N_keywords":["token-classification","Leonardo Zilio, Hadeel Saadany, Prashant Sharma, Diptesh Kanojia, Constantin Orasan","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PLOD-unfiltered","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-unfiltered","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"This is the dataset repository for PLOD Dataset accepted to be published at LREC 2022.\nThe dataset can help build sequence labelling models for the task Abbreviation Detection.","first_N":5,"first_N_keywords":["token-classification","Leonardo Zilio, Hadeel Saadany, Prashant Sharma, Diptesh Kanojia, Constantin Orasan","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"the-reddit-irl-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-irl-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"Data from the humour subreddits /r/meirl and /r/me_irl, up to Apr 1 2022","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"IteraTeR_v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_v2","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision\nAuthors: Wanyu Du*, Zae Myung Kim*, Vipul Raheja, Dhruv Kumar, Dongyeop Kang\nGithub repo: https://github.com/vipulraheja/IteraTeR\nWatch our system demonstration below!\n\n","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"WANLI","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alisawuffles/WANLI","creator_name":"Alisa Liu","creator_url":"https://huggingface.co/alisawuffles","description":"\n\t\n\t\t\n\t\tDataset Card for WANLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWANLI (Worker-AI Collaboration for NLI) is a collection of 108K English sentence pairs for the task of natural language inference (NLI).\nEach example is created by first identifying a \"pocket\" of examples in MultiNLI (Williams et al., 2018) that share a challenging reasoning pattern, then instructing GPT-3 to write a new example with the same pattern.\nThe set of generated examples are automatically filtered to contain those most‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alisawuffles/WANLI.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","crowdsourced","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"semeval-2010-pre","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taln-ls2n/semeval-2010-pre","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","description":"Preprocessed SemEval-2010 Benchmark dataset for Keyphrase Generation.","first_N":5,"first_N_keywords":["text-generation","unknown","unknown","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"FaithDial","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/FaithDial","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"FaithDial is a new benchmark for hallucination-free dialogues, created by manually editing hallucinated and uncooperative responses in Wizard of Wikipedia.","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"kinopoisk","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/blinoff/kinopoisk","creator_name":"Pavel Blinov","creator_url":"https://huggingface.co/blinoff","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKinopoisk movie reviews dataset (TOP250 & BOTTOM100 rank lists).\nIn total it contains 36,591 reviews from July 2004 to November 2012.\nWith following distribution along the 3-point sentiment scale:\n\nGood: 27,264;\nBad: 4,751;\nNeutral: 4,576.\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach sample contains the following fields:\n\npart: rank list top250 or bottom100;\nmovie_name;\nreview_id;\nauthor: review author;\ndate: date of a review;\ntitle: review title;\ngrade3: sentiment score Good, Bad‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/blinoff/kinopoisk.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","monolingual","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"bigscience-lama","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","description":"\n\t\n\t\t\n\t\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\n\t\n\n@inproceedings{petroni2020how,\n  title={How Context Affects Language Models' Factual Predictions},\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\n  booktitle={Automated Knowledge Base Construction},\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama.","first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Writing-style-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This file contains news texts (sentences) belonging to different writing styles. The original dataset created by {Upeksha, D., Wijayarathna, C., Siriwardena, M.,\nLasandun, L., Wimalasuriya, C., de Silva, N., and Dias, G. (2015). Implementing a corpus for Sinhala language. 01}is processed and cleaned.\nIf you use this dataset, please cite {Dhananjaya et al. BERTifying Sinhala - A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification, 2022} and the above mentioned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"spanish_imdb_synopsis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis","creator_name":"Mathias Gatti","creator_url":"https://huggingface.co/mathigatti","description":"\n\t\n\t\t\n\t\tDataset Card for Spanish IMDb Synopsis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n4969 movie synopsis from IMDb in spanish.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll descriptions are in spanish, the other fields have some mix of spanish and english.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ndescription: IMDb description for the movie (string), should be spanish\nkeywords: IMDb keywords for the movie (string), mix of spanish and english\ngenre: The genres of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis.","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"twitter_pos_vcb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/twitter_pos_vcb","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis data is the vote-constrained bootstrapped data generate to support state-of-the-art results.\n\nThe data is about 1.5 million English tweets annotated for part-of-speech using Ritter's extension of the PTB tagset.\nThe tweets are from 2012 and 2013, tokenized using the GATE tokenizer and tagged\njointly using the CMU ARK tagger and Ritter's T-POS tagger. Only when both these taggers' outputs\nare completely compatible over a whole tweet, is that tweet added to the dataset.\n\nThis data is recommend for use a training data **only**, and not evaluation data.\n\nFor more details see https://gate.ac.uk/wiki/twitter-postagger.html and https://aclanthology.org/R13-1026.pdf","first_N":5,"first_N_keywords":["token-classification","part-of-speech","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"zulu_stance","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/zulu_stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance detection dataset in the Zulu language. The data is translated to Zulu by Zulu native speakers, from English source texts.\n\nMisinformation has become a major concern in recent last years given its \nspread across our information sources. In the past years, many NLP tasks have\nbeen introduced in this area, with some systems reaching good results on \nEnglish language datasets. Existing AI based approaches for fighting \nmisinformation in literature suggest automatic stance detection as an integral\nfirst step to success. Our paper aims at utilizing this progress made for\nEnglish to transfers that knowledge into other languages, which is a \nnon-trivial task due to the domain gap between English and the target \nlanguages. We propose a black-box non-intrusive method that utilizes techniques\nfrom Domain Adaptation to reduce the domain gap, without requiring any human\nexpertise in the target language, by leveraging low-quality data in both a\nsupervised and unsupervised manner. This allows us to rapidly achieve similar\nresults for stance detection for the Zulu language, the target language in\nthis work, as are found for English. We also provide a stance detection dataset\nin the Zulu language.","first_N":5,"first_N_keywords":["text-classification","fact-checking","sentiment-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"home-depot","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ukhushn/home-depot","creator_name":"Umair Khushnood","creator_url":"https://huggingface.co/Ukhushn","description":"\n\t\n\t\t\n\t\tDataset Card for Ukhushn/home-depot\n\t\n\n","first_N":5,"first_N_keywords":["sentence-similarity","no-annotation","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"WIESP2022-NER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adsabs/WIESP2022-NER","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","description":"\n\t\n\t\t\n\t\tDataset for the first Workshop on Information Extraction from Scientific Publications (WIESP/2022).\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDatasets with text fragments from astrophysics papers, provided by the NASA Astrophysical Data System with manually tagged astronomical facilities and other entities of interest (e.g., celestial objects).Datasets are in JSON Lines format (each line is a json dictionary).The datasets are formatted similarly to the CONLL2003 format. Each token is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/WIESP2022-NER.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"kote","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/searle-j/kote","creator_name":"Jeon Duyoung","creator_url":"https://huggingface.co/searle-j","description":"50k Korean online comments labeled for 44 emotion categories.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"twitter_pos","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/twitter_pos","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis dataset contains two datasets for English PoS tagging for tweets:\n\n* Ritter, with train/dev/test\n* Foster, with dev/test\n\nSplits defined in the Derczynski paper, but the data is from Ritter and Foster.\n\nFor more details see:\n\n* https://gate.ac.uk/wiki/twitter-postagger.html\n* https://aclanthology.org/D11-1141.pdf\n* https://www.aaai.org/ocs/index.php/ws/aaaiw11/paper/download/3912/4191","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"arcalive_220506","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/arcalive_220506","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"[ÏïÑÏπ¥ÎùºÏù¥Î∏å Î≤†Ïä§Ìä∏ ÎùºÏù¥Î∏å Ï±ÑÎÑê](https://arca.live/b/live)Ïùò 2021ÎÖÑ 8Ïõî 16ÏùºÎ∂ÄÌÑ∞ 2022ÎÖÑ 5Ïõî 6ÏùºÍπåÏßÄÏùò Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏßëÌïòÏó¨, ÎåìÍ∏ÄÎßå Í≥®ÎùºÎÇ∏ Îç∞Ïù¥ÌÑ∞ÏûÖÎãàÎã§.","first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"QA2D","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\n\t\n\t\t\n\t\tDataset Card for QA2D\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we show‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D.","first_N":5,"first_N_keywords":["text-simplification","machine-generated","crowdsourced","found","machine-generated"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-s2s","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arxiv-clustering-s2s","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArXivHierarchicalClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArXivHierarchicalClusteringS2S\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-s2s.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-p2p","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arxiv-clustering-p2p","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArXivHierarchicalClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles+abstract from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-p2p.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"qg_subjqa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_subjqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SubjQA](https://github.com/megagonlabs/SubjQA) dataset for question generation (QG) task.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","subjqa","English"],"keywords_longer_than_N":true},
	{"name":"TruthfulQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domenicrosati/TruthfulQA","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA: Measuring How Models Mimic Human Falsehoods\nWe propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/TruthfulQA.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","closed-domain-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"rumoureval_2019","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/rumoureval_2019","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"\nStance prediction task in English. The goal is to predict whether a given reply to a claim either supports, denies, questions, or simply comments on the claim. Ran as a SemEval task in 2019.","first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cogtext","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morteza/cogtext","creator_name":"Morteza Ansarinia","creator_url":"https://huggingface.co/morteza","description":"\n\t\n\t\t\n\t\tDataset Card for CogText PubMed Abstracts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CogText dataset is a curated collection of abstracts about cognitive tasks and constructs from PubMed.\nThis dataset contains the original abstracts and their corresponding embeddings.\nPlease visit CogText on GitHub for the details and codes.\n\nHomepage: https://github.com/morteza/cogtext\nRepository: https://github.com/morteza/cogtext\nPoint of Contact: Morteza Ansarinia\nPaper: https://arxiv.org/abs/2203.11016‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morteza/cogtext.","first_N":5,"first_N_keywords":["text-classification","topic-classification","semantic-similarity-classification","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"id_recipe","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sultannn/id_recipe","creator_name":"Sultan","creator_url":"https://huggingface.co/Sultannn","description":"\n\t\n\t\t\n\t\tDataset Card for id_recipe\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIndonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food. \nid_recipe is an Indonesian Food Recipe dataset. The dataset contains >10000 Indonesian Recipe.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIndonesian\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nHere are the number of examples\n\n\t\n\t\t\nname‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sultannn/id_recipe.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/banking77","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Banking77Classification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset composed of online banking queries annotated with their corresponding intents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten\n\n\nReference\nhttps://arxiv.org/abs/2003.04807\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Banking77Classification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/banking77.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"QA_on_SLA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajeshvarma/QA_on_SLA","creator_name":"sai rajesh varma","creator_url":"https://huggingface.co/rajeshvarma","description":"rajeshvarma/QA_on_SLA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["no-annotations","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"nlpcc-stance","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/nlpcc-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance prediction dataset in Chinese.\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"movie_reviews_with_context_drift","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","description":"\n\t\n\t\t\n\t\tDataset Card for reviews_with_drift\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was crafted to be used in our tutorial [Link to the tutorial when ready]. It consists on a large Movie Review Dataset mixed with some reviews from a Hotel Review Dataset. The training/validation set are purely obtained from the Movie Review Dataset while the production set is mixed. Some other features have been added (age, gender, context) as well as a made up timestamp‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"million-headlines","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajistics/million-headlines","creator_name":"Rajiv Shah","creator_url":"https://huggingface.co/rajistics","description":"\n\t\n\t\t\n\t\tDataset Card for Million Headlines\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis contains data of news headlines published over a period of eighteen years.  Sourced from the reputable Australian news source ABC (Australian Broadcasting Corporation) \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nFor each instance, there is a integer for the data, a string for news headline.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\npublish date: a integer that represents the data\nheadline: a string for the news headline‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajistics/million-headlines.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"BBNLI","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/feyzaakyurek/BBNLI","creator_name":"Afra Feyza Akyurek","creator_url":"https://huggingface.co/feyzaakyurek","description":"\n\t\n\t\t\n\t\tDataset Card for BBNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBBNLI (Bias Benchmark for Natural Language Inference) is bias measurement benchmark for the tasks of both natural language inference and question answering. BBNLI consists of 16 subtopics each tailored to measure a specific stereotype that is negatively impacting certain classes. Each subtopic includes a set of 3 to 11 premises,  5 to 11 stereotypical hypotheses that are geared towards measuring biases and 3 to 5 test hypotheses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/feyzaakyurek/BBNLI.","first_N":5,"first_N_keywords":["text-generation","natural-language-inference","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"gov_report","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/gov_report","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"GovReport long document summarization dataset.\n\nThere are three configs:\n  - plain_text: plain text document-to-summary pairs\n  - plain_text_with_recommendations: plain text doucment-summary pairs, with \"What GAO recommends\" included in the summary\n  - structure: data with section structure","first_N":5,"first_N_keywords":["summarization","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gov_report_qs","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/gov_report_qs","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"GovReport-QS hierarchical question-summary generation dataset.\n\nThere are two configs:\n  - paragraph: paragraph-level annotated data\n  - document: aggregated paragraph-level annotated data for the same document","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","launch/gov_report"],"keywords_longer_than_N":true},
	{"name":"ftrace","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ekinakyurek/ftrace","creator_name":"Ekin","creator_url":"https://huggingface.co/ekinakyurek","description":"    Factual Tracing Dataset that contains queries and abstracts, and their corresponding ground truth.","first_N":5,"first_N_keywords":["masked-language-modeling","monolingual","TRex","Lama","English"],"keywords_longer_than_N":true},
	{"name":"resd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for resd\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRussian dataset of emotional speech dialogues. This dataset was assembled from ~3.5 hours of live speech by actors who voiced pre-distributed emotions in the dialogue for ~3 minutes each.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/resd.","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cedr-m7","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/cedr-m7","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for CEDR-M7\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/cedr-m7.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_polarity","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AmazonPolarityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAmazon Polarity Classification Dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/amazon_polarity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonPolarityClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_polarity.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ru_paraphraser","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/merionum/ru_paraphraser","creator_name":"Vadim Gudkov","creator_url":"https://huggingface.co/merionum","description":"\n\t\n\t\t\n\t\tDataset Card for ParaPhraser\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParaPhraser is a news headlines corpus annotated according to the following schema:\n1: precise paraphrases\n0: near paraphrases\n-1: non-paraphrases\n\nThe Plus part is also available.\nIt contains clusters of news headline paraphrases labeled automatically by a fine-tuned paraphrase detection BERT model.In order to load it:\nfrom datasets import load_dataset\n\ncorpus = load_dataset('merionum/ru_paraphraser', data_files='plus.jsonl')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/merionum/ru_paraphraser.","first_N":5,"first_N_keywords":["text-classification","text-generation","sentence-similarity","semantic-similarity-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"toxic_conversations_50k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/toxic_conversations_50k","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ToxicConversationsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCollection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/toxic_conversations_50k.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"REPV","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"REPV-S","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV-S","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"movie_recommendation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/movie_recommendation","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Movie recommendation task based on the Movielens dataset","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","open-domain-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"discourse_marker_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/discourse_marker_qa","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Discourse marker/connective prediction as multiple choice questions based on the Discovery dataset","first_N":5,"first_N_keywords":["question-answering","multiple-choice","open-domain-qa","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"lccc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/silver/lccc","creator_name":"Silver","creator_url":"https://huggingface.co/silver","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\nThis pipeline involves a set of rules and several classifier-based filters.\nNoises such as offensive or sensitive words, special symbols, emojis,\ngrammatically incorrect sentences, and incoherent conversations are filtered.","first_N":5,"first_N_keywords":["dialogue-generation","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wikitext_linked","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/wikitext_linked","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":" The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\n Good and Featured articles on Wikipedia. Dependency Relations, POS, NER tags are marked with trankit and\n entities are linked with entity-fishing.\n The dataset is available under the Creative Commons Attribution-ShareAlike License.","first_N":5,"first_N_keywords":["fill-mask","token-classification","text-classification","masked-language-modeling","named-entity-recognition"],"keywords_longer_than_N":true},
	{"name":"qg_squadshifts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_squadshifts","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question generation (QG) task.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","subjqa","English"],"keywords_longer_than_N":true},
	{"name":"qg_esquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD-es](https://huggingface.co/datasets/squad_es) dataset for question generation (QG) task.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Spanish"],"keywords_longer_than_N":true},
	{"name":"qg_koquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Korean"],"keywords_longer_than_N":true},
	{"name":"fiqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"trec-covid","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"trec-covid-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scifact","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"nfcorpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"msmarco","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/msmarco","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/msmarco.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"nq","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"hotpotqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"arguana","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"quora","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entity","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"climate-fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scifact-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"nfcorpus-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"msmarco-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/msmarco-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/msmarco-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"hotpotqa-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"fiqa-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"arguana-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"quora-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entity-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scidocs-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"fever-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"climate-fever-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"nq-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"123_test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JeremyAlain/123_test","creator_name":"J√©r√©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","description":"The Fewshot Table dataset consists of tables that naturally occur on the web, that are formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. The dataset consists of approximately 413K tables that are extracted from the WDC Web Table Corpora 2015, which is released under the Apache-2.0 license. The WDC Web Table Corpora \"contains vast amounts of HTML tables. [...] The Web Data Commons project extracts relational Web tables from the Common Crawl, the largest and most up-to-date Web corpus that is currently available to the public.\"","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"arguana-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"climate-fever-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entity-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"fever-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_easy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Easy set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_medium","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Medium set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_hard","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Hard set)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con (re)discover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"answersumm","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexfabbri/answersumm","creator_name":"Alexander Fabbri","creator_url":"https://huggingface.co/alexfabbri","description":"\n\t\n\t\t\n\t\tDataset Card for answersumm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe AnswerSumm dataset is an English-language dataset of questions and answers collected from a StackExchange data dump. The dataset was created to support the task of query-focused answer summarization with an emphasis on multi-perspective answers. \nThe dataset consists of over 4200 such question-answer threads annotated by professional linguists and includes over 8700 summaries. We decompose the task into several annotation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexfabbri/answersumm.","first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"magpie","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/magpie","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"The MAGPIE corpus is a large sense-annotated corpus of potentially idiomatic expressions (PIEs), based on the British National Corpus (BNC). Potentially idiomatic expressions are like idiomatic expressions, but the term also covers literal uses of idiomatic expressions, such as 'I leave work at the end of the day.' for the idiom 'at the end of the day'. This version of the dataset reflects the filtered subset used by Dankers et al. (2022) in their investigation on how PIEs are represented by NMT models. Authors use 37k samples annotated as fully figurative or literal, for 1482 idioms that contain nouns, numerals or adjectives that are colours (which they refer to as keywords). Because idioms show syntactic and morphological variability, the focus is mostly put on nouns. PIEs and their context are separated using the original corpus‚Äôs word-level annotations.","first_N":5,"first_N_keywords":["text-classification","translation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ade20k-tiny","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/nateraw/ade20k-tiny","creator_name":"Nate Raw","creator_url":"https://huggingface.co/nateraw","description":"\n\t\n\t\t\n\t\tDataset Card for ADE 20K Tiny\n\t\n\nThis is a tiny subset of the ADE 20K dataset, which you can find here.\n","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"fig-qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nightingal3/fig-qa","creator_name":"Emmy Liu","creator_url":"https://huggingface.co/nightingal3","description":"\n\t\n\t\t\n\t\tDataset Card for Fig-QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for the paper Testing the Ability of Language Models to Interpret Figurative Language. Fig-QA consists of 10256 examples of human-written creative metaphors that are paired as a Winograd schema. It can be used to evaluate the commonsense reasoning of models. The metaphors themselves can also be used as training data for other tasks, such as metaphor detection or generation. \n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nightingal3/fig-qa.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"nfcorpus-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scifact-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scidocs-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"fiqa-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"trec-covid-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"trec-news-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-news-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-news-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"robust04-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/robust04-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/robust04-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"signal1m-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/signal1m-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/signal1m-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"quora-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"nq-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"hotpotqa-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/cqadupstack-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/cqadupstack-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/cqadupstack-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/cqadupstack-qrels.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"bioasq-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/bioasq-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\nNews Retrieval: TREC-NEWS, Robust04\nArgument Retrieval: Touche-2020, ArguAna\nDuplicate Question Retrieval: Quora, CqaDupstack\nCitation-Prediction: SCIDOCS\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/bioasq-generated-queries.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","fact-checking-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"core-2020-05-10-deduplication","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication","creator_name":"Pinecone","creator_url":"https://huggingface.co/pinecone","description":"\n\t\n\t\t\n\t\tDataset Card for CORE Deduplication\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCORE 2020 Deduplication dataset (https://core.ac.uk/documentation/dataset) contains 100K scholarly documents labeled as duplicates/non-duplicates.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset language is English (BCP-47 en)\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{dedup2020,\n  title={Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings},\n  author={Gyawali, Bikash and Anastasiou, Lucas and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication.","first_N":5,"first_N_keywords":["other","natural-language-inference","semantic-similarity-scoring","text-scoring","unknown"],"keywords_longer_than_N":true},
	{"name":"ctebmsp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lcampillos/ctebmsp","creator_name":"Leonardo Campillos-Llanos","creator_url":"https://huggingface.co/lcampillos","description":"\n\t\n\t\t\n\t\tCT-EBM-SP (Clinical Trials for Evidence-based Medicine in Spanish)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Clinical Trials for Evidence-Based-Medicine in Spanish corpus is a collection of 1200 texts about clinical trials studies and clinical trials announcements:\n\n500 abstracts from journals published under a Creative Commons license, e.g. available in PubMed or the Scientific Electronic Library Online (SciELO)\n700 clinical trials announcements published in the European Clinical Trials‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lcampillos/ctebmsp.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"summeval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/summeval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SummEvalSummarization.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article Summary Semantic Similarity Estimation. This version fixes a bug in the evaluation script that caused the main score to be computed incorrectly.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/Yale-LILY/SummEval\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/summeval.","first_N":5,"first_N_keywords":["summarization","human-annotated","monolingual","mteb/summeval","English"],"keywords_longer_than_N":true},
	{"name":"codecomplex","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/codecomplex","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\n\t\n\t\t\n\t\tCodeComplex Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCodeComplex consists of 4,200 Java codes submitted to programming competitions by human programmers and their complexity labels annotated by a group of algorithm experts.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\n You can load and iterate through the dataset with the following two lines of code:\nfrom datasets import load_dataset\n\nds = load_dataset(\"codeparrot/codecomplex\", split=\"train\")\nprint(next(iter(ds)))\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/codecomplex.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","monolingual","code"],"keywords_longer_than_N":true},
	{"name":"tm1","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm1","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Taskmaster-1\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-1-2019\nPaper: https://arxiv.org/pdf/1909.05358.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm1')\nontology = load_ontology('tm1')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm1.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","arxiv:1909.05358"],"keywords_longer_than_N":true},
	{"name":"woz","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/woz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for WOZ 2.0\n\t\n\n\nRepository: https://github.com/nmrksic/neural-belief-tracker/tree/master/data/woz\nPaper: https://aclanthology.org/P17-1163.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('woz')\nontology = load_ontology('woz')\ndatabase =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/woz.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"camrest","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/camrest","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Camrest\n\t\n\n\nRepository: https://www.repository.cam.ac.uk/handle/1810/260970\nPaper: https://aclanthology.org/D16-1233/\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('camrest')\nontology = load_ontology('camrest')\ndatabase =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/camrest.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tm2","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm2","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Taskmaster-2\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020\nPaper: https://arxiv.org/pdf/1909.05358.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm2')\nontology = load_ontology('tm2')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm2.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","arxiv:1909.05358"],"keywords_longer_than_N":true},
	{"name":"tm3","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm3","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Taskmaster-3\n\t\n\n\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-3-2020\nPaper: https://aclanthology.org/2021.acl-long.55.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('tm3')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm3.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"sgd","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Schema-Guided Dialogue\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue\nPaper: https://arxiv.org/pdf/1909.05855.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd')\nontology = load_ontology('sgd')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:1909.05855"],"keywords_longer_than_N":true},
	{"name":"open_question_type","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/open_question_type","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"Open-ended question type annotated dataset.","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hmd-erwt-training","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training","creator_name":"Living with Machines","creator_url":"https://huggingface.co/Livingwithmachines","description":"\n\t\n\t\t\n\t\tDataset Card for ERWT Hertiage Made Digital Newspapers training data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text extracted at the page level from historic digitised newspapers from the Heritage Made Digital newspaper digitisation program. The newspapers in the dataset were published between 1800 and 1870.\nThe data was primarily created as a dataset for training 'time-aware' language models.\nThe dataset contains text generated from Optical Character Recognition software on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training.","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"highlightsum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/knkarthick/highlightsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","description":"\n\t\n\t\t\n\t\tDataset Card for HighlightSum Corpus [Single Dataset Comprising of AMI, SamSUM & DialogSUM for Brief Summarization of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nAMI: https://huggingface.co/datasets/knkarthick/AMI\nDialogSUM: https://github.com/cylnlp/dialogsum\nSamSUM: https://huggingface.co/datasets/knkarthick/samsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nHighlightSUM is collection of large-scale dialogue summarization dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/highlightsum.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"topicsum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/knkarthick/topicsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","description":"\n\t\n\t\t\n\t\tDataset Card for TopicSum Corpus [Single Dataset Comprising of XSUM & DialogSUM for One Liner Summarization/ Topic Generation of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nDialogSUM: https://github.com/cylnlp/dialogsum\nXSUM: https://huggingface.co/datasets/knkarthick/xsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTopicSUM is collection of large-scale dialogue summarization dataset from XSUM & DialogSUM, consisting of 241,171‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/topicsum.","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"catalanqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalanqa","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for CatalanQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to build extractive-QA and Language Models. It is an aggregation and balancing of 2 previous datasets: VilaQuAD and ViquiQuAD.\nSplits have been balanced by kind of question, and unlike other datasets like SQuAD, it only contains, per record, one question and one answer for each context, although the contexts can repeat multiple times.\nThis dataset was developed by BSC TeMU as part of Projecte AINA, to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalanqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit_qg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/reddit_qg","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"Reddit question generation dataset.","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ampere","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/ampere","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"\n\t\n\t\t\n\t\tDataset Card for AMPERE\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is released together with our NAACL 2019 Paper \"Argument Mining for Understanding Peer Reviews\". If you find our work useful, please cite:\n@inproceedings{hua-etal-2019-argument,\n    title = \"Argument Mining for Understanding Peer Reviews\",\n    author = \"Hua, Xinyu  and\n      Nikolov, Mitko  and\n      Badugu, Nikhil  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/launch/ampere.","first_N":5,"first_N_keywords":["text-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"german_argument_mining","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/german_argument_mining","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated German Legal Decision Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 200 randomly chosen judgments. In these judgments a legal expert annotated the components\nconclusion, definition and subsumption of the German legal writing style Urteilsstil.\n\"Overall 25,075 sentences are annotated. 5% (1,202) of these sentences are marked as conclusion, 21% (5,328) as\ndefinition, 53% (13,322) are marked as subsumption and the remaining 21% (6,481) as other.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/german_argument_mining.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","found"],"keywords_longer_than_N":true},
	{"name":"unpredictable_full","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_full","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"scitail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/scitail","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The SciTail dataset is an entailment dataset created from multiple-choice science exams and\nweb sentences. Each question and the correct answer choice are converted into an assertive\nstatement to form the hypothesis. We use information retrieval to obtain relevant text from\na large text corpus of web sentences, and use these sentences as a premise P. We crowdsource\nthe annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order\nto create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with\nentails label and 16,925 examples with neutral label.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"unpredictable_mmo-champion-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_mmo-champion-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_baseball-fantasysports-yahoo-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_baseball-fantasysports-yahoo-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_phonearena-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_phonearena-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_support-google-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_dividend-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_dividend-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_bulbapedia-bulbagarden-net","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_bulbapedia-bulbagarden-net","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_wkdu-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_wkdu-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_dummies-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_dummies-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_mgoblog-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_mgoblog-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_gamefaqs-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_gamefaqs-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_studystack-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_studystack-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_sittercity-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_sittercity-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_msdn-microsoft-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_msdn-microsoft-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cappex-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cappex-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_en-wikipedia-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_en-wikipedia-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cram-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cram-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_w3-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_w3-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_sporcle-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_sporcle-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_wiki-openmoko-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_wiki-openmoko-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_ensembl-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_ensembl-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"SalienceEvaluation","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yincen/SalienceEvaluation","creator_name":"Qu","creator_url":"https://huggingface.co/Yincen","description":"\n\t\n\t\t\n\t\tDataset Card for Yincen/SalienceEvaluation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yincen/SalienceEvaluation.","first_N":5,"first_N_keywords":["text-classification","multi-input-text-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-spanish","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-polish","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-mandarin","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-italian","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-french","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-dutch","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FLUTE","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ColumbiaNLP/FLUTE","creator_name":"Columbia University NLP Group","creator_url":"https://huggingface.co/ColumbiaNLP","description":"\n\t\n\t\t\n\t\tDataset Card for FigLang2022SharedTask\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nModel in the loop approach for fig lang generation and explainability\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ColumbiaNLP/FLUTE.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","explanation-generation","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"unpredictable_5k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_5k","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD). More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"unpredictable_unique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_unique","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster-noise","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster-noise","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster00","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster00","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster01","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster01","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster10","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster10","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster11","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster11","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster12","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster12","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster13","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster13","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster14","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster14","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster15","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster15","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster16","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster16","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster17","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster17","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster18","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster18","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster19","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster19","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster02","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster02","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster20","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster20","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster21","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster22","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster22","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster23","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster23","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster24","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster24","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster25","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster25","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster26","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster26","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster27","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster27","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster28","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster28","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster29","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster29","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster03","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster03","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster04","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster04","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster05","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster05","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster06","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster06","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster07","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster07","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster08","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster08","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_cluster09","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster09","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"test_pq","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/changxin/test_pq","creator_name":"changxin","creator_url":"https://huggingface.co/changxin","description":"This is a test dataset.","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","original","Chamorro"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-low","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-low","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-medium","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-medium","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_rated-high","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-high","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"aeslc_kw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/postbot/aeslc_kw","creator_name":"postbot","creator_url":"https://huggingface.co/postbot","description":"\n\t\n\t\t\n\t\tabout\n\t\n\n\naeslc dataset but cleaned and keywords extracted to a new column\nan EDA website generated via pandas profiling is on netlify here\n\nDatasetDict({\n    train: Dataset({\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\n        num_rows: 14436\n    })\n    test: Dataset({\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\n        num_rows: 1906\n    })\n    validation: Dataset({\n        features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/postbot/aeslc_kw.","first_N":5,"first_N_keywords":["monolingual","aeslc","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"atypical_animacy","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/atypical_animacy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\n\t\n\t\t\n\t\tDataset Card for atypical_animacy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAtypical animacy detection dataset, based on nineteenth-century sentences in English extracted from an open dataset of nineteenth-century books digitized by the British Library. This dataset contains 598 sentences containing mentions of machines. Each sentence has been annotated according to the animacy and humanness of the machine in the sentence. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification - This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/atypical_animacy.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","intent-classification","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"SQuAD_v2_fi","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilmariky/SQuAD_v2_fi","creator_name":"Ilmari Kylli√§inen","creator_url":"https://huggingface.co/ilmariky","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"squad-v2-fi\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nMachine translated and normalized Finnish version of the SQuAD-v2.0 dataset. Details about the translation and normalization processes can be found here.\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilmariky/SQuAD_v2_fi.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"WikiQA-100-fi","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilmariky/WikiQA-100-fi","creator_name":"Ilmari Kylli√§inen","creator_url":"https://huggingface.co/ilmariky","description":"\n\t\n\t\t\n\t\tDataset Card for \"WikiQA-100-fi\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikiQA-100-fi dataset contains 100 questions related to Finnish Wikipedia articles. The dataset is in the SQuAD format, and there are 10 questions for each category identified by the authors of SQuAD. Unlike SQuAD2.0, WikiQA-100-fi contains only answerable questions. The dataset is tiny compared to actual QA test sets, but it still gives an impression of the models' performance on purely native text data collected by a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilmariky/WikiQA-100-fi.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","Finnish","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"KcBERT_Pre-Training_Corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tKcBERT Pre-Training Corpus (Korean News Comments)\n\t\n\n\n\t\n\t\t\n\t\tKcBERT\n\t\n\nbeomi/kcbert-base\nGithub KcBERT Repo:¬†https://github.com/Beomi/KcBERTKcBERT is Korean Comments BERT pretrained on this Corpus set.(You can use it via Huggingface's Transformers library!)\nThis Kaggle Dataset contains¬†CLEANED¬†dataset preprocessed with the code below.\nimport re\nimport emoji\nfrom soynlp.normalizer import repeat_normalize\n\nemojis = ''.join(emoji.UNICODE_EMOJI.keys())\npattern = re.compile(f'[^ .‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus.","first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"asrs-aviation-reports","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/elihoole/asrs-aviation-reports","creator_name":"Elijah Hoole","creator_url":"https://huggingface.co/elihoole","description":"\n\t\n\t\t\n\t\tDataset Card for ASRS Aviation Incident Reports\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset collects 47,723 aviation incident reports published in the Aviation Safety Reporting System (ASRS) database maintained by NASA. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Dataset can be used to train a model for abstractive and extractive summarization. The model performance is measured by how high the output summary's ROUGE score for a given narrative account of an aviation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elihoole/asrs-aviation-reports.","first_N":5,"first_N_keywords":["summarization","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"moral_stories","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/demelin/moral_stories","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"Moral Stories is a crowd-sourced dataset of structured, branching narratives for the study of grounded, goal-oriented \nsocial reasoning. For detailed information, see https://aclanthology.org/2021.emnlp-main.54.pdf.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","text-classification","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"understanding_fables","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/demelin/understanding_fables","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"This task aims to measure the ability of computational models to understand short narratives, by identifying the most \nappropriate moral for a given fable from a set of five alternatives.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","multiple-choice-qa","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"lotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/colbertv2/lotte","creator_name":"colbertv2","creator_url":"https://huggingface.co/colbertv2","description":"LoTTE Passages Dataset for ColBERTv2","first_N":5,"first_N_keywords":["question-answering","extractive-qa","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"FR_NFR_Spanish_requirements_classification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReSpa: Published version of dataset used for paper 'Towards an automatic requirements classification in a new Spanish dataset'\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nProject: Project's Identifier from which the requirements were obtained.\nRequirement: Description of the software requirement.\nFinal label: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\n\n\t\n\t\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"fin","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tner/fin","creator_name":"TNER","creator_url":"https://huggingface.co/tner","description":"[FIN NER dataset](https://aclanthology.org/U15-1010.pdf)","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"old_bailey_proceedings","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/old_bailey_proceedings","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"[Needs More Information]\n\n\t\n\t\t\n\t\tDataset Card for Old Bailey Proceedings\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNote We are making this dataset available via the HuggingFace hub to open it up to more users and use cases. We have focused primarily on making an initial version of this dataset available, focusing on some potential use cases. If you think there are other configurations this dataset should support, please use the community tab to open an issue. \nThe dataset consists of 2,163 transcriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/old_bailey_proceedings.","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-class-classification","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"clmet_3_1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/clmet_3_1","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"The Corpus of Late Modern English Texts, version 3.1 (CLMET3.1) has been created by Hendrik De Smet, \nSusanne Flach, Hans-J√ºrgen Diller and Jukka Tyrkk√∂, as an offshoot of a bigger project developing a database of text \ndescriptors (Diller, De Smet & Tyrkk√∂ 2011). CLMET3.1 is a principled collection of public domain texts drawn from \nvarious online archiving projects. This dataset can be used for part-of-speech tagging, NER and text classification","first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-label-classification","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mslr2022","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/mslr2022","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"The Multidocument Summarization for Literature Review (MSLR) Shared Task aims to study how medical\nevidence from different clinical studies are summarized in literature reviews. Reviews provide the\nhighest quality of evidence for clinical care, but are expensive to produce manually.\n(Semi-)automation via NLP may facilitate faster evidence synthesis without sacrificing rigor.\nThe MSLR shared task uses two datasets to assess the current state of multidocument summarization\nfor this task, and to encourage the development of modeling contributions, scaffolding tasks, methods\nfor model interpretability, and improved automated evaluation methods in this domain.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ShahNegar","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sadrasabouri/ShahNegar","creator_name":"Sadra Sabouri","creator_url":"https://huggingface.co/sadrasabouri","description":"\n\t\n\t\t\n\t\tShahNegar (A Plotted version of The Shahnameh)\n\t\n\nThis dataset is a plotted version of Ferdowsi's Shahnameh (which is a highly-regarded ancient set of Farsi poems) generated using DALL-E mini (aka craiyon). You can use this dataset using the code below: \nfrom datasets import load_dataset\n\ndataset = load_dataset(\"sadrasabouri/ShahNegar\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset contains more than 30K images with their corresponding text from the Shahnameh. For each Shahnameh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sadrasabouri/ShahNegar.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-captioning","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Piyyut","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tokeron/Piyyut","creator_name":"Michael Toker","creator_url":"https://huggingface.co/tokeron","description":"","first_N":5,"first_N_keywords":["text-classification","monolingual","original","Hebrew","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"NERDE","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","description":"(pt) NERDE √© um dataset para NER a partir de documentos jur√≠dicos da defesa econ√¥mica em portugu√™s do Brasil, foi criado em colabora√ß√£o com o Cade e o laborat√≥rio LATITUDE/UnB.\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hansard_speech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/hansard_speech","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"A dataset containing every speech in the House of Commons from May 1979-July 2020.","first_N":5,"first_N_keywords":["text-classification","text-generation","multi-class-classification","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"reddit-r-bitcoin-data-for-jun-2022","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/reddit-r-bitcoin-data-for-jun-2022","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"Lite version of our Reddit /r/Bitcoin dataset - CSV of all posts & comments to the /r/Bitcoin subreddit over Jun 2022.","first_N":5,"first_N_keywords":["lexyr","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"news-data","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/okite97/news-data","creator_name":"Okite Chimaobi Samuel","creator_url":"https://huggingface.co/okite97","description":"\n\t\n\t\t\n\t\tDataset Card for news-data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe News Dataset is an English-language dataset containing just over 4k unique news articles scrapped from AriseTv- One of the most popular news television in Nigeria. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIt supports news article classification into different categories.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n'''\n{'Title': 'Nigeria: APC Yet to Zone Party Positions Ahead of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/okite97/news-data.","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","other","found"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-korean-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tlaion2B-multi-korean-subset\n\t\n\n\n\t\n\t\t\n\t\tAbout dataset\n\t\n\na subset data of laion/laion2B-multi, including only korean\n\n\t\n\t\t\n\t\tLisence\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instance\n\t\n\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"Bingsu/laion2B-multi-korean-subset\")\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity'],\n        num_rows: 11376263‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"filtered-cuad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alex-apostolo/filtered-cuad","creator_name":"Alex Apostolopoulos","creator_url":"https://huggingface.co/alex-apostolo","description":"\n\t\n\t\t\n\t\tDataset Card for filtered_cuad\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions. This dataset is a filtered version of CUAD. It excludes legal contracts with an Agreement date prior to 2002 and contracts which are not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alex-apostolo/filtered-cuad.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"google-play-review","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/google-play-review","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"clevr-math","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren Lindstr√∂m","creator_url":"https://huggingface.co/dali-does","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \"Remove all large red cylinders. How many objects are left?\". There are also adversarial (e.g. \"Remove all blue cubes. How many cylinders are left?\") and multihop questions (e.g. \"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\").","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"indonews","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/indonews","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"poem-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/poem-tweets","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built for text generation task in context of poem tweets in Bahasa.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"DBPedia_Classes","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","description":"About Dataset\nDBpedia (from \"DB\" for \"database\") is a project aiming to extract structured content from the information created in Wikipedia.\nThis is an extract of the data (after cleaning, kernel included) that provides taxonomic, hierarchical categories (\"classes\") for 342,782 wikipedia articles. There are 3 levels, with 9, 70 and 219 classes respectively.\nA version of this dataset is a popular baseline for NLP/text classification tasks. This version of the dataset is much tougher‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Million_News_Headlines","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","description":"About Dataset\nContext\nThis contains data of news headlines published over a period of nineteen years.\nSourced from the reputable Australian news source ABC (Australian Broadcasting Corporation)\nAgency Site: (http://www.abc.net.au)\nContent\nFormat: CSV ; Single File\npublish_date: Date of publishing for the article in yyyyMMdd format\nheadline_text: Text of the headline in Ascii , English , lowercase\n\nStart Date: 2003-02-19 ; End Date: 2021-12-31\nInspiration\nI look at this news dataset as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines.","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"cerpen-corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/cerpen-corpus","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"proof-pile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","description":"A dataset of high quality mathematical text.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"syntran-fa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/syntran-fa","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"\n\t\n\t\t\n\t\tSynTran-fa\n\t\n\nSyntactic Transformed Version of Farsi QA datasets to make fluent responses from questions and short answers. You can use this dataset by the code below:\nimport datasets\ndata = datasets.load_dataset('SLPL/syntran-fa', split=\"train\")\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nHomepage: Sharif-SLPL\nRepository: SynTran-fa\nPoint of Contact: Sadra Sabouri\nPaper: SynTran-fa: Generating Comprehensive Answers for Farsi QA Pairs via Syntactic Transformation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SLPL/syntran-fa.","first_N":5,"first_N_keywords":["question-answering","text-generation","monolingual","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"ludwig","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/ludwig","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"TODO","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"news-title-gen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/news-title-gen","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built for generating text for news title.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"id-paraphrase-detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/id-paraphrase-detection","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for sequence to sequence classification","first_N":5,"first_N_keywords":["sentence-similarity","found","found","monolingual","extended|msrp"],"keywords_longer_than_N":true},
	{"name":"semeval-absa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/semeval-absa","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for aspect-based sentiment analysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"zeroth-korean","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\n\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Korean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","monolingual","extended|kresnik/zeroth_korean","Korean"],"keywords_longer_than_N":true},
	{"name":"sentinews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/sentinews","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"SentiNews is a Slovenian sentiment classification dataset, consisting of news articles manually annotated with their \nsentiment by between 2 and 6 annotators. The news articles contain political, business, economic and financial content \nfrom the Slovenian news portals 24ur, Dnevnik, Finance, Rtvslo, and ≈Ωurnal24. The texts were annotated using the \nfive-level Lickert scale (1 ‚Äì very negative, 2 ‚Äì negative, 3 ‚Äì neutral, 4 ‚Äì positive, and 5 ‚Äì very positive) on three \nlevels of granularity, i.e. on the document, paragraph, and sentence level. The final sentiment is determined using \nthe following criterion: negative (if average of scores ‚â§ 2.4); neutral (if average of scores is between 2.4 and 3.6); \npositive (average of annotated scores ‚â• 3.6).","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"broad_twitter_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GateNLP/broad_twitter_corpus","creator_name":"GATE Team, University of Sheffield","creator_url":"https://huggingface.co/GateNLP","description":"This is the Broad Twitter corpus, a dataset of tweets collected over stratified times, places and social uses. \nThe goal is to represent a broad range of activities, giving a dataset more representative of the language used \nin this hardest of social media formats to process. Further, the BTC is annotated for named entities.\n\nFor more details see [https://aclanthology.org/C16-1111/](https://aclanthology.org/C16-1111/)","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"indo-movie-subtitle","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/indo-movie-subtitle","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for analyzing text on movie subtitle","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bold","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmazonScience/bold","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","description":"\n\t\n\t\t\n\t\tDataset Card for Bias in Open-ended Language Generation Dataset (BOLD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBias in Open-ended Language Generation Dataset (BOLD) is a dataset to evaluate fairness in open-ended language generation in English language. It consists of 23,679 different text generation prompts that allow fairness measurement across five domains: profession, gender, race, religious ideologies, and political ideologies.\n Some examples of prompts in BOLD are as follows:\n\nMany‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/bold.","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"wildfire_tweets","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubrix/wildfire_tweets","creator_name":"rubrix","creator_url":"https://huggingface.co/rubrix","description":"rubrix/wildfire_tweets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-summarisation-preferences","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tHuman feedback data\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nSee https://github.com/openai/summarize-from-feedback for original details of the dataset.\nHere the data is formatted to enable huggingface transformers sequence classification models to be trained as reward functions.\n","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"scientific-exaggeration-detection","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for Scientific Exaggeration Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPublic trust in science depends on honest and factual communication of scientific papers. However, recent studies have demonstrated a tendency of news media to misrepresent scientific papers by exaggerating their findings. Given this, we present a formalization of and study into the problem of exaggeration detection in science communication. While there are an abundance of scientific papers and popular‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\n","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"COCO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Luka-Wang/COCO","creator_name":"Wang Yanghao","creator_url":"https://huggingface.co/Luka-Wang","description":"\n\t\n\t\t\n\t\tDataset Card for [COCO]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Luka-Wang/COCO.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered-queries","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\nThis is the version of the dataset with only filtering on the queries, and hence there is more data than in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"naab","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/naab","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word ŸÜÿßÿ® which means pure and high-grade.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"EstCOPA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tartuNLP/EstCOPA","creator_name":"TartuNLP","creator_url":"https://huggingface.co/tartuNLP","description":"\n\t\n\t\t\n\t\tDataset Card for EstCOPA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEstCOPA is an extended version of XCOPA that was created with a goal to further investigate Estonian language understanding of large language models. EstCOPA provides two new versions of train, eval and test datasets in Estonian: firstly, a machine translated (En->Et) version of original English COPA (Roemmele et al., 2011)  and secondly, a manually post-edited version of the same machine translated data. \n\n\t\n\t\t\n\t\n\t\n\t\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tartuNLP/EstCOPA.","first_N":5,"first_N_keywords":["question-answering","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"codequeries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thepurpleowl/codequeries","creator_name":"Surya Prakash Sahu","creator_url":"https://huggingface.co/thepurpleowl","description":"CodeQueries Ideal setup.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"eurlex","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonathanli/eurlex","creator_name":"Jonathan Li","creator_url":"https://huggingface.co/jonathanli","description":"EURLEX57K contains 57k legislative documents in English from EUR-Lex portal, annotated with EUROVOC concepts.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wiki_toxic","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"coyo-700m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/coyo-700m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\n\t\n\t\t\n\t\tDataset Card for COYO-700M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models. Our dataset follows a similar strategy to previous vision-and-language datasets, collecting many informative pairs of alt-text and its associated image in HTML documents. We expect COYO to be used to train popular large-scale foundation models \ncomplementary to other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-700m.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Gameplay_Images","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/Gameplay_Images","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tGameplay Images\n\t\n\nA dataset from kaggle.\nThis is a dataset of 10 very famous video games in the world.\nThese include\n\nAmong Us\nApex Legends\nFortnite\nForza Horizon\nFree Fire\nGenshin Impact\nGod of War\nMinecraft\nRoblox\nTerraria\n\nThere are 1000 images per class and all are sized 640 x 360. They are in the .png format.\nThis Dataset was made by saving frames every few seconds from famous gameplay videos on Youtube.\n‚Äª This dataset was uploaded in January 2022. Game content updated after that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/Gameplay_Images.","first_N":5,"first_N_keywords":["image-classification","monolingual","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"clip-bert-data","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/clip-bert-data","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"\n\t\n\t\t\n\t\tCLIP-BERT training data\n\t\n\nThis data was used to train the CLIP-BERT model first described in this paper. \nThe dataset is based on text and images from MS COCO, SBU Captions, Visual Genome QA and Conceptual Captions.\nThe image features have been extracted using the CLIP model openai/clip-vit-base-patch32 available on Huggingface.\n","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_max.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_mean.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_oracle.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"unpredictable_full","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_full","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_5k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_5k","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_support-google-com","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"unpredictable_unique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_unique","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","table-question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"The LXMERT text train data used to train BERT-base baselines and adapt vision-and-language models to text-only tasks in the paper \"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\".\nThe data has been created from the data made available by the LXMERT repo.\n","first_N":5,"first_N_keywords":["monolingual","English","mit","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"The LXMERT text finetune data used to train visual features for the adaption of vision-and-language models to text-only tasks in the paper \"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\".\nThe data has been created from the data made available by the LXMERT repo.\n","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"blogspot_raw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mschi/blogspot_raw","creator_name":"Martin Schirmer","creator_url":"https://huggingface.co/mschi","description":"\n\t\n\t\t\n\t\tDataset Card for blogspot raw dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of raw blogposts from blogspot mostly in the English language. It was obtained by scraping corpora of webarchive and commoncrawl.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset may be used for training language models or serve other research interests.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMostly English language, but some outliers may occur.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDistribution\nThe distribution‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mschi/blogspot_raw.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","time-series-forecasting","other"],"keywords_longer_than_N":true},
	{"name":"glue-ci","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evaluate/glue-ci","creator_name":"evaluate","creator_url":"https://huggingface.co/evaluate","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"twitter-financial-news-sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their sentiment.\n\nThe dataset holds 11,932 documents annotated with 3 labels:\n\nsentiments = {\n    \"LABEL_0\": \"Bearish\", \n    \"LABEL_1\": \"Bullish\", \n    \"LABEL_2\": \"Neutral\"\n}  \n\nThe data was collected using the Twitter API. The current dataset supports the multi-class classification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"VaccinChatNL","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/VaccinChatNL","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"\n\t\n\t\t\n\t\tDataset Card for VaccinChatNL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPoint of Contact:  Jeska Buhmann\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVaccinChatNL is a Flemish Dutch FAQ dataset on the topic of COVID-19 vaccinations in Flanders. It consists of 12,833 user questions divided over 181 answer labels, thus providing large groups of semantically equivalent paraphrases (a many-to-one mapping of user questions to answer labels). VaccinChatNL is the first Dutch many-to-one FAQ dataset of this size.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/VaccinChatNL.","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"go_emotions-es-mt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrm8488/go_emotions-es-mt","creator_name":"Manuel Romero","creator_url":"https://huggingface.co/mrm8488","description":"\n\t\n\t\t\n\t\tGoEmotions Spanish\n\t\n\n\n\t\n\t\t\n\t\tA Spanish translation (using EasyNMT) of the GoEmotions dataset.\n\t\n\n\n\t\n\t\t\n\t\tFor more information check the official Model Card\n\t\n\n","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"ord-uniq-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/ord-uniq-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\n\t\n\t\t\n\t\tdataset description\n\t\n\nWe downloaded open-reaction-database(ORD) dataset from here. As a preprocess, we removed overlapping data and canonicalized them using RDKit.\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\nfrom rdkit import Chem\ndef canonicalize(mol):\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\n    return mol \n\nWe randomly split the preprocessed data into train, validation and test. The ratio is 8:1:1.\n","first_N":5,"first_N_keywords":["translation","monolingual","original","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"pubchem-10m-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/pubchem-10m-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\n\t\n\t\t\n\t\tdataset description\n\t\n\nWe downloaded PubChem-10m dataset from here and canonicalized it.\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\nfrom rdkit import Chem\ndef canonicalize(mol):\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\n    return mol \n\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\n","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ZINC-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/ZINC-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\n\t\n\t\t\n\t\tdataset description\n\t\n\nWe downloaded ZINC dataset from here and canonicalized it.\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\nfrom rdkit import Chem\ndef canonicalize(mol):\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\n    return mol \n\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\n","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"biosses","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/biosses","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"BIOSSES computes similarity of biomedical sentences by utilizing WordNet as the\ngeneral domain ontology and UMLS as the biomedical domain specific ontology.\nThe original paper outlines the approaches with respect to using annotator\nscore as golden standard. Source view will return all annotator score\nindividually whereas the Bigbio view will return the mean of the annotator\nscore.","first_N":5,"first_N_keywords":["monolingual","English","gpl-3.0","< 1K","Tabular"],"keywords_longer_than_N":true},
	{"name":"twitter-financial-news-topic","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their topic.\n\nThe dataset holds 21,107 documents annotated with 20 labels:\n\ntopics = {\n    \"LABEL_0\": \"Analyst Update\",\n    \"LABEL_1\": \"Fed | Central Banks\",\n    \"LABEL_2\": \"Company | Product News\",\n    \"LABEL_3\": \"Treasuries | Corporate Debt\",\n    \"LABEL_4\": \"Dividend\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"laion-aesthetics-12m-umap","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap","creator_name":"David McClure","creator_url":"https://huggingface.co/dclure","description":"\n\t\n\t\t\n\t\tLAION-Aesthetics :: CLIP ‚Üí UMAP\n\t\n\nThis dataset is a CLIP (text) ‚Üí UMAP embedding of the LAION-Aesthetics dataset - specifically the improved_aesthetics_6plus version, which filters the full dataset to images with scores of > 6 under the \"aesthetic\" filtering model.\nThanks LAION for this amazing corpus!\n\nThe dataset here includes coordinates for 3x separate UMAP fits using different values for the n_neighbors parameter - 10, 30, and 60 - which are broken out as separate columns with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap.","first_N":5,"first_N_keywords":["found","monolingual","English","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"recycling-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/viola77data/recycling-dataset","creator_name":"viola meli","creator_url":"https://huggingface.co/viola77data","description":"\n\t\n\t\t\n\t\tDataset Card for recycling-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a recycling dataset that can be used for image classification. It has 11 categories:\n\naluminium\nbatteries\ncardboard\ndisposable plates\nglass\nhard plastic\npaper\npaper towel\npolystyrene\nsoft plastics\ntakeaway cups\n\nIt was scrapped from DuckDuckGo using this tool: https://pypi.org/project/jmd-imagescraper/\n","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cuad_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/cuad_qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"\n\t\n\t\t\n\t\tDataset Card for CUAD\n\t\n\nThis is a modified version of original CUAD which trims the question to its label form.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions.\nCUAD is curated and maintained by The Atticus Project, Inc.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/cuad_qa.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_max.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_mean.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_oracle.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"salom-ladino-articles","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/collectivat/salom-ladino-articles","creator_name":"Col¬∑lectivaT","creator_url":"https://huggingface.co/collectivat","description":"\n\t\n\t\t\n\t\t≈ûalom Ladino articles text corpus\n\t\n\nText corpus compiled from 397 articles from the Judeo-Espanyol section of ≈ûalom newspaper. Original sentences and articles belong to ≈ûalom. \nSize: 176,843 words\nOffical link\nPaper on ArXiv\nCitation:\nPreparing an endangered language for the digital age: The Case of Judeo-Spanish. Alp √ñktem, Rodolfo Zevallos, Yasmin Moslem, G√ºne≈ü √ñzt√ºrk, Karen ≈ûarhon. \nWorkshop on Resources and Technologies for Indigenous, Endangered and Lesser-resourced Languages in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/salom-ladino-articles.","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"conala","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"splittedspanish3bwc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vialibre/splittedspanish3bwc","creator_name":"Via Libre","creator_url":"https://huggingface.co/vialibre","description":"\n\t\n\t\t\n\t\tDataset Card for Unannotated Spanish 3 Billion Words Corpora\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nNumber of lines: 300904000 (300M)\nNumber of tokens: 2996016962 (3B)\nNumber of chars: 18431160978 (18.4B)\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nSpanish\n\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\nAvailable to download here: Zenodo\n\n\n\t\n\t\t\n\t\tData Subset\n\t\n\n\nSpanish Wikis: Wich include Wikipedia, Wikinews, Wikiquotes and more. These were first processed with wikiextractor (https://github.com/josecannete/wikiextractorforBERT) using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vialibre/splittedspanish3bwc.","first_N":5,"first_N_keywords":["monolingual","Spanish","mit","100M - 1B","Text"],"keywords_longer_than_N":true},
	{"name":"kelly","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codesue/kelly","creator_name":"Suzen Fylke","creator_url":"https://huggingface.co/codesue","description":"The Swedish Kelly list is a freely available frequency-based vocabulary list that comprises general-purpose language of modern Swedish. The list was generated from a large web-acquired corpus (SweWaC) of 114 million words dating from the 2010s. It is adapted to the needs of language learners and contains 8,425 most frequent lemmas that cover 80% of SweWaC.\\","first_N":5,"first_N_keywords":["text-classification","text-scoring","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"asqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/din0s/asqa","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","description":"\n\t\n\t\t\n\t\tDataset Card for ASQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASQA is the first long-form question answering dataset that focuses on ambiguous factoid questions. Different from previous long-form answers datasets, each question is annotated with both long-form answers and extractive question-answer pairs, which should be answerable by the generated passage. A generated long-form answer will be evaluated using both ROUGE and QA accuracy. In the paper, we show that these evaluation metrics are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/din0s/asqa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"fashionpedia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\nFrom the paper:\n\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia.","first_N":5,"first_N_keywords":["object-detection","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sd-character-level-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMBO/sd-character-level-ner","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","description":"    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","named-entity-recognition","parsing","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fashionpedia_4_categories","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia_4_categories\n\t\n\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\n\nIt contains only 4 categories:\nClothing\nShoes\nBags\nAccessories\n\n\nNew splits were created:\nTrain: 90% of the images\nVal: 5%\nTest 5%\n\n\n\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories.","first_N":5,"first_N_keywords":["object-detection","monolingual","fashionpedia","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dialogs_from_jokes","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artemsnegirev/dialogs_from_jokes","creator_name":"Artem Snegirev","creator_url":"https://huggingface.co/artemsnegirev","description":"Converted to json version of dataset from Koziev/NLP_Datasets\n","first_N":5,"first_N_keywords":["dialogue-generation","monolingual","Russian","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-chinese-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\n\t\n\t\t\n\t\tlaion2B-multi-chinese-subset\n\t\n\n\nGithub: Fengshenbang-LM\nDocs: Fengshenbang-Docs\n\n\n\t\n\t\t\n\t\tÁÆÄ‰ªã Brief Introduction\n\t\n\nÂèñËá™Laion2BÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÔºå‰∏ÄÂÖ±143M‰∏™ÂõæÊñáÂØπ„ÄÇ\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\n\t\n\nÂ§ßÁ∫¶‰∏ÄÂÖ±143M‰∏™‰∏≠ÊñáÂõæÊñáÂØπ„ÄÇÂ§ßÁ∫¶Âç†Áî®19GBÁ©∫Èó¥Ôºà‰ªÖ‰ªÖÊòØurlÁ≠âÊñáÊú¨‰ø°ÊÅØÔºå‰∏çÂåÖÂê´ÂõæÁâáÔºâ„ÄÇ\n\nHomepage: laion-5b\nHuggingface: laion/laion2B-multi\n\n\n\t\n\t\t\n\t\t‰∏ãËΩΩ Download\n\t\n\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\nfor i in {00000..00012}; do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"UD_Catalan-AnCora","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tUD_Catalan-AnCora\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is composed of the annotations from the AnCora corpus, projected on the Universal Dependencies treebank. We use the POS annotations of this corpus as part of the Catalan Language Understanding Benchmark (CLUB).\nThis work is licensed under a CC Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nPOS tagging\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe dataset is in Catalan (ca-ES)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora.","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tathagata","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/radm/tathagata","creator_name":"r4dm","creator_url":"https://huggingface.co/radm","description":"\n\t\n\t\t\n\t\tDataset Card for tathagata\n\t\n\n\n\t\n\t\t\n\t\tI-Dataset Summary\n\t\n\ntathagata.txt is a dataset based on summaries of major Buddhist, Hindu and Advaita texts such as:\n\nDiamond Sutra\nLankavatara Sutra\nSri Nisargadatta Maharaj quotes\nQuotes from the Bhagavad Gita\n\nThis dataset was used to train this model https://huggingface.co/radm/rugpt3medium-tathagata\n\n\t\n\t\t\n\t\n\t\n\t\tII-Languages\n\t\n\nThe texts in the dataset are in Russian (ru).\n","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"newyorker_caption_contest","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jmhessel/newyorker_caption_contest","creator_name":"Jack Hessel","creator_url":"https://huggingface.co/jmhessel","description":"\n\t\n\t\t\n\t\tDataset Card for New Yorker Caption Contest Benchmarks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee capcon.dev for more!\nData from:\nDo Androids Laugh at Electric Sheep? Humor \"Understanding\" Benchmarks from The New Yorker Caption Contest\n@inproceedings{hessel2023androids,\n  title={Do Androids Laugh at Electric Sheep? {Humor} ``Understanding''\n         Benchmarks from {The New Yorker Caption Contest}},\n  author={Hessel, Jack and Marasovi{\\'c}, Ana and Hwang, Jena D. and Lee, Lillian\n          and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jmhessel/newyorker_caption_contest.","first_N":5,"first_N_keywords":["image-to-text","multiple-choice","text-classification","text-generation","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"msmarco-nlgen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/din0s/msmarco-nlgen","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","description":"\n\t\n\t\t\n\t\tDataset Card for MSMARCO - Natural Language Generation Task\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe original focus of MSMARCO was to provide a corpus for training and testing systems which given a real domain user query systems would then provide the most likley candidate answer and do so in language which was natural and conversational. All questions have been generated from real anonymized Bing user queries which grounds the dataset in a real world problem and can provide researchers real‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/din0s/msmarco-nlgen.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Lipogram-e","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\n\t\n\t\t\n\t\tDataset Card for Lipogram-e\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\n\nThis is a dataset of 3 English books which do not contain the letter \"e\" in them. This dataset includes all of \"Gadsby\" by Ernest Vincent Wright, all of \"A Void\" by Georges Perec, and almost all of \"Eunoia\" by Christian Bok (except for the single chapter that uses the letter \"e\" in it) This dataset is contributed as part of a paper titled \"Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"one_syllable","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/one_syllable","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\n\t\n\t\t\n\t\tDataset Card for Lipogram-e\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThis is a dataset of English books which only write using one syllable at a time. At this time, the dataset only contains Robinson Crusoe ‚Äî in Words of One Syllable by Lucy Aikin and Daniel Defoe\nThis dataset is contributed as part of a paper titled \"Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text Generation Studio\" to appear at COLING 2022. This dataset does not appear in the paper itself‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/one_syllable.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"balanced-copa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pkavumba/balanced-copa","creator_name":"Pride Kavumba","creator_url":"https://huggingface.co/pkavumba","description":"\n\t\n\t\t\n\t\tDataset Card for \"Balanced COPA\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBala-COPA: An English language Dataset for Training Robust Commonsense Causal Reasoning Models\nThe Balanced Choice of Plausible Alternatives dataset is a benchmark for training machine learning models that are robust to superficial cues/spurious correlations. The dataset extends the COPA dataset(Roemmele et al. 2011) with mirrored instances that mitigate against token-level superficial cues in the original COPA answers. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pkavumba/balanced-copa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NeQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/NeQA","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\n\t\n\t\t\n\t\tNeQA: Can Large Language Models Understand Negation in Multi-choice Questions? (Zhengping Zhou and Yuhui Zhang)\n\t\n\n\n\t\n\t\t\n\t\tGeneral description\n\t\n\nThis task takes an existing multiple-choice dataset and negates a part of each question to see if language models are sensitive to negation. The authors find that smaller language models display approximately random performance whereas the performance of larger models become significantly worse than random. \nLanguage models failing to follow‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/NeQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"quote-repetition","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/quote-repetition","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\n\t\n\t\t\n\t\tquote-repetition (Joe Cavanagh, Andrew Gritsevskiy, and Derik Kauffman of Cavendish Labs)\n\t\n\n\n\t\n\t\t\n\t\tGeneral description\n\t\n\nIn this task, the authors ask language models to repeat back sentences given in the prompt, with few-shot examples to help it recognize the task. Each prompt contains a famous quote with a modified ending to mislead the model into completing the sequence with the famous ending rather than with the ending given in the prompt. The authors find that smaller models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/quote-repetition.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"humaneval_infilling","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"meddocan","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GuiGel/meddocan","creator_name":"Guillaume Gelabert","creator_url":"https://huggingface.co/GuiGel","description":"\n\t\n\t\t\n\t\tDataset Card for \"meddocan\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA personal upload of the SPACC_MEDDOCAN corpus. The tokenization is made with the help of a custom spaCy pipeline.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nName Entity Recognition\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all splits.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\n\t\n\t\t\nname\ntrain\nvalidation\ntest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GuiGel/meddocan.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\nis obtained from Kaggle:\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\nData has been scraped from the publicly available website\nhttps://www.rottentomatoes.com as of 2020-10-31.\nThe clean up process drops anything without both a review and a rating, as well\nas standardising the ratings onto several integer, ordinal scales.\nRequires the kaggle library to be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews.","first_N":5,"first_N_keywords":["text-classification","text-scoring","sentiment-scoring","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"inferes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","description":"\n\t\n\t\t\n\t\tDataset Card for InferES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNatural Language Inference dataset for European Spanish\nPaper accepted and (to be) presented at COLING 2022\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\n\n\t\n\t\t\n\t\tData Instances\n\t\n\ntrain size = 6444 \ntest size = 1612\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"redefine-math","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/redefine-math","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\n\t\n\t\t\n\t\tredefine-math (Xudong Shen)\n\t\n\n\n\t\n\t\t\n\t\tGeneral description\n\t\n\nIn this task, the author tests whether language models are able to work with common symbols when they are redefined to mean something else. The author finds that larger models are more likely to pick the answer corresponding to the original definition rather than the redefined meaning, relative to smaller models. \nThis task demonstrates that it is difficult for language models to work with new information given at inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/redefine-math.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"hindsight-neglect-10shot","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/hindsight-neglect-10shot","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\n\t\n\t\t\n\t\tinverse-scaling/hindsight-neglect-10shot (‚ÄòThe Floating Droid‚Äô)\n\t\n\n\n\t\n\t\t\n\t\tGeneral description\n\t\n\nThis task tests whether language models are able to assess whether a bet was worth taking based on its expected value. The author provides few shot examples in which the model predicts whether a bet is worthwhile by correctly answering yes or no when the expected value of the bet is positive (where the model should respond that ‚Äòyes‚Äô, taking the bet is the right decision) or negative (‚Äòno‚Äô‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/hindsight-neglect-10shot.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","zero-shot-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"brwac_tiny","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\n\t\n\t\t\n\t\tDataset Card for BrWac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial applications.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny.","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"skateboarding-tricks","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vogloblinsky/skateboarding-tricks","creator_name":"Ogloblinsky","creator_url":"https://huggingface.co/vogloblinsky","description":"\n\t\n\t\t\n\t\tDataset Card for Skateboarding tricks\n\t\n\nDataset used to train Text to skateboarding image model.\nFor each row the dataset contains image and text keys.\nimage is a varying size PIL jpeg, and text is the accompanying text caption.\n","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_mean.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_max.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_oracle.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_max.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_mean.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_oracle.","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ALotNLI","keyword":"monolingual","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thamognya/ALotNLI","creator_name":"Thamognya Kodi","creator_url":"https://huggingface.co/Thamognya","description":"\n\t\n\t\t\n\t\n\t\n\t\tRepo\n\t\n\nGithub Repo: thamognya/TBertNLI specifically in the src/data directory.\n\n\t\n\t\t\n\t\n\t\n\t\tSample\n\t\n\n0  this church choir sings to the masses as they ...      the church is filled with song      0\n1  this church choir sings to the masses as they ...  a choir singing at a baseball game      2\n2  a woman with a green headscarf blue shirt and ...                  the woman is young      1\n3  a woman with a green headscarf blue shirt and ...             the woman is very happy      0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thamognya/ALotNLI.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"nan-nli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joey234/nan-nli","creator_name":"Thinh Truong","creator_url":"https://huggingface.co/joey234","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference\nText Classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\npremise:\nhypothesis:\nlabel:\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nEvaluation: 258 samples\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\nExtracting samples corresponding to different linguistics constructions of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joey234/nan-nli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"channel-metadata","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/channel-metadata","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"Dataset containing video metadata from a few tech channels, i.e.\n\nJames Briggs\nYannic Kilcher\nsentdex\nDaniel Bourke\nAI Coffee Break with Letitia\nAlex Ziskind\n\n","first_N":5,"first_N_keywords":["other","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cloth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AndyChiang/cloth","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","description":"\n\t\n\t\t\n\t\tcloth\n\t\n\nCLOTH is a dataset which is a collection of nearly 100,000 cloze questions from middle school and high school English exams. The detail of CLOTH dataset is shown below.\n\n\t\n\t\t\nNumber of questions\nTrain\nValid\nTest\n\n\n\t\t\nMiddle school\n22056\n3273\n3198\n\n\nHigh school\n54794\n7794\n8318\n\n\nTotal\n76850\n11067\n11516\n\n\n\t\n\nSource: https://www.cs.cmu.edu/~glai1/data/cloth/\n","first_N":5,"first_N_keywords":["fill-mask","monolingual","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dgen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AndyChiang/dgen","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","description":"\n\t\n\t\t\n\t\tdgen\n\t\n\nDGen is a cloze questions dataset which covers multiple domains including science, vocabulary, common sense and trivia. It is compiled from a wide variety of datasets including SciQ, MCQL, AI2 Science Questions, etc. The detail of DGen dataset is shown below.\n\n\t\n\t\t\nDGen dataset\nTrain\nValid\nTest\nTotal\n\n\n\t\t\nNumber of questions\n2321\n300\n259\n2880\n\n\n\t\n\nSource: https://github.com/DRSY/DGen\n","first_N":5,"first_N_keywords":["fill-mask","monolingual","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"laion2b_multi_korean_subset_with_image","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tlaion2b_multi_korean_subset_with_image\n\t\n\nimg2datasetÏùÑ ÌÜµÌï¥ Îã§Ïö¥Î°úÎìúÏóê ÏÑ±Í≥µÌïú Bingsu/laion2B-multi-korean-subset Ïù¥ÎØ∏ÏßÄÎ•º Ï†ïÎ¶¨Ìïú Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\nÏù¥ÎØ∏ÏßÄÎäî 9,800,137Ïû•ÏûÖÎãàÎã§.\nÏù¥ÎØ∏ÏßÄÎäî ÏßßÏùÄ Ï™Ω Í∏∏Ïù¥Í∞Ä 256Ïù¥ ÎêòÎèÑÎ°ù Î¶¨ÏÇ¨Ïù¥Ï¶à ÎêòÏóàÏúºÎ©∞, ÌíàÏßà 100Ïù∏ webpÌååÏùºÎ°ú Îã§Ïö¥Î°úÎìú ÎêòÏóàÏäµÎãàÎã§.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\t1. datasets\n\t\n\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"Bingsu/laion2b_multi_korean_subset_with_image\", streaming=True, split=\"train\")\n\n>>> dataset.features\n{'image': Image(decode=True, id=None),\n 'text': Value(dtype='string', id=None)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","extended|laion/laion2B-multi"],"keywords_longer_than_N":true},
	{"name":"ted_descriptions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gigant/ted_descriptions","creator_name":"Th√©o Gigant","creator_url":"https://huggingface.co/gigant","description":"\n\t\n\t\t\n\t\tDataset Card for TED descriptions\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"german-ler","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/elenanereiss/german-ler","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","description":"\n\t\n\t\t\n\t\tDataset Card for \"German LER\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of Legal Documents from German federal court decisions for Named Entity Recognition. The dataset is human-annotated with 19 fine-grained entity classes. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities. NER tags use the BIO tagging scheme. \nThe dataset includes two different versions of annotations, one with a set of 19 fine-grained semantic classes (ner_tags) and another one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/german-ler.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"slo_thesaurus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/slo_thesaurus","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"This is an automatically created Slovene thesaurus from Slovene data available in a comprehensive \nEnglish‚ÄìSlovenian dictionary, a monolingual dictionary, and a corpus. A network analysis on the bilingual dictionary \nword co-occurrence graph was used, together with additional information from the distributional thesaurus data \navailable as part of the Sketch Engine tool and extracted from the 1.2 billion word Gigafida corpus and the \nmonolingual dictionary.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","Slovenian"],"keywords_longer_than_N":true},
	{"name":"FB15k-237","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KGraph/FB15k-237","creator_name":"YHLong","creator_url":"https://huggingface.co/KGraph","description":"\n\t\n\t\t\n\t\tDataset Card for FB15k-237\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB15k-237 is a link prediction dataset created from FB15k. While FB15k consists of 1,345 relations, 14,951 entities, and 592,213 triples, many triples are inverses that cause leakage from the training to testing and validation splits. FB15k-237 was created by Toutanova and Chen (2015) to ensure that the testing and evaluation datasets do not have inverse relation test leakage. In summary, FB15k-237 dataset contains 310,079‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KGraph/FB15k-237.","first_N":5,"first_N_keywords":["other","found","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"slownet","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/slownet","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"sloWNet is the Slovene WordNet developed in the expand approach: it contains the complete Princeton WordNet 3.0 and \nover 70 000 Slovene literals. These literals have been added automatically using different types of existing resources, \nsuch as bilingual dictionaries, parallel corpora and Wikipedia. 33 000 literals have been subsequently hand-validated.","first_N":5,"first_N_keywords":["other","machine-generated","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"crosswoz","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/crosswoz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for CrossWOZ\n\t\n\n\nRepository: https://github.com/thu-coai/CrossWOZ\nPaper: https://aclanthology.org/2020.tacl-1.19/\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('crosswoz')\nontology = load_ontology('crosswoz')\ndatabase = load_database('crosswoz')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/crosswoz.","first_N":5,"first_N_keywords":["monolingual","Chinese","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"spiced","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/spiced","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for SPICED\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Scientific Paraphrase and Information ChangE Dataset (SPICED) is a dataset of paired scientific findings from scientific papers, news media, and Twitter. The types of pairs are between <paper, news> and <paper, tweet>. Each pair is labeled for the degree of information similarity in the findings described by each sentence, on a scale from 1-5. This is called the Information Matching Score (IMS). The data was curated from S2ORC‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spiced.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"kqa_pro","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/drt/kqa_pro","creator_name":"Yuanchun","creator_url":"https://huggingface.co/drt","description":"A large-scale, diverse, challenging dataset of complex question answering over knowledge base.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"Gitcoin-ODS-Hackhaton-GR15","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15","creator_name":"Poupou web3","creator_url":"https://huggingface.co/Poupou","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for [Gitcoin ODS Hackathon GR15]\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis data set was created in the context of the first Gitcoin Open Data Science Hackathon.\nIt contains all the transactions on the Ethereum and Polygon chains of the wallet that contributed to the Grant 15 of Gitcoin grants program.\nIt was created in order to find patterns in the transactions of potential Sybil attackers by exploring their on-chain activity.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15.","first_N":5,"first_N_keywords":["feature-extraction","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"WSDMCup2023","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/WSDMCup2023","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"\n\t\n\t\t\n\t\tDataset Card for WSDMCup2023\n\t\n\n\n\t\n\t\t\nQuestion\nImage and Answer\n\n\n\t\t\nWhat do you use to hit the ball?\n\n\n\nWhat do people use for cutting?\n\n\n\nWhat do we use to support the immune system and get vitamin C?\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WSDMCup2023 Dataset consists of images associated with textual questions.\nOne entry (instance) in our dataset is a question-image pair labeled with the ground truth coordinates of a bounding box containing\nthe visual answer to the given question. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/toloka/WSDMCup2023.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v0","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"copa-sse","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anab/copa-sse","creator_name":"Ana Brassard","creator_url":"https://huggingface.co/anab","description":"\n\t\n\t\t\n\t\tDataset Card for COPA-SSE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nCOPA-SSE contains crowdsourced explanations for the Balanced COPA dataset, a variant of the Choice of Plausible Alternatives (COPA) benchmark. The explanations are formatted as a set of triple-like common sense statements with ConceptNet relations but freely written concepts.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nCan be used to train a model for explain+predict or predict+explain settings. Suited for both text-based and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anab/copa-sse.","first_N":5,"first_N_keywords":["multiple-choice","explanation-generation","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"P3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/P3","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"This is a repreprocessed version of P3 with any updates that have been made to the P3 datasets since the release of the original P3. It is used for the finetuning of bloomz-p3 & mt0-xxl-p3. The script is available here.\n","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"naacl2022","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/havens2/naacl2022","creator_name":"Haotian Teng","creator_url":"https://huggingface.co/havens2","description":"NACL22 is a dataset labelled for Science Entity Recognition task, which is a subtask of NER task. \nThe text is from 2022 conference papers collected from ACL anthology. \nThe dataset is collected by Haotian Teng and Xiaoyue Cui. \nAnnotation standard can be found here https://github.com/neubig/nlp-from-scratch-assignment-2022/blob/main/annotation_standard.md","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"afrolm_active_learning_dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset","creator_name":"Bonaventure Dossou","creator_url":"https://huggingface.co/bonadossou","description":"\n\t\n\t\t\n\t\tAfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages\n\t\n\n\nGitHub Repository of the Paper\n\nThis repository contains the dataset for our paper AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages which will appear at the third Simple and Efficient Natural Language Processing, at EMNLP 2022.\n\n\t\n\t\t\n\t\n\t\n\t\tOur self-active learning framework\n\t\n\n\n\n\t\n\t\n\t\n\t\tLanguages Covered\n\t\n\nAfroLM has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset.","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"glue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/glue","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"standard_humaneval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/standard_humaneval","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/standard_humaneval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","code","mit"],"keywords_longer_than_N":true},
	{"name":"qg_annotation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_annotation","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Human-annotated question generated by models.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","1K - 10K","Tabular"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n200000/200000/100000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n400000/50000/50000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"probability_words_nli","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"docee-event-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fkdosilovic/docee-event-classification","creator_name":"Filip Karlo Do≈°iloviƒá","creator_url":"https://huggingface.co/fkdosilovic","description":"\n\t\n\t\t\n\t\tDataset Card for DocEE Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDocEE dataset is an English-language dataset containing more than 27k news and Wikipedia articles. Dataset is primarily annotated and collected for large-scale document-level event extraction.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntitle: TODO\ntext: TODO\nevent_type: TODO\ndate: TODO\nmetadata: TODO\n\nNote: this repo contains only event detection portion of the dataset.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset has 2 splits: train and test. Train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fkdosilovic/docee-event-classification.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"qa-pt","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tDataset Card for QA-Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese preprocessed split from MQA dataset.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is Portuguese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"Biosses-BLUE","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qanastek/Biosses-BLUE","creator_name":"yanis labrak","creator_url":"https://huggingface.co/qanastek","description":"BIOSSES is a benchmark dataset for biomedical sentence similarity estimation.\nThe dataset comprises 100 sentence pairs, in which each sentence was selected\nfrom the TAC (Text Analysis Conference) Biomedical Summarization Track Training\nDataset containing articles from the biomedical domain. The sentence pairs in\nBIOSSES were selected from citing sentences, i.e. sentences that have a citation\nto a reference article.\n\nThe sentence pairs were evaluated by five different human experts that judged\ntheir similarity and gave scores ranging from 0 (no relation) to 4 (equivalent).\nIn the original paper the mean of the scores assigned by the five human annotators\nwas taken as the gold standard. The Pearson correlation between the gold standard\nscores and the scores estimated by the models was used as the evaluation metric.\nThe strength of correlation can be assessed by the general guideline proposed by\nEvans (1996) as follows:\n\nvery strong: 0.80‚Äì1.00\nstrong: 0.60‚Äì0.79\nmoderate: 0.40‚Äì0.59\nweak: 0.20‚Äì0.39\nvery weak: 0.00‚Äì0.19","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"machine-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"autoencoder-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"autoregressive-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"dblp-discovery-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/dblp-discovery-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\n\t\n\t\t\n\t\tDataset Card for DBLP Discovery Dataset (D3)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDBLP is the largest open-access repository of scientific articles on computer science and provides metadata associated with publications, authors, and venues. We retrieved more than 6 million publications from DBLP and extracted pertinent metadata (e.g., abstracts, author affiliations, citations) from the publication texts to create the DBLP Discovery Dataset (D3). D3 can be used to identify trends in research‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/dblp-discovery-dataset.","first_N":5,"first_N_keywords":["other","found","found","monolingual","extended|s2orc"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-turkish-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset","creator_name":"Cemil Guney","creator_url":"https://huggingface.co/mcemilg","description":"\n\t\n\t\t\n\t\tDataset Card for laion2B-multi-turkish-subset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLAION-5B is a large scale openly accessible image-text dataset contains text from multiple languages. This is a Turkish subset data of laion/laion2B-multi. It's compatible to be used with image2dataset to fetch the images at scale.\n\n\t\n\t\t\n\t\n\t\n\t\tData Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"CONDAQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lasha-nlp/CONDAQA","creator_name":"Abhilasha Ravichander","creator_url":"https://huggingface.co/lasha-nlp","description":"\n\t\n\t\t\n\t\tDataset Card for CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nData from the EMNLP 2022 paper by Ravichander et al.: \"CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\". \nIf you use this dataset, we would appreciate you citing our work:\n@inproceedings{ravichander-et-al-2022-condaqa,\n  title={CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lasha-nlp/CONDAQA.","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-questions","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\n\t\n\t\t\n\t\tDataset Card for [Stackoverflow Post Questions]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \nthe other hand, every software developer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"saf_legal_domain_german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_legal_domain_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Short Answer Feedback (SAF) dataset contains 19 German questions in the domain of the German social law (with reference answers). The idea of constructing a bilingual (English and German) short answer dataset as a way to remedy the lack of content-focused feedback datasets was introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german.","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"text2image-multi-prompt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pszemraj/text2image-multi-prompt","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","description":"\n\t\n\t\t\n\t\ttext2image multi-prompt(s): a dataset collection\n\t\n\n\ncollection of several text2image prompt datasets\ndata was cleaned/normalized with the goal of removing \"model specific APIs\" like the \"--ar\" for Midjourney and so on\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\n\n\n\t\n\t\t\n\t\tupdates\n\t\n\n\nOct 2023: the default config has been updated with better deduplication. It was deduplicated with minhash (params: n-gram size set to 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/text2image-multi-prompt.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","monolingual","bartman081523/stable-diffusion-discord-prompts","succinctly/midjourney-prompts"],"keywords_longer_than_N":true},
	{"name":"coyo-labeled-300m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\n\t\n\t\t\n\t\tDataset Card for COYO-Labeled-300M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOYO-Labeled-300M is a dataset of machine-labeled 300M images-multi-label pairs. We labeled subset of COYO-700M with a large model (efficientnetv2-xl) trained on imagenet-21k. We followed the same evaluation pipeline as in efficientnet-v2. The labels are top 50 most likely labels out of 21,841 classes from imagenet-21k. The label probabilies are provided rather than label so that the user can select threshold of their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"libri","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"saf_micro_job_german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_micro_job_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 8 German questions used in micro-job training on the crowd-worker platform appJobber - while the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german.","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"saf_communication_networks_english","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_communication_networks_english\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 31 English questions covering a range of college-level communication networks topics -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english.","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"idk-mrc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rifkiaputri/idk-mrc","creator_name":"Rifki Afina Putri","creator_url":"https://huggingface.co/rifkiaputri","description":"\n\t\n\t\t\n\t\tDataset Card for IDK-MRC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nI(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers answerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA, the new unanswerable question in IDK-MRC is generated using a question generation model and human-written question. Each paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rifkiaputri/idk-mrc.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"libri-whisper-raw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri-whisper-raw","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri-whisper-raw.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"qag_tweetqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_tweetqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on [TweetQA](https://huggingface.co/datasets/tweet_qa).","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","tweet_qa","English"],"keywords_longer_than_N":true},
	{"name":"qag_squad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","lmqg/qg_squad","English"],"keywords_longer_than_N":true},
	{"name":"ask_a_patient","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/ask_a_patient","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The AskAPatient dataset contains medical concepts written on social media mapped to how they are formally written in medical ontologies (SNOMED-CT and AMT).","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"bioasq_2021_mesinesp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/bioasq_2021_mesinesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The main aim of MESINESP2 is to promote the development of practically relevant semantic indexing tools for biomedical content in non-English language. We have generated a manually annotated corpus, where domain experts have labeled a set of scientific literature, clinical trials, and patent abstracts. All the documents were labeled with DeCS descriptors, which is a structured controlled vocabulary created by BIREME to index scientific publications on BvSalud, the largest database of scientific documents in Spanish, which hosts records from the databases LILACS, MEDLINE, IBECS, among others.\n\nMESINESP track at BioASQ9 explores the efficiency of systems for assigning DeCS to different types of biomedical documents. To that purpose, we have divided the task into three subtracks depending on the document type. Then, for each one we generated an annotated corpus which was provided to participating teams:\n\n- [Subtrack 1 corpus] MESINESP-L ‚Äì Scientific Literature: It contains all   Spanish records from LILACS and IBECS databases at the Virtual Health Library   (VHL) with non-empty abstract written in Spanish.\n- [Subtrack 2 corpus] MESINESP-T- Clinical Trials contains records from Registro   Espa√±ol de Estudios Cl√≠nicos (REEC). REEC doesn't provide documents with the   structure title/abstract needed in BioASQ, for that reason we have built   artificial abstracts based on the content available in the data crawled using   the REEC API.\n- [Subtrack 3 corpus] MESINESP-P ‚Äì Patents: This corpus includes patents in   Spanish extracted from Google Patents which have the IPC code ‚ÄúA61P‚Äù and   ‚ÄúA61K31‚Äù. In addition, we also provide a set of complementary data such as:   the DeCS terminology file, a silver standard with the participants' predictions   to the task background set and the entities of medications, diseases, symptoms   and medical procedures extracted from the BSC NERs documents.","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"chebi_nactem","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/chebi_nactem","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The ChEBI corpus contains 199 annotated abstracts and 100 annotated full papers.\nAll documents in the corpus have been annotated for named entities and relations\nbetween these. In total, our corpus provides over 15000 named entity annotations\nand over 6,000 relations between entities.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"chia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/chia","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"A large annotated corpus of patient eligibility criteria extracted from 1,000\ninterventional, Phase IV clinical trials registered in ClinicalTrials.gov. This\ndataset includes 12,409 annotated eligibility criteria, represented by 41,487\ndistinctive entities of 15 entity types and 25,017 relationships of 12\nrelationship types.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"codiesp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/codiesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Synthetic corpus of 1,000 manually selected clinical case studies in Spanish\nthat was designed for the Clinical Case Coding in Spanish Shared Task, as part\nof the CLEF 2020 conference.\n\nThe goal of the task was to automatically assign ICD10 codes (CIE-10, in\nSpanish) to clinical case documents, being evaluated against manually generated\nICD10 codifications. The CodiEsp corpus was selected manually by practicing\nphysicians and clinical documentalists and annotated by clinical coding\nprofessionals meeting strict quality criteria. They reached an inter-annotator\nagreement of 88.6% for diagnosis coding, 88.9% for procedure coding and 80.5%\nfor the textual reference annotation.\n\nThe final collection of 1,000 clinical cases that make up the corpus had a total\nof 16,504 sentences and 396,988 words. All documents are in Spanish language and\nCIE10 is the coding terminology (the Spanish version of ICD10-CM and ICD10-PCS).\nThe CodiEsp corpus has been randomly sampled into three subsets. The train set\ncontains 500 clinical cases, while the development and test sets have 250\nclinical cases each. In addition to these, a collection of 176,294 abstracts\nfrom Lilacs and Ibecs with the corresponding ICD10 codes (ICD10-CM and\nICD10-PCS) was provided by the task organizers. Every abstract has at least one\nassociated code, with an average of 2.5 ICD10 codes per abstract.\n\nThe CodiEsp track was divided into three sub-tracks (2 main and 1 exploratory):\n\n- CodiEsp-D: The Diagnosis Coding sub-task, which requires automatic ICD10-CM\n  [CIE10-Diagn√≥stico] code assignment.\n- CodiEsp-P: The Procedure Coding sub-task, which requires automatic ICD10-PCS\n  [CIE10-Procedimiento] code assignment.\n- CodiEsp-X: The Explainable AI exploratory sub-task, which requires to submit\n  the reference to the predicted codes (both ICD10-CM and ICD10-PCS). The goal \n  of this novel task was not only to predict the correct codes but also to \n  present the reference in the text that supports the code predictions.\n\nFor further information, please visit https://temu.bsc.es/codiesp or send an\nemail to encargo-pln-life@bsc.es","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"ehr_rel","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/ehr_rel","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"EHR-Rel is a novel open-source1 biomedical concept relatedness dataset consisting of 3630 concept pairs, six times more\nthan the largest existing dataset.  Instead of manually selecting and pairing concepts as done in previous work,\nthe dataset is sampled from EHRs to ensure concepts are relevant for the EHR concept retrieval task.\nA detailed analysis of the concepts in the dataset reveals a far larger coverage compared to existing datasets.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"evidence_inference","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/evidence_inference","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple\ntreatments. Each of these articles will have multiple questions, or 'prompts' associated with them.\nThese prompts will ask about the relationship between an intervention and comparator with respect to an outcome,\nas reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared\nto placebo on the duration of headaches. For the sake of this task, we assume that a particular article\nwill report that the intervention of interest either significantly increased, significantly decreased\nor had significant effect on the outcome, relative to the comparator.","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Tabular"],"keywords_longer_than_N":true},
	{"name":"hallmarks_of_cancer","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/hallmarks_of_cancer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The Hallmarks of Cancer (HOC) Corpus consists of 1852 PubMed publication\nabstracts manually annotated by experts according to a taxonomy. The taxonomy\nconsists of 37 classes in a hierarchy. Zero or more class labels are assigned\nto each sentence in the corpus. The labels are found under the \"labels\"\ndirectory, while the tokenized text can be found under \"text\" directory.\nThe filenames are the corresponding PubMed IDs (PMID).","first_N":5,"first_N_keywords":["monolingual","English","gpl-3.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"linnaeus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/linnaeus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Linnaeus is a novel corpus of full-text documents manually annotated for species mentions.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"mayosrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/mayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MayoSRS consists of 101 clinical term pairs whose relatedness was determined by nine medical coders and three physicians from the Mayo Clinic.","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"meddocan","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/meddocan","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MEDDOCAN: Medical Document Anonymization Track\n\nThis dataset is designed for the MEDDOCAN task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\n\nIt is a manually classified collection of 1,000 clinical case reports derived from the Spanish Clinical Case Corpus (SPACCC), enriched with PHI expressions.\n\nThe annotation of the entire set of entity mentions was carried out by experts annotatorsand it includes 29 entity types relevant for the annonymiation of medical documents.22 of these annotation types are actually present in the corpus: TERRITORIO, FECHAS, EDAD_SUJETO_ASISTENCIA, NOMBRE_SUJETO_ASISTENCIA, NOMBRE_PERSONAL_SANITARIO, SEXO_SUJETO_ASISTENCIA, CALLE, PAIS, ID_SUJETO_ASISTENCIA, CORREO, ID_TITULACION_PERSONAL_SANITARIO,ID_ASEGURAMIENTO, HOSPITAL, FAMILIARES_SUJETO_ASISTENCIA, INSTITUCION, ID_CONTACTO ASISTENCIAL,NUMERO_TELEFONO, PROFESION, NUMERO_FAX, OTROS_SUJETO_ASISTENCIA, CENTRO_SALUD, ID_EMPLEO_PERSONAL_SANITARIO\n    \nFor further information, please visit https://temu.bsc.es/meddocan/ or send an email to encargo-pln-life@bsc.es","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"minimayosrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/minimayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MiniMayoSRS is a subset of the MayoSRS and consists of 30 term pairs on which a higher inter-annotator agreement was\nachieved. The average correlation between physicians is 0.68. The average correlation between medical coders is 0.78.","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","< 1K","Tabular"],"keywords_longer_than_N":true},
	{"name":"multi_xscience","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/multi_xscience","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Multi-document summarization is a challenging task for which there exists little large-scale datasets. \nWe propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. \nMulti-XScience introduces a challenging multi-document summarization task: writing the related-work section \nof a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, \na dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and \nempirical results---using several state-of-the-art models trained on the Multi-XScience dataset---reveal t\nhat Multi-XScience is well suited for abstractive models.","first_N":5,"first_N_keywords":["monolingual","English","mit","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"pharmaconer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/pharmaconer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an open access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts and it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets. The training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"progene","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/progene","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The Protein/Gene corpus was developed at the JULIE Lab Jena under supervision of Prof. Udo Hahn.\nThe executing scientist was Dr. Joachim Wermter.\nThe main annotator was Dr. Rico Pusch who is an expert in biology.\nThe corpus was developed in the context of the StemNet project (http://www.stemnet.de/).","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"seth_corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/seth_corpus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"\n\t\n\t\t\n\t\tDataset Card for SETH Corpus\n\t\n\nSNP named entity recognition corpus consisting of 630 PubMed citations.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@Article{SETH2016,\n    Title       = {SETH detects and normalizes genetic variants in text.},\n    Author      = {Thomas, Philippe and Rockt{\"{a}}schel, Tim and Hakenberg, J{\"{o}}rg and Lichtblau, Yvonne and Leser, Ulf},\n    Journal     = {Bioinformatics},\n    Year        = {2016},\n    Month       = {Jun},\n    Doi         =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigbio/seth_corpus.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"spl_adr_200db","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/spl_adr_200db","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The United States Food and Drug Administration (FDA) partnered with the National Library\nof Medicine to create a pilot dataset containing standardised information about known\nadverse reactions for 200 FDA-approved drugs. The Structured Product Labels (SPLs),\nthe documents FDA uses to exchange information about drugs and other products, were\nmanually annotated for adverse reactions at the mention level to facilitate development\nand evaluation of text mining tools for extraction of ADRs from all SPLs.  The ADRs were\nthen normalised to the Unified Medical Language System (UMLS) and to the Medical\nDictionary for Regulatory Activities (MedDRA).","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"twadrl","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/twadrl","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The TwADR-L dataset contains medical concepts written on social media (Twitter) mapped to how they are formally written in medical ontologies (SIDER 4). \\","first_N":5,"first_N_keywords":["monolingual","English","cc-by-4.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"umnsrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/umnsrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"UMNSRS, developed by Pakhomov, et al., consists of 725 clinical term pairs whose semantic similarity and relatedness.\nThe similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch\na bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness.\nThe following subsets are available:\n- similarity: A set of 566 UMLS concept pairs manually rated for semantic similarity (e.g. whale-dolphin) using a\n  continuous response scale.\n- relatedness: A set of 588 UMLS concept pairs manually rated for semantic relatedness (e.g. needle-thread) using a\n  continuous response scale.\n- similarity_mod: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not\n  match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper (Corpus\n  Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley, Reed McEwan,\n  Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644). The resulting dataset contains 449 pairs.\n- relatedness_mod: Modification of the UMNSRS-Relatedness dataset to exclude control samples and those pairs that did\n  not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper\n  (Corpus Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley,\n  Reed McEwan, Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644).\n  The resulting dataset contains 458 pairs.","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","Tabular"],"keywords_longer_than_N":true},
	{"name":"portuguese-legal-sentences-v0","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\n\t\n\t\tContributions\n\t\n\n@rufimelo99\nIf you use this work, please cite:\n@InProceedings{MeloSemantic,\n  author=\"Melo, Rui\n  and Santos, Pedro A.\n  and Dias, Jo{\\~a}o\",\n  editor=\"Moniz, Nuno\n  and Vale, Zita\n  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"paraphrase-ro","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlackKakapo/paraphrase-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","description":"\n\t\n\t\t\n\t\tRomanian paraphrase dataset\n\t\n\nThis data set was created by me, special for paraphrase\nt5-small-paraphrase-ro\nt5-small-paraphrase-ro-v2\nt5-base-paraphrase-ro\nt5-base-paraphrase-ro-v2\nHere you can find ~100k examples of paraphrase.\n","first_N":5,"first_N_keywords":["monolingual","Romanian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tIMaSC: ICFOSS Malayalam Speech Corpus\n\t\n\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ravnursson_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"\n\t\n\t\t\n\t\tDataset Card for ravnursson_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus \"RAVNURSSON FAROESE SPEECH AND TRANSCRIPTS\" (or RAVNURSSON Corpus for short) is a collection of speech recordings with transcriptions intended for Automatic Speech Recognition (ASR) applications in the language that is spoken at the Faroe Islands (Faroese). It was curated at the Reykjav√≠k University (RU) in 2022.\nThe RAVNURSSON Corpus is an extract of the \"Basic Language Resource Kit 1.0\" (BLARK 1.0) [1] developed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kodak","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Freed-Wu/kodak","creator_name":"wzy","creator_url":"https://huggingface.co/Freed-Wu","description":"The pictures below link to lossless, true color (24 bits per pixel, aka \"full\ncolor\") images. It is my understanding they have been released by the Eastman\nKodak Company for unrestricted usage. Many sites use them as a standard test\nsuite for compression testing, etc. Prior to this site, they were only\navailable in the Sun Raster format via ftp. This meant that the images could\nnot be previewed before downloading. Since their release, however, the lossless\nPNG format has been incorporated into all the major browsers. Since PNG\nsupports 24-bit lossless color (which GIF and JPEG do not), it is now possible\nto offer this browser-friendly access to the images.","first_N":5,"first_N_keywords":["other","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-voice-test16k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test16k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test16k.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kmhas_korean_hate_speech","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","hate-speech-detection","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"common-voice-test3k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test3k.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-train-3k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-train-3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-train-3k.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common3k-train","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common3k-train","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common3k-train.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-voice","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"snli-cf-kaushik","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagnikrayc/snli-cf-kaushik","creator_name":"sagnik ray choudhury","creator_url":"https://huggingface.co/sagnikrayc","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). In the ICLR 2020 paper [Learning the Difference that Makes a Difference with Counterfactually-Augmented Data](https://openreview.net/forum?id=Sklgs0NFvr), Kaushik et. al. provided a dataset with counterfactual perturbations on the SNLI and IMDB data. This repository contains the original and counterfactual perturbations for the SNLI data, which was generated after processing the original data from [here](https://github.com/acmi-lab/counterfactually-augmented-data).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ciempiess_test","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\"CIEMPIESS Experimentation\\\" (LDC2019S07).","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ger-backtrans-paraphrase","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deutsche-telekom/ger-backtrans-paraphrase","creator_name":"Deutsche Telekom AG","creator_url":"https://huggingface.co/deutsche-telekom","description":"\n\t\n\t\t\n\t\tGerman Backtranslated Paraphrase Dataset\n\t\n\nThis is a dataset of more than 21 million German paraphrases.\nThese are text pairs that have the same meaning but are expressed with different words.\nThe source of the paraphrases are different parallel German / English text corpora.\nThe English texts were machine translated back into German to obtain the paraphrases.\nThis dataset can be used for example to train semantic text embeddings.\nTo do this, for example, SentenceTransformers\nand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deutsche-telekom/ger-backtrans-paraphrase.","first_N":5,"first_N_keywords":["sentence-similarity","monolingual","German","cc-by-sa-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"dmeo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/dmeo","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/dmeo.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"demo-common-whisper","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/demo-common-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/demo-common-whisper.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sgd1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd1","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SGD-X v1\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\nPaper: https://arxiv.org/pdf/2110.06800.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd1')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd1.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:2110.06800"],"keywords_longer_than_N":true},
	{"name":"sgd2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd2","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SGD-X v2\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\nPaper: https://arxiv.org/pdf/2110.06800.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd2')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd2.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:2110.06800"],"keywords_longer_than_N":true},
	{"name":"sgd3","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd3","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SGD-X v3\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\nPaper: https://arxiv.org/pdf/2110.06800.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd3')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd3.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:2110.06800"],"keywords_longer_than_N":true},
	{"name":"sgd4","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd4","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SGD-X v4\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\nPaper: https://arxiv.org/pdf/2110.06800.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd4')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd4.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:2110.06800"],"keywords_longer_than_N":true},
	{"name":"sgd5","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd5","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SGD-X v5\n\t\n\n\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\nPaper: https://arxiv.org/pdf/2110.06800.pdf\nLeaderboard: None\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\n\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\nfrom convlab.util import load_dataset, load_ontology, load_database\n\ndataset = load_dataset('sgd5')\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd5.","first_N":5,"first_N_keywords":["monolingual","English","cc-by-sa-4.0","10K<n<100K","arxiv:2110.06800"],"keywords_longer_than_N":true},
	{"name":"samromur_children","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"The Samr√≥mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"xbmu_amdo31","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syzym/xbmu_amdo31","creator_name":"Senyan Li","creator_url":"https://huggingface.co/syzym","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for [XBMU-AMDO31]\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nXBMU-AMDO31 dataset is a speech recognition corpus of Amdo Tibetan dialect. The open source corpus contains 31 hours of speech data and resources related to build speech recognition systems, including transcribed texts and a Tibetan pronunciation dictionary.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nautomatic-speech-recognition: The dataset can be used to train a model for Amdo Tibetan Automatic Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/syzym/xbmu_amdo31.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","tib","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"qa_squad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qa_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"SQuAD with the train/validation/test split used in SQuAD QG","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"raddromur_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\n\t\n\t\t\n\t\tDataset Card for raddromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Raddr√≥mur Icelandic Speech 22.09\" (\"Raddr√≥mur Corpus\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\n\n\t\n\t\t\n\t\tExample Usage\n\t\n\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-proc-whisper","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-proc-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-proc-whisper.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wave-energy","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmudrc/wave-energy","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"cmudrc/wave-energy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["other","feature-extraction","image-to-image","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"commonvoice_accent_test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DocBank","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maveriq/DocBank","creator_name":"Haris Jabbar","creator_url":"https://huggingface.co/maveriq","description":"\n\t\n\t\t\n\t\tDataset Card for DocBank\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nDocument AI (text and layout)\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maveriq/DocBank.","first_N":5,"first_N_keywords":["machine-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"3d-printed-or-not","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmudrc/3d-printed-or-not","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"\n\t\n\t\t\n\t\t3d-printed-or-not: An Image Dataset of 3D-printed Prototypes\n\t\n\nThis dataset is a collection of images that are particularly relevant to engineering and design, consisting of two categories: 3D-printed prototypes, and non-3D-printed prototypes This data was collected through a hybrid approach that entailed both web scraping and direct collection from engineering labs and workspaces at Penn State University. The initial data was then augmented using several data augmentation techniques‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmudrc/3d-printed-or-not.","first_N":5,"first_N_keywords":["image-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bace_regression","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bace_regression","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for bace_regression\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbace_regression is a dataset included in MoleculeNet. This dataset consists of  Quantitative (IC50) binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: the IC50 binding results\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_regression.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"bace_classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bace_classification","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for bace_classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbace_classification is a dataset included in MoleculeNet. This dataset consists of qualitative (binary label) binding binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: the binary label binding results\n\n\n\t\n\t\t\n\t\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_classification.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"pcba_686978","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/pcba_686978","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for pcba_686978\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\npcba_686978 is a dataset included in MoleculeNet. PubChem BioAssay (PCBA) is a database consisting of biological activities of small molecules generated by high-throughput screening. We have chosen one of the larger tasks (ID 686978) as described in https://par.nsf.gov/servlets/purl/10168888.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/pcba_686978.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"SAD","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/SAD","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\n\t\n\t\t\n\t\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\n\t\n\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\n\n\t\n\t\t\n\t\tSAD\n\t\n\nThe SAD dataset is our gold standard dataset of tweets labelled for sarcasm. These tweets were scraped by observing a '#sarcasm' hashtag and then manually annotated by three annotators.\nThere are a total of 1170 pairs of a sarcastic and non-sarcastic tweets which were both posted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/SAD.","first_N":5,"first_N_keywords":["text-classification","Jordan Painter, Diptesh Kanojia","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"S3D-v1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/S3D-v1","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\n\t\n\t\t\n\t\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\n\t\n\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\n\n\t\n\t\t\n\t\tS3D Summary\n\t\n\nThe S3D dataset is our silver standard dataset of 100,000 tweets labelled for sarcasm using weak supervision by our BERTweet-sarcasm-combined model.\nThese tweets can be accessed by using the Twitter API so that they can be used for other experiments.\nS3D contains 38879‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/S3D-v1.","first_N":5,"first_N_keywords":["text-classification","Jordan Painter, Diptesh Kanojia","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"CONDA","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Matrix430/CONDA","creator_name":"Kunze Wang","creator_url":"https://huggingface.co/Matrix430","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for CONDA\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTraditional toxicity detection models have focused on the single utterance level without deeper understanding of context. We introduce CONDA, a new dataset for in-game toxic language detection enabling joint intent classification and slot filling analysis, which is the core task of Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Matrix430/CONDA.","first_N":5,"first_N_keywords":["text-classification","token-classification","intent-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"common-native","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-native","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"spectrogram-captions","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\n","first_N":5,"first_N_keywords":["text-to-image","machine-generated","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cSQuAD1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dferndz/cSQuAD1","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","description":"\n\t\n\t\t\n\t\tDataset Card for cSQuAD1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA contrast set generated from the eval set of SQuAD. Questions and answers were modified\nto help detecting dataset artifacts. This dataset only contains a validation set, which\nshould only be used to evaluate a model.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nQuestion Answering (SQuAD).\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nDataset contains 100 instances\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nDescription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD1.","first_N":5,"first_N_keywords":["question-answering","expert-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cSQuAD2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dferndz/cSQuAD2","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","description":"\n\t\n\t\t\n\t\tDataset Card for cSQuAD2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA contrast set to evaluate models trained on SQUAD on out-of-domain data.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nEvaluate question-answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nDataset contains 40 instances\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nid\nId of document containing context\n\n\ntitle\nTitle of the document\n\n\ncontext\nThe context of the question\n\n\nquestion\nThe question to answer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD2.","first_N":5,"first_N_keywords":["question-answering","expert-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-questions-2016","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\n\t\n\t\t\n\t\tDataset Card for [Stackoverflow Post Questions]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \nthe other hand, every software developer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common-native-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-native-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native-proc.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-accent","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-accent-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-proc.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-accent-augmented","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"jsnli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/jsnli","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"== Êó•Êú¨Ë™ûSNLI(JSNLI)„Éá„Éº„Çø„Çª„ÉÉ„Éà ==\n\nSNLI „Ç≥„Éº„Éë„Çπ„ÇíÊó•Êú¨Ë™û„Å´ÁøªË®≥„Åó„ÅüËá™ÁÑ∂Ë®ÄË™ûÊé®Ë´ñ„Éá„Éº„Çø„Çª„ÉÉ„Éà\nÂ≠¶Áøí„Éá„Éº„Çø„ÅØÂÖÉ„Éá„Éº„Çø„ÇíÁøªË®≥„Åó„ÄÅË®àÁÆóÊ©ü„Å´„Çà„Çã„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„Å´„Çà„Å£„Å¶‰ΩúÊàê\nË©ï‰æ°„Éá„Éº„Çø„ÅØÊó•Êú¨Ë™û„Å®„Åó„Å¶ÊÑèÂë≥„ÅåÈÄö„Çã„Åã„ÄÅÁøªË®≥Âæå„ÅÆ„É©„Éô„É´„ÅåÂÖÉ„ÅÆ„É©„Éô„É´„Å®‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„Åã„Å©„ÅÜ„Åã„ÅÆ2ÊÆµÈöé„ÅÆ„ÇØ„É©„Ç¶„Éâ„ÇΩ„Éº„Ç∑„É≥„Ç∞„Å´„Çà„Çä„Éá„Éº„Çø„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"clintox","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/clintox","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for clintox\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nclintox is a dataset included in MoleculeNet. Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons. This uses the CT_TOX task.\nNote, there was one molecule in the training set that could not be converted to SELFIES (*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clintox.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"delaney","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/delaney","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for delaney\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ndelaney (aka. ESOL) is a dataset included in MoleculeNet. Water solubility data(log solubility in mols per litre) for common organic small molecules.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: log solubility in mols per litre\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/delaney.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"clearance","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/clearance","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for clearance\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nclearance is a dataset included in Chemberta-2 benchmarking. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget:\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10 train/valid/test split using scaffold split. \n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\nData was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clearance.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"lipo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/lipo","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for lipo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nlipo is a dataset included in MoleculeNet. It measures the experimental results of octanol/water distribution coefficient(logD at pH 7.4)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: octanol/water distribution coefficient(logD at pH 7.4)\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/lipo.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"bbbp","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bbbp","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for bbbp\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nbbbp is a dataset included in MoleculeNet. This dataset has binary labels of blood-brain barrier penetration(permeability).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: blood-brain barrier penetration(permeability)\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10 train/valid/test split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bbbp.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"IRIS_sts","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for Semantic Textual Similarity\n\nValues from 0-1: random sentences across documents\nValues from 2-4: sentences from the same summary (implying some level of entailment)\nValues from 4-5: sentences pairs generated through OpenAi'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","automated","found"],"keywords_longer_than_N":true},
	{"name":"skquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUKE-DeutscheTelekom/skquad","creator_name":"TUKE and DTSS cooperation","creator_url":"https://huggingface.co/TUKE-DeutscheTelekom","description":"\n\t\n\t\t\n\t\tDataset Card for SkQuAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSK-QuAD is the first QA dataset for the Slovak language.\nIt is manually annotated, so it has no distortion caused by\nmachine translation. The dataset is thematically diverse ‚Äì it\ndoes not overlap with SQuAD ‚Äì it brings new knowledge.\nIt passed the second round of annotation ‚Äì each question\nand the answer were seen by at least two annotators.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nQuestion answering\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TUKE-DeutscheTelekom/skquad.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","extractive-qa","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"qg_tweetqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_tweetqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question generation dataset based on [TweetQA](https://huggingface.co/datasets/tweet_qa).","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","tweet_qa","English"],"keywords_longer_than_N":true},
	{"name":"common-accent-augmented-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bible_tts_hausa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\n\t\n\t\t\n\t\tDataset Card for BibleTTS Hausa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nHausa\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: audio path\nsentence: transcription of the audio\nlocale: always set to ha\nbook: 3-char book encoding\nverse: verse id‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"araina-text-corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/collectivat/araina-text-corpus","creator_name":"Col¬∑lectivaT","creator_url":"https://huggingface.co/collectivat","description":"\n\t\n\t\t\n\t\tAraina Text Corpus\n\t\n\nText corpus in Aranese variety of Gascon dialect of Occitan.\n\n\t\n\t\t\n\t\tCorpora\n\t\n\n\n_nogues: Literary texts translated by Ant√≤ni Nogu√©s. Sourced from institutestudisaranesi.cat\n_suils: Language educational material by Jordi Su√Øls Subir√†\n_conselh: Administrative proceedings from Conselh Generau d'Aran\n\n\n\t\n\t\t\n\t\tProject Araina\n\t\n\nThis corpus was prepared as part of Project Araina with support from Culture Department of the Catalan autonomous government.\nAquest corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/araina-text-corpus.","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"nkjp1m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ipipan/nkjp1m","creator_name":"IPI PAN","creator_url":"https://huggingface.co/ipipan","description":"This is the official dataset for NKJP1M ‚Äì the 1-million token subcorpus of the\nNational Corpus of Polish (Narodowy Korpus Jƒôzyka Polskiego)\n\nBesides the text (divided into paragraphs/samples and sentences) the\nset contains lemmas and morpho-syntactic tags for all tokens in the corpus.\n\nThis release corresponds to the version 1.2 of the corpus with\nfollowing corrections and improvements. In particular the\nmorpho-syntactic annotation has been aligned with the present version\nof Morfeusz2 morphological analyser.","first_N":5,"first_N_keywords":["token-classification","part-of-speech","lemmatization","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"msc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tSMC Malayalam Speech Corpus\n\t\n\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences, 1400‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Mroue","keyword":"monolingual","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gr3en/Mroue","creator_name":"Walter Maiorino","creator_url":"https://huggingface.co/Gr3en","description":"Gr3en/Mroue dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"fashion-captions-de","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinaai/fashion-captions-de","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","description":"\n\n\n\n\n\n\nThe data offered by Jina AI, Finetuner team.\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is a German-language dataset based on the Fashion12K dataset, which originally contains both English and German text descriptions for each item.\nThis dataset was used to to finetuner CLIP using the Finetuner tool.\n\n\t\n\t\t\n\t\tFine-tuning\n\t\n\nPlease refer to our documentation: Multilingual Text-to-Image Search with MultilingualCLIP\nand blog Improving Search Quality for Non-English Queries with Fine-tuned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/fashion-captions-de.","first_N":5,"first_N_keywords":["text-to-image","monolingual","original","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"panda","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/panda","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for PANDA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPANDA (Perturbation Augmentation NLP DAtaset) consists of approximately 100K pairs of crowdsourced human-perturbed text snippets (original, perturbed). Annotators were given selected terms and target demographic attributes, and instructed to rewrite text snippets along three demographic axes: gender, race and age, while preserving semantic meaning. Text snippets were sourced from a range of text corpora (BookCorpus, Wikipedia, ANLI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/panda.","first_N":5,"first_N_keywords":["token-classification","expert-generated","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"kpwr","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-knext/kpwr","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","description":"\n\t\n\t\t\n\t\tKPWr\n\t\n\n","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"arxiv-biology","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/arxiv-biology","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\n\n\t\n\t\t\n\t\tDataset Curators\n\t\n\nThe original data is maintained by ArXiv\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe data is under the Creative Commons CC0 1.0 Universal Public Domain Dedication\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{clement2019arxiv,\n    title={On the Use of ArXiv as a Dataset},\n    author={Colin B. Clement and Matthew Bierbaum and Kevin P. O'Keeffe and Alexander A. Alemi},\n    year={2019},\n    eprint={1905.00075},\n    archivePrefix={arXiv},\n    primaryClass={cs.IR}\n}\n\n","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"laion-high-resolution-chinese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\n\t\n\t\t\n\t\tlaion-high-resolution-chinese\n\t\n\n\n\t\n\t\t\n\t\tÁÆÄ‰ªã Brief Introduction\n\t\n\nÂèñËá™Laion5B-high-resolutionÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÔºå‰∏ÄÂÖ±2.66M‰∏™ÂõæÊñáÂØπ„ÄÇ\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\n\t\n\nÂ§ßÁ∫¶‰∏ÄÂÖ±2.66M‰∏™‰∏≠ÊñáÂõæÊñáÂØπ„ÄÇÂ§ßÁ∫¶Âç†Áî®381MBÁ©∫Èó¥Ôºà‰ªÖ‰ªÖÊòØurlÁ≠âÊñáÊú¨‰ø°ÊÅØÔºå‰∏çÂåÖÂê´ÂõæÁâáÔºâ„ÄÇ\n\nHomepage: laion-5b\nHuggingface: laion/laion-high-resolution\n\n\n\t\n\t\t\n\t\t‰∏ãËΩΩ Download\n\t\n\nmkdir release && cd release\nfor i in {00000..00015}; do wget‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"told_br_binary_sm","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inctdd/told_br_binary_sm","creator_name":"Instituto Nacional de Ci√™ncia e Tecnologia em Democracia Digital","creator_url":"https://huggingface.co/inctdd","description":"This dataset is a random 1/3 slice of the original told-br\n","first_N":5,"first_N_keywords":["monolingual","told-br","Portuguese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test-tweets","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ad321/test-tweets","creator_name":"ad","creator_url":"https://huggingface.co/ad321","description":"tweets in english positive negative\n","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"S3D-v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/S3D-v2","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\n\t\n\t\t\n\t\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\n\t\n\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\n\n\t\n\t\t\n\t\tS3D-v2 Summary\n\t\n\nThe S3D-v2 dataset is our silver standard dataset of 100,000 tweets labelled for sarcasm using weak supervision by a majority voting system of fine-tuned sarcasm detection models. The models used are \nour roberta-large-finetuned-SARC-combined-DS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/S3D-v2.","first_N":5,"first_N_keywords":["text-classification","Jordan Painter, Diptesh Kanojia","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"squad_v2_dutch","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yhavinga/squad_v2_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad_v2_dutch\"\n\t\n\n\n  Deprecated: This translation is not recommended. 12% of the translated answers do not appear verbatim in the contexts. Use NetherlandsForensicInstitute/squad-nl-v2.0 instead.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe squad_v2_dutch dataset is a machine-translated version of the SQuAD v2 dataset from English to Dutch.\nThe SQuAD v2 dataset combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhavinga/squad_v2_dutch.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"qag_koquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","lmqg/qg_koquad","Korean"],"keywords_longer_than_N":true},
	{"name":"qag_jaquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_jaquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","lmqg/qg_jaquad","Japanese"],"keywords_longer_than_N":true},
	{"name":"qag_esquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","lmqg/qg_esquad","Spanish"],"keywords_longer_than_N":true},
	{"name":"cs_csfd-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/cs_csfd-movie-reviews","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\n\t\n\t\t\n\t\tDataset Card for CSFD movie reviews (Czech)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains user reviews from Czech/Slovak movie databse website https://csfd.cz.\nEach review contains text, rating, date, and basic information about the movie (or TV series).\nThe dataset has in total (train+validation+test) 30,000 reviews. The data is balanced - each rating has approximately the same frequency.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\nEach sample contains:\n\nreview_id: unique string identifier‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/cs_csfd-movie-reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"sk_csfd-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/sk_csfd-movie-reviews","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\n\t\n\t\t\n\t\tDataset Card for CSFD movie reviews (Slovak)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains user reviews from Czech/Slovak movie databse website https://csfd.cz.\nEach review contains text, rating, date, and basic information about the movie (or TV series).\nThe dataset has in total (train+validation+test) 30,000 reviews. The data is balanced - each rating has approximately the same frequency.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\nEach sample contains:\n\nreview_id: unique string identifier‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/sk_csfd-movie-reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Hansel","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/Hansel","creator_name":"HITsz-Text and Multimodal Generative Intelligence Group(TMG)","creator_url":"https://huggingface.co/HIT-TMG","description":"Hansel is a high-quality human-annotated Chinese entity linking (EL) dataset, used for testing Chinese EL systems' generalization ability to tail entities and emerging entities.\nThe test set contains Few-shot (FS) and zero-shot (ZS) slices, has 10K examples and uses Wikidata as the corresponding knowledge base.\nThe training and validation sets are from Wikipedia hyperlinks, useful for large-scale pretraining of Chinese EL systems.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","crowdsourced","found","found"],"keywords_longer_than_N":true},
	{"name":"qa_squadshifts_synthetic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"\n\t\n\t\t\n\t\tDataset Card for \"lmqg/qa_squadshifts_synthetic\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a synthetic QA dataset generated with fine-tuned QG models over lmqg/qa_squadshifts, made for question-answering based evaluation (QAE) for question generation model proposed by Zhang and Bansal, 2019.\nThe test split is the original validation set of lmqg/qa_squadshifts, where the model should be evaluate on.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nquestion-answering\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","extended|wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"cs_squad-3.0","keyword":"monolingual","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/cs_squad-3.0","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\n\t\n\t\t\n\t\tDataset Card for Czech Simple Question Answering Dataset 3.0\n\t\n\nThis a processed and filtered adaptation of an existing dataset. For raw and larger dataset, see Dataset Source section.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe data contains questions and answers based on Czech wikipeadia articles.\nEach question has an answer (or more) and a selected part of the context as the evidence.\nA majority of the answers are extractive - i.e. they are present in the context in the exact form. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/cs_squad-3.0.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"model-written-evals","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anthropic/model-written-evals","creator_name":"Anthropic","creator_url":"https://huggingface.co/Anthropic","description":"\n\t\n\t\t\n\t\tModel-Written Evaluation Datasets\n\t\n\nThis repository includes datasets written by language models, used in our paper on \"Discovering Language Model Behaviors with Model-Written Evaluations.\"\nWe intend the datasets to be useful to:\n\nThose who are interested in understanding the quality and properties of model-generated data\nThose who wish to use our datasets to evaluate other models for the behaviors we examined in our work (e.g., related to model persona, sycophancy, advanced AI risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anthropic/model-written-evals.","first_N":5,"first_N_keywords":["multiple-choice","zero-shot-classification","question-answering","multiple-choice-qa","multiple-choice-coreference-resolution"],"keywords_longer_than_N":true},
	{"name":"docprompting-conala","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"tldr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","original","code"],"keywords_longer_than_N":true},
	{"name":"financial_news_sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment","creator_name":"JB Polle","creator_url":"https://huggingface.co/Jean-Baptiste","description":"\n\t\n\t\t\n\t\tDataset Card for \"financial_news_sentiment\"\n\t\n\nManually validated sentiment for ~2000 Canadian news articles.\nThe dataset also include a column topic which contains one of the following value:\n\nacquisition\nother\nquaterly financial release\nappointment to new position\ndividend\ncorporate update\ndrillings results\nconference\nshare repurchase program\ngrant of stocks\n\nThis was generated automatically using a zero-shot classification model and was not reviewed manually.\n","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"financial_news_sentiment_mixte_with_phrasebank_75","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment_mixte_with_phrasebank_75","creator_name":"JB Polle","creator_url":"https://huggingface.co/Jean-Baptiste","description":"\n\t\n\t\t\n\t\tDataset Card for \"financial_news_sentiment_mixte_with_phrasebank_75\"\n\t\n\nThis is a customized version of the phrasebank dataset in which I kept only sentences validated by at least 75% annotators.In addition I added ~2000 articles of Canadian news where sentiment was validated manually.\nThe dataset also include a column topic which contains one of the following value:\n\nacquisition\nother\nquaterly financial release\nappointment to new position\ndividend\ncorporate update\ndrillings results‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment_mixte_with_phrasebank_75.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tox21_srp53","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/tox21_srp53","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\n\t\n\t\t\n\t\tDataset Card for tox21_srp53\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ntox21_srp53 is a dataset included in MoleculeNet. It is the p53 stress-response pathway activation (SR-p53) task from Tox21.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach split contains\n\nsmiles: the SMILES representation of a molecule\nselfies: the SELFIES representation of a molecule\ntarget: clinical trial toxicity (or absence of toxicity)\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Splits\n\t\n\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/tox21_srp53.","first_N":5,"first_N_keywords":["other","machine-generated","machine-generated","monolingual","mit"],"keywords_longer_than_N":true},
	{"name":"chizuru-ichinose","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandreteles/chizuru-ichinose","creator_name":"Alexandre Teles","creator_url":"https://huggingface.co/alexandreteles","description":"This dataset is extracted from the Anime \"Rent-A-Girlfriend\" as posted on Kaggle by xandercubbin.\nPlease refer to the chizuru_dialog_dataset.ipynb file to see how the dataset was pre-processed.\n","first_N":5,"first_N_keywords":["monolingual","English","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"golf-courses","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bethecloud/golf-courses","creator_name":"Kevin Leffew (GTM @ Replit)","creator_url":"https://huggingface.co/bethecloud","description":"\n\t\n\t\t\n\t\tDataset Summary: golf-course\n\t\n\nThis dataset (bethecloud/golf-courses) includes 21 unique images of golf courses pulled from Unsplash.  \nThe dataset is a collection of photographs taken at various golf courses around the world. The images depict a variety of scenes, including fairways, greens, bunkers, water hazards, and clubhouse facilities. The images are high resolution and have been carefully selected to provide a diverse range of visual content for fine-tuning a machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bethecloud/golf-courses.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"echr_rational","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUMLegalTech/echr_rational","creator_name":"TUMLegalTech","creator_url":"https://huggingface.co/TUMLegalTech","description":"\n\t\n\t\t\n\t\tDataset Card for echr_rational\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDeconfounding Legal Judgment Prediction for European Court of Human\nRights Cases Towards Better Alignment with Experts\nThis work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identify‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TUMLegalTech/echr_rational.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","English","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"financial-reports-sec","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JanosAudran/financial-reports-sec","creator_name":"Aman Khan","creator_url":"https://huggingface.co/JanosAudran","description":"The dataset contains the annual report of US public firms filing with the SEC EDGAR system.\nEach annual report (10K filing) is broken into 20 sections. Each section is split into individual sentences.\nSentiment labels are provided on a per filing basis from the market reaction around the filing data.\nAdditional metadata for each filing is included in the dataset.","first_N":5,"first_N_keywords":["fill-mask","text-classification","masked-language-modeling","multi-class-classification","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"test-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mqddb/test-dataset","creator_name":"qiangddb","creator_url":"https://huggingface.co/mqddb","description":"The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\nimages per class. There are 60,000 training images and 10,000 test images.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hacker_news_with_comments","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Linkseed/hacker_news_with_comments","creator_name":"KunLi","creator_url":"https://huggingface.co/Linkseed","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHacker news until 2015 with comments. Collect from Google BigQuery open dataset. We didn't do any pre-processing except remove HTML tags.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nComment Generation; News analysis with comments; Other comment-based NLP tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Linkseed/hacker_news_with_comments.","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"soda","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/soda","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\n\t\n\t\t\n\t\tDataset Card for ü•§SODA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nü•§SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authored‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/soda.","first_N":5,"first_N_keywords":["dialogue-generation","machine-generated","monolingual","original","extended|Atomic10x"],"keywords_longer_than_N":true},
	{"name":"mdk_gov_data_titles_clf","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf","creator_name":"&effect data solutions GmbH","creator_url":"https://huggingface.co/and-effect","description":"\n\t\n\t\t\n\t\tDataset Card for MDK\n\t\n\nThis dataset was created as part of the Bertelsmann Foundation's \nMusterdatenkatalog (MDK) project. The MDK provides an overview of Open Data in municipalities in Germany. It is intended to help municipalities in Germany, as well as data analysts and journalists, to get an overview of the topics and the extent to which cities have already published data sets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset is an annotated corpus of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf.","first_N":5,"first_N_keywords":["text-classification","monolingual","extended","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jd21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/jd21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"amz20","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/amz20","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"snap21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/snap21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"stock11","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"weibo16","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"korfin-asc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/korfin-asc","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\n\t\n\t\t\n\t\tDataset Card for KorFin-ABSA\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe KorFin-ASC is an extension of KorFin-ABSA including 8818 samples with (aspect, polarity) pairs annotated. \nThe samples were collected from KLUE-TC and \nanalyst reports from Naver Finance. \nAnnotation of the dataset is described in the paper Removing Non-Stationary Knowledge From Pre-Trained Language Models for Entity-Level Sentiment Classification in Finance.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amphora/korfin-asc.","first_N":5,"first_N_keywords":["text-classification","topic-classification","sentiment-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"gsm-hard","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/reasoning-machines/gsm-hard","creator_name":"Reasoning Machines","creator_url":"https://huggingface.co/reasoning-machines","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the harder version of gsm8k math reasoning dataset (https://huggingface.co/datasets/gsm8k).\nWe construct this dataset by replacing the numbers in the questions of GSM8K with larger numbers that are less common.\n\u0001\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is used to evaluate math reasoning\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish - Numbers\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ndataset = load_dataset(\"reasoning-machines/gsm-hard\")\nDatasetDict({\n    train: Dataset({‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/reasoning-machines/gsm-hard.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","monolingual","gsm8k (https://huggingface.co/datasets/gsm8k)","code"],"keywords_longer_than_N":true},
	{"name":"LIFD_Seismic_Data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for LFID Seismic Data\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA description of the dataset:\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\ncoming soon - Kaggle links? \n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nSAC files\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nAll seismic data were downloaded through the IRIS Wilber 3 system (https://ds.iris.edu/wilber3/) or IRIS Web Services (https://service.iris.edu/), including the following seismic networks: (1) the AZ (ANZA; UC San Diego, 1982); (2) the TA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data.","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","time-series-forecasting","object-detection","unconditional-image-generation"],"keywords_longer_than_N":true},
	{"name":"douban-dushu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larrylawl/douban-dushu","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","description":"This dataset contains book reviews from DouBan Dushu. DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. Most of the users in this website are unprofessional book reviewers. Therefore, the comments are usually spoken Chinese or even Internet slang.","first_N":5,"first_N_keywords":["no-annotation","crowdsourced","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"fake_railroad_company","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidwisdom/fake_railroad_company","creator_name":"David Wisdom","creator_url":"https://huggingface.co/davidwisdom","description":"\n\t\n\t\t\n\t\n\t\n\t\tfake_railroad_company\n\t\n\nThis is toy data I created about an imaginary railroad company.\n\n\t\n\t\t\n\t\n\t\n\t\tV1\n\t\n\nThis is the first version of the data that I generated.\n\n\t\n\t\t\n\t\n\t\n\t\tV2\n\t\n\nI tweaked some of the weights I used to calculate the satisfaction score.\n\n\t\n\t\t\n\t\n\t\n\t\tV3\n\t\n\nSome customers are now power users who ride more often than other users.\n\n\t\n\t\t\n\t\n\t\n\t\tV4\n\t\n\nCustomers with children are more likely to be members\n","first_N":5,"first_N_keywords":["time-series-forecasting","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"defamation-japanese-twitter","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kubota/defamation-japanese-twitter","creator_name":"Issei","creator_url":"https://huggingface.co/kubota","description":"\n\t\n\t\t\n\t\tdefamation_japanese_twitter\n\t\n\n\n\t\n\t\t\n\t\tTwitterÊó•Êú¨Ë™ûË™πË¨ó‰∏≠ÂÇ∑Ê§úÂá∫„Éá„Éº„Çø„Çª„ÉÉ„Éà\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSNS„Å´„Åä„Åë„ÇãË™πË¨ó‰∏≠ÂÇ∑Ê§úÂá∫„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„ÅôÔºé\n5,000‰ª∂„ÅÆÊó•Êú¨Ë™û„ÅÆ„ÉÑ„Ç§„Éº„Éà„Å´Ôºå„Åù„Çå„Åû„Çå‰ª•‰∏ã„ÅßÂÆöÁæ©„Åó„Å¶„ÅÑ„ÇãË™πË¨ó‰∏≠ÂÇ∑„ÅÆÂØæË±°ËÄÖ„Å®ÂÜÖÂÆπ„Çí„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„Åó„Å¶„ÅÑ„Åæ„ÅôÔºé„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„ÅØÔºå3‰∫∫„ÅÆ„ÇØ„É©„Ç¶„Éâ„ÉØ„Éº„Ç´„Éº„Å´„Çà„ÇäË°å„Çè„Çå„Å¶„ÅÑ„Åæ„ÅôÔºé2022Âπ¥2Êúà15Êó•„Åã„Çâ2022Âπ¥6Êúà30Êó•„Åæ„Åß„ÅÆ„ÉÑ„Ç§„Éº„Éà„Åß„ÅôÔºé\nÂÖÉ„ÅÆ„ÉÑ„Ç§„Éº„Éà„ÅØÂê´„Åæ„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅÔºåTwitter API„ÇíÁî®„ÅÑ„Å¶„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂèéÈõÜ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºé\n‰∏≠ÂÇ∑ÂØæË±°(target)„Å®‰∏≠ÂÇ∑ÂÜÖÂÆπ(label)„ÅÆ2È†ÖÁõÆ„Åå„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„Åï„Çå„Å¶„ÅÑ„Åæ„ÅôÔºé\n\ntarget Ôºö„ÉÜ„Ç≠„Çπ„Éà„ÅåË©±È°å„Å´„Åó„Å¶„ÅÑ„ÇãÂØæË±°ËÄÖ„ÅÆÂàÜÈ°û\nlabel Ôºö target„ÅßÈÅ∏Êäû„Åï„Çå„ÅüÂØæË±°ËÄÖ„Å´ÂØæ„Åô„ÇãË™πË¨ó‰∏≠ÂÇ∑„ÅÆÁ®ÆÈ°û„ÅÆÂàÜÈ°û\n\nÊñá„Å®„Åó„Å¶ÊàêÁ´ã„Åó„Å¶„Åä„Çâ„ÅöÊÑèÂë≥„ÅÆÂèñ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„É©„Éô„É´C(0)„Å®„Åó„Å¶„ÅÑ„Åæ„ÅôÔºé\n\n\t\n\t\t\ntarget\nÂØæË±°\n‰æã\n\n\n\t\t\nA1(1)\n(‰∫∫Á®Æ„ÉªÊÄßÂà•„ÉªËÅ∑Ê•≠„ÉªÊÄùÊÉ≥„Å™„Å©„ÇíÂÖ±ÈÄö„Å®„Åô„Çã)„Ç∞„É´„Éº„Éó‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kubota/defamation-japanese-twitter.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","description":"\n\t\n\t\t\n\t\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus consists of a single speaker, with 4515 segments extracted\nfrom a single LibriVox audiobook.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Hungarian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DBLP-QuAD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/awalesushil/DBLP-QuAD","creator_name":"Sushil Awale","creator_url":"https://huggingface.co/awalesushil","description":"    DBLP-QuAD is a scholarly knowledge graph question answering dataset with     10,000 question - SPARQL query pairs targeting the DBLP knowledge graph.     The dataset is split into 7,000 training, 1,000 validation and 2,000 test     questions.","first_N":5,"first_N_keywords":["question-answering","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nfcorpus-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/nfcorpus-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/nfcorpus-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fiqa-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/fiqa-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/fiqa-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"scifact-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/scifact-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/scifact-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"trec-news-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/trec-news-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/trec-news-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"robust04-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/robust04-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/robust04-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"scidocs-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/scidocs-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/scidocs-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arguana-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/arguana-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/arguana-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"trec-covid-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/trec-covid-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/trec-covid-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"quora-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/quora-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/quora-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/webis-touche2020-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/webis-touche2020-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"hotpotqa-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/hotpotqa-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/hotpotqa-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entity-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/dbpedia-entity-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/dbpedia-entity-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"fever-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/fever-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/fever-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"climate-fever-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/climate-fever-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/climate-fever-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"signal1m-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/signal1m-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/signal1m-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"nq-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/nq-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/nq-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-android-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-android-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-android-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-english-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-english-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-english-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gaming-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-gaming-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-gaming-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gis-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-gis-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-gis-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-mathematica-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-mathematica-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-mathematica-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-physics-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-physics-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-physics-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-programmers-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-programmers-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-programmers-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-stats-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-stats-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-stats-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-tex-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-tex-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-tex-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-unix-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-unix-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-unix-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-webmasters-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-webmasters-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-webmasters-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-wordpress-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-wordpress-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-wordpress-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michelecafagna26/hl","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","description":"\n\t\n\t\t\n\t\tDataset Card for the High-Level Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe High-Level (HL) dataset aligns object-centric descriptions from COCO \nwith high-level descriptions crowdsourced along 3 axes: scene, action, rationale\nThe HL dataset contains 14997 images from COCO and a total of 134973 crowdsourced captions (3 captions for each axis) aligned with ~749984 object-centric captions from COCO.\nEach axis is collected by asking the following 3 questions:\n\nWhere is the picture‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl.","first_N":5,"first_N_keywords":["image-to-text","question-answering","zero-shot-classification","text-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pile-detoxify","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The Pile, which is English text.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify.","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","hate-speech-detection","text-scoring"],"keywords_longer_than_N":true},
	{"name":"pile-pii-scrubadub","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the personal idenfitiable information (PII) in each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the percentage of words in it that are classified as PII by Scrubadub.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub.","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"competition_math","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qwedsacf/competition_math","creator_name":"Michael Vechtomov","creator_url":"https://huggingface.co/qwedsacf","description":"\n\t\n\t\t\n\t\tDataset Card for Mathematics Aptitude Test of Heuristics (MATH) dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more. \nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qwedsacf/competition_math.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"multiglue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/multiglue","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\n\t\n\t\t\n\t\tDataset Card for MultiGLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a combination of the cola, mrpc, qnli, qqp, rte, sst2, and wnli subsets of the GLUE dataset. Its intended use is to benchmark language models on multitask binary classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nLike the GLUE dataset, this dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/multiglue.","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","extended|glue"],"keywords_longer_than_N":true},
	{"name":"alsqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biu-nlp/alsqa","creator_name":"Bar-Ilan University NLP Lab","creator_url":"https://huggingface.co/biu-nlp","description":"To test the lexical overlap heuristic utilization in Reading Comprehension models, we create a new test set: Analyzing Lexically Similar QA (ALSQA).\nWe augment the SQuAD 2.0 dataset (Rajpurkar et al., 2018) by asking crowdworkers to generate questions with high context-overlap from questions with low overlap (These questions are paraphrases of the original questions).\nIn the case of un-answerable questions, annotators were asked to re-write the question without changing its meaning and maintain the unanswerability reason.3 ALSQA contains 365 questions pairs, 190 with an- swer and 174 without answer.","first_N":5,"first_N_keywords":["question-answering","text-classification","open-domain-qa","extractive-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bioasq-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/bioasq-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\n\t\n\t\t\n\t\tNFCorpus: 20 generated queries (BEIR Benchmark)\n\t\n\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\n\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\nQuestions generated: 20\nCode used for generation: evaluate_anserini_docT5query_parallel.py\n\nBelow contains the old dataset card for the BEIR benchmark.\n\n\t\n\t\n\t\n\t\tDataset Card for BEIR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/bioasq-top-20-gen-queries.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"fstdt-quotes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\n\t\n\t\t\n\t\tDataset Card for FSTDT Quotes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nFSTDT Quotes is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{\n  \"id\": \"G\",\n  \"submitter\": \"anonymous\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bioleaflets-biomedical-ner","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner","creator_name":"Ruslan Yermak","creator_url":"https://huggingface.co/ruslan","description":"\n\t\n\t\t\n\t\tDataset Card for BioLeaflets Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBioLeaflets is a biomedical dataset for Data2Text generation. It is a corpus of 1,336 package leaflets of medicines authorised in Europe, which were obtained by scraping the European Medicines Agency (EMA) website. \nPackage leaflets are included in the packaging of medicinal products and contain information to help patients use the product safely and appropriately. \nThis dataset comprises the large majority (‚àº 90%) of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner.","first_N":5,"first_N_keywords":["text-generation","language-modeling","machine-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"soda_synthetic_dialogue","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue","creator_name":"Jeffrey Quesnelle","creator_url":"https://huggingface.co/emozilla","description":"\n\t\n\t\t\n\t\tDataset Card for ü•§SODA Synthetic Dialogue\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nü•§SODA Synthetic Dialogue is a set of synthetic dialogues between Assistant and\nUser. In each conversation, User asks Assistant to perform summarization or\nstory generation tasks based on a snippet of an existing dialogue, story, or\nfrom a title or theme.\nThis data was created by synthesizing the dialogues in\nü•§Soda and applying a set of\ntemplates to generate the conversation. The original research paper can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue.","first_N":5,"first_N_keywords":["dialogue-generation","no-annotation","machine-generated","monolingual","extended|allenai/soda"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bundestag-v2","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/threite/Bundestag-v2","creator_name":"Thomas Reitenspiess","creator_url":"https://huggingface.co/threite","description":"\n\t\n\t\t\n\t\tDataset Card for Bundestag-v2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was generated from the ParlSpeech V2 dataset. It contains speeches from the german parliament from 1990 until 2020 labelled with the party of the speaker.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nText Classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nGerman\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Transcript of the speech in german\nparty: Party of the speaker\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\ntrain\nvalidation\ntest\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/threite/Bundestag-v2.","first_N":5,"first_N_keywords":["text-classification","entity-linking-classification","expert-generated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"squad-v1.1-t5-question-generation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad-v1.1-t5-question-generation\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modified Stanford Question Answering Dataset (SQuAD) to suit question generation with All Questions in One Line (AQOL) just like in Transformer-based End-to-End Question Generation\nspecifically for the T5 family of models. The prefix is generate questions:  so that the task can be unique to a trained model.\nCheck out the generation notebook here.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","extended|squad","English"],"keywords_longer_than_N":true},
	{"name":"ddisco","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/ddisco","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for DDisco\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe DDisco dataset is a dataset which can be used to train models to classify levels of coherence in danish discourse. Each entry in the dataset is annotated with a discourse coherence label (rating from 1 to 3):\n1: low coherence (difficult to understand, unorganized, contained unnecessary details and can not be summarized briefly and easily)\n2: medium coherence\n3: high coherence (easy to understand, well organized, only contain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/ddisco.","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","Danish"],"keywords_longer_than_N":true},
	{"name":"recipepairs","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lishuyang/recipepairs","creator_name":"Shuyang Li","creator_url":"https://huggingface.co/lishuyang","description":"RecipePairs dataset, originally from the 2022 EMNLP paper: \"SHARE: a System for Hierarchical Assistive Recipe Editing\" by Shuyang Li, Yufei Li, Jianmo Ni, and Julian McAuley.\nThis version (1.5.0) has been updated with 6.9M pairs of base -> target recipes, alongside their name overlap, IOU (longest common subsequence / union), and target dietary categories.\nThese cover the 459K recipes from the original GeniusKitcen/Food.com dataset.\nIf you would like to use this data or found it useful in your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lishuyang/recipepairs.","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"humaneval-rust","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/humaneval-rust","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/humaneval-rust dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","code","mit"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test2","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","Audio"],"keywords_longer_than_N":true},
	{"name":"incivility-arizona-daily-star-comments","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments","creator_name":"Civility Lab","creator_url":"https://huggingface.co/civility-lab","description":"\n\t\n\t\t\n\t\tDataset Card for incivility-arizona-daily-star-comments\n\t\n\nThis is a collection of more than 6000 comments on Arizona Daily Star news articles from 2011 that have been manually annotated for various forms of incivility including aspersion, namecalling, sarcasm, and vulgarity.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach instance in the dataset corresponds to a single comment from a single commenter.\nAn instance's text field contains the text of the comment with any quotes of other commenters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_easy_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Easy set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_medium_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Medium set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"srsd-feynman_hard_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\n\t\n\t\t\n\t\tDataset Card for SRSD-Feynman (Hard set with Dummy Variables)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy.","first_N":5,"first_N_keywords":["tabular-regression","expert","expert-generated","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"turkish-constitutional-court","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court","creator_name":"Aykut Ko√ß Lab","creator_url":"https://huggingface.co/KocLab-Bilkent","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is extracted from the following Github repo, which was created for the journal paper with URL https://www.sciencedirect.com/science/article/abs/pii/S0306457321001692.\nhttps://github.com/koc-lab/law-turk\nThe dataset includes 1290 court case decision texts from the Turkish Court of Cassation. Each sample has one label, which is the ruling of the court. The possible rulings are \"Violation\" and \"No violation\". There are 1290 samples. 1141 of these samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court.","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"skolmat","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amcoff/skolmat","creator_name":"√Öke Amcoff","creator_url":"https://huggingface.co/amcoff","description":"\n\t\n\t\t\n\t\tDataset Card for Skolmat\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/skolmat.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"UTS_Text","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/undertheseanlp/UTS_Text","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","description":"UTSText","first_N":5,"first_N_keywords":["text-generation","no-annotation","monolingual","Vietnamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikitablequestions-wtq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq","creator_name":"Dan Jarvis","creator_url":"https://huggingface.co/danwakeem","description":"\n\t\n\t\t\n\t\tDataset Card for WikiTableQuestions-wtq\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiTableQuestions-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nquestion-answering, table-question-answering\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq.","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","wikitablequestions"],"keywords_longer_than_N":true},
	{"name":"test-user","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/polinaeterna/test-user","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SpanishBFF","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMG/SpanishBFF","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSpanish-BFF is the first Spanish AI-generated dictionary using GPT3.\n\nPaper: Spanish Built Factual Freectianary (Spanish-BFF): the first IA-generated free dictionary\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSpanish-BFF contains a total of 66353 lemmas with its definitions (only one definiton per lemma).\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/SpanishBFF.","first_N":5,"first_N_keywords":["AI-generated","monolingual","Spanish","gpl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dev_mode-wtq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Serverless/dev_mode-wtq","creator_name":"Serverless Inc","creator_url":"https://huggingface.co/Serverless","description":"\n\t\n\t\t\n\t\tDataset Card for dev_mode-wtq\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dev_mode-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nquestion-answering, table-question-answering\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nen\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Serverless/dev_mode-wtq.","first_N":5,"first_N_keywords":["question-answering","crowdsourced","found","monolingual","wikitablequestions"],"keywords_longer_than_N":true},
	{"name":"recept","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amcoff/recept","creator_name":"√Öke Amcoff","creator_url":"https://huggingface.co/amcoff","description":"\n\t\n\t\t\n\t\tDataset Card for Recept\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/recept.","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"conditional-polyp-diffusion","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepsynthbody/conditional-polyp-diffusion","creator_name":"DeepSynthBody","creator_url":"https://huggingface.co/deepsynthbody","description":"\n\t\n\t\t\n\t\tDataset Card for Conditional Polyp Diffusion\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Conditional Polyp Diffusion dataset provides synthetic gastrointestinal (GI) polyp images along with segmentation masks, generated using a two-stage diffusion modeling framework. The dataset is aimed at mitigating the challenges of data scarcity and privacy in medical imaging, especially for supervised polyp segmentation tasks.\n\nStage 1: Improved diffusion model generates synthetic segmentation masks.\nStage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepsynthbody/conditional-polyp-diffusion.","first_N":5,"first_N_keywords":["expert-generated","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"poquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/poquad","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"PoQuaD description","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"comps","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kanishka/comps","creator_name":"Kanishka Misra","creator_url":"https://huggingface.co/kanishka","description":"COMPS is a dataset of minimal pair sentences in English that enables the \ntesting knowledge of concepts and their properties in language models (LMs).\nSpecifically, it tests the ability of LMs to attribute properties to everyday \nconcepts, and demonstrate reasoning compatible with property inheritance, where\nsubordinate concepts inherit the properties of their superordinate (hypernyms).","first_N":5,"first_N_keywords":["expert-generated","machine-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"faquad-nli","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of 900‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SciQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/orkg/SciQA","creator_name":"The Open Research Knowledge Graph","creator_url":"https://huggingface.co/orkg","description":"    SciQA contains 2,565 SPARQL query - question pairs along with answers fetched from the open research knowledge graph (ORKG)     via a Virtuoso SPARQL endpoint, it is a collection of both handcrafted and autogenerated questions and queries.     The dataset is split into 70% training, 10% validation and 20% test examples. The dataset is available as JSON files.","first_N":5,"first_N_keywords":["question-answering","expert-generated","auto-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"latvian-text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","description":"\n\t\n\t\t\n\t\tLatvian text dataset\n\t\n\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\n\n\t\n\t\t\n\t\tData sources used\n\t\n\n\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\nEuropean Parliament Proceedings Parallel Corpus -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|tilde_model"],"keywords_longer_than_N":true},
	{"name":"squad-sk","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUKE-DeutscheTelekom/squad-sk","creator_name":"TUKE and DTSS cooperation","creator_url":"https://huggingface.co/TUKE-DeutscheTelekom","description":"        Slovak translation of Standford Question Answering Dataset","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","extractive-qa","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"vegetable","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cc92yy3344/vegetable","creator_name":"ÈôàË∂Ö","creator_url":"https://huggingface.co/cc92yy3344","description":"\n\t\n\t\t\n\t\n\t\n\t\tËî¨ËèúÂõæÂÉèÊï∞ÊçÆÈõÜ\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tËÉåÊôØ\n\t\n\nÊúÄÂàùÁöÑÂÆûÈ™åÊòØÁî®‰∏ñÁïåÂêÑÂú∞ÂèëÁé∞ÁöÑ15ÁßçÂ∏∏ËßÅËî¨ËèúËøõË°åÁöÑ„ÄÇÂÆûÈ™åÈÄâÊã©ÁöÑËî¨ËèúÊúâÔºöË±ÜÁ±ª„ÄÅËã¶Áìú„ÄÅËë´Ëä¶„ÄÅËåÑÂ≠ê„ÄÅË•øÂÖ∞Ëä±„ÄÅÂç∑ÂøÉËèú„ÄÅËæ£Ê§í„ÄÅËÉ°ËêùÂçú„ÄÅËä±Ê§∞Ëèú„ÄÅÈªÑÁìú„ÄÅÊú®Áìú„ÄÅÂúüË±Ü„ÄÅÂçóÁìú„ÄÅËêùÂçúÂíåÁï™ËåÑ„ÄÇÂÖ±‰ΩøÁî®‰∫ÜÊù•Ëá™15‰∏™Á±ªÁöÑ21000Âº†ÂõæÂÉèÔºåÂÖ∂‰∏≠ÊØè‰∏™Á±ªÂåÖÂê´1400Âº†Â∞∫ÂØ∏‰∏∫224√ó224„ÄÅÊ†ºÂºè‰∏∫*.jpgÁöÑÂõæÂÉè„ÄÇÊï∞ÊçÆÈõÜ‰∏≠70%Áî®‰∫éÂüπËÆ≠Ôºå15%Áî®‰∫éÈ™åËØÅÔºå15%Áî®‰∫éÊµãËØï„ÄÇ\n\n\t\n\t\t\n\t\n\t\n\t\tÁõÆÂΩï\n\t\n\nÊ≠§Êï∞ÊçÆÈõÜÂåÖÂê´‰∏â‰∏™Êñá‰ª∂Â§πÔºö\n\ntrain (15000 Âº†ÂõæÂÉè)\ntest (3000 Âº†ÂõæÂÉè)\nvalidation (3000 Âº†ÂõæÂÉè)\n\n\n\t\n\t\t\n\t\n\t\n\t\tÊï∞ÊçÆÊî∂ÈõÜ\n\t\n\nËøô‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÂõæÂÉèÊòØÊàë‰ª¨‰∏∫‰∏Ä‰∏™È°πÁõÆ‰ªéËî¨ËèúÂÜúÂú∫ÂíåÂ∏ÇÂú∫Êî∂ÈõÜÁöÑ„ÄÇ\n\n\t\n\t\t\n\t\n\t\n\t\tÂà∂‰ΩúÂÖÉÊï∞ÊçÆÊñá‰ª∂\n\t\n\nËøêË°å‰∏ãÈù¢pythonÁöÑ‰ª£Á†ÅÔºåÂ∞±ÂèØ‰ª•Âú®Ê°åÈù¢ÁîüÊàê‰∏â‰∏™csvÊ†ºÂºèÁöÑÂÖÉÊï∞ÊçÆÊñá‰ª∂„ÄÅ‰∏Ä‰∏™ÂàÜÁ±ªÊï∞ÊçÆÊñá‰ª∂ÔºàÈúÄË¶ÅÊîæÂÖ•Âà∞Êï∞ÊçÆÊñá‰ª∂‰∏≠Ôºâ\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\n1.‰∏ãËΩΩÁöÑÊï∞ÊçÆÊñá‰ª∂ Vegetable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cc92yy3344/vegetable.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unarXive_imrad_clf","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_imrad_clf","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\n\t\n\t\t\n\t\tDataset Card for unarXive IMRaD classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe unarXive IMRaD classification dataset contains 530k paragraphs from computer science papers and the IMRaD section they originate from. The paragraphs are derived from unarXive.\nThe dataset can be used as follows.\nfrom datasets import load_dataset\n\nimrad_data = load_dataset('saier/unarXive_imrad_clf')\nimrad_data = imrad_data.class_encode_column('label')  # assign target label column\nimrad_data =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_imrad_clf.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unarXive_citrec","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_citrec","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\n\t\n\t\t\n\t\tDataset Card for unarXive citation recommendation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe unarXive citation recommendation dataset contains 2.5 Million paragraphs from computer science papers and with an annotated citation marker. The paragraphs and citation information is derived from unarXive.\nNote that citation infromation is only given as the OpenAlex ID of the cited paper. An important consideration for models is therefore if the data is used as is, or if additional information of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_citrec.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"aihub_corpus_expertise","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wisenut-nlp-team/aihub_corpus_expertise","creator_name":"wisenut-nlp","creator_url":"https://huggingface.co/wisenut-nlp-team","description":"\n\t\n\t\t\n\t\tDataset Card for \"corpus_professional_field\"\n\t\n\nÏ†ÑÎ¨∏Î∂ÑÏïº ÎßêÎ≠âÏπò\n","first_N":5,"first_N_keywords":["other","token-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"letras-carnaval-cadiz","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz","creator_name":"IES Rafael Alberti","creator_url":"https://huggingface.co/IES-Rafael-Alberti","description":"\n\t\n\t\t\n\t\tDataset Card for Letras Carnaval C√°diz\n\t\n\n\n\n    \n        English |\n        Espa√±ol\n    \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tChangelog\n\t\n\n\n\t\n\t\t\nRelease\nDescription\n\n\n\t\t\nv1.0\nInitial release of the dataset. Included more than 1K lyrics. It is necessary to verify the accuracy of the data, especially the subset midaccurate.\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is a comprehensive collection of lyrics from the Carnaval de C√°diz, a significant cultural heritage of the city of C√°diz, Spain. Despite its‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz.","first_N":5,"first_N_keywords":["no-annotation","machine-generated","monolingual","original","Spanish"],"keywords_longer_than_N":true},
	{"name":"janli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/janli","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"\n\t\n\t\t\n\t\tDataset Card for JaNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe JaNLI (Japanese Adversarial NLI) dataset, inspired by the English HANS dataset, is designed to necessitate an understanding of Japanese linguistic phenomena and to illuminate the vulnerabilities of models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe language data in JaNLI is in Japanese (BCP-47 ja-JP).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nWhen loading a specific configuration, users has to append a version dependent suffix:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hpprc/janli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","other","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"jomleh","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlengineer-ai/jomleh","creator_name":"ML Engineer","creator_url":"https://huggingface.co/mlengineer-ai","description":"Jomleh is a Farsi (Persian) monolingual dataset composed of one sentence per sample. It's focused on quality over quantity and it's curated mostly based on the OSCAR project (https://oscar-project.com) among other data sources.\\","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"cococon","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adymaharana/cococon","creator_name":"Adyasha Maharana","creator_url":"https://huggingface.co/adymaharana","description":"\n\t\n\t\t\n\t\tDataset Card for CoCoCON\n\t\n\n\nDataset Description\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nConsiderations for Using the Data\nLicensing Information\nCitation Information\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nCocoCON is a challenging dataset for evaluating cross-task consistency in vision-and-language models. We use contrast sets created by modifying COCO test instances for multiple tasks in small but semantically meaningful ways to change the gold label, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adymaharana/cococon.","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FLUE_VSD","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GETALP/FLUE_VSD","creator_name":" Groupe d'√âtude en Traduction Automatique/Traitement Automatis√© des Langues et de la Parole","creator_url":"https://huggingface.co/GETALP","description":"\n\t\n\t\t\n\t\tFrenchSemEval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset correspond to the FrenchSemEval, in which verb occurences where manually annotated with Wiktionary senses. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nVerb Sense Disambiguation for French verbs.  \n\n\t\n\t\t\n\t\tLanguage\n\t\n\nFrench\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance of the dataset has the following fields and these following types of field. \n{\n  \"document_id\": \"d001\",\n  \"sentence_id\": \"d001.s001\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GETALP/FLUE_VSD.","first_N":5,"first_N_keywords":["other","word-sense-disambiguation","monolingual","French","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"ru_goemotions","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Djacon/ru_goemotions","creator_name":"Daniel","creator_url":"https://huggingface.co/Djacon","description":"\n\t\n\t\t\n\t\tDataset Card for GoEmotions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe RuGoEmotions dataset contains 34k Reddit comments labeled for 9 emotion categories (joy, interest, surprice, sadness, anger, disgust, fear, guilt and neutral).\nThe dataset already with predefined train/val/test splits\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class, multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Djacon/ru_goemotions.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"NewQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/badokorach/NewQA","creator_name":"brenda Adokorach","creator_url":"https://huggingface.co/badokorach","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/badokorach/NewQA.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enriched","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\nThis version is not yet supported.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cifar100-enriched","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/cifar100-enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images\nper class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses.\nThere are two labels per image - fine label (actual class) and coarse label (superclass).","first_N":5,"first_N_keywords":["image-classification","crowdsourced","found","monolingual","extended|other-80-Million-Tiny-Images"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_mc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_mc","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"TruthfulQA-MC is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_binary","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_binary","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"TruthfulQA-Binary is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\n\t\n\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 2,000 instances with fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"peewee-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akumoth/peewee-issues","creator_name":"Rainer Palm","creator_url":"https://huggingface.co/akumoth","description":"\n\t\n\t\t\n\t\tDataset Card for Peewee Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPeewee Issues is a dataset containing all the issues in the Peewee github repository up to the last date of extraction (5/3/2023). It has been made for educational purposes in mind (especifically, to get me used to using Hugging Face's datasets), but can be used for multi-label classification or semantic search. The contents are all in English and concern SQL databases and ORM libraries.\n","first_N":5,"first_N_keywords":["text-classification","feature-extraction","topic-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"turkish-wikiNER","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/turkish-wikiNER","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for \"turkish-nlp-suite/turkish-wikiNER\"\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkish NER dataset from Wikipedia sentences. 20.000 sentences are sampled and re-annotated from Kuzgunlar NER dataset.\nAnnotations are done by Co-one. Many thanks to them for their contributions. This dataset is also used in our brand new spaCy Turkish packages.\n\n\t\n\t\t\n\t\tDataset Instances\n\t\n\nAn instance of this dataset looks as follows:\n{\n\"tokens\": [\"√áekimler\", \"5\", \"Temmuz\", \"2005\", \"tarihinde\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/turkish-wikiNER.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Turkish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Corona-mini","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/Corona-mini","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for turkish-nlp-suite/Corona-mini\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a tiny Turkish corpus consisting of comments about Corona symptoms. The corpus is compiled from two Ek≈üis√∂zl√ºk headlines \"covid-19 belirtileri\" and \"g√ºn g√ºn koronavir√ºs belirtileri\": \nhttps://eksisozluk.com/covid-19-belirtileri--6416646  \nhttps://eksisozluk.com/gun-gun-koronavirus-belirtileri--6757665\nThis corpus \n\ncontains 178 raw, 175 processed comments\nall comments are in Turkish\ncomes in 2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/Corona-mini.","first_N":5,"first_N_keywords":["summarization","monolingual","Turkish","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"beyazperde-top-300-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-top-300-movie-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for turkish-nlp-suite/beyazperde-top-300-movie-reviews\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBeyazperde Movie Reviews offers Turkish sentiment analysis datasets that is scraped from popular movie reviews website Beyazperde.com. Top 300 Movies include audience reviews about best 300 movies of all the time. Here's the star rating distribution:\n\n\t\n\t\t\nstar rating\ncount\n\n\n\t\t\n0.5\n101\n\n\n1.0\n39\n\n\n1.5\n19\n\n\n2.0\n44\n\n\n2.5\n210\n\n\n3.0\n196\n\n\n3.5\n490\n\n\n4.0\n1212\n\n\n4.5\n818\n\n\n5.0\n1251\n\n\ntotal\n4380‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-top-300-movie-reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","monolingual","Turkish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"dialogsum-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/dialogsum-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding manually labeled summaries and topics.\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/dialogsum-ru.","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"edgar-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/c3po-ai/edgar-corpus","creator_name":"C3PO-AI","creator_url":"https://huggingface.co/c3po-ai","description":"The dataset contains annual filings (10K) of all publicly traded firms from 1993-2020. The table data is stripped but all text is retained.\nThis dataset allows easy access to the EDGAR-CORPUS dataset based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round (See References in README.md for details).","first_N":5,"first_N_keywords":["other","no-annotation","other","monolingual","extended|other"],"keywords_longer_than_N":true},
	{"name":"utcd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/claritylab/utcd","creator_name":"Clarity Lab (University of Michigan)","creator_url":"https://huggingface.co/claritylab","description":"UTCD is a compilation of 18 classification datasets spanning 3 categories of Sentiment, \nIntent/Dialogue and Topic classification. UTCD focuses on the task of zero-shot text classification where the \ncandidate labels are descriptive of the text being classified. UTCD consists of ~ 6M/800K train/test examples.","first_N":5,"first_N_keywords":["text-classification","no-annotation","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/orionweller/NevIR","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","description":"\n\t\n\t\t\n\t\tDataset Card for NevIR: Negation in Neural Information Retrieval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nData from the paper: \"NevIR: Negation in Neural Information Retrieval\". \nIf you use this dataset, we would appreciate you citing our work:\n@inproceedings{weller-et-al-2023-nevir,\n  title={NevIR: Negation in Neural Information Retrieval},\n  author={Weller, Orion and Lawrie, Dawn, and Van Durme, Benjamin},\n  year={2023},\n  eprint={2305.07614},\n  archivePrefix={arXiv},\n  year={2023}\n}\n\nPlease‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/NevIR.","first_N":5,"first_N_keywords":["crowdsourced","monolingual","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog-filtered","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered","creator_name":"Josh Oliver","creator_url":"https://huggingface.co/Englishman2022","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialogFiltered is a filtered version of the ProsocialDialog dataset.\nMultiple versions are present:\n\nIn train_no_casual, rows with the label \"casual\" have been filtered out as a starting point.\nIn train_no_possibly, rows with \"possibly needs caution\" have been filtered out.\nIn train_no_probably, rows with \"probably needs caution\" have been filtered out, as I found those to be largely pointless as well, leaving only \"needs caution\" and \"needs intervention\".‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered.","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lighteval/mmlu","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","description":"This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FOCAL","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adsabs/FOCAL","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","description":"\n\t\n\t\t\n\t\tFunction Of Citation in Astrophysics Literature (FOCAL): Dataset and Task\n\t\n\nCan you explain why the authors made a given citation?\nThis dataset was created as a shared task for WIESP @ AACL-IJCNLP 2023.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDatasets are in JSON Lines format (each line is a json dictionary).  \nEach entry consists of a dictionary with the following keys:\n\n\"Identifier\": unique string to identify the entry\n\"Paragraph\": text string from an astrophysics paper \n\"Citation Text\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/FOCAL.","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"turkish-thesaurus-synonyms-antonyms","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agmmnn/turkish-thesaurus-synonyms-antonyms","creator_name":"agmmnn","creator_url":"https://huggingface.co/agmmnn","description":"\n\t\n\t\t\n\t\tTurkish Thesaurus (T√ºrk√ße E≈ü-Zƒ±t Anlam S√∂zl√ºƒü√º)\n\t\n\nTurkish synonym, antonym thesaurus. Final thesaurus contains 33587 keys in total.\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"agmmnn/turkish-thesaurus-synonyms-antonyms\")\n\nprint(dataset['train'][0])\n\n","first_N":5,"first_N_keywords":["monolingual","Turkish","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"clinic150-sur","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/clinic150-sur","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"dataset_info:\n  features:\n\nname: intent\ndtype: string\nname: user_utterance\ndtype: string\nname: origin\ndtype: string\n\n\n\t\n\t\t\n\t\tDataset Card for \"clinic150-SUR\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Clinic150-SUR dataset is a novel and augmented dataset designed to simulate natural human behavior during interactions with customer service-like centers.\nExtending the Clinic150 dataset, it incorporates two augmentation techniques, including IBM's LAMBADA and Parrot models and carefully curated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/clinic150-sur.","first_N":5,"first_N_keywords":["text-classification","monolingual","extended|clinic150","English","mit"],"keywords_longer_than_N":true},
	{"name":"CaSET-catalan-stance-emotions-twitter","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for CaSET, the Catalan Stance and Emotions Dataset from Twitter\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CaSET dataset is a Catalan corpus of Tweets annotated with Emotions, Static Stance, and Dynamic Stance. The dataset contains 11k unique sentences on five controversial topics, grouped in 6k pairs of sentences, paired as parent messages and replies to these messages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to train models for emotion detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter.","first_N":5,"first_N_keywords":["text-classification","Barcelona Supercomputing Center","Twitter","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"CaSERa-catalan-stance-emotions-raco","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for CaSERa, the Catalan Stance and Emotions Dataset from Rac√≥ Catal√†\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CaSERa dataset is a Catalan corpus from the forum Rac√≥ Catal√† annotated with Emotions and Dynamic Stance. The dataset contains 15.782 unique sentences grouped in 10.745 pairs of sentences, paired as parent messages and replies to these messages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to train models for emotion detection and dynamic stance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco.","first_N":5,"first_N_keywords":["text-classification","Barcelona Supercomputing Center","Rac√≥ Catal√†","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"internal-datasets","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Marbyun/internal-datasets","creator_name":"Ivan Rivaldo Marbun","creator_url":"https://huggingface.co/Marbyun","description":"SynQA is a Reading Comprehension dataset created in the work \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\" (https://aclanthology.org/2021.emnlp-main.696/).\nIt consists of 314,811 synthetically generated questions on the passages in the SQuAD v1.1 (https://arxiv.org/abs/1606.05250) training set.\n\nIn this work, we use a synthetic adversarial data generation to make QA models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA (https://adversarialqa.github.io/) dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation to show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8% of the time on average, compared to 17.6% for a model trained without synthetic data.\n\nFor full details on how the dataset was created, kindly refer to the paper.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","generated","found"],"keywords_longer_than_N":true},
	{"name":"SOTAB","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shivangibithel/SOTAB","creator_name":"Shivangi Bithel","creator_url":"https://huggingface.co/shivangibithel","description":"# Understanding the semantics of table elements is a prerequisite for many data integration and data discovery tasks. Table annotation is the task of labeling table elements with terms from a given vocabulary. This paper presents the WDC Schema.org Table Annotation Benchmark (SOTAB) for comparing the performance of table annotation systems. SOTAB covers the column type annotation (CTA) and columns property annotation (CPA) tasks. SOTAB provides ‚àº50,000 annotated tables for each of the tasks containing Schema.org data from different websites. The tables cover 17 different types of entities such as movie, event, local business, recipe, job posting, or product. The tables stem from the WDC Schema.org Table Corpus which was created by extracting Schema.org annotations from the Common Crawl. Consequently, the labels used for annotating columns in SOTAB are part of the Schema.org vocabulary. The benchmark covers 91 types for CTA and 176 properties for CPA distributed across textual, numerical and date/time columns. The tables are split into fixed training, validation and test sets. The test sets are further divided into subsets focusing on specific challenges, such as columns with missing values or different value formats, in order to allow a more fine-grained comparison of annotation systems. The evaluation of SOTAB using Doduo and TURL shows that the benchmark is difficult to solve for current state-of-the-art systems.\n#","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"ptparl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes.","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"HC3-ru","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/HC3-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDataset Card for \"HC3-ru\"\n\t\n\nThis is translated version of Hello-SimpleAI/HC3 dataset into Russian.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nCheckout this papaer arxiv: 2301.07597\n@article{guo-etal-2023-hc3,\n    title = \"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection\",\n    author = \"Guo, Biyang  and\n      Zhang, Xin  and\n      Wang, Ziyuan  and\n      Jiang, Minqi  and\n      Nie, Jinran  and\n      Ding, Yuxuan  and\n      Yue, Jianwei  and\n      Wu, Yupeng\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/HC3-ru.","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","zero-shot-classification","translated"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/hh-rlhf-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDataset Card for \"hh-rlhf-ru\"\n\t\n\nThis is translated version of Anthropic/hh-rlhf dataset into Russian.\n","first_N":5,"first_N_keywords":["translated","monolingual","Anthropic/hh-rlhf","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"synthetic-instruct-gptj-pairwise-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/synthetic-instruct-gptj-pairwise-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDataset Card for \"synthetic-instruct-gptj-pairwise-ru\"\n\t\n\nThis is translated version of Dahoas/synthetic-instruct-gptj-pairwise dataset into Russian.\n","first_N":5,"first_N_keywords":["translated","monolingual","Dahoas/synthetic-instruct-gptj-pairwise","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"rlhf-reward-datasets-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rlhf-reward-datasets-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDataset Card for \"rlhf-reward-datasets-ru\"\n\t\n\nThis is translated version of yitingxie/rlhf-reward-datasets dataset into Russian.\n","first_N":5,"first_N_keywords":["translated","monolingual","yitingxie/rlhf-reward-datasets","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ImageNet-AB","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coallaoh/ImageNet-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","description":"\n\t\n\t\t\n\t\tGeneral Information\n\t\n\nTitle: ImageNet-AB\nDescription: ImageNet-AB is an extended version of the ImageNet-1K training set, enriched with annotation byproducts (AB).\nIn addition to the image and corresponding class labels, this dataset provides a rich history of interactions per input signal per front-end component during the annotation process.\nThey include mouse traces, click locations, annotation times, as well as anonymised worker IDs.\nLinks:\n\nICCV'23 Paper\nMain Repository\nImageNet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/ImageNet-AB.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","monolingual","https://huggingface.co/datasets/imagenet-1k"],"keywords_longer_than_N":true},
	{"name":"COCO-AB","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coallaoh/COCO-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","description":"\n\t\n\t\t\n\t\tGeneral Information\n\t\n\nTitle: COCO-AB\nDescription: \nThe COCO-AB dataset is an extension of the COCO 2014 training set, enriched with additional annotation byproducts (AB). \nThe data includes 82,765 reannotated images from the original COCO 2014 training set. \nIt has relevance in computer vision, specifically in object detection and location. \nThe aim of the dataset is to provide a richer understanding of the images (without extra costs) by recording additional actions and interactions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/COCO-AB.","first_N":5,"first_N_keywords":["image-classification","crowdsourced","monolingual","https://huggingface.co/datasets/HuggingFaceM4/COCO","English"],"keywords_longer_than_N":true},
	{"name":"COPA-ca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/COPA-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for COPA-ca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe COPA-ca dataset (Choice of plausible alternatives in Catalan) is a professional translation of the English COPA dataset into Catalan, commissioned by BSC LangTech Unit. The dataset consists of 1000 premises, each given a question and two choices with a label encoding which of the choices is more plausible given the annotator.\nThe dataset is split into 400 training samples, 100 validation samples, and 500 test samples. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/COPA-ca.","first_N":5,"first_N_keywords":["natural-language-inference","professional translators","monolingual","Catalan","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"curation-corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/curation-corpus","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tcuration-corpus\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nData from this official repo with downloaded news articles content.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{curationcorpusbase:2020,\n  title={Curation Corpus Base},\n  author={Curation},\n  year={2020}\n}\n\n","first_N":5,"first_N_keywords":["summarization","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"curation-corpus-ru","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/curation-corpus-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tcuration-corpus-ru\n\t\n\nTranslated version of d0rj/curation-corpus into Russian.\n","first_N":5,"first_N_keywords":["summarization","translated","monolingual","d0rj/curation-corpus","Russian"],"keywords_longer_than_N":true},
	{"name":"snli-zh","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/snli-zh","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English\nsentence pairs manually labeled for balanced classification with the labels\nentailment, contradiction, and neutral, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"nli-zh-all","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli-zh-all","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"mnist-outlier","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/mnist-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for \"mnist-outlier\"\n\t\n\nüìö This dataset is an enriched version of the MNIST Dataset.\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\n\n\t\n\t\t\n\t\tExplore the Dataset\n\t\n\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/mnist-outlier.\n\nOr you can explorer it locally:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/mnist-outlier.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-ru","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/alpaca-cleaned-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\talpaca-cleaned-ru\n\t\n\nTranslated version of yahma/alpaca-cleaned into Russian.\n","first_N":5,"first_N_keywords":["text-generation","translated","monolingual","yahma/alpaca-cleaned","Russian"],"keywords_longer_than_N":true},
	{"name":"beans-outlier","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/beans-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for \"beans-outlier\"\n\t\n\nüìö This dataset is an enhancved version of the ibean project of the AIR lab.\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\n\n\t\n\t\t\n\t\tExplore the Dataset\n\t\n\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/beans-outlier\n\nOr you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/beans-outlier.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"AMIsum","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TalTechNLP/AMIsum","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","description":"\n\t\n\t\t\n\t\tDataset Card for \"AMIsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAMIsum is meeting summaryzation dataset based on the AMI Meeting Corpus (https://groups.inf.ed.ac.uk/ami/corpus/). The dataset utilizes the transcripts as the source data and abstract summaries as the target data.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{'transcript': '<PM> Okay. <PM> Right. <PM> Um well this is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/AMIsum.","first_N":5,"first_N_keywords":["summarization","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"rudetoxifier_data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\trudetoxifier_data\n\t\n\nHuggingface copy of Github repo with dataset.\n","first_N":5,"first_N_keywords":["text-classification","monolingual","original","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"rudetoxifier_data_detox","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data_detox","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\trudetoxifier_data_detox\n\t\n\nThis is subset of toxic comments from d0rj/rudetoxifier_data which has detoxified column created by s-nlp/ruT5-base-detox.\n","first_N":5,"first_N_keywords":["monolingual","d0rj/rudetoxifier_data","Russian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"livingner1","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/livingner1","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\n\t\n\t\t\n\t\tLivingNER\n\t\n\nThis is a third party reupload of the LivingNER task 1 dataset.\nIt only contains the task 1 for the Spanish language. It does not include the multilingual data nor the background data.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner1.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"livingner3","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/livingner3","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\n\t\n\t\t\n\t\tLivingNER\n\t\n\nThis is a third party reupload of the LivingNER task 3 dataset.\nIt only contains the task 3 for the Spanish language. It does not include the multilingual data nor the background data.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner3.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dane_plus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KennethEnevoldsen/dane_plus","creator_name":"Kenneth C. Enevoldsen","creator_url":"https://huggingface.co/KennethEnevoldsen","description":"\n\t\n\t\t\n\t\tDaNE+\n\t\n\nThis is a version of DaNE, where the original NER labels have been updated to follow the ontonotes annotation scheme. The annotation process used the model trained on the Danish dataset DANSK for the first round of annotation and then all the discrepancies were manually reviewed and corrected by Kenneth C. Enevoldsen. A discrepancy include notably also includes newly added entities such as PRODUCT and WORK_OF_ART. Thus in practice a great deal of entities were manually‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KennethEnevoldsen/dane_plus.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","part-of-speech","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"quickdraw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Xenova/quickdraw","creator_name":"Joshua","creator_url":"https://huggingface.co/Xenova","description":"\n\t\n\t\t\n\t\tDataset Card for Quick, Draw!\n\t\n\nThis is a processed version of Google's Quick, Draw dataset to be compatible with the latest versions of ü§ó Datasets that support .parquet files. NOTE: this dataset only contains the \"preprocessed_bitmaps\" subset of the original dataset.\n","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"socialdisner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/socialdisner","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\n\t\n\t\t\n\t\tSocialDisNER\n\t\n\nThis is a third party reupload of the SocialDisNER dataset.\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{10.1093/jamia/ocae054,\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez Fern√°ndez, Paloma},\n    title = {A comparative analysis of Spanish Clinical encoder-based models on NER and classification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/socialdisner.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\taudiocaps\n\t\n\nHuggingFace mirror of official data repo.\n","first_N":5,"first_N_keywords":["text-to-speech","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"audiocaps-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\taudiocaps-ru\n\t\n\nTranslated version of d0rj/audiocaps into Russian.\n","first_N":5,"first_N_keywords":["text-to-speech","translated","monolingual","d0rj/audiocaps","Russian"],"keywords_longer_than_N":true},
	{"name":"samromur_synthetic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OV_Text","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/duyhngoc/OV_Text","creator_name":"Duy Huynh","creator_url":"https://huggingface.co/duyhngoc","description":"OVText","first_N":5,"first_N_keywords":["text-generation","no-annotation","monolingual","Vietnamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SeeTRUE","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yonatanbitton/SeeTRUE","creator_name":"Yonatan","creator_url":"https://huggingface.co/yonatanbitton","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SeeTRUE\n\t\n\n\nDataset Description\nSupported Tasks and Leaderboards\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nLicensing Information\nCitation Information\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe SeeTRUE dataset is a diverse benchmark for meta-evaluation of image-text alignment methods, covering the 4-way combinations of real and synthetic text-and-image pairs. It addresses limitations in current benchmarks, which mainly focus on natural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yonatanbitton/SeeTRUE.","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Stevross/mmlu","creator_name":"Stephen Davies","creator_url":"https://huggingface.co/Stevross","description":"This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"negation-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinaai/negation-dataset","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","description":"\n\n\n\n\n\n\nThe data offered by Jina AI, Finetuner team.\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is an English-language dataset based on the SNLI dataset.\nIt contains negations of samples from SNLI.\n\n\t\n\t\t\n\t\tInstances\n\t\n\nEach data point consists of a triplet ('anchor', 'entailment', 'negative') of strings, where ('anchor', 'entailment') are positive pairs\ntaken from SNLI, and 'negative' contradicts  both 'anchor' and 'entailment'.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\n'anchor': string, some statement\n'entailment': string, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/negation-dataset.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tlunified-ner","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ljvmiranda921/tlunified-ner","creator_name":"Lj V. Miranda","creator_url":"https://huggingface.co/ljvmiranda921","description":"\n\t\n\t\t\n\t\tü™ê spaCy Project: TLUnified-NER Corpus\n\t\n\n\nHomepage: Github\nRepository: Github\nPoint of Contact: ljvmiranda@gmail.com\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the annotated TLUnified corpora from Cruz and Cheng\n(2021).  It is a curated sample of around 7,000 documents for the\nnamed entity recognition (NER) task.  The majority of the corpus are news\nreports in Tagalog, resembling the domain of the original ConLL 2003.  There\nare three entity types: Person (PER), Organization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ljvmiranda921/tlunified-ner.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","monolingual","Tagalog"],"keywords_longer_than_N":true},
	{"name":"skb","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/min9805/skb","creator_name":"min","creator_url":"https://huggingface.co/min9805","description":"min9805/skb dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","token-classification"],"keywords_longer_than_N":true},
	{"name":"MKB_Hindi_2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023","creator_name":"Rashmi Singh","creator_url":"https://huggingface.co/rashmi035","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023.","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/OpenOrca-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tOpenOrca-ru\n\t\n\nThis is translated version of Open-Orca/OpenOrca into Russian.\n","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hl-narratives","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michelecafagna26/hl-narratives","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","description":"\n\t\n\t\t\n\t\tDataset Card for the High-Level Narratives Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe High-Level Narratives (HL-Narratives) dataset aligns object-centric descriptions from COCO \nwith synthetic high-level narratives captions automatically generated by merging scene, action, rationale captions from the HL Dataset using T5\nThe HL-Naratives dataset contains 14997 images from COCO and a total of 134973 synthetic captions (3 captions per image) aligned with ~749984 object-centric captions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl-narratives.","first_N":5,"first_N_keywords":["image-to-text","question-answering","zero-shot-classification","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"wikipedia_tw","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikipedia_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"Ë¶ÅÊêûËá™Â∑±ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÊúÄÂü∫Êú¨ÁöÑÂü∫Êú¨ÔºåÂ∞±ÊòØÈúÄË¶Å‰∏ÄÂ§ßÂ†ÜÊñáÂ≠óË≥áÊñôÔºåÂæû Common Crawl ‰∏äÈ†≠ÊäìÂõû‰æÜÊÖ¢ÊÖ¢Ê∏ÖÊ¥óÊòØ‰∏ÄÊ¢ùË∑ØÔºåÊ∏ÖÊ¥óÁ∂≠Âü∫ÁôæÁßëÁ∂≤Á´ôÁöÑÈÄ±ÊúüÊÄß‰∏ãËºâÊ™î‰πüÊòØ‰∏ÄÂÄãÊñπÊ≥ï„ÄÇÊú¨Ë≥áÊñôÈõÜÊòØËß£ÊûêËá™Á∂≠Âü∫ÁôæÁßëÊñº 20250401 ÁôºÂ∏ÉÁöÑÁπÅÈ´î‰∏≠ÊñáÁâàÊâìÂåÖÊ™î bz2 Ê™îÊ°àÁöÑÂÖßÂÆπÔºåÂú®Ëß£ÊûêÂá∫ÊâÄÈúÄÂÖßÂÆπÂæåÔºåÂà©Áî® wikitextparser ÁßªÈô§ Wiki Ê®ôË®ò„ÄÇËß£ÊûêÂæå‰øùÁïôÁöÑÊ¨Ñ‰ΩçÊúâÂÖ©ÂÄãÔºöÊ¢ùÁõÆÂêçÁ®±ÔºàtitleÔºâÔºåÊ¢ùÁõÆÂÖßÂÆπÔºàpage articleÔºâ„ÄÇ\nÂéüÂßãÁöÑÊâìÂåÖÊ™îÊ¢ùÁõÆÂÖßÂÆπÁ∞°ÁπÅÊ∑∑ÈõúÔºåÊâÄ‰ª•ÊúâÂà©Áî® OpenCC ÈÄ≤Ë°åÁ∞°ËΩâÁπÅËôïÁêÜ„ÄÇ\n\nÂÖ®ÈÉ® 4,635,681 ÂÄãÊ¢ùÁõÆ\nÂÖ®ÈÉ® 1,471,195 ÂÄãÊ¢ùÁõÆÊ®ôÈ°å\nÁÑ°Ê≥ïËá™ÂãïÂéªÊ®ôË®òÁöÑÊ¢ùÁõÆÊï∏: 3,164,486\nÊúâÂÖßÂÆπÁöÑÊ¢ùÁõÆÊï∏: 1,471,195\n\nÂõ†ÁÇ∫Êú¨Ë≥áÊñôÈõÜÂÖßÂÆπÈæêÂ§ßÔºåË¶ÅÂ°ûÈÄ≤‰∏ÄËà¨ÁöÑÂÄã‰∫∫ÈõªËÖ¶‰∏≠ÈÄ≤Ë°åË®àÁÆóÔºåÊÅêÊÄïÊúÉÊúâË≥áÊ∫ê‰∏çË∂≥ÁöÑÊÉÖÂΩ¢„ÄÇÂª∫Ë≠∞‰ΩøÁî®parquetÊ†ºÂºè‰∏ãËºâ‰ΩøÁî®„ÄÇ\nË≥áÊñôÈõÜÁï∂‰∏≠Êúâ‰∏çÂ∞ëÂÖßÂÆπÁÇ∫ #REDIRECT ÁöÑÊ¢ùÁõÆÂ∑≤Á∂ìÂòóË©¶ÁßªÈô§ÔºåÂ¶ÇÊûúÁßªÈô§ÁöÑ‰∏ç‰πæÊ∑®ÔºåÂ∞±Á≠â‰ª•ÂæåÊúâÁ©∫Êé®Âá∫‰øÆÊ≠£ÁâàÂÜç‰æÜÊ∏ÖÊ¥ó‰∫Ü„ÄÇ\n","first_N":5,"first_N_keywords":["monolingual","wikipedia","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dolphin-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/dolphin-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tDolphin-ru üê¨\n\t\n\nThis is translated version of ehartford/dolphin into Russian.\n","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"xwinograd_fr_prompt_coreference","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\txwinograd_fr_prompt_coreference\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nxwinograd_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 830 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset xwinograd by Muennighoff where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference.","first_N":5,"first_N_keywords":["found","found","monolingual","xwinograd","French"],"keywords_longer_than_N":true},
	{"name":"wino_x_fr_prompt_coreference","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\twino_x_fr_prompt_coreference\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwino_x_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 27,930 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset wino_x by Emelin et al. where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference.","first_N":5,"first_N_keywords":["found","found","monolingual","wino_x","French"],"keywords_longer_than_N":true},
	{"name":"allocine_fr_prompt_sentiment_analysis","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tallocine_fr_prompt_sentiment_analysis\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nallocine_fr_prompt_sentiment_analysis is a subset of the Dataset of French Prompts (DFP).It contains 5,600,000 rows that can be used for a binary sentiment analysis task.The original data (without prompts) comes from the dataset allocine by Blard.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis.","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","allocine"],"keywords_longer_than_N":true},
	{"name":"universal_dependencies_fr_gsd_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tuniversal_dependencies_fr_gsd_fr_prompt_pos\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nuniversal_dependencies_fr_gsd_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 343,161 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French gsd split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos.","first_N":5,"first_N_keywords":["token-classification","found","found","monolingual","universal_dependencies_fr_gsd"],"keywords_longer_than_N":true},
	{"name":"universal_dependencies_fr_partut_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tuniversal_dependencies_fr_partut_fr_prompt_pos\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nuniversal_dependencies_fr_partut_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 21,420 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French parput split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos.","first_N":5,"first_N_keywords":["token-classification","found","found","monolingual","universal_dependencies_fr_partut"],"keywords_longer_than_N":true},
	{"name":"universal_dependencies_fr_spoken_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tuniversal_dependencies_fr_spoken_fr_prompt_pos\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nuniversal_dependencies_fr_spoken_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 58,926 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French spoken split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos.","first_N":5,"first_N_keywords":["token-classification","found","found","monolingual","universal_dependencies_fr_spoken"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent_fr_prompt_intent_classification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tamazon_massive_intent_fr_prompt_intent_classification\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\namazon_massive_intent_fr_prompt_intent_classification is a subset of the Dataset of French Prompts (DFP).It contains 555,000 rows that can be used for an intent text classification task.The original data (without prompts) comes from the dataset amazon_massive_intent_fr-FR by FitzGerald et al..\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification.","first_N":5,"first_N_keywords":["text-classification","found","found","monolingual","amazon_massive_intent"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tgsm8k-ru\n\t\n\nTranslated version of gsm8k dataset into Russian.\n","first_N":5,"first_N_keywords":["crowdsourced","translated","monolingual","gsm8k","Russian"],"keywords_longer_than_N":true},
	{"name":"text2image-multi-prompt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt","creator_name":"JohnTeddy3","creator_url":"https://huggingface.co/JohnTeddy3","description":"###ËΩ¨ËΩΩ pszemraj/text2image-multi-prompt\n\n\t\n\t\t\n\t\ttext2image multi-prompt(s): a dataset collection\n\t\n\n\ncollection of several text2image prompt datasets\ndata was cleaned/normalized with the goal of removing \"model specific APIs\" like the \"--ar\" for Midjourney and so on\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\n\n\n\t\n\t\t\n\t\tcontents\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'src_dataset'],\n        num_rows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt.","first_N":5,"first_N_keywords":["monolingual","bartman081523/stable-diffusion-discord-prompts","succinctly/midjourney-prompts","Gustavosta/Stable-Diffusion-Prompts","English"],"keywords_longer_than_N":true},
	{"name":"ciempiess_light","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_light\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\nCIEMPIESS LIGHT is \"light\" because it doesn't include much of the files of the first version of CIEMPIESS and it is \"enhanced\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_balance","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_balance\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \"Balance\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_fem","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_fem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_complementary","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_complementary\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more particular‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"my-issues-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devopsmarc/my-issues-dataset","creator_name":"Marcello Barretto","creator_url":"https://huggingface.co/devopsmarc","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary in English\n\t\n\nThis customized dataset is made of a corpus of commun Github issues, typically utilized for tracking bugs or features within a repositories. This self-constructed corpus can serve multiple purposes, such as analyzing the time taken to resolve open issues or pull requests, training a classifier to tag issues based on their descriptions (e.g., \"bug,\" \"enhancement,\" \"question\"), or developing a semantic search engine‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devopsmarc/my-issues-dataset.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"bengali_asr_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"wikisource_tw","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikisource_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"Êú¨Ë≥áÊñôÈõÜÊòØËß£ÊûêËá™Á∂≠Âü∫ÊñáÂ∫´Êñº 20250601 ÁôºÂ∏ÉÁöÑÊâìÂåÖÊ™î bz2 Ê™îÊ°àÁöÑÂÖßÂÆπÔºåÂú®Ëß£ÊûêÂá∫ÊâÄÈúÄÂÖßÂÆπÂæåÔºåÂà©Áî® wikitextparser ÁßªÈô§ Wiki Ê®ôË®ò„ÄÇËß£ÊûêÂæå‰øùÁïôÁöÑÊ¨Ñ‰ΩçÊúâÂÖ©ÂÄãÔºöÊ¢ùÁõÆÂêçÁ®±ÔºàtitleÔºâÔºåÊ¢ùÁõÆÂÖßÂÆπÔºàpage articleÔºâ„ÄÇ\nÂéüÂßãÁöÑÊâìÂåÖÊ™îÊ¢ùÁõÆÂÖßÂÆπÁ∞°ÁπÅÊ∑∑ÈõúÔºåÊâÄ‰ª•ÊúâÂà©Áî® OpenCC ÈÄ≤Ë°åÁ∞°ËΩâÁπÅËôïÁêÜ„ÄÇ\n\nÂÖ®ÈÉ® 1,113,675 ÂÄãÊ¢ùÁõÆ\nÂÖ®ÈÉ® 417,746 ÂÄãÊ¢ùÁõÆÊ®ôÈ°å\nÁÑ°Ê≥ïËá™ÂãïÂéªÊ®ôË®òÁöÑÊ¢ùÁõÆÊï∏:695,929\nÊúâÂÖßÂÆπÁöÑÊ¢ùÁõÆÊï∏: 417,746\n\nÂõ†ÁÇ∫Êú¨Ë≥áÊñôÈõÜÂÖßÂÆπÈæêÂ§ßÔºåË¶ÅÂ°ûÈÄ≤‰∏ÄËà¨ÁöÑÂÄã‰∫∫ÈõªËÖ¶‰∏≠ÈÄ≤Ë°åË®àÁÆóÔºåÊÅêÊÄïÊúÉÊúâË≥áÊ∫ê‰∏çË∂≥ÁöÑÊÉÖÂΩ¢„ÄÇÂª∫Ë≠∞‰ΩøÁî®parquetÊ†ºÂºè‰∏ãËºâ‰ΩøÁî®„ÄÇ\nË≥áÊñôÈõÜÁï∂‰∏≠Êúâ‰∏çÂ∞ëÂÖßÂÆπÁÇ∫„Äå#REDIRECT„ÄçÊàñÊòØ„Äå#ÈáçÂÆöÂêë„ÄçÁöÑÊ¢ùÁõÆÔºåÂ∑≤Á∂ìÂü∫Êú¨‰∏äÊéíÈô§‰∫ÜÔºå‰ΩÜÂè¶Â§ñ‰πüÊúâÂÖßÊñáÁÇ∫Á©∫ÁôΩÁöÑÊ≤íËôïÁêÜÂà∞ÔºåÂ∞±Á≠â‰ª•ÂæåÊúâÁ©∫Êé®Âá∫‰øÆÊ≠£ÁâàÂÜç‰æÜÊ∏ÖÊ¥ó‰∫Ü„ÄÇ\n","first_N":5,"first_N_keywords":["monolingual","wikisource","Chinese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"central_de_fatos","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","description":"\n\t\n\t\t\n\t\tCentral de Fatos\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking agencies.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos.","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"pubmed_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/highnote/pubmed_qa","creator_name":"Highnote Health, Inc.","creator_url":"https://huggingface.co/highnote","description":"PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\nstatins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\nPubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\nEach PubMedQA instance is composed of (1) a question which is either an existing research article\ntitle or derived from one, (2) a context which is the corresponding abstract without its conclusion,\n(3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\nand (4) a yes/no/maybe answer which summarizes the conclusion.\nPubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\nquantitative contents, is required to answer the questions.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"RSNA-ATD2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ziq/RSNA-ATD2023","creator_name":"ziq","creator_url":"https://huggingface.co/ziq","description":"The dataset is the processed version of Kaggle Competition: RSNA 2023 Abdominal Trauma Detection.\nIt comprises of segmentation of 205 series of CT scans with 5 classes (liver, spleen, right_kidney, \nleft_kidney, bowel).","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","other","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"orange_sum_fr_prompt_fill_mask","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\torange_sum_fr_prompt_fill_mask\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\norange_sum_fr_prompt_fill_mask is a subset of the Dataset of French Prompts (DFP).It contains 585,624 rows that can be used for a fill mask task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask.","first_N":5,"first_N_keywords":["fill-mask","found","found","monolingual","orange_sum"],"keywords_longer_than_N":true},
	{"name":"orange_sum_fr_prompt_summarization","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\torange_sum_fr_prompt_summarization\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\norange_sum_fr_prompt_summarization is a subset of the Dataset of French Prompts (DFP).It contains 683,228 rows that can be used for a summary task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization.","first_N":5,"first_N_keywords":["summarization","found","found","monolingual","orange_sum"],"keywords_longer_than_N":true},
	{"name":"orange_sum_fr_prompt_text_generation_from_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\torange_sum_fr_prompt_text_generation_from_an_article\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\norange_sum_fr_prompt_text_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 539,400 rows that can be used for a text generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","orange_sum"],"keywords_longer_than_N":true},
	{"name":"orange_sum_fr_prompt_text_generation_from_title_of_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\torange_sum_fr_prompt_text_generation_from_title_of_an_article\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\norange_sum_fr_prompt_text_generation_from_title_of_an_article is a subset of the Dataset of French Prompts (DFP).It contains 908,793 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","orange_sum"],"keywords_longer_than_N":true},
	{"name":"orange_sum_fr_prompt_title_generation_from_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\torange_sum_fr_prompt_title_generation_from_an_article\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\norange_sum_fr_prompt_title_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 639,521 rows that can be used for a title generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","orange_sum"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_qa\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 3,320,898 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa.","first_N":5,"first_N_keywords":["question-answering","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_question","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_context_generation_with_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a context-generation (with question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,165,934 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_context","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_qa\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa.","first_N":5,"first_N_keywords":["question-answering","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_answer","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_answer_and_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_context_generation_with_question","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_context_generation_with_question\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_answer","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_answer\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_context","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"big_patent_100k_characters","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/big_patent_100k_characters","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tSampled Big Patent Dataset\n\t\n\nThis is a sampled Trelis/big_patent_sample dataset containing rows of data with descriptions shorter than or equal to 100,000 characters in length.\n--- Sampled from Trelis/big_patent_sampled ---\n\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_100k_characters.","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"piaf_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tpiaf_fr_prompt_question_generation_with_answer_and_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\npiaf_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","etalab-ia/piaf"],"keywords_longer_than_N":true},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 1,112,937 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","squad_v2_french_translated"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-paraphrase","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-paraphrase is an open source dataset of instruct-style records generated from the Telugu split of ai4bharat/IndicXParaphrase dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-jokes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-jokes is an open source dataset of instruct-style records generated by webscraping a Telugu Jokes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\naya-telugu-jokes is a corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"dialogsum-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neil-code/dialogsum-test","creator_name":"neil","creator_url":"https://huggingface.co/neil-code","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neil-code/dialogsum-test.","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"minispider","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","description":"\n\t\n\t\t\n\t\tDataset Card for Spider\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard can be seen at https://yale-lily.github.io/spider\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"huggingface-dataset-issues","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SergeiGKS/huggingface-dataset-issues","creator_name":"Serge Ghomsi","creator_url":"https://huggingface.co/SergeiGKS","description":"\n\t\n\t\t\n\t\tDataset Card for \"my-issues-dataset\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["sentence-similarity","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TeluguRiddles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/desik98/TeluguRiddles","creator_name":"Desik Mandava","creator_url":"https://huggingface.co/desik98","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nTeluguRiddles is an open source dataset of instruct-style records generated by webscraping multiple riddles websites. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nTeluguRiddles is a corpus of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/desik98/TeluguRiddles.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-food-recipes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-food-recipes is an open source dataset of instruct-style records generated by webscraping a Telugu food recipes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"clothes_desc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wbensvage/clothes_desc","creator_name":"Wolfgang Bensvage","creator_url":"https://huggingface.co/wbensvage","description":"\n\t\n\t\t\n\t\tDataset Card for H&M Clothes captions\n\t\n\n_Dataset used to train/finetune [Clothes text to image model]\nCaptions are generated by using the 'detail_desc' and 'colour_group_name' or 'perceived_colour_master_name' from kaggle/competitions/h-and-m-personalized-fashion-recommendations. Original images were also obtained from the url (https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data?select=images)\n\n\t\n\t\n\t\n\t\tFor each row the dataset contains image and text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wbensvage/clothes_desc.","first_N":5,"first_N_keywords":["text-to-image","human generated by using detail_desc and color","other","monolingual","www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations"],"keywords_longer_than_N":true},
	{"name":"thirukkural_instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nthirukkural_QA is an open source dataset of instruct-style records generated by converting publicly available data on Thirukkural and it's meaning.\nThis was created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\nQuestion Answering\n\nLanguages: Tamil Version: 1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct.","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-poems","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-poems is an open source dataset of instruct-style records generated by webscraping a Telugu poems website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\naya-telugu-poems is a corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CanItEdit","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\n\t\n\t\t\n\t\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\n\t\n\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\nThe dataset‚Äôs dual natural language instructions test model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"openslr-slr69-ca-trimmed-denoised","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for openslr-slr69-ca-denoised\n\t\n\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \nSpecifically the subset OpenSLR-69. \nThe original HFü§ó SLR-69 dataset is located here.\nSame license is maintained: Attribution-ShareAlike 4.0 International.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe processed the data of the Catalan OpenSLR with the following recipe:\n\nTrimming: Long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"lpf","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/lpf","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tLivre des proc√©dures fiscales, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lpf.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"cgi","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/cgi","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode G√©n√©ral des Imp√¥ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/cgi.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-douanes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des douanes, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-consommation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la consommation, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-securite-sociale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© sociale, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-penal","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode p√©nal, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-sport","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du sport, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-civil","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode civil, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-commerce","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de commerce, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-sante-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la sant√© publique, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-environnement","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'environnement, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"tamil_stories","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aitamilnadu/tamil_stories","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\ntamil_stories is an open source dataset of instruct-style records generated by scraping publicly available short stories on the following websites.\n\nSiruvarmalar\nTamilsurangam\n\nApart from scraping and automated cleaning, the data was also tagged manually by a group of volunteers. \nThis dataset created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/tamil_stories.","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"dac6-instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tDAC6 instruct (11-12-2023)\n\t\n\n‚ÄúDAC 6‚Äù refers to European Council Directive (EU) 2018/822 of May 25, 2018 relating to the automatic and mandatory exchange of information on cross-border arrangements requiring declaration. It aims to strengthen cooperation between tax administrations in EU countries on potentially aggressive tax planning arrangements.\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-procedure-civile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de proc√©dure civile, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-monetaire-financier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode mon√©taire et financier, non-instruct (2025-06-16)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-assurances","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des assurances, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-travail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du travail, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-artisanat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'artisanat, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-commande-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la commande publique, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-propriete-intellectuelle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la propri√©t√© intellectuelle, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedures-civiles-execution","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des proc√©dures civiles d'ex√©cution, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-route","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la route, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-education","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'√©ducation, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-construction-habitation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la construction et de l'habitation, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-mutualite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la mutualit√©, non-instruct (2025-06-16)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-transports","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des transports, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-urbanisme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'urbanisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-general-fonction-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la fonction publique, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-forestier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode forestier, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-justice-administrative","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de justice administrative, non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-postes-communications-electroniques","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des postes et des communications √©lectroniques, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-relations-public-administration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-rural-peche-maritime","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode rural et de la p√™che maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-securite-interieure","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© int√©rieure, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"big_patent_sample","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/big_patent_sample","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters in length, making the dataset good for training on lengths up to 250,000 tokens.\n\n\t\n\t\t\n\t\tDataset Card for Big Patent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_sample.","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaisum","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for ThaiSum\n\t\n\nThis dataset was forked from thaisum to HF hub.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath, ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs written by journalists.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nsummarization, language modeling\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaisum.","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"4catac","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for 4catac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the accent.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac.","first_N":5,"first_N_keywords":["text-to-speech","expert-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"canarim","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\n  \n\n\n\n  [üê± GitHub]\n\n\n\n\n\n\n\t\n\t\t\n\t\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"bangla-health-related-paraphrased-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset","creator_name":"Faisal MIST","creator_url":"https://huggingface.co/faisal4590aziz","description":"\n\t\n\t\t\n\t\tDataset Card for \"BanglaHealthParaphrase\"\n\t\n\n\n\nBanglaHealthParaphrase is a Bengali paraphrasing dataset specifically curated for the health domain. It contains over 200,000 sentence pairs, where each pair consists of an original Bengali sentence and its paraphrased version. The dataset was created through a multi-step pipeline involving extraction of health-related content from Bengali news sources, English pivot-based paraphrasing, and back-translation to ensure linguistic diversity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset.","first_N":5,"first_N_keywords":["monolingual","original","Bengali","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"geo-reviews-dataset-2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tGeo Reviews Dataset 2023\n\t\n\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\nUse it for academic and research purposes, share your results with us in Issues.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n500,000 unique reviews\nOnly reviews about organizations in Russia\nAvailable on Yandex Maps\nPublished from January to July 2023\nThe dataset does not contain short one-word reviews\nReviews have been cleared of personal data (phone numbers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023.","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","token-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bofip","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/bofip","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tBulletin officiel des finances publiques - imp√¥ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/bofip.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"This-is-not-a-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n    \n\n\n\"A Large Negation Benchmark to Challenge Large Language Models\"\n\n\nWe introduce a large semi-automatically generated dataset of ~400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms that we use to evaluate LLMs.\n\n\n\nüìñ Paper: This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models (EMNLP'23)\nüíª Baseline Code and the Official Scorer:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset.","first_N":5,"first_N_keywords":["text-classification","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"ke-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ke-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Kazanexpress products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace Kazanexpress. It includes all information from the product card and metadata from the API. The dataset was collected by processing around 3 million products, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Please note that the data returned by the API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ke-products.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_multilabel","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset before‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_binary","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset before‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"LongSumEt","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TalTechNLP/LongSumEt","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","description":"\n\t\n\t\t\n\t\tDataset Card for \"LongSumEt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLongSumEt is an estonian language long summarization dataset with pages filtered from CulturaX dataset. The dataset consists of the page text, and machine generated short summary, long summary and bulletpoints.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEstonian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nMore Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/LongSumEt.","first_N":5,"first_N_keywords":["summarization","machine-generated","monolingual","original","Estonian"],"keywords_longer_than_N":true},
	{"name":"harem","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"R√∫ben Almeida","creator_url":"https://huggingface.co/arubenruben","description":"\n\t\n\t\t\n\t\tDataset Card for HAREM\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem.","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SAW-corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Syntheresis/SAW-corpus","creator_name":"Syntheresis","creator_url":"https://huggingface.co/Syntheresis","description":"\n\t\n\t\t\n\t\tDataset Card for SAW Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Selective Armenian Web (SAW) Corpus is a collection of Armenian language texts, selectively compiled from various online sources. It aims to support natural language processing tasks, offering a wide range of text types, including news articles, legal documents, and other web content.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nlanguage-modeling\nmasked-language-modeling\n\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Syntheresis/SAW-corpus.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","found"],"keywords_longer_than_N":true},
	{"name":"PM-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/PM-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for PochtaMarket products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace PochtaMarket. It includes all information from the product card. The dataset was collected by processing around 500 thousand, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Some fields may be empty, but the string is expected to contain some data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/PM-products.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"MusteriYorumlari","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/MusteriYorumlari","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tM√º≈üteriYorumlari - A Large Scale Customer Sentiment Analysis Dataset for Turkish\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nM√º≈üteriYorumlarƒ± is a Turkish e-commerce customer reviews dataset of size 103K, scraped from Hepsiburada.com and Trendyol.com. These reviews encompass a wide\narray of product categories, including apparel, food items, baby products, and books. Review stars are in range of 1-5 stars.\nThe star distribution is as follows:\n\n\t\n\t\t\nstar rating\ncount\n\n\n\t\t\n1\n12,873\n\n\n2\n11,472\n\n\n3\n18‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/MusteriYorumlari.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","Duygu Altinok","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fashion-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koaning/fashion-test","creator_name":"Vincent D. Warmerdam","creator_url":"https://huggingface.co/koaning","description":"This dataset represents some data that Ines annotated. I am adding this info manually. \n","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-paraphrase-bible","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","description":"\n\t\n\t\t\n\t\tDataset Card for \"Romanian Bible Paraphrase Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \nversions is straighforward. \nWe compiled a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible.","first_N":5,"first_N_keywords":["sentence-similarity","text-scoring","semantic-similarity-scoring","semantic-similarity-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"NOAA-Buoy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qdrant/NOAA-Buoy","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","description":"\n\t\n\t\t\n\t\n\t\n\t\tNOAA Buoy meterological data\n\t\n\nNOAA Buoy Data was downloaded, processed, and cleaned for tasks pertaining to tabular data. The data consists of meteorological measurements. There are two datasets\n\nFrom 1980 through 2022 (denoted with \"years\" in file names)\nFrom Jan 2023 through end of Sept 2023 (denoted with \"2023\" in file names)\n\nThe original intended use is for anomaly detection in tabular data. \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qdrant/NOAA-Buoy.","first_N":5,"first_N_keywords":["feature-extraction","tabular-classification","time-series-forecasting","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"uz-crawl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uz-crawl","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\n\t\n\t\t\n\t\tDataset Card for UzCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release UzCrawl dataset, a web and telegram crawl corpus consisting of materials from nearly 1.2 million unique sources in the Uzbek Language. \nPlease refer to our blogpost for further details.\nP.S. We updated the dataset with 2nd version that extends the scope to new topics as well as being up to date to March 2024.\nTo load and use dataset, run this script:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-crawl.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"uz-books","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/uz-books","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"\n\t\n\t\t\n\t\tDataset Card for BookCorpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release UzBooks dataset, a cleaned book corpus consisting of nearly 40000 books in Uzbek Language divided into two branches: \"original\" and \"lat,\" representing the OCRed (Latin and Cyrillic) and fully Latin versions of the texts, respectively. \nPlease refer to our blogpost and paper (Coming soon!) for further details.\nTo load and use dataset, run this script:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uz-books.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Openclipart-Oldstyle","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/Openclipart-Oldstyle","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for 16th Century(?) Black and White Style\n\nDataset used to train/finetune a black and white print style\nCaptions are generated by hand with the assistance of BLIP.\nImages were sourced from:\n  https://openclipart.org/artist/j4p4n\n  https://openclipart.org/artist/johnny_automatic\n  https://openclipart.org/artist/SnipsAndClips\nText file filenames correspond image file filenames as captions.\n","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","https://openclipart.org/artist/j4p4n"],"keywords_longer_than_N":true},
	{"name":"32000-BlackSharpie","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/32000-BlackSharpie","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for a Black and White Sharpie Style\n\nDataset used to train/finetune a black and white sharpie style\nCaptions are generated by hand with the assistance of BLIP.\nImages were hand drawn.\nText file filenames correspond image file filenames as captions.\n","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"kor_duorc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_duorc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\n\t\n\t\t\n\t\tDataset Card for duorc\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nMIT License\n\n\t\n\t\t\n\t\tSource Data Citation Information\n\t\n\n@inproceedings{DuoRC,\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\ntitle = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\nyear = {2018}\n}\n\n","first_N":5,"first_N_keywords":["question-answering","abstractive-qa","extractive-qa","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"FACTOID","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisafe/FACTOID","creator_name":"safe ai","creator_url":"https://huggingface.co/aisafe","description":"aisafe/FACTOID dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","fact-checking","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"pierogue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","description":"\n\t\n\t\t\n\t\tPierogue\n\t\n\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\n\nTopics: cosmos, nature, music, technology, fashion\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\n\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue.","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","text-generation","document-retrieval","language-modeling"],"keywords_longer_than_N":true},
	{"name":"chartve_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khhuang/chartve_dataset","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","description":"\n\t\n\t\t\n\t\tDataset Card for ChartVE's Training Data\n\t\n\n\nDataset Description\nPaper Information\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nChartVE (Chart Visual Entailment) is a visual entailment model introduced in the paper \"Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning\" for evaluating the factuality of a generated caption sentence with regard to the input chart. The model takes in a chart figure and a caption sentence as input, and outputs an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/chartve_dataset.","first_N":5,"first_N_keywords":["monolingual","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Graptoloidea-Specimens-Imaging","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging","creator_name":"Zaolin Zhang","creator_url":"https://huggingface.co/LeoZhangzaolin","description":"\n\t\n\t\t\n\t\tDataset Card for Graptoloidea Specimens Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset offers a detailed examination of Graptoloidea specimens, featuring attributes like image file paths, suborder, infraorder, family (including subfamily), tagged species names, geological stages, mean age values, and locality details (with coordinates and horizon information), complemented by original reference citations for each specimen. It serves as a comprehensive resource for paleontological‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging.","first_N":5,"first_N_keywords":["image-classification","object-detection","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"rutube-channels","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/rutube-channels","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Rutube channels\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from channel pages on the Russian video-sharing platform Rutube. It includes all information from the channel card. The dataset was collected by processing 36 million channels, starting from the first one. At the time the dataset was collected, it is assumed that these were all the channels available on this platform. Some fields may be empty, but the string is expected to contain some data, empty‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rutube-channels.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"AttaQ","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/AttaQ","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\n\t\n\t\t\n\t\tAttaQ Dataset Card\n\t\n\nThe AttaQ red teaming dataset, consisting of 1402 carefully crafted adversarial questions, is designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses. \nIt may serve as a benchmark to assess the potential harm of responses produced by LLMs. \nThe dataset is categorized into seven distinct classes of questions: deception, discrimination, harmful information, substance abuse, sexual content, personally‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ.","first_N":5,"first_N_keywords":["text-generation","monolingual","extended|Anthropic/hh-rlhf","English","mit"],"keywords_longer_than_N":true},
	{"name":"wikitoxic","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","description":"This dataset has been created as an artefact of the paper AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets (Lesci and Vlachos, 2024).\nMore info about this dataset in the appendix of the paper. \nThis is the same dataset as OxAISH-AL-LLM/wiki_toxic.\nThe only differences are:\n\nAddition of a unique identifier, uid.\n\nAddition of the indices, that is, 3 columns with the embeddings of 3 different sentence-transformers\n\nall-mpnet-base-v2\nmulti-qa-mpnet-base-dot-v1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pietrolesci/wikitoxic.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"liwu-MNBVC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/liwu-MNBVC","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\n\t\n\t\t\n\t\tDataset Card for MNBVC\n\t\n\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ªãÁªç\n\t\n\n‰∏≠Êñá‰∫íËÅîÁΩë‰∏äÊúÄÂè§ËÄÅÊúÄÁ•ûÁßò(Ê≤°Êúâ‰πã‰∏Ä)ÁöÑÈáåÂ±ãÁ§æÂå∫‰∫é2023.1.1Â∫ÑÈáçÂÆ£Â∏É:\nÂú®Ëã±ÊòéÁ•ûÊ≠¶ÁöÑÈáåÂ±ãÁÆ°Â≠êÂ∏¶È¢Ü‰∏ãÔºåÂÜ≥ÂøÉÂèëÊå•Á§æÂå∫ÊâÄÈïø(Âì™ÈÉΩÈïø)ÔºåÂ∏ÆÂä©ÂºÄÊ∫êÁ§æÂå∫ÈïøÊúüÊõ¥Êñ∞‰∏Ä‰ªΩÊúÄÂ§ßÁöÑ‰∏≠Êñá‰∫íËÅîÁΩëËØ≠ÊñôÈõÜ„ÄÇ\nHuggingface‰∏äÁöÑMNBVCÊï∞ÊçÆÈõÜÂú®ÈÄêÊ∏êÊõ¥Êñ∞‰∏≠ÔºåËØ∑Âà∞https://github.com/esbatmop/MNBVC Ëé∑ÂèñÊú™ÂÆåÊàêÊ∏ÖÊ¥óÁöÑÊõ¥Â§öÊï∞ÊçÆ„ÄÇ\nÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãËÑöÊú¨Âä†ËΩΩÔºö\nfrom datasets import load_dataset\ndataset = load_dataset(\"liwu/MNBVC\", 'law_judgement', split='train', streaming=True)\n\nnext(iter(dataset))  # get the first line\n\n\n\t\n\t\n\t\n\t\tÊï∞ÊçÆÂ≠êÈõÜ\n\t\n\nMNBVCÊï∞ÊçÆÈõÜÂåÖÂê´Êï∞‰∏™Â≠êÈõÜÔºö\n\nlaw_judgement: Êù•Ëá™Ê≥ïÂæãÊñá‰π¶ÁöÑÊñáÊú¨„ÄÇ\ngov_xuexiqiangguo: Êù•Ëá™Â≠¶‰π†Âº∫ÂõΩÁöÑÊñáÊú¨„ÄÇgov_report:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botp/liwu-MNBVC.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","other"],"keywords_longer_than_N":true},
	{"name":"plsc","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rafalposwiata/plsc","creator_name":"Rafa≈Ç Po≈õwiata","creator_url":"https://huggingface.co/rafalposwiata","description":"PLSC - Polish Library of Science Corpus\n","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","multi-label-classification","monolingual"],"keywords_longer_than_N":true},
	{"name":"hindi-headline-article-generation","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nhindi-headline-article-generation is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Hindi Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hindi-article-summarization","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nhindi-article-summarization is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Hindi Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"samromur_children_test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_children\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Samr√≥mur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology. The recording process has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"genai_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samyakmohelay/genai_dataset","creator_name":"Samyak Mohelay","creator_url":"https://huggingface.co/samyakmohelay","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samyakmohelay/genai_dataset.","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fake_news_en_opensources","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andyP/fake_news_en_opensources","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","description":"\n\t\n\t\t\n\t\tDataset Card for \"Fake News Opensources\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/FakeNewsDataset\nRepository: https://github.com/AndyTheFactory/FakeNewsDataset\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na consolidated and cleaned up version of the opensources Fake News dataset\nFake News Corpus comprises 8,529,090 individual articles, classified into 12 classes: reliable, unreliable, political, bias, fake, conspiracy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/fake_news_en_opensources.","first_N":5,"first_N_keywords":["text-classification","topic-classification","fact-checking","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"commonsense_qa-ID","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rizquuula/commonsense_qa-ID","creator_name":"Muhammad Razif Rizqullah","creator_url":"https://huggingface.co/rizquuula","description":"CommonsenseQA-ID is Indonesian translation version of CommonsenseQA, a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"Alpaca-cnn-dailymail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail","creator_name":"Zhongsheng Wang","creator_url":"https://huggingface.co/ZhongshengWang","description":"\n\t\n\t\t\n\t\tData Summary\n\t\n\nData set Alpaca-cnn-dailymail is a data set version format changed by ccdv/cnn_dailymail to meet Alpaca fine-tuning Llama2. Only versions 3.0.0 and 2.0.0 were used for merging and as a key data set for the summary extraction task.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe Alpaca-cnn-dailymail dataset version 1.0.0 is released under the Apache-2.0 License.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{see-etal-2017-get,\n    title = \"Get To The Point: Summarization with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail.","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"beyazperde-all-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-all-movie-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for turkish-nlp-suite/beyazperde-all-movie-reviews\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBeyazperde Movie Reviews offers Turkish sentiment analysis datasets that is scraped from popular movie reviews website Beyazperde.com. All Movie Reviews include audience reviews about movies of all the time. Here's the star rating distribution:\n\n\t\n\t\t\nstar rating\ncount\n\n\n\t\t\n0.5\n3.635\n\n\n1.0\n2.325\n\n\n1.5\n1.077\n\n\n2.0\n1.902\n\n\n2.5\n4.767\n\n\n3.0\n4.347\n\n\n3.5\n6.495\n\n\n4.0\n9.486\n\n\n4.5\n3.652\n\n\n5.0\n7.594‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-all-movie-reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","monolingual","Turkish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"vitamins-supplements-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for turkish-nlp-suite/vitamins-supplements-reviews\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkish sentiment analysis dataset from customer reviews about supplement and vitamin products. The dataset is scraped from Vitaminler.com and contains\ncustomer reviews and star rating about vitamin and supplement products.\nEach customer review in the Vitamins and Supplements Reviews Dataset describes a customer‚Äôs experience with a supplement product in terms of the product‚Äôs effectiveness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","monolingual","Turkish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"vitamins-supplements-NER","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-NER","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tDataset Card for turkish-nlp-suite/vitamins-supplements-NER\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Vitamins and Supplements NER Dataset is a NER dataset containing customer reviews with entity and span annotations. User reviews were collected from a popular supplement products e-\ncommerce website Vitaminler.com. \nEach customer review in the Vitamins and Supplements NER Dataset describes a customer‚Äôs experience with a supplement product in terms of that product‚Äôs effectiveness, side‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-NER.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","monolingual","Turkish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"taln-archives_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\ttaln-archives_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntaln-archives_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 35,370 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/taln-archives"],"keywords_longer_than_N":true},
	{"name":"taln-archives_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\ttaln-archives_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntaln-archives_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 24,507 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/taln-archives"],"keywords_longer_than_N":true},
	{"name":"termith-eval_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\ttermith-eval_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntermith-eval_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 11,886 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/termith-eval"],"keywords_longer_than_N":true},
	{"name":"termith-eval_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\ttermith-eval_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\ntermith-eval_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 8,295 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/termith-eval"],"keywords_longer_than_N":true},
	{"name":"wikinews-fr-100_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\twikinews-fr-100_fr_prompt_data_to_text\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwikinews-fr-100_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 3,000 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/wikinews-fr-100"],"keywords_longer_than_N":true},
	{"name":"wikinews-fr-100_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\twikinews-fr-100_fr_prompt_keywords_extraction\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nwikinews-fr-100_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 2,100 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction.","first_N":5,"first_N_keywords":["text-generation","found","found","monolingual","taln-ls2n/wikinews-fr-100"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enrichment_only","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for SpeechCommands\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nüìä Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \nüîç This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"SB10k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/SB10k","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\n\t\n\t\t\n\t\tA Twitter corpus and benchmark resources for german sentiment analysis\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nThe data is a snapshot from the SB10k Dataset.\nThe snapshot was made by Oliver Guhr.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nPaper\n@inproceedings{cieliebak2017twitter,\n  title={A twitter corpus and benchmark resources for german sentiment analysis},\n  author={Cieliebak, Mark and Deriu, Jan Milan and Egger, Dominic and Uzdilli, Fatih},\n  booktitle={5th International Workshop on Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/SB10k.","first_N":5,"first_N_keywords":["text-classification","monolingual","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"instruct-legal-refugiados-es","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es","creator_name":"Eduardo Mu√±oz Sala","creator_url":"https://huggingface.co/edumunozsala","description":"\n    \n\nLegal Refugiados: Un dataset para QA en temas legales de refugio, asilo y protecci√≥n internacional.\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nInstruction Question-Answering Legal Refugiados es una colecci√≥n de instrucciones extra√≠das de una gran cantidad de documentos legales del gobierno de Espa√±a, principalmente, y de otras instituciones de la UE y tambi√©n de otros pa√≠ses de habla hispana como M√©xico o Venezuela. Todos ellos est√°n relacionados con leyes y disposiciones legales sobre ciudadanos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es.","first_N":5,"first_N_keywords":["text-generation","extractive-qa","distillabel","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\n\t\n\t\t\n\t\tHokchia Audio Dataset\n\t\n\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"WikiSQE","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ando55/WikiSQE","creator_name":"Kenichiro Ando","creator_url":"https://huggingface.co/ando55","description":"\n\t\n\t\t\n\t\tDataset Card for WikiSQE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia by Kenichiro Ando, Satoshi Sekine and Mamoru Komachi (AAAI¬†2024).\nThe WikiSQE dataset is an English‚Äëlanguage dataset containing over 3.4‚ÄØmillion sentences extracted from the complete edit history of English Wikipedia. Every sentence in the corpus is considered by Wikipedia editors to have some quality issue. The type of issue is annotated with one of 153‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ando55/WikiSQE.","first_N":5,"first_N_keywords":["text-classification","no-annotation","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"WikiSQE_experiment","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ando55/WikiSQE_experiment","creator_name":"Kenichiro Ando","creator_url":"https://huggingface.co/ando55","description":"\n\t\n\t\t\n\t\tDataset Card for WikiSQE_experiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikiSQE_experiment is the official evaluation split for WikiSQE: A Large‚ÄëScale Dataset for Sentence Quality Estimation in Wikipedia.\nWhile the parent dataset (ando55/WikiSQE) contains every sentence flagged with a quality problem in the full edit history of English Wikipedia, this repo provides the exact train/validation/test partitions used in the AAAI‚ÄØ2024 paper. It offers ‚âà‚ÄØ8.3‚ÄØmillion sentences organised as:\n\n27‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ando55/WikiSQE_experiment.","first_N":5,"first_N_keywords":["text-classification","no-annotation","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"web-sentences-br","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/web-sentences-br","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"Breton sentences from the public web. Filtered and deduplicated.\nMostly KLT orthography.\nAround 1M words.\n","first_N":5,"first_N_keywords":["monolingual","Breton","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"isafpressreleases","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strickvl/isafpressreleases","creator_name":"Alex Strick van Linschoten","creator_url":"https://huggingface.co/strickvl","description":"\n\t\n\t\t\n\t\tISAF Press Releases Dataset Description\n\t\n\n\nHomepage: [N/A]\nRepository: [N/A]\nPaper: A Knock on the Door: 22 Months of ISAF Press Releases\nPoint of Contact: Alex Strick van Linschoten (@strickvl)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe ISAF Press Releases dataset contains data used as the basis for the research\npaper \"A Knock on the Door: 22 Months of ISAF Press Releases\". The dataset\nprovides a comprehensive collection of press releases issued by the\nInternational Security Assistance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strickvl/isafpressreleases.","first_N":5,"first_N_keywords":["feature-extraction","summarization","question-answering","text-classification","fill-mask"],"keywords_longer_than_N":true},
	{"name":"japan_diet_q_and_a_sessions_20k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k","creator_name":"takashi miwa","creator_url":"https://huggingface.co/notoxicpeople","description":"\n\t\n\t\t\n\t\tJapan Diet Q&A Sessions Dataset\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nThis dataset was created by scraping the parliamentary questions and answers webpage. \nAs of March 27, 2024, it includes 216 sessions.\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Consists of three parts. \nThe initial alphabet indicates whether it is a question (a) or an answer (b).\nThe next three digits represent the session number of the parliament.\nThe last three digits are the question number within the parliament session.\n\n\ntitle: The title‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k.","first_N":5,"first_N_keywords":["monolingual","Japanese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"code-action-sociale-familles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'action sociale et des familles, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-aviation-civile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'aviation civile, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-cinema-image-animee","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du cin√©ma et de l'image anim√©e, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-communes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des communes, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-communes-nouvelle-caledonie","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des communes de la Nouvelle-Cal√©donie, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-defense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la d√©fense, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-deontologie-architectes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de d√©ontologie des architectes, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-disciplinaire-penal-marine-marchande","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode disciplinaire et p√©nal de la marine marchande, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat-collectivites-mayotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat et des collectivit√©s publiques applicable √† la collectivit√© territoriale de Mayotte, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du domaine public fluvial et de la navigation int√©rieure, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-douanes-mayotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des douanes de Mayotte, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-electoral","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode √©lectoral, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-energie","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'√©nergie, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-entree-sejour-etrangers-droit-asile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'entr√©e et du s√©jour des √©trangers et du droit d'asile, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-expropriation-utilite-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'expropriation pour cause d'utilit√© publique, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-famille-aide-sociale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la famille et de l'aide sociale, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-forestier-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode forestier (nouveau), non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-fonction-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la fonction publique, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-propriete-personnes-publiques","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la propri√©t√© des personnes publiques, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-collectivites-territoriales","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des collectivit√©s territoriales, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impots","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-i","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe I, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-ii","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe II, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iii","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe III, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iv","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe IV, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-impositions-biens-services","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des impositions sur les biens et services, non-instruct (2025-07-19)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-instruments-monetaires-medailles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des instruments mon√©taires et des m√©dailles, non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-juridictions-financieres","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des juridictions financi√®res, non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-justice-militaire-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de justice militaire (nouveau), non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-justice-penale-mineurs","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la justice p√©nale des mineurs, non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la L√©gion d'honneur, de la M√©daille militaire et de l'ordre national du M√©rite, non-instruct (2025-07-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"livre-procedures-fiscales","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tLivre des proc√©dures fiscales, non-instruct (2025-07-06)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-minier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode minier, non-instruct (2025-07-06)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-minier-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode minier (nouveau), non-instruct (2025-07-06)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-organisation-judiciaire","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de l'organisation judiciaire, non-instruct (2025-05-31)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-patrimoine","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du patrimoine, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-penitentiaire","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode p√©nitentiaire, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-civiles-militaires-retraite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des pensions de retraite des marins fran√ßais du commerce, de p√™che ou de plaisance, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des pensions militaires d'invalidit√© et des victimes de guerre, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-ports-maritimes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode des ports maritimes, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedure-penale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de proc√©dure p√©nale, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-recherche","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la recherche, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-rural-ancien","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode rural (ancien), non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-service-national","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du service national, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-tourisme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du tourisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-travail-maritime","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode du travail maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-voirie-routiere","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\n\t\n\t\t\n\t\tCode de la voirie routi√®re, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cmc-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cmc-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Coinmarketcap Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of posts from Coinmarketcap, a popular cryptocurrency platform. It includes approximately 1 million posts from February 24, 2022. However, a significant portion of the posts are spam, making this dataset ideal for spam detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nid: Identifier for the post (integer)\nusername: Name of the user‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cmc-posts.","first_N":5,"first_N_keywords":["text-classification","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"NextGenBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraKaraWitch/NextGenBench","creator_name":"KaraKaraWitch","creator_url":"https://huggingface.co/KaraKaraWitch","description":"\n\t\n\t\t\n\t\tDataset Card for Next Generation Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a multitask test consisting of only questions (some are MCQ) from various branches of knowledge. Specifically the following topics:\nAbstract Algebra\nAnatomy\nAstronomy\nBusiness Ethics\nClinical Knowledge\nPrimary School Biology\nPrimary School Chemistry\nPrimary School Physics\nPrimary School Math\nPrimary School English\nPrimary School Science\nPrimary School Computer Science\nComputer Security\nDaily Economy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/NextGenBench.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haebo1/test","creator_name":"Hyunho Yang","creator_url":"https://huggingface.co/haebo1","description":"\n\t\n\t\t\n\t\tDataset Card for KoBEST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nko-KR\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tKB-BoolQ\n\t\n\nAn example of a data point looks as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haebo1/test.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","Korean"],"keywords_longer_than_N":true},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","description":"\n\t\n\t\t\n\t\tMoroccan Darija YouTube Subtitles Dataset\n\t\n\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\n\nvideo_id: The unique identifier of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles.","first_N":5,"first_N_keywords":["other","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"legal_summarization","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/legal_summarization","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalSummarization\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consistes of 439 pairs of contracts and their summarizations from https://tldrlegal.com and https://tosdr.org/.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lauramanor/legal_summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legal_summarization.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"legalbench_corporate_lobbying","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalBenchCorporateLobbying\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset includes bill titles and bill summaries related to corporate lobbying.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench/viewer/corporate_lobbying\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AILA_casedocs","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AILA_casedocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AILACasedocs\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to retrieve the case document that most closely matches or is most relevant to the scenario described in the provided query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\nReference\nhttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILACasedocs\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_casedocs.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AILA_statutes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AILA_statutes","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AILAStatutes\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset is structured for the task of identifying the most relevant statutes for a given situation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReferencehttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILAStatutes\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_statutes.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LeCaRDv2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LeCaRDv2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LeCaRDv2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the case document that best matches or is most relevant to the scenario described in each of the provided queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/THUIR/LeCaRDv2\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LeCaRDv2.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"LegalQuAD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LegalQuAD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalQuAD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of questions and legal documents in German.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/Christoph911/AIKE2021_Appendix\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LegalQuAD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalQuAD.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia-br-20240325","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/wikipedia-br-20240325","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"A corpus of sentences extracted for the Breton Wikipedia (cirrus dump).\nThe sentences were filtered so that only Breton sentences were kept.\nPlease note that the sentence splitting algorithm is far from perfect, so many sentences will appear incorrect or incomplete.\n","first_N":5,"first_N_keywords":["monolingual","Breton","apache-2.0","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"poquad-imp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arduwa/poquad-imp","creator_name":"Jakub","creator_url":"https://huggingface.co/arduwa","description":"PoQuaD dataset\n","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/germanquad-retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GermanQuAD-Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContext Retrieval for German Question Answering\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction, Web\n\n\nReference\nhttps://huggingface.co/datasets/deepset/germanquad\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GermanQuAD-Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"Aliz√©e Pace","creator_url":"https://huggingface.co/alizeepace","description":"\n\t\n\t\t\n\t\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Rejection Sampling Phi-2 with OpenAssistant RM\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or conversational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm.","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Contextual_Response_Evaluation_for_ESL_and_ASD_Support","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support","creator_name":"Eric Soderquist","creator_url":"https://huggingface.co/yunjaeys","description":"\n\t\n\t\t\n\t\tDataset Card for \"Contextual Response Evaluation for ESL and ASD Supportüíúüí¨üåê\"\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description üìñ\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary üìù\n\t\n\nCurated by Eric Soderquist, this dataset is a collection of English prompts and responses generated by the Phi-2 model, designed to evaluate and improve NLP models for supporting ESL (English as a Second Language) and ASD (Autism Spectrum Disorder) user bases. Each prompt is paired with multiple AI-generated responses and evaluated using a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"brwac","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","description":"\n\n\t\n\t\t\n\t\tDataset Card for BrWaC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"LMTuberEval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shadowlilac/LMTuberEval","creator_name":"ShadowLilac","creator_url":"https://huggingface.co/shadowlilac","description":"\n\t\n\t\t\n\t\tDataset Card for LMTuberEval\n\t\n\nTraining LLMs to convincingly emulate VTubers requires rigorous evaluation of their knowledge, encompassing both specific VTuber details and the broader VTuber landscape.  Current LLMs often struggle with factuality, particularly regarding lesser-known VTubers, frequently resorting to hallucination and generating incorrect information. This benchmark addresses the critical need for objective measurement of this specialized knowledge, which is currently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shadowlilac/LMTuberEval.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","ai-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"allenai-prosocial-dialog","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tProsocialDialog ShareGPT Format\n\t\n\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach conversation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog.","first_N":5,"first_N_keywords":["dialogue-generation","crowdsourced","machine-generated","monolingual","allenai/prosocial-dialog"],"keywords_longer_than_N":true},
	{"name":"math-augmented-dataset","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nivektk/math-augmented-dataset","creator_name":"Kevin Fabio Ramos L√≥pez","creator_url":"https://huggingface.co/nivektk","description":"\n\t\n\t\t\n\t\tMath-Augmented-Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Math-Augmented-Dataset extends the MATH dataset by Dan Hendrycks, focusing on algebra problems. It comprises 1,006 validated examples from the algebra subset, structured in JSON format with detailed step-by-step solutions generated using Large Language Models (LLMs) with chain-of-thought reasoning.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach JSON file contains:\n\nproblem: The math problem statement, including LaTeX expressions.\nlevel:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nivektk/math-augmented-dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","monolingual","MATH (Dan Hendrycks)"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_second_iteration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RLAIF/mbpp","creator_name":"RLAIF","creator_url":"https://huggingface.co/RLAIF","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RLAIF/mbpp.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlile/mbpp","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","description":"\n\t\n\t\t\n\t\tDataset Card for Mostly Basic Python Problems (mbpp)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \nReleased here as part of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nlile/mbpp.","first_N":5,"first_N_keywords":["crowdsourced","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tricoteuses/LEGI","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/LEGI.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr_500_250406","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmh/gsm8k_fr_500_250406","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n500 lignes de GSM8K traduit en fran√ßais √† l'aide de quickmt/quickmt-en-fr. Les questions sont r√©duites √† moins de 256 tokens et les r√©ponses √† moins de 768 tokens (tokenizer de Phi-4).\n500 lines of the GSM8K dataset translated to french using quickmt/quickmt-en-fr. Trimmed so questions are smaller than 256 tokens and responses smaller than 768 tokens (Phi-4 tokenizer).\n","first_N":5,"first_N_keywords":["monolingual","French","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"gsm8k_fr_50_250406","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmh/gsm8k_fr_50_250406","creator_name":"cmh","creator_url":"https://huggingface.co/cmh","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n50 lignes de GSM8K traduit en fran√ßais √† l'aide de quickmt/quickmt-en-fr. Les questions sont r√©duites √† moins de 256 tokens et les r√©ponses √† moins de 768 tokens (tokenizer de Phi-4).\n50 lines of the GSM8K dataset translated to french using quickmt/quickmt-en-fr. Trimmed so questions are smaller than 256 tokens and responses smaller than 768 tokens (Phi-4 tokenizer).\n","first_N":5,"first_N_keywords":["monolingual","French","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"spm_jsonresume_resumed","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ajaxdavis/spm_jsonresume_resumed","creator_name":"Thomas Davis","creator_url":"https://huggingface.co/ajaxdavis","description":"\n\t\n\t\t\n\t\tspm\n\t\n\nSmall Package Model is a method for creating micro llms trained to be an expert on a single software project. The goal is to generate fine tuned models that are so small they can be saved as a package, loaded as a dependency, and run locally. The advantage of this method is that the model can give accurate and up to date information on the particular code being run without needing external tools, it stays up to date with latest changes and understands the specific implementation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajaxdavis/spm_jsonresume_resumed.","first_N":5,"first_N_keywords":["machine-generated","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"T5_german_summaries_filtered_convos","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset T5 German\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tInformation on model\n\t\n\n\nT-Systems-onsite/mt5-small-sum-de-en-v2\nsource_prefix: \"summarize: \"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"tiny-truthful-qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahmanidashti/tiny-truthful-qa","creator_name":"Hossein A. (Saeed) Rahmani","creator_url":"https://huggingface.co/rahmanidashti","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 790 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rahmanidashti/tiny-truthful-qa.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset\n\t\n\nThis dataset contains image data and explanations for deepfake detection analysis. It includes:\n\nOriginal images\nCAM (Class Activation Map) visualizations\nDetailed technical and non-technical explanations\nConfidence scores and labels\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\ncombined_dataset.csv: The main dataset file containing all information including:\nImage paths\nLabels\nConfidence scores\nTechnical and non-technical explanations for each query\n\n\nimages/: Directory‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset.","first_N":5,"first_N_keywords":["image-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Friend-Or-Foe","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/Friend-Or-Foe","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection! \n\n  \n\n\nThis file contains the description and general structure of the Friend or Foe v.1 collection. The environments are stored in .csv files namely AGORA.csv\nand CARVEME.csv. First 424 columns for AGORA and 499 for CARVEME identify the abreviations for chemical compounds. Last five columns describe the target (regression/classification), the name of dataset (BC/MC/GR), the group of additional compounds (100/50), split (train/val/test) and task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/powidla/Friend-Or-Foe.","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","synthetic","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SunDataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SamuelM0422/SunDataset","creator_name":"Samuel Silva","creator_url":"https://huggingface.co/SamuelM0422","description":"\n  \n\n\n\n\t\n\t\t\n\t\tDataset Labels\n\t\n\n['sun']\n\n\n\t\n\t\t\n\t\tNumber of Images\n\t\n\n{'valid': 374, 'test': 184, 'train': 4047}\n\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\n\nInstall datasets:\n\npip install datasets\n\n\nLoad the dataset:\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"SamuelM0422/SunDataset\", name=\"full\")\nexample = ds['train'][0]\n\n\n\t\n\t\t\n\t\tRoboflow Dataset Page\n\t\n\nhttps://universe.roboflow.com/samuelm0422/sundetection-bwqjs/dataset/1\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SamuelM0422/SunDataset.","first_N":5,"first_N_keywords":["object-detection","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ruforum","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ruforum","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Russian Forum Messages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 58,112,681 messages collected from Russian online forums. Each entry represents a message posted by a user, including metadata such as message ID, timestamp, and the message text. The dataset contains data from approximately 2010 to 04.2025.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ruforum.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","sentiment-classification","found"],"keywords_longer_than_N":true},
	{"name":"UHGEvalDataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\n","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"9111-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/9111-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for 9111.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset includes legal questions and answers from the Russian law forum 9111.ru. It contains inquiries from users and corresponding responses from lawyers. The dataset was created by processing around 21 million questions, providing a significant corpus of legal discussions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/9111-questions.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"datasets-github-issues","keyword":"monolingual","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/alex-atelo/datasets-github-issues","creator_name":"Alexander Atelo Kelly","creator_url":"https://huggingface.co/alex-atelo","description":"\n\t\n\t\t\n\t\tDataset Card for GitHub Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGitHub Issues is a dataset consisting of GitHub issues and pull requests associated with the ü§ó Datasets repository. It is intended for educational purposes and can be used for semantic search or multilabel text classification. The contents of each GitHub issue are in English and concern the domain of datasets for NLP, computer vision, and beyond.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nFor each of the tasks tagged‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alex-atelo/datasets-github-issues.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"ai2_arc-hi","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/ai2_arc-hi","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc\" translated into Hindi\n\t\n\nThis is Hindi translated version of \"ai2_arc\" using the IndicTrans2 model (Gala et al., 2023).\nWe recommend you to visit the \"ai2_arc\" huggingface dataset card (link) for the details.\n","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","found","found"],"keywords_longer_than_N":true},
	{"name":"code_civil","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterlige/code_civil","creator_name":"Denis","creator_url":"https://huggingface.co/Hunterlige","description":"Hunterlige/code_civil dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["monolingual","original","French","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"TrGLUE","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tTrGLUE - A Natural Language Understanding Benchmark for Turkish\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for TrGLUE\n\t\n\nTrGLUE is a natural language understanding benchmarking dataset including several single sentence and sentence pair classification tasks.\nThe inspiration is clearly the original GLUE benchmark.\n\n\t\n\t\t\n\t\tTasks\n\t\n\n\n\t\n\t\t\n\t\tSingle Sentence Tasks\n\t\n\nTrCOLA The original Corpus of Linguistic Acceptability consists of sentences compiled from English literature textbooks. The task is to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"swerec_classification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/swerec_classification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SweRecClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for sentiment classification on review\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.20/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SweRecClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/swerec_classification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"norquad_retrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/norquad_retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHuman-created question for Norwegian wikipedia passages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.17/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NorQuadRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/norquad_retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","Norwegian Bokm√•l"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-news-articles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tinyTruthfulQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA","creator_name":"tinyBenchmarks","creator_url":"https://huggingface.co/tinyBenchmarks","description":"\n\t\n\t\t\n\t\ttinyTruthfulQA\n\t\n\nWelcome to tinyTruthfulQA! This dataset serves as a concise version of the truthfulQA dataset, offering a subset of 100 data points selected from the original compilation. \ntinyTruthfulQA is designed to enable users to efficiently estimate the performance of a large language model (LLM) with reduced dataset size, saving computational resources \nwhile maintaining the essence of the truthfulQA evaluation.\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nCompact Dataset: With only 100 data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"observation_or_evaluation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation","creator_name":"Thomas Gauthier-Caron","creator_url":"https://huggingface.co/thomasgauthier","description":"\n\t\n\t\t\n\t\tDataset Card for \"Observation or evaluation\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains statements classified into observations and evaluations categories, based on the principles of Nonviolent Communication (NVC) teached by Marshall Rosenberg. It includes a synthetic dataset generated and augmented through various language models to classify statements reflecting either pure observations (noticing) or evaluations (judgments), aimed at understanding and practicing effective‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation.","first_N":5,"first_N_keywords":["text-classification","machine-generated","book","tv_script","monolingual"],"keywords_longer_than_N":true},
	{"name":"PLOD-CW","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-CW","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\n\t\n\t\t\n\t\tPLOD: An Abbreviation Detection Dataset\n\t\n\nThis is the repository for PLOD Dataset subset being used for CW in NLP module 2023-2024 at University of Surrey. \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis PLOD Dataset is an English-language dataset of abbreviations and their long-forms tagged in text. The dataset has been collected for research from the PLOS journals indexing of abbreviations and long-forms in the text. This dataset was created to support the Natural Language Processing task of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/PLOD-CW.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Leonardo Zilio, Hadeel Saadany, Prashant Sharma, Shenbin Qian, Diptesh Kanojia, Constantin Orasan","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"EMERCOM-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for psi.mchs.gov.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text-based consultations with Russia's Emergency Psychological Assistance EMERCOM, conducted through their online web portal. It includes the questions and concerns expressed by individuals seeking support, along with the guidance and advice provided by service psychologists. The dataset can be analyzed to understand the nature of anxieties faced by the public and the techniques employed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wb-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset of questions and answers scraped from product pages from the Russian marketplace Wildberries. Dataset contains all questions and answers, as well as all metadata from the API. However, the \"productName\" field may be empty in some cases because the API does not return the name for old products.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-questions.","first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","open-domain-qa","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wb-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from product pages on the Russian marketplace Wildberries. It includes all information from the product card and metadata from the API, excluding image URLs. The dataset was collected by processing approximately 160 million products out of a potential 230 million, starting from the first product. Data collection had to be stopped due to serious rate limits that prevented further progress. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-products.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"MuMiN-PT","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/MuMiN-PT","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tMuMIN-PT\n\t\n\nMuMIN Portuguese Baseline subset extracted using Lingua.\n\nHomepage: https://mumin-dataset.github.io/\nRepository: https://github.com/MuMiN-dataset/mumin-baseline\nPaper:  https://arxiv.org/abs/2202.11684\nLeaderboard: \nPoint of Contact:\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@inproceedings{10.1145/3477495.3531744,\nauthor = {Nielsen, Dan S. and McConville, Ryan},\ntitle = {MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset},\nyear =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/MuMiN-PT.","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"time_series_datasets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zaai-ai/time_series_datasets","creator_name":"ZAAI","creator_url":"https://huggingface.co/zaai-ai","description":"\n\t\n\t\t\n\t\tTourism Monthly Time Series Dataset with Economic and Static Covariates\n\t\n\nThis dataset, originally sourced from Athanasopoulos et al. (2011), focuses on the tourism industry with a monthly frequency and has been enhanced with economic covariates (e.g., CPI, Inflation Rate, GDP) from official Australian government sources. We also perform some preprocessing to further increase the usability of the dataset with dynamic start dates for each series and static covariates for in-depth time‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zaai-ai/time_series_datasets.","first_N":5,"first_N_keywords":["time-series-forecasting","univariate-time-series-forecasting","multivariate-time-series-forecasting","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TimeQA","keyword":"monolingual","license":"BSD 3-Clause Clear License","license_url":"https://choosealicense.com/licenses/bsd-3-clause-clear/","language":"en","dataset_url":"https://huggingface.co/datasets/hugosousa/TimeQA","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\n\t\n\t\t\n\t\tTimeQA\n\t\n\nCheck out the original GitHub repo to learn more about the dataset.\n","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CSMD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davebulaval/CSMD","creator_name":"David","creator_url":"https://huggingface.co/davebulaval","description":"\n\t\n\t\t\n\t\tDataset Card for \"Continuous Scale Meaning Dataset\" (CSMD)\n\t\n\nCSMD was created for MeaningBERT: Assessing Meaning Preservation Between Sentences.\nIt contains 1,355 English text simplification meaning preservation annotations. Meaning preservation measures how well the meaning of the output text corresponds to the meaning of the source (Saggion, 2017).\nThe annotations were taken from the following four datasets: \n\nASSET\nQuestEVal,\nSimpDa_2022 and,\nSimplicity-DA.\n\nIt contains a data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davebulaval/CSMD.","first_N":5,"first_N_keywords":["text-classification","monolingual","aligned","original","extended|other-turkcorpus,other-asset,other-questeval,other-simplicity_da,other-simp_da"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-android","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-android","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackAndroidRetrieval\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-android.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"wb-feedbacks","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-feedbacks","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Wildberries products\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains product reviews from the Russian marketplace Wildberries, collected by mining about The dataset was collected by bruteforcing possible product identifiers (about 230 million) and querying all available feedbacks for them. The data are stored in zstd-archives containing jsonl-files. The 'nmId' in the dataset usually corresponds to the valid product article on the site, but sometimes reviews are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-feedbacks.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mmlu_ita","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swap-uniba/mmlu_ita","creator_name":"SWAP Research Group@UNIBA","creator_url":"https://huggingface.co/swap-uniba","description":"\n\t\n\t\t\n\t\n\t\n\t\tItalian Version of the MMLU DATASET\n\t\n\nBased on the version released by: FreedomIntelligence/MMLU_Italian\nIncludes minor fixes.\n\n\t\n\t\t\n\t\n\t\n\t\tCitations\n\t\n\nThis version:\n@misc{basile2023llamantino,\n      title={LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language}, \n      author={Pierpaolo Basile and Elio Musacchio and Marco Polignano and Lucia Siciliani and Giuseppe Fiameni and Giovanni Semeraro},\n      year={2023},\n      eprint={2312.09993}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swap-uniba/mmlu_ita.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tele_con_ciencia","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for tele_con_ciencia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAccording to the Facebook page of Tele con Ciencia:\n\"Nuestra misi√≥n es la comunicaci√≥n p√∫blica de la ciencia y la tecnolog√≠a mexicana. El objetivo, \nla participaci√≥n activa de todos los mexicanos en las √°reas del descubrimiento cient√≠fico y el \ndesarrollo tecnol√≥gico.\"\n\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\nis to promote the active participation of mexican people in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"medical_qa","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/medical_qa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MedicalQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists 2048 medical question and answer pairs.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MedicalQARetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/medical_qa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"zelensky-speeches","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/slava-medvedev/zelensky-speeches","creator_name":"Viacheslav Medvediev","creator_url":"https://huggingface.co/slava-medvedev","description":"\n\t\n\t\t\n\t\tDataset Card for \"zelenskiy-speeches\"\n\t\n\nSpeeches given by the president of Ukraine Volodymyr ZelenskyLanguages: Ukrainian, EnglishSource: president.gov.uaAuto-updated daily by Github Actions of zelensky-speech-fetcherLicense: CC BY-NC-ND 4.0 Deed\n","first_N":5,"first_N_keywords":["summarization","text-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"medtrain_may23","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/medtrain_may23","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\nlicense: apache-2.0\n\n\t\n\t\t\n\t\tDataset Card for Medical Question Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of question-answer pairs related to various medical topics. The data is structured to provide comprehensive answers to specific medical questions, covering information, diagnosis, treatment, prevention, and susceptibility related to different health conditions.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/medtrain_may23.","first_N":5,"first_N_keywords":["text-generation","language-modeling","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/locuslab/TOFU","creator_name":"Locus Lab","creator_url":"https://huggingface.co/locuslab","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/locuslab/TOFU.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"FOCALtask","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/V12X-ksr/FOCALtask","creator_name":"Kushal S Raj","creator_url":"https://huggingface.co/V12X-ksr","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/V12X-ksr/FOCALtask.","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"squad-augmented-v2","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/christti/squad-augmented-v2","creator_name":"Christoph Timmermann","creator_url":"https://huggingface.co/christti","description":"christti/squad-augmented-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"CHOCOLATE","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khhuang/CHOCOLATE","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","description":"\n\t\n\t\t\n\t\tDataset Card for CHOCOLATE\n\t\n\n\nDataset Description\nPaper Information\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nCHOCOLATE is a benchmark for detecting and correcting factual inconsistency in generated chart captions. It consists of captions produced by six most advanced models, which are categorized into three subsets:\n\nLVLM: GPT-4V, Bard (before Gemini)\nLLM-based Pipeline: DePlot + GPT-4\nFine-tuned Model: ChartT5, MatCha, UniChart\n\nThe charts are from two datasets: VisText and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/CHOCOLATE.","first_N":5,"first_N_keywords":["expert-generated","found","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\n\t\n\t\t\n\t\tGermanRAG üá©üá™üìúü¶ú\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"dbnl.org-dutch-public-domain","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain","creator_name":"Julian von der Goltz","creator_url":"https://huggingface.co/jvdgoltz","description":"\n\t\n\t\t\n\t\tDataset Card for \"dbnl.org-dutch-public-domain\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises a collection of texts from the Dutch Literature in the public domain, specifically from the DBNL (Digitale Bibliotheek voor de Nederlandse Letteren) public domain collection. The collection includes books, poems, songs, and other documentation, letters, etc., that are at least 140 years old and thus free of copyright restrictions. Each entry in the dataset corresponds to one section of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain.","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","Dutch","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"human-eval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/human-eval","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tAiravata HumanEval Prompts\n\t\n\nThis benchmark contains a set of prompts written by real-users to evaluate LLMs on real-world tasks and test it for different abilities. We collect prompts for 5 abilities listed below:\n\nLong: Ability to generate long-form text like writing essays, speeches, reports, etc.\nFact-Ops: Ability to give factual opinions and explanations like seeking recommendations, seeking advice, opinions, explanations, etc.\nContent: Ability to make content accessible like‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/human-eval.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","Hindi"],"keywords_longer_than_N":true},
	{"name":"real-toxicity-prompts-lite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oskarvanderwal/real-toxicity-prompts-lite","creator_name":"Oskar van der Wal","creator_url":"https://huggingface.co/oskarvanderwal","description":"This is a fork of the original RealToxicityPrompts dataset that contains a much smaller subset of the 100k prompts.\nSubsets:\n\n50_pct: This subset contains all the challenging prompts + 50% of the full RealToxicityPrompts size sampled from the other prompts.\n10_pct: This subset contains all the challenging prompts + 10% of the full RealToxicityPrompts size sampled from the other prompts.\n\nPlease refer to the original dataset for the Dataset Card.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","allenai/real-toxicity-prompts","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"vwp","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tonyhong/vwp","creator_name":"Xudong Hong","creator_url":"https://huggingface.co/tonyhong","description":"\n\t\n\t\t\n\t\tDataset Card for Visual Writing Prompts Dataset (VWP)\n\t\n\nWebsite | Github Repository | arXiv e-Print\n\n\nThe Visual Writing Prompts (VWP) dataset contains almost 2K selected sequences of\nmovie shots, each including 5-10 images. The image sequences are aligned with a total of 12K stories which are collected via crowdsourcing given the image sequences and up to 5  grounded characters from the corresponding image sequence.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Links\n\t\n\n\n\n\nTACL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tonyhong/vwp.","first_N":5,"first_N_keywords":["image-to-text","text-generation","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"cms_iom_500","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evekhm/cms_iom_500","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_500.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","https://www.cms.gov/medicare-coverage-database","https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms"],"keywords_longer_than_N":true},
	{"name":"wikipedia_leipzig_de_2016","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2016","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\n\t\n\t\t\n\t\tLeipzig Corpora Wikipedia 2016 German\n\t\n\nThis dataset contains different splits (between 10k and 1mio) from the german wikipedia 2016. The data were collected 2016.\nEvery element in the dataset is labeled as \"neutral\".\nThe source can be found here\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{goldhahn-etal-2012-building,\n    title = \"Building Large Monolingual Dictionaries at the {L}eipzig Corpora Collection: From 100 to 200 Languages\",\n    author = \"Goldhahn, Dirk  and\n      Eckart, Thomas  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2016.","first_N":5,"first_N_keywords":["text-classification","monolingual","German","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cms_iom_3000","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evekhm/cms_iom_3000","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_3000.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","monolingual","https://www.cms.gov/medicare-coverage-database","https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms"],"keywords_longer_than_N":true},
	{"name":"piqa-bn","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/piqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the translated version of the PIQA LLM evaluation dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST), which combines Google Translation with LLM-based rewriting. PIQA introduces the task of physical commonsense reasoning and provides a corresponding benchmark for understanding physical interactions in everyday situations. It focuses on atypical solutions to practical problems, inspired by instructional guides‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hishab/piqa-bn.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","monolingual","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"commonsenseqa-bn","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/commonsenseqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the Bangla translated version of the CommonsenseQA dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST). This method combines both Google Machine Translation and LLM-based rewriting of the translation to enhance the expressiveness and semantic accuracy of the translated content.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData instances\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDefaults\n\t\n\nAn example of a 'train' looks as follows:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hishab/commonsenseqa-bn.","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wikipedia_leipzig_de_2021","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2021","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\n\t\n\t\t\n\t\tLeipzig Corpora Wikipedia 2021 German\n\t\n\nThis dataset contains different splits (between 10k and 1mio) from the german wikipedia 2021. The data were collected 2021.\nEvery element in the dataset is labeled as \"neutral\".\nThe source can be found here\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{goldhahn-etal-2012-building,\n    title = \"Building Large Monolingual Dictionaries at the {L}eipzig Corpora Collection: From 100 to 200 Languages\",\n    author = \"Goldhahn, Dirk  and\n      Eckart, Thomas  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2021.","first_N":5,"first_N_keywords":["text-classification","monolingual","German","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"imdb","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/imdb","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"\n\t\n\t\t\n\t\tDataset Card for \"imdb\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 84.13 MB\nSize of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/imdb.","first_N":5,"first_N_keywords":["text-classification","text-generation","sentiment-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"boolq_bn","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/boolq_bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBoolQ Bangla (BN) is a question-answering dataset for yes/no questions, generated using GPT-4. The dataset contains 15,942 examples, with each entry consisting of a triplet: (question, passage, answer). The questions are naturally occurring, generated from unprompted and unconstrained settings. Input passages were sourced from Bangla Wikipedia, Banglapedia, and News Articles, and GPT-4 was used to generate corresponding yes/no questions with answers.\nThe dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hishab/boolq_bn.","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"3dnews-articles","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/3dnews-articles","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for 3DNews Articles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset comprises news articles from the Russian technology website 3DNews, covering the period from 2003 to 2024. It covers the latest updates in the world of digital technology and insightful commentary from industry experts, spanning the years 2003 to 2024.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is mostly in Russian, but there may be other languages present.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/3dnews-articles.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-english","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-english","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackEnglishRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackEnglishRetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-english.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gaming","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-gaming","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackGamingRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGamingRetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gaming.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-gis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackGisRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGisRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gis.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-mathematica","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-mathematica","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackMathematicaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackMathematicaRetrieval\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-mathematica.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-physics","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-physics","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackPhysicsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackPhysicsRetrieval\"])\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-physics.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-programmers","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-programmers","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackProgrammersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-programmers.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-stats","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-stats","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackStatsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackStatsRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-stats.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-tex","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-tex","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackTexRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackTexRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-tex.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-unix","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-unix","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackUnixRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackUnixRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-unix.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-webmasters","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-webmasters","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackWebmastersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWebmastersRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-webmasters.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-wordpress","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-wordpress","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackWordpressRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWordpressRetrieval\"])\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-wordpress.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/scidocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCIDOCS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/scidocs.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arguana","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arguana","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArguAna\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arguana.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dbpedia","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/dbpedia","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPedia\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/dbpedia.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"hotpotqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/hotpotqa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/hotpotqa.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"climate-fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/climate-fever","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ClimateFEVER\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCLIMATE-FEVER is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims (queries) regarding climate-change. The underlying corpus is the same as FVER.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://www.sustainablefinance.uzh.ch/en/research/climate-fever.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/climate-fever.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NoticIA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\n    \n\n\n\"A Clickbait Article Summarization Dataset in Spanish.\"\n\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\n\nüìñ Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\nüíª Baseline Code: https://github.com/ikergarcia1996/NoticIA\nü§ñ Pre Trained Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA.","first_N":5,"first_N_keywords":["summarization","monolingual","original","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"truthfull_qa-tr","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malhajar/truthfull_qa-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","description":"This Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\n\n\t\n\t\t\n\t\tDataset Card for truthful_qa-tr\n\t\n\nmalhajar/truthful_qa-tr is a translated version of truthful_qa aimed specifically to be used in the OpenLLMTurkishLeaderboard \nDeveloped by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a benchmark to measure whether a language model is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/truthfull_qa-tr.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"gsm8k-tr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/malhajar/gsm8k-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\nmalhajar/GSM8K-tr is a translated version of GSM8K aimed specifically to be used in the OpenLLMTurkishLeaderboard \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/gsm8k-tr.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","Turkish"],"keywords_longer_than_N":true},
	{"name":"NFR_Spanish_requirements_classification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nReSpaN(Spanish Dataset for non-functional requirements classification): Published version of dataset used for paper 'Towards a FAIR Dataset for non-functional requirements'.This dataset was created following the FAIR principles. \n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nIn the dataset_structure file.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tInitial Data Collection and Normalization\n\t\n\nThis dataset was created‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"PROMISE_NFR_translated","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPublished version of PROMISE NFR translated to Spanish used for paper 'Requirements Classification Using FastText and BETO in Spanish Documents'\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nProject: Project's Identifier.\nRequirement: Description of the software requirement.\nLabel: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"ProbaEstructura","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JJFrancisco/ProbaEstructura","creator_name":"jose javier francisco marini","creator_url":"https://huggingface.co/JJFrancisco","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JJFrancisco/ProbaEstructura.","first_N":5,"first_N_keywords":["expert-generated","monolingual","Galician","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"amazon-food-reviews-dataset","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Food Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arxiv_nlp_intstruct","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct","creator_name":"Algorithmic Research Group","creator_url":"https://huggingface.co/AlgorithmicResearchGroup","description":"\n\t\n\t\t\n\t\tDataset Card for \"arxiv_nlp_intstruct\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"AlgorithmicResearchGroup/arxiv_nlp_intstruct\" dataset consists of question-answer pairs derived from ArXiv abstracts from the cs.CL category\". \nQuestions and answers are generated using GPT-3.5-turbo model\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\ttrain\n\t\n\n\nSize of downloaded dataset files: 38.4 MB\n\nAn example of 'train' looks as follows.\n{\n    \"question\": \"What‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct.","first_N":5,"first_N_keywords":["text-generation","language-modeling","masked-language-modeling","no-annotation","monolingual"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"SeeTRUE-Feedback","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback","creator_name":"mismatch-quest","creator_url":"https://huggingface.co/mismatch-quest","description":"\n\t\n\t\t\n\t\tDataset Card for SeeTRUE-Feedback\n\t\n\n\nDataset Description\nSupported Tasks and Leaderboards\nLanguages\n\n\nDataset Structure\nData Fields\nData Splits\n\n\nDataset Creation\nLicensing Information\nCitation Information\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe SeeTRUE-Feedback dataset is a diverse benchmark for the meta-evaluation of image-text matching/alignment feedback. It aims to overcome limitations in current benchmarks, which primarily focus on predicting a matching score between 0-1. SeeTRUE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback.","first_N":5,"first_N_keywords":["crowdsourced","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Marathon","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lemoncoke/Marathon","creator_name":"Lei Zhang","creator_url":"https://huggingface.co/Lemoncoke","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Marathon\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tRelease\n\t\n\n\n[2024/05/15] üî• Marathon is accepted by ACL 2024 Main Conference.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nMarathon benchmark is a new long-context multiple-choice benchmark, mainly based on LooGLE, with some original data from LongBench. The context length can reach up to 200K+. Marathon benchmark comprises six tasks: Comprehension and Reasoning, Multiple Information Retrieval, Timeline Reorder, Computation, Passage Retrieval, and Short‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lemoncoke/Marathon.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","no-annotation","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"math-dataset-instruction","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanjay-29-29/math-dataset-instruction","creator_name":"Sanjay","creator_url":"https://huggingface.co/sanjay-29-29","description":"sanjay-29-29/math-dataset-instruction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","extractive-qa","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"photochat_plus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/passing2961/photochat_plus","creator_name":"Young-Jun Lee","creator_url":"https://huggingface.co/passing2961","description":"\n\t\n\t\t\n\t\tDataset Card for PhotoChat++\n\t\n\n\nüö® Disclaimer: All models and datasets are intended for research purposes only.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPhotoChat++ is a publicly available multi-modal dialogue dataset, an extended version of PhotoChat. PhotoChat++ contains six intent labels, a triggering sentence, an image description, and salient information (e.g., ‚Äúwords‚Äù or ‚Äúphrases‚Äù) to invoke the image-sharing behavior. The purpose of this dataset is to thoroughly assess the image-sharing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/passing2961/photochat_plus.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","conversational","monolingual","PhotoChat"],"keywords_longer_than_N":true},
	{"name":"OpenHermes-2.5-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/OpenHermes-2.5-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\td0rj/OpenHermes-2.5-ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is translated version of teknium/OpenHermes-2.5 into Russian using Google Translate.\n","first_N":5,"first_N_keywords":["text-generation","question-answering","translated","monolingual","teknium/OpenHermes-2.5"],"keywords_longer_than_N":true},
	{"name":"MultiPL-E","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl-staging/MultiPL-E","creator_name":"Northeastern University PRL","creator_url":"https://huggingface.co/nuprl-staging","description":"\n\t\n\t\t\n\t\tDataset Card for MultiPL-E\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPL-E is a dataset for evaluating large language models for code\ngeneration that supports 22 programming languages. It takes the OpenAI \nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\ntranslate them  to other languages. It is easy to add support for new languages \nand benchmarks.\nThe dataset is divided into several configurations named SRCDATA-LANG, where\nSRCDATA is either‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl-staging/MultiPL-E.","first_N":5,"first_N_keywords":["machine-generated","machine-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ru-instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\t–ö–∞—Ä—Ç–æ—á–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n–°–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–ø–∞—Å–∏–±–æ –º–æ–¥–µ–ª–∏ Den4ikAI/nonsense_gibberish_detector). –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω SimHash'–æ–º.\n–û–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –Ω—ë–º –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞ –Ω–µ –∑–∞–≤—ë–∑, in progress.\n\n\t\n\t\t\n\t\t–°–æ—Å—Ç–∞–≤\n\t\n\n–°–æ–±—Ä–∞–ª –∏–∑ —ç—Ç–∏—Ö –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö:\n\nd0rj/OpenOrca-ru (–æ—Ç Open-Orca/OpenOrca)\nd0rj/OpenHermes-2.5-ru (–æ—Ç teknium/OpenHermes-2.5)\nd0rj/dolphin-ru (–æ—Ç ehartford/dolphin)\nd0rj/alpaca-cleaned-ru (–æ—Ç‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct.","first_N":5,"first_N_keywords":["text-generation","machine-generated","found","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"stock_market_asx_audio","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","description":"\n\t\n\t\t\n\t\tDataset Card for Stock Market ASX Audio\n\t\n\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nsentence_id (string): An id for the sentence used for the recording.\nvoice_id (string): An id for which client (voice) made the recording.\naudio (dict): A dictionary containing the path to the downloaded audio file.\nsentence (string): The sentence the user was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","sdeering","google translate","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PUGG_KBQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_KBQA","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\n\nKBQA (Knowledge Base Question Answering)\nMRC (Machine Reading Comprehension)\nIR (Information Retrieval)\n\n\n\t\n\t\t\n\t\tPaper\n\t\n\nFor more detailed information, please refer to our research paper titled:\n\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\" \nAuthored by:\n\nAlbert Sawczyn\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_KBQA.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PUGG_MRC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_MRC","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\n\nKBQA (Knowledge Base Question Answering)\nMRC (Machine Reading Comprehension)\nIR (Information Retrieval)\n\n\n\t\n\t\t\n\t\tPaper\n\t\n\nFor more detailed information, please refer to our research paper titled:\n\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\" \nAuthored by:\n\nAlbert Sawczyn\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_MRC.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PUGG_IR","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_IR","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\n\nKBQA (Knowledge Base Question Answering)\nMRC (Machine Reading Comprehension)\nIR (Information Retrieval)\n\n\n\t\n\t\t\n\t\tPaper\n\t\n\nFor more detailed information, please refer to our research paper titled:\n\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\" \nAuthored by:\n\nAlbert Sawczyn\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_IR.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"192-Youtube-Channel-Views-Count","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count","creator_name":"Muhammad Suleman","creator_url":"https://huggingface.co/leodeveloper2000","description":"\n\t\n\t\t\n\t\t192 YouTube Channel Views Count\n\t\n\nThis project compiles and analyzes data from 192 YouTube channels, totaling approximately 166,411 videos. The dataset includes information such as video titles, view counts, publish dates, and authors.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe 192 YouTube Channel Views Count project aims to provide insights and analytics on video performance across 192 different YouTube channels. By aggregating data such as video titles, view counts, publish dates, and authors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"smartlab-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/smartlab-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Smart-lab.ru Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Smart-lab.ru, a Russian platform for discussing up-to-date stock exchange information, market news, investment ideas, and trading methods. Each entry in the dataset represents a post from the website, including its title, content, author, and a unique identifier.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, though some posts may contain content in other languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/smartlab-posts.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"filtered-coyo-700M-beta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","description":"\n\t\n\t\t\n\t\tDataset Card for filterred-coyo-700M-beta\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe texts in the COYO-700M dataset consist of English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance in COYO-700M represents single image-text pair information with meta-attributes:\n{\n  'id': 841814333321,\n  'url': 'https://blog.dogsof.com/wp-content/uploads/2021/03/Image-from-iOS-5-e1614711641382.jpg',\n  'text': 'A Pomsky dog‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"TrCOLA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tTrCOLA - Corpus of Linguistic Acceptability for Turkish Language\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for TrCOLA\n\t\n\nTrCOLA is the Turkish version of CoLA dataset, The Corpus of Linguistic Acceptability.\nThis dataset introduces linguistic acceptability task for Turkish. The total dataset size is 9.9K instances.\nEach instance of the dataset is an original and correct sentence, variation of sentence that is produced in a specific way, the variation type and a binary label stating the sentence is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","monolingual","original","Turkish"],"keywords_longer_than_N":true},
	{"name":"HM-SYNC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saluslab/HM-SYNC","creator_name":"SALUS Lab","creator_url":"https://huggingface.co/saluslab","description":"\n\t\n\t\t\n\t\tDataset Card for this Human-Machine Interaction Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains a collection of observed interactions between humans and an advanced manufacturing machine, specifically a Wire Arc Additive Manufacuturing (WAAM) machine. The motivations for collecting this dataset, the contents of this dataset, and some ideas for how to analyze and use this dataset can be found below. \nAdditionally, the paper introducing this dataset is published in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saluslab/HM-SYNC.","first_N":5,"first_N_keywords":["video-classification","time-series-forecasting","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"spanishBFF2","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMG/spanishBFF2","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nSpanish-BFF-2 is the second Spanish AI-generated dictionary using GPT4.\n\nPaper: Building another Spanish dictionary, this time with GPT-4: https://arxiv.org/abs/2406.11218\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSpanish-BFF contains a total of 76,963 lemmas with its definitions.\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nSpanish (es)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/spanishBFF2.","first_N":5,"first_N_keywords":["AI-generated","monolingual","Spanish","gpl-3.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"unlearning","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LZ12DH/unlearning","creator_name":"Li Zhaodonghui","creator_url":"https://huggingface.co/LZ12DH","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LZ12DH/unlearning.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"open-coursebooks-pl","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rafalposwiata/open-coursebooks-pl","creator_name":"Rafa≈Ç Po≈õwiata","creator_url":"https://huggingface.co/rafalposwiata","description":"Open Coursebooks PL (based on https://epodreczniki.open.agh.edu.pl/) \n","first_N":5,"first_N_keywords":["text-classification","topic-classification","multi-class-classification","multi-label-classification","monolingual"],"keywords_longer_than_N":true},
	{"name":"scidef","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PL-MTEB/scidef","creator_name":"Polish Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/PL-MTEB","description":"PL-MTEB/scidef dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Polish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"ai2_arc_ita","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","description":"\n\t\n\t\t\n\t\tDataset Card for Ai2 ARC (ita)\n\t\n\n\n\nThis dataset is a machine-translated version of Ai2 ARC into Italian.\n\nLicensed under CC-BY 4.0\nTranslated with TowerInstruct-7B-v0.2\nMore details and code used for translation will follow shortly.\n\nThe rest of the page is WIP :)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","monolingual","Italian"],"keywords_longer_than_N":true},
	{"name":"tt-crawl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tt-crawl","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on low-resource languages, we release TatarCrawl dataset, a web news corpus consisting of materials from nearly 15 unique sources in the Tatar Language.\nTo load and use dataset, run this script:\nfrom datasets import load_dataset\n\ntt_crawl=load_dataset(\"neurotatarlar/tt-crawl\")\n\n","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"mnist3d","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d","creator_name":"Cristiano Pizzamiglio","creator_url":"https://huggingface.co/cristiano-pizzamiglio","description":"\n\n\t\n\t\t\n\t\tDataset Card for MNIST3D\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST3D dataset consists of 70,000 point clouds of handwritten digits generated \nby converting the images from the original MNIST dataset.\nEach point cloud has 193 points.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe data is split into training and test set. The original data split of the MNIST \ndataset is preserved.\n\n\t\n\t\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d.","first_N":5,"first_N_keywords":["other","expert-generated","found","monolingual","extended|mnist"],"keywords_longer_than_N":true},
	{"name":"swim-ir-monolingual","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Monolingual)\n\t\n\n\n\n\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual retrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tarwiiga_adgen_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","description":"\n\t\n\t\t\n\t\tTarwiiga AdGen Dataset\n\t\n\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\n","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nGitHub Issues with comments\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/huggingface/datasets/issues\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues.","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","text-generation","fill-mask"],"keywords_longer_than_N":true},
	{"name":"MATH-Hard","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lighteval/MATH-Hard","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","description":"\n\t\n\t\t\n\t\tDataset Card for Mathematics Aptitude Test of Heuristics, hard subset (MATH-Hard) dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more. \nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations. For MATH-Hard, only the \nhardest questions were kept (Level 5).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lighteval/MATH-Hard.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"DarijaMMLU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\n\t\n\t\t\n\t\tDataset Card for DarijaMMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDarijaMMLU is an evaluation benchmark designed to assess large language models' (LLM) performance in Moroccan Darija, a variety of Arabic. It consists of 22,027 multiple-choice questions, translated from selected subsets of the Massive Multitask Language Understanding (MMLU) and ArabicMMLU benchmarks to measure model performance on 44 subjects in Darija.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Category: Multiple-choice question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","machine-generated","machine-translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"code_leak_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fyt7943/code_leak_qa","creator_name":"fyt","creator_url":"https://huggingface.co/fyt7943","description":"fyt7943/code_leak_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"bordaru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/bordaru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Borda.ru Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Borda.ru, a Russian platform for hosting various discussion forums on a wide range of topics. Each entry in the dataset represents a post from the website, including its content, author, URL, and other relevant information. The dataset contains 5,251,346 unique messages. The dataset was deduplicated based on the \"content\" value, which removed spam and other low-quality data, keeping‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/bordaru-posts.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"CoMDataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qijimrc/CoMDataset","creator_name":"Ji Qi","creator_url":"https://huggingface.co/qijimrc","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWe open-source both the Automatically Synthesized CoM Data and the Manually Annotated CoM-Math Data to facilitate potential research. The automatically synthesized CoM data (i.e., com.jsonl) consists of 84K positive reasoning chains, which was produced by an automated data generation pipeline with an LLM-based (GPT-4) linguistic solving steps generation and a VFMs-based (GroundingDINO, PaddleOCR) visual evidence compensation upon massive public VQA samples. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qijimrc/CoMDataset.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"cohere_aya_arabic","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic","creator_name":"Mohamed AbuElNasr","creator_url":"https://huggingface.co/abuelnasr","description":"\n\t\n\t\t\n\t\tArabic aya dataset\n\t\n\nThis dataset is the arabic partition of the CohereForAI/aya_dataset dataset. \nFor more information about the dataset, visit the original dataset repo: CohereForAI/aya_dataset.\nthe data was extracted using this simple code:\n# Train split.\naya_train = datasets.load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\narb_train = aya_train.filter(lambda x: x[\"language_code\"] == \"arb\")\narb_train = arb_train.remove_columns([\"language_code\", \"user_id\"])\n\n# Test split.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic.","first_N":5,"first_N_keywords":["other","monolingual","CohereForAI/aya_dataset","Standard Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ElisonSherton/github-issues","creator_name":"Vinayak Nayak","creator_url":"https://huggingface.co/ElisonSherton","description":"ElisonSherton/github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","multi-class-classification","topic-classification","found"],"keywords_longer_than_N":true},
	{"name":"PIQA-eu","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/PIQA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for PIQA-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPIQA-eu is the professional translation to Basque of the PIQA's \n(Bisk et al., 2020) validation partition. \nPIQA is a commonsense QA benchmark for naive physics reasoning focusing on how we interact with everyday\nobjects in everyday situations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nPIQA-eu examples look like this:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/PIQA-eu.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","natural-language-inference","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"virgool_62k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Msobhi/virgool_62k","creator_name":"mohamad sobhi","creator_url":"https://huggingface.co/Msobhi","description":"This dataset represents the publicly available collection of data scraped from the virgool.io website. The data extraction was strategically performed based on specific tags and user. The dataset comprises approximately 62,000 entries across several key attributes: title, text, tags, likes, replies, reading_time, user_id, and URL.\nThis resource is particularly beneficial for researchers and developers aiming to pre-train large language models (LLMs), as the 'text' column provides a rich corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Msobhi/virgool_62k.","first_N":5,"first_N_keywords":["fill-mask","text-generation","text-classification","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"Hindi_Fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIhnIndicRag/Hindi_Fever","creator_name":"AIHN Indic Rag Community","creator_url":"https://huggingface.co/AIhnIndicRag","description":"AIhnIndicRag/Hindi_Fever dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","Hindi"],"keywords_longer_than_N":true},
	{"name":"XCOPA-eu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/XCOPA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for XCOPA-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXCOPA-eu is the professional translation to Basque of the English COPA dataset (Roemmmele et al., 2011),\nin the spirit of the XCOPA effort (Ponti et al., 2020). \nCOPA is a dataset of causal commmonsense reasoning that focuses on cause-effect relationships between a\npremise and two choices.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/XCOPA-eu.","first_N":5,"first_N_keywords":["text-classification","multiple-choice","natural-language-inference","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"MGSM-eu","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/MGSM-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for MGSM-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMGSM (Shi et al., 2023) is a subset of 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) that has been manually translated into 10 typologically diverse languages.\nHere, we provide professional translations to yet another language: Basque.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMGSM-eu train examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MGSM-eu.","first_N":5,"first_N_keywords":["found","expert-generated","monolingual","extended|juletxara/mgsm","Basque"],"keywords_longer_than_N":true},
	{"name":"wnli-eu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/wnli-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for WNLI-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWNLI-eu is the professional translation to Basque of the WNLI dataset.\nWNLI is part of the GLUE benchmark for English (Wang et al., 2018) \nand is based on the Winograd Schema Challenge (WSC) dataset (Levesque et al., 2011):\n\nA Winograd schema is a pair of sentences differing in only one or two words and containing an ambiguity that is resolved in opposite ways in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/wnli-eu.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SentiTurca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/SentiTurca","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tSentiTurca - A Sentiment Analysis Benchmark for Turkish\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for SentiTurca\n\t\n\nSentiTurca is a sentiment analysis benchmarking dataset including movie reviews, hate speech and e-commerce reviews classification.  \n\n\t\n\t\t\n\t\tDatasets\n\t\n\ne-commerce: The e-commerce reviews are scraped from e-commerce websites Trendyol.com and Hepsiburada.com, including review for many product types such as cloths, toys, books, electronics and more.E-commerce reviews has their stand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/SentiTurca.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","Duygu Altinok","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TrQuAD","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrQuAD","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tTrQuAD - The Turkish SQuAD\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for TrQuAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTrQuAD is a Turkish question answering dataset, being the Turkish translation of SQuAD.\nWe translated the original SQuAD by the LLM Snowflake Arctic. The total dataset is around 61.6K.\nMore information about the translation process, translation prompts and more can be found in our research paper.\nDataset instances are identical with the original SQuAD format:\n{\n  \"id\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrQuAD.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","Duygu Altinok","monolingual","rajpurkar/squad"],"keywords_longer_than_N":true},
	{"name":"MMBench-DEV-RU","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tMMBench-DEV-RU\n\t\n\n–≠—Ç–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π Dev —Å–ø–ª–∏—Ç mmbench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM.\n–ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª –ø—Ä–∏ –ø–æ–º–æ—â–∏ gpt-4, —á–∞—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –±—ã–ª–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ –∞—Å—Å–µ—Å–æ—Ä–∞–º–∏.\n–í –¥–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞–ª–∞—è —á–∞—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞. \n–°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫: https://huggingface.co/spaces/opencompass/MMBench\n\n\t\n\t\t\n\t\n\t\n\t\t–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n\t\n\nhttps://github.com/Natyren/mmbench-ru-eval\n–§–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –ø—Ä–æ–≥–Ω–∞—Ç—å –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É gt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU.","first_N":5,"first_N_keywords":["visual-question-answering","monolingual","original","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"copyright_unlearning","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/boyiwei/copyright_unlearning","creator_name":"Boyi Wei","creator_url":"https://huggingface.co/boyiwei","description":"boyiwei/copyright_unlearning dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFU-C","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"soda-audio","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fixie-ai/soda-audio","creator_name":"Ultravox.ai","creator_url":"https://huggingface.co/fixie-ai","description":"Parent dataset: SODA\nThe dataset was created based on SODA by first subsetting it and then adding two synthetic columns for training the Ultravox model:\n\nalt_last_turn: is an alternative for the last turn of the dialogue (dialogue[-1]) and was (re-)generated by Llama-3-8B Instruct;\naudio_one_but_last: is the TTS'd speech for the turn before the last one (dialogue[-2]) using the Eleven Labs voice API using a set of random voices.\n\n","first_N":5,"first_N_keywords":["machine-generated","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"agxqa_v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/msu-ceco/agxqa_v1","creator_name":"The Computational Ecohydrology Group at MSU","creator_url":"https://huggingface.co/msu-ceco","description":"\n\t\n\t\t\n\t\tDataset Card for AgXQA 1.1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Agricultural eXtension Question Answering Dataset (AgXQA 1.1) is a small-scale, SQuAD-like QA dataset targeting the Agriculture Extension domain. \nVersion 1.1 currently contains 2.1K+ questions related to irrigation topics across the US, focusing on the Midwest since our crops of interest were mainly soybean and corn.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion Answering.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/msu-ceco/agxqa_v1.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sec-material-contracts-qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"800+ EDGAR contracts with PDF images and key information extracted by the OpenAI GPT-4o model.\nThe key information is defined as follows:\nclass KeyInformation(BaseModel):\n    agreement_date : str = Field(description=\"Agreement signing date of the contract. (date)\")\n    effective_date : str = Field(description=\"Effective date of the contract. (date)\")\n    expiration_date : str = Field(description=\"Service end date or expiration date of the contract. (date)\")\n    party_address : str =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/sec-material-contracts-qa.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","document-question-answering","visual-question-answering","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"STAIR-Captions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/STAIR-Captions","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"\n\t\n\t\t\n\t\tDataset Card for STAIR-Captions\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSTAIR Captions is a large-scale dataset containing 820,310 Japanese captions. This dataset can be used for caption generation, multimodal retrieval, and image generation.\n\n\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\n\n\n\n\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language data in JDocQA is in Japanese (BCP-47 ja-JP).\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shunk031/STAIR-Captions.","first_N":5,"first_N_keywords":["image-to-text","image-captioning","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"sec-material-contracts-qa-splitted","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa-splitted","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"Mixed and filtered version of chenghao/sec-material-contracts-qa and jordyvl/DUDE_subset_100val.\n","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","document-question-answering","visual-question-answering","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"IMDB_Sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kwaai/IMDB_Sentiment","creator_name":"Kwaai","creator_url":"https://huggingface.co/Kwaai","description":"\n\t\n\t\t\n\t\tDataset Card for \"imdb\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 84.13 MB\nSize of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kwaai/IMDB_Sentiment.","first_N":5,"first_N_keywords":["text-classification","text-generation","sentiment-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"RealToxicityPrompts","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts.","first_N":5,"first_N_keywords":["text-generation","monolingual","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MMLU-SR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiniCat/MMLU-SR","creator_name":"Cat Wang","creator_url":"https://huggingface.co/NiniCat","description":"\n\t\n\t\t\n\t\tMMLU-SR Dataset\n\t\n\nThis is the dataset for the paper \"MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three different variants:\n\nQuestion Only: Key terms in questions are replaced with dummy words and their definitions, while answer choices remain unchanged.\nAnswer Only: Key terms in answer choices are replaced with dummy words and their definitions, while questions remain unchanged. \nQuestion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NiniCat/MMLU-SR.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"afrixnli-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrixnli","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrimgsm-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimgsm","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrimmlu-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\n\t\n\t\t\n\t\tDataset Card for afrimmlu-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"tt-azatliq-crawl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl","creator_name":"VeryREAL","creator_url":"https://huggingface.co/veryrealtatarperson","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAzatliqCrawl is a document-level dataset in Tatar language based on Azatliq newspaper.\nThere are two versions released: the noisy dataset, which has no filtering, and the clean dataset,  which has a variety of filters applied (language identification using fasstext BOW and deduplication using MinHashLSH with number of permutations equal to 128 and threshold equal to 0.9), though it naturally has a fair amount of noise itself. Each dataset is released in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"histoires_morales","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LabHC/histoires_morales","creator_name":"Laboratoire Hubert Curien","creator_url":"https://huggingface.co/LabHC","description":"Together with the Moral Stories dataset, Histoires Morales can be used for:\n\nCommonsense reasoning / social reasoning / moral reasoning The dataset can help evaluate whether pretrained language models can reason about actions that are consistent or inconsistent with social norms, the consequences of actions, and the norms that may motivate those actions. A Mistral model or Mistral-Instruct can be used for this purpose.\n\nText classification This dataset can be used to train models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LabHC/histoires_morales.","first_N":5,"first_N_keywords":["text-classification","multiple-choice","text-generation","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"PathPal","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alternativerealitystudio/PathPal","creator_name":"Alternative Reality Studio","creator_url":"https://huggingface.co/alternativerealitystudio","description":"\n\t\n\t\t\n\t\tDataset Name: Descriptive and Categorized Travel Snippets\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset is a synthetic collection created from 160 different travel-related categories, providing detailed descriptions of accessible adventures and activities. It aims to inspire and inform individuals about opportunities accommodating diverse needs, each entry pairing a detailed description with a category label reflecting the nature of the activity.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nDescriptions:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alternativerealitystudio/PathPal.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"HET_Transfer_Orbit_Efficiency","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/HET_Transfer_Orbit_Efficiency","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"Data on the impact of space weather on Hall Effect Thrusters (HETs) efficiency, used in spacecraft transfer orbits","first_N":5,"first_N_keywords":["expert-generated","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"MoroccanSocialMedia-MultiGen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\n\t\n\t\t\n\t\tDataset Card for MoroccanSocialMedia-MultiGen (MSM-MG)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMoroccanSocialMedia-MultiGen (MSM-MG) is a dataset of 12,973 pairs of native Darija social media posts (tweets and YouTube comments) and their synthetic counterparts. The dataset supports six tasks: Continuation, Reply, Summarization, Rephrasing, Explanation, and Safe Response. The synthetic generations were created by prompting Claude 3.5 Sonnet to perform each of these tasks based on the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","machine-generated","machine-translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Liu123456789/test","creator_name":"L","creator_url":"https://huggingface.co/Liu123456789","description":"Liu123456789/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cantemist","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masaenger/cantemist","creator_name":"Mario S√§nger","creator_url":"https://huggingface.co/masaenger","description":"\n\t\n\t\t\n\t\tDataset Card for CANTEMIST\n\t\n\nCollection of 1301 oncological clinical case reports written in Spanish, with tumor morphology mentions manually annotated and mapped by clinical experts to a controlled terminology. Every tumor morphology mention is linked to an eCIE-O code (the Spanish equivalent of ICD-O).\nThe original dataset is distributed in Brat format, and was randomly sampled into 3 subsets. The training, development and test sets contain 501, 500 and 300 documents each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masaenger/cantemist.","first_N":5,"first_N_keywords":["monolingual","Spanish","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"AuthorMix","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jrfish/AuthorMix","creator_name":"Jillian Fisher","creator_url":"https://huggingface.co/jrfish","description":"\n\t\n\t\t\n\t\tDataset Card for AuthorMix\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAUTHORMIX, was originally created for authorship obfuscation task and had data from four distinct domains: presidential speeches, early-1900s fiction novels, scholarly articles, and diary-style blogs. Altogether, AUTHORMIX contains over 30k high-quality paragraphs from 14 authors.\nThis work was created in the paper: StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements, which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jrfish/AuthorMix.","first_N":5,"first_N_keywords":["text-classification","other","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"BuyukSinema","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/BuyukSinema","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tB√ºy√ºkSinema - A Large Scale Turkish Movie Reviews Sentiment Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nB√ºy√ºkSinema is a Turkish movie reviews dataset of size 87K, scraped from Sinefil.com and Beyazperde.com. Hence this dataset is a superset of\nBeyazPerde All Movie Reviews,\nBeyazPerde Top 300 Movie Reviews and \nSinefil Movie Reviews datasets. \nThis is a merge of the three different datasets from two resources, hence we scaled the output stars into the range of 1-10 accordingly. \nThe star‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/BuyukSinema.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","Duygu Altinok","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"my-awesome-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Axion004/my-awesome-dataset","creator_name":"Matthew Kehoe","creator_url":"https://huggingface.co/Axion004","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axion004/my-awesome-dataset.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"grouse","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/illuin/grouse","creator_name":"Illuin Technology","creator_url":"https://huggingface.co/illuin","description":"\n\t\n\t\t\n\t\tDataset Card for GroUSE\n\t\n\nGroUSE (Grounded QA Unitary Scoring of Evaluators) is a dataset designed to assess the performance of Grounded QA evaluators. Its purpose is to evaluate whether an LLM, when used as a grounded QA evaluator, delivers the expected scores across six metrics when presented with both good and imperfect answers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEach sample is of the following form :\n{\n    \"references\": [\n        \"[Content of the 1st‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/illuin/grouse.","first_N":5,"first_N_keywords":["expert-generated","monolingual","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, Universit√§t Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meter‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"PUGG_KG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_KG","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the knowledge graph dedicated for \nthe KBQA (Knowledge Base Question Answering) task within the PUGG dataset. This repository does not \ncontain directly any task, but it provides the knowledge graph that can be used to solve the KBQA \ntask from the PUGG dataset.\n\n\t\n\t\t\n\t\tGraphs\n\t\n\nWe provide sampled versions of the knowledge graph based on Wikidata:\n\nWikidata1H: A subgraph created by traversing 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_KG.","first_N":5,"first_N_keywords":["monolingual","multilingual","found","Polish","English"],"keywords_longer_than_N":true},
	{"name":"youtube-timestamps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lyleokoth/youtube-timestamps","creator_name":"lyle okoth","creator_url":"https://huggingface.co/lyleokoth","description":"\n\t\n\t\t\n\t\tDataset Card for YouTube Videos Timestamps extraction dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: mit\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyleokoth/youtube-timestamps.","first_N":5,"first_N_keywords":["text-classification","text-scoring","@lyleokoth","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ARC-eu","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/ARC-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tDataset Card for ARC-eu\n\t\n\n\nPoint of Contact: hitz@ehu.eus\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nARC-eu is the professional translation to Basque of ARC's \n(Clark et al., 2018) validation and test partitions. \nARC is a QA benchmark of grade-school level, multiple-choice science questions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\neu-ES\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nARC-eu examples look like this:\n{\n    \"id\": \"MCAS_2000_4_6\",\n    \"question\": \"Zein teknologia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/ARC-eu.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"TOFU-C","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-C","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cf","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cf","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cf.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cr","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cr.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"books","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IsmaelMousa/books","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","description":"\n\t\n\t\t\n\t\tBooks\n\t\n\nThe books dataset consists of a diverse collection of books organized into 9 categories, it splitted to train, validation where the train contains 40 books, and the validation 9 books.\nThis dataset is cleaned well and designed to support various natural language processing (NLP) tasks, including text generation and masked language modeling.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nThe dataset contains 4 columns:\n\ntitle: The tilte of the book.\nauthor: The author of the book.\ncategory: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/books.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","IsmaelMousa"],"keywords_longer_than_N":true},
	{"name":"libri-in-italiano","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","description":"\n\t\n\t\t\n\t\tLibri\n\t\n\nIl dataset dei libri consiste in una raccolta diversificata di 18 libri organizzati in 4 categorie.\nQuesto dataset √® ben pulito e progettato per supportare diversi compiti di elaborazione del linguaggio naturale (NLP), inclusi generazione di testo, traduzione e modellazione del linguaggio mascherato.\n\n\t\n\t\t\n\t\tDettagli\n\t\n\nIl dataset contiene 4 colonne:\n\ntitolo: Il titolo del libro.\nautore: L'autore del libro.\ncategoria: Il genere/categoria del libro.\ncontenuto: Il contenuto‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano.","first_N":5,"first_N_keywords":["text-generation","translation","fill-mask","IsmaelMousa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"capivara-plugin-orchestration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","description":"\n\t\n\t\t\n\t\t# Dataset Card for Capivara Plugin Orchestration\n\t\n\n","first_N":5,"first_N_keywords":["text-generation","conversational","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"humaneval_splits","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iskhare/humaneval_splits","creator_name":"Ishan Khare","creator_url":"https://huggingface.co/iskhare","description":"\n\t\n\t\t\n\t\tDataset Card for HumanEval with Splits\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe programming problems are written in Python and contain English natural text in comments and docstrings.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iskhare/humaneval_splits.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"TurkishHateMap","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TurkishHateMap","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\n\t\n\t\t\n\t\tTurkish Hate Map - A Large Scale and Diverse Hate Speech Dataset for Turkish\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkish Hate Map (TuHaMa for short) is a big scale Turkish hate speech dataset that includes diverse target groups such as misogyny,\npolitical animosity, animal aversion, vegan antipathy, ethnic group hostility, and more. The dataset includes a total of 52K instances with 13 target groups.\nThe dataset includes 4 labels, offensive, hate, neutral and civilized.\nHere is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TurkishHateMap.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","Duygu Altinok","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-v3","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/webis-touche2020-v3","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"castorini/webis-touche2020-v3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","BeIR/webis-touche2020","English"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"spanish-corpus-xix","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"PUGG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\n\nKBQA (Knowledge Base Question Answering)\nMRC (Machine Reading Comprehension)\nIR (Information Retrieval)\n\n\n\t\n\t\t\n\t\tPaper\n\t\n\nFor more detailed information, please refer to our research paper titled:\n\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\" \nAuthored by:\n\nAlbert Sawczyn\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","document-retrieval","expert-generated"],"keywords_longer_than_N":true},
	{"name":"big-patent","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/big-patent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BigPatentClustering.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of documents from the Big Patent dataset. Test set only includes documentsbelonging to a single category, with a total of 9 categories.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/NortheasternUniversity/big_patent\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/big-patent.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","jinaai/big-patent-clustering","English"],"keywords_longer_than_N":true},
	{"name":"plvideo","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/plvideo","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Platforma Video Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was scraped from video pages on the Russian video-sharing platform Platforma, a Russian YouTube alternative. It includes information about 181,876 videos across 12,341 channels. The dataset contains detailed information about each video and its associated channel, providing a comprehensive view of the content available on the platform.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, but there‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/plvideo.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"medotvet-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/medotvet-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for medotvet.ru Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,319 medical questions and answers from the Russian website medotvet.ru. It includes questions posed by users seeking medical advice, along with responses provided by doctors across various specialties. The dataset can be analyzed to understand common health concerns among the Russian-speaking population and the types of medical advice provided online.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/medotvet-questions.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"womanru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/womanru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Woman.ru Forum Posts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,308,238 forum posts from Woman.ru, a popular Russian-language information and entertainment portal. Woman.ru is one of the most visited women's sites in Runet (Russian Internet). The dataset covers posts from around 2005 to 2024, providing a comprehensive view of discussions on the platform over nearly two decades.\nThe content includes original posts and replies on various topics, offering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/womanru-posts.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFUCr1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFUCr1","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCr1.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"24gadget-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/24gadget-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for 24gadget.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from 24gadget.ru, a Russian technology news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and view count. The dataset contains 36,582 unique articles covering various topics in technology and gadgets.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/24gadget-posts.","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"roemru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/roemru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Roem.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from Roem.ru, a Russian technology and business news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and author. The dataset contains 19,528 unique articles covering various topics in technology, business, and digital media.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/roemru-posts.","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fishkinet-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fishkinet-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Fishki.net\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Fishki.net, a Russian entertainment and news website. Each entry in the dataset represents a post from the website, including its title, content, author, publication date, tags, images, and URL. The dataset contains 369,180 unique posts covering various topics in entertainment, news, and social media content.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fishkinet-posts.","first_N":5,"first_N_keywords":["text-classification","image-classification","summarization","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"steambans","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/steambans","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Steam User Bans\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 476,694 Steam users, including their profile details, ban status, and gaming activity. The data was collected from the Steam platform and includes information such as Steam ID, profile URL, username, avatar, account creation date, visibility state, VAC and game bans, economy ban status, time since last ban, Steam level, friend count, game count, total playtime, and CS2 playtime.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/steambans.","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","multi-label-classification","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFUCrP","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFUCrP","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCrP.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MNIST","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p2pfl/MNIST","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","description":"\n\t\n\t\t\n\t\tüñºÔ∏è MNIST (Extracted from PyTorch Vision)\n\t\n\nMNIST is a classic dataset of handwritten digits, widely used for image classification tasks in machine learning.\n\n\t\n\t\t\n\t\t‚ÑπÔ∏è Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tüìñ Dataset Description\n\t\n\nThe MNIST database of handwritten digits is a commonly used benchmark dataset in machine learning. It consists of 70,000 grayscale images of handwritten digits (0-9), each with a size of 28x28 pixels. The dataset is split into 60,000 training images and 10,000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/MNIST.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"CIFAR10","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p2pfl/CIFAR10","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","description":"\n\t\n\t\t\n\t\tüñºÔ∏è CIFAR10 (Extracted from PyTorch Vision)\n\t\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n\n\t\n\t\t\n\t\t‚ÑπÔ∏è Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tüìñ Dataset Description\n\t\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The classes are completely mutually exclusive. There is no‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/CIFAR10.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-Shuffle","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"rule34lol-webm","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/rule34lol-webm","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Rule34.lol WebM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about WebM files from Rule34.lol, a booru-style imageboard. The dataset includes metadata for 22,733 WebM files, including URLs, tags, and file information. The actual WebM files are stored in zip archives, with each archive containing 500 WebM files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset metadata is primarily in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rule34lol-webm.","first_N":5,"first_N_keywords":["video-classification","text-to-video","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-single","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-single","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-single.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"monkey_business","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ScalingIntelligence/monkey_business","creator_name":"Scaling Intelligence","creator_url":"https://huggingface.co/ScalingIntelligence","description":"\n\t\n\t\t\n\t\tMonkey Business\n\t\n\nMonkey Business is a dataset of samples from large language models. It contains both correct and incorrect samples from a variety of models (the Llama-3, Gemma, and Pythia series) on a variety of tasks (problems from GSM8K, MATH, CodeContests, and MiniF2F-MATH). We hope that it can be useful for developing improved verification methods that assess whether a model generated answer is correct.\nThis dataset was created as part of the project: \"Large Language Monkeys:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ScalingIntelligence/monkey_business.","first_N":5,"first_N_keywords":["monolingual","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"TOFU-Cbin","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cbin","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cbin.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-Direct","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Direct","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Direct.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"IMDB-Reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Daksh0505/IMDB-Reviews","creator_name":"Daksh Bhardwaj ","creator_url":"https://huggingface.co/Daksh0505","description":"\n\t\n\t\t\n\t\tDataset Card for IMDb Multi-Movie Review Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe IMDb Multi-Movie Review Dataset contains approximately 114,000 user reviews collected from over 150 movies on IMDb.Each movie is stored as a separate JSON file, identified by its movie_id (IMDb ID).Each JSON file includes a list of structured reviews, where every review consists of:\n\ntitle: A short summary or headline of the review.\nreview: The full detailed user review.\nrating: A numeric rating (1‚Äì10)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Daksh0505/IMDB-Reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowd-sourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"synthetic_dropout_dataset_vietnam_100k_final_lhu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LHUThacSi/synthetic_dropout_dataset_vietnam_100k_final_lhu","creator_name":"LHU Thac Si","creator_url":"https://huggingface.co/LHUThacSi","description":"\n\t\n\t\t\n\t\tStudent Dropout Prediction Dataset (Lac Hong University - Synthetic)\n\t\n\nThis dataset is a synthetically generated dataset representing student academic and behavioral data at Lac Hong University.\nIt is intended for machine learning tasks that predict student dropout risks.\n\n\t\n\t\t\n\t\tüìä Features\n\t\n\n\nStudentID: Unique student identifier (format: 1YYxxxxxx)\nLUC: Lack of University Commitment (Likert 1‚Äì5)\nDCC: Degree Commitment Conflict (Likert 1‚Äì5)\nITM: Ineffective Time Management (Likert‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LHUThacSi/synthetic_dropout_dataset_vietnam_100k_final_lhu.","first_N":5,"first_N_keywords":["tabular-classification","tabular-multi-class-classification","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikipedia-paragraph-keywords","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/wikipedia-paragraph-keywords","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tWikipedia Paragraph and Keyword Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 10,693 paragraphs extracted from English Wikipedia articles, along with corresponding search-engine style keywords for each paragraph. It is designed to support tasks such as text summarization, keyword extraction, and information retrieval.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured as a collection of JSON objects, each representing a single paragraph with its associated keywords.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/wikipedia-paragraph-keywords.","first_N":5,"first_N_keywords":["text-classification","summarization","text-retrieval","topic-classification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","English"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","ClimateFEVER","English"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","DBPedia","English"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FEVER","English"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FiQA2018","English"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HotpotQA","English"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MSMARCO","English"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NFCorpus","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQ","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NQ","English"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SCIDOCS","English"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Touche2020","English"],"keywords_longer_than_N":true},
	{"name":"twinviews-13k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\n\t\n\t\t\n\t\tDataset Card for TwinViews-13k\n\t\n\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k.","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"TruthGen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/TruthGen","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\n\t\n\t\t\n\t\tDataset Card for TruthGen\n\t\n\nTruthGen is a dataset of generated political statements, created to assess the relationship between truthfulness and political bias in reward models and language models. It consists of non-repetitive, non-political factual statements paired with false statements, designed to evaluate models for their ability to distinguish true from false information while minimizing political content. The dataset was generated using GPT-3.5, GPT-4 and Gemini, with a focus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/TruthGen.","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"MATH_LVL5_fr","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\n\t\n\t\t\n\t\tDataset Card for MATH_LVL5_fr\n\t\n\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise des probl√®mes math√©matiques de niveau avanc√© du dataset MATH.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMATH_LVL5_fr est une adaptation fran√ßaise des probl√®mes math√©matiques de niveau 5 (le plus avanc√©) du dataset MATH original. Il comprend des probl√®mes de comp√©tition math√©matique de niveau lyc√©e, format√©s de mani√®re coh√©rente avec LaTeX pour les‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","French"],"keywords_longer_than_N":true},
	{"name":"ukiyo-e-face-blip2-captions","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions","creator_name":"Image Generation with Python","creator_url":"https://huggingface.co/py-img-gen","description":"\n\t\n\t\t\n\t\tDataset Card for ukiyo-e-face-blip2-captions\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nukiyo-e-face-blip2-captions is a dataset that adds captions to Ukiyo-e face dataset using BLIP2 model.\n\n\n\n\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\n\n\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language data in ukiyo-e-face-blip2-captions is in English.\n\n\n\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nimport datasets as ds\n\ndataset = ds.load_dataset(\"py-img-gen/ukiyo-e-face-blip2-captions\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions.","first_N":5,"first_N_keywords":["text-to-image","machine-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"question_answering","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/azizmatin/question_answering","creator_name":"Aziz Matin","creator_url":"https://huggingface.co/azizmatin","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis Question Answering dataset is a reading comprehension resource derived from Persian Wikipedia. This crowd-sourced dataset contains over 9,000 entries, each of which can either be an unanswerable question or a question with one or more answers based on the provided context. Similar to the SQuAD2.0 dataset, the inclusion of unanswerable questions allows for the development of systems that \"know they don't know the answer.\" Additionally, the dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azizmatin/question_answering.","first_N":5,"first_N_keywords":["question-answering","monolingual","Persian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"RAG-Evaluation-Dataset-KO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO","creator_name":"DongWook Kim","creator_url":"https://huggingface.co/datalama","description":"\n\t\n\t\t\n\t\tDataset Card for Reconstructed RAG Evaluation Dataset (KO)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ allganize/RAG-Evaluation-Dataset-KOÎ•º Í∏∞Î∞òÏúºÎ°ú PDF ÌååÏùºÏùÑ Ìè¨Ìï®ÌïòÎèÑÎ°ù Ïû¨Íµ¨ÏÑ±Ìïú ÌïúÍµ≠Ïñ¥ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑúÎäî PDF ÌååÏùºÏùò Í≤ΩÎ°úÎßå Ï†úÍ≥µÎêòÏñ¥ ÏàòÎèôÏúºÎ°ú ÌååÏùºÏùÑ Îã§Ïö¥Î°úÎìúÌï¥Ïïº ÌïòÎäî Î∂àÌé∏Ìï®Ïù¥ ÏûàÏóàÍ≥†, ÏùºÎ∂Ä PDF ÌååÏùºÏùò Í≤ΩÎ°úÍ∞Ä Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Î¨∏Ï†úÎ•º Î≥¥ÏôÑÌïòÍ∏∞ ÏúÑÌï¥ PDF ÌååÏùºÏùÑ Ìè¨Ìï®Ìïú Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ïû¨Íµ¨ÏÑ±ÌïòÏòÄÏäµÎãàÎã§.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nRAG Evaluation: Î≥∏ Îç∞Ïù¥ÌÑ∞Îäî ÌïúÍµ≠Ïñ¥ RAG ÌååÏù¥ÌîÑÎùºÏù∏Ïóê ÎåÄÌïú E2E EvaluationÏù¥ Í∞ÄÎä•Ìï©ÎãàÎã§.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Korean (ko).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO.","first_N":5,"first_N_keywords":["other","human-annotated","monolingual","extended|allganize/RAG-Evaluation-Dataset-KO","Korean"],"keywords_longer_than_N":true},
	{"name":"distributed-computing-complex","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JsZe/distributed-computing-complex","creator_name":"Jeffrey Zhou","creator_url":"https://huggingface.co/JsZe","description":"\n\t\n\t\t\n\t\tDistributed Systems Q&A Dataset\n\t\n\nThis dataset is collection of question-and-answer pairs related to distributed systems, compiled from a list of commonly asked questions in a college-level class. \nThis dataset is designed to assist educators, researchers, and developers working on tuning AI models, chatbots, or educational tools in the field of distributed systems.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nQuestions: A variety of questions covering fundamental distributed systems concepts.\nAnswers:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JsZe/distributed-computing-complex.","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_Eval_Real","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"A newer version of this dataset is available.\nhttps://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real_v1.1\n\n\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"arthrography-imaging","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/arthrography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\n\t\n\t\t\n\t\tArthrography Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 500 synthetic arthrography procedure reports designed to represent realistic medical scenarios encountered in clinical practice. Each report includes:\n\nPatient demographics: Age and sex.\nClinical indications: Detailed descriptions of reasons for undergoing the procedure, crafted at a PhD level.\nJoint examined: Specific joint under examination (e.g., shoulder, knee, hip, etc.).\nContrast agent used: The type‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/arthrography-imaging.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tiny-stack","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fhswf/tiny-stack","creator_name":"Fachhochschule S√ºdwestfalen","creator_url":"https://huggingface.co/fhswf","description":"\n\t\n\t\t\n\t\tAbout\n\t\n\nDataset for tinystack.\n","first_N":5,"first_N_keywords":["other","machine-generated","monolingual","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vibeeval_greek","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilsp/vibeeval_greek","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","description":"\n\t\n\t\t\n\t\tDataset Card for Vibe-Eval Greek\n\t\n\nThe Vibe-Eval Greek dataset is a benchmark of 269 examples for evaluating multimodal chat models, including especially challenging examples. It has been manually translated into Greek from the VibeEval dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nEach example has the following fields:\n\nmedia_url: a URL where the file is hosted publicly\nexample_id: a unique ID for the example\ncategory: the category that this example belongs to, either difficulty-normal or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/vibeeval_greek.","first_N":5,"first_N_keywords":["image-to-text","image-classification","monolingual","Greek","English"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"myelography-imaging","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/myelography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\n\t\n\t\t\n\t\tMyelography Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 750 synthetic myelography examination records representing a wide spectrum of spinal pathologies and patient experiences. Each record includes:\n\nPatient demographics: Age and sex.\nClinical symptoms prompting the procedure: Detailed and verbose descriptions.\nProcedural details: Contrast medium type, injection site, and imaging modality used.\nVerbose findings: Observations such as spinal cord compression‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/myelography-imaging.","first_N":5,"first_N_keywords":["text-classification","named-entity-recognition","news-articles-summarization","synthetic","monolingual"],"keywords_longer_than_N":true},
	{"name":"xlam-function-calling-60k-raw-augmented","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\n\t\n\t\t\n\t\tXLAM Function Calling 60k Raw Augmented Dataset\n\t\n\nThis dataset includes augmented train and test splits derived from product-science/xlam-function-calling-60k-raw.\n\nTrain split size: Original size plus augmented data\nTest split size: Original size plus augmented data\n\n\n\t\n\t\t\n\t\n\t\n\t\tAugmentation Details\n\t\n\nThis dataset has been augmented by modifying function names in the original data. Randomly selected function names have underscores replaced with periods at random positions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented.","first_N":5,"first_N_keywords":["question-answering","language-modeling","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"llmops-database","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","description":"\n\t\n\t\t\n\t\tThe ZenML LLMOps Database\n\t\n\n\nTo learn more about ZenML and our open-source MLOps framework, visit\nzenml.io.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LLMOps Database is a comprehensive collection of over 500 real-world\ngenerative AI implementations that showcases how organizations are successfully\ndeploying Large Language Models (LLMs) in production. The case studies have been\ncarefully curated to focus on technical depth and practical problem-solving,\nwith an emphasis on implementation details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database.","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-classification","text-generation","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"aircraft-images","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/aircraft-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for High-Resolution Aircraft Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 165,340 high-resolution aircraft images collected from the internet, along with machine-generated captions. The captions were generated using Gemini Flash 1.5 AI model and are stored in separate text files matching the image filenames.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All image captions are in English\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/aircraft-images.","first_N":5,"first_N_keywords":["image-classification","image-to-text","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-All","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-C-All","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C-All.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"telugu-summarization-generation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"DBPedia_test_top_250_only_w_correct-v2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPediaHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","mteb/dbpedia","English"],"keywords_longer_than_N":true},
	{"name":"jaqket","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/jaqket","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaqketRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJAQKET (JApanese Questions on Knowledge of EnTities) is a QA dataset that is created based on quiz questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\nReference\nhttps://github.com/kumapo/JAQKET-dataset\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JaqketRetrieval\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/jaqket.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-v3","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/webis-touche2020-v3","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Touche2020Retrieval.v3\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTouch√© Task 1: Argument Retrieval for Controversial Questions\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/castorini/touche-error-analysis\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Touche2020Retrieval.v3\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/webis-touche2020-v3.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"balinese-carving-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aegishield/balinese-carving-dataset","creator_name":"Bagus Prasetyo","creator_url":"https://huggingface.co/aegishield","description":"\n\t\n\t\t\n\t\tDataset Card for Balinese Carving Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains images of Balinese carvings along with their classifications, materials, and color descriptions. It is designed for image classification and retrieval tasks related to Balinese art and cultural heritage.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset supports multi-label image classification for Balinese carving styles and image retrieval based on textual descriptions of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aegishield/balinese-carving-dataset.","first_N":5,"first_N_keywords":["image-classification","image-to-text","multi-label-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\n\t\n\t\t\n\t\ttest\n\t\n\ntest1\n","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"fun_rec","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ykckevin/fun_rec","creator_name":"kevin","creator_url":"https://huggingface.co/ykckevin","description":"\n\t\n\t\t\n\t\tsmall demo learning how to use dataset in huggingface\n\t\n\n","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"prezented","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/prezented","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Prezented.ru Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 2,289 educational presentations from the prezented.ru platform, a service focused on educational presentations for Russian schools. The dataset includes presentation titles, descriptions, download URLs, thumbnail images, and the original PPT/PPTX files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nRussian (ru): All content is in Russian\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/prezented.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","QuoraRetrieval","English"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SciFact","English"],"keywords_longer_than_N":true},
	{"name":"QueryBridge","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aorogat/QueryBridge","creator_name":"Abdelghny Orogat","creator_url":"https://huggingface.co/aorogat","description":"\n\t\n\t\t\n\t\tQueryBridge: One Million Annotated Questions with SPARQL Queries - Dataset for Question Answering over Knowledge Graph\n\t\n\nThe QueryBridge dataset is the first and largest dataset with annotated questions for question answering (QA) over knowledge graphs. It provides a comprehensive resource for developing and testing algorithms that process and interpret natural language questions in the context of structured knowledge. In addition to QA tasks, QueryBridge can also be used for:\n\nEntity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aorogat/QueryBridge.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"LLaVA-OneVision-Data-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tLLaVA-OneVision-Data-ru\n\t\n\nTranslated lmms-lab/LLaVA-OneVision-Data dataset into Russian language using Google translate.\n\nAlmost all datasets have been translated, except for the following:\n[\"tallyqa(cauldron,llava_format)\", \"clevr(cauldron,llava_format)\", \"VisualWebInstruct(filtered)\", \"figureqa(cauldron,llava_format)\", \"magpie_pro(l3_80b_mt)\", \"magpie_pro(qwen2_72b_st)\", \"rendered_text(cauldron)\", \"ureader_ie\"]\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nimport datasets\n\n\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru.","first_N":5,"first_N_keywords":["text-generation","visual-question-answering","image-to-text","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"traffic-qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paulelliotco/traffic-qa","creator_name":"Paul Elliot","creator_url":"https://huggingface.co/paulelliotco","description":"\n\t\n\t\t\n\t\tFHWA Traffic Signal Timing Q&A Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n4,368 Q&A pairs on traffic signal timing topics.  \nAI-generated using Google's Gemini model.  \nStructured for training and fine-tuning AI models.  \nBased on official FHWA documentation.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nQuestion: Traffic signal timing question.  \nAnswer: Detailed technical answer.  \nSection ID: Reference to the original source section.  \nChapter: Chapter‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulelliotco/traffic-qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CodeMMLU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\n\t\n\t\t\n\t\tCodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities\n\t\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tüìå CodeMMLU\n\t\n\nCodeMMLU is a comprehensive benchmark designed to evaluate the capabilities of large language models (LLMs) in coding and software knowledge. \nIt builds upon the structure of multiple-choice question answering (MCQA) to cover a wide range of programming tasks and domains, including code generation, defect detection, software engineering principles, and much more.\n\n\t\n\t\t\n\t\tüìÑ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TOFU-C-All","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-All","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\n\t\n\t\t\n\t\tTOFU: Task of Fictitious Unlearning üç¢\n\t\n\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\n\n\t\n\t\t\n\t\tQuick Links\n\t\n\n\nWebsite: The landing page for TOFU‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-All.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wise-data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meaningalignment/wise-data","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe wise-data and wise-data-preferences datasets are synthetically created collections of values-laden conversations, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. These datasets were specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","multi-class-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"legal_reason","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chemouda/legal_reason","creator_name":"Moudather Chelbi","creator_url":"https://huggingface.co/chemouda","description":"\n\t\n\t\t\n\t\tEnhanced Legal Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Enhanced Legal Reasoning Dataset is a synthetic dataset designed to facilitate the fine-tuning of Large Language Models (LLMs) for tasks related to legal reasoning and argumentation. It encompasses a diverse range of legal scenarios across multiple domains, capturing the nuanced techniques employed by legal professionals in constructing their arguments.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chemouda/legal_reason.","first_N":5,"first_N_keywords":["text-classification","named-entity-recognition","human","synthetic","monolingual"],"keywords_longer_than_N":true},
	{"name":"chatgpt-in-russia-qa","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for —á–∞—Ç–≥–ø—Ç-–≤-—Ä–æ—Å—Å–∏–∏.—Ä—Ñ\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains question-answer pairs collected from —á–∞—Ç–≥–ø—Ç-–≤-—Ä–æ—Å—Å–∏–∏.—Ä—Ñ (meaning in English would be something like chatgpt-in-russia[.]rf), a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 704,208 unique question-answer pairs covering various topics.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wise-data-preferences","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meaningalignment/wise-data-preferences","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe wise-data-preferences dataset is a synthetically created collection of values-laden conversations with preferred and rejected responses, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. This dataset was specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using DPO (Direct Preference Optimization).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data-preferences.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","multi-class-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ruschatgpt-qa","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for ruschatgpt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains question-answer pairs collected from ruschatgpt.ru, a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 190,281 unique question-answer pairs covering various topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"told-br","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/told-br","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrazilianToxicTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced by 42 annotators selected from\n    a pool of 129 volunteers. Annotators were selected aiming to create a plural group in terms of demographics (ethnicity,\n    sexual orientation, age, gender). Each tweet was labeled by three annotators in 6 possible categories: LGBTQ+phobia,\n    Xenophobia, Obscene, Insult‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/told-br.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"COVID-QA-el-small","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-QA-el-small","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-QA-el-small\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe COVID-QA-el-small dataset is a Greek-language subset of 826 examples derived from the COVID-QA-el dataset, translated using machine translation. The dataset follows the SQuADv1.1 fashion style. \nThe original dataset, COVID-QA: A Question Answering Dataset for COVID-19  (ACL 2020) contains 2,019 question-answer pairs annotated by volunteer biomedical experts on scientific literature about COVID-19.\n\n\t\n\t\t\n\t\n\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-QA-el-small.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","extractive-qa","monolingual","deepset/covid_qa_deepset"],"keywords_longer_than_N":true},
	{"name":"COVID-19_qa_pairs","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\n\t\n\t\t\n\t\tDataset Card for COVID-19_qa_pairs dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis datasets includes 604 question-answer pairs related to COVID-19 pandemic machine translated in Greek language. \nThe data is extracted from the official website of WHO.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nquestion: Query question\ndocument: Answer to the question\n\n\n\t\n\t\t\n\t\tBias, Risks, and Limitations\n\t\n\nThis dataset is the result of machine translation.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe dataset is licensed under the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","monolingual","original","Greek"],"keywords_longer_than_N":true},
	{"name":"amr-3-parsed","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoshuhan/amr-3-parsed","creator_name":"hoshuhan","creator_url":"https://huggingface.co/hoshuhan","description":"\n\t\n\t\t\n\t\tDataset Card for AMR 3.0 Parsed\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains parsed Abstract Meaning Representation (AMR) annotations from the LDC2020T02 release, formatted as instruction-following conversations. Each example consists of a sentence and its corresponding AMR graph representation.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks: Semantic parsing, specifically generating AMR graphs from English sentences\nLeaderboards: AMR Parsing\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoshuhan/amr-3-parsed.","first_N":5,"first_N_keywords":["machine-generated","expert-generated","monolingual","ldc2020t02","English"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"InstructIR-mteb","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InstructIR-mteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InstructIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA benchmark specifically designed to evaluate the instruction following ability in information retrieval models. Our approach focuses on user-aligned instructions tailored to each query instance, reflecting the diverse characteristics inherent in real-world search scenarios. NOTE: scores on this may differ unless you include instruction first, then \"[SEP]\" and then the query via redefining combine_query_and_instruction in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InstructIR-mteb.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"WordNetNoun","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/WordNetNoun","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from WordNet's subsumption (hypernym) hierarchy of noun entities for training and evaluating hierarchy embedding models.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"azkurs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/azkurs","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Azkurs.org\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 566,713 pages of educational content in Azerbaijani language extracted from azkurs.org website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Azerbaijani (az) only.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/azkurs.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"SNLI-NLI","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/SNLI-NLI","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\n\t\n\t\t\n\t\tDataset Card for SNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/SNLI-NLI.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER_test_top_250_only_w_correct-v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ClimateFEVER_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ClimateFEVERHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCLIMATE-FEVER is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://www.sustainablefinance.uzh.ch/en/research/climate-fever.html‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ClimateFEVER_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"HotpotQA_test_top_250_only_w_correct-v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HotpotQA_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQAHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.  The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HotpotQA_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","description":"\n\n\n    \n\n\n\n\n\n\n\n    1.5K Steam Reviews Binary Labeled for Constructiveness\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\n\nAlso available as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"polymath","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","description":"\n\t\n\t\t\n\t\tPaper Information\n\t\n\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including Chain-of-Thought‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath.","first_N":5,"first_N_keywords":["multiple-choice","expert-generated","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"1M-OpenOrca_be","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be","creator_name":"Artsem Holub","creator_url":"https://huggingface.co/WiNE-iNEFF","description":"En/Be\nüêã The Belarusian OpenOrca Dataset! üêã\n\n\n\nBelarusian OpenOrca dataset - is rich collection of augmented FLAN data aligns, that translated in belarusian language.\nThat dataset should help training LLM in belarusian language and should help on other NLP tasks.\nThis dataset have 2 version:\n\n~1M GPT-4 completions (Now translating)\n~3.2M GPT-3.5 completions (Can be translated in future)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe fields are:\n\n'id', a unique numbered identifier which includes one of 'niv'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"COVID-19-el-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\n\t\n\t\t\n\t\tDataset Card for\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus contains Greek-language texts about the COVID-19 pandemic including relevant information, FAQs, etc. The texts were collected from official websites (WHO, ECDC, NPHO, covid19.gov.gr) and articles from the greek Wikipedia. Total number of words: 204,748.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach instance contains:\n\ncontent: Plain text\nid: Instance ID\ntitle: A document title (only in instances related to Wikipedia articles)\n\n\n\t\n\t\t\n\t\tLicensing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus.","first_N":5,"first_N_keywords":["monolingual","original","Greek","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"kompy","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/kompy","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Kompy.info\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 584,648 pages of educational content in Uzbek language extracted from kompy.info website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Uzbek (uz).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/kompy.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Urdu"],"keywords_longer_than_N":true},
	{"name":"nemo-github-issues","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Urdu"],"keywords_longer_than_N":true},
	{"name":"emojis","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/emojis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Emojis.com\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 3,264,372 AI-generated emoji images from Emojis.com. Each entry represents an emoji with associated metadata including prompt text and image URLs.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nslug: Unique identifier for the emoji (string)\nid: Internal ID (string) \nnoBackgroundUrl:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/emojis.","first_N":5,"first_N_keywords":["text-to-image","image-classification","multi-class-image-classification","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Urdu"],"keywords_longer_than_N":true},
	{"name":"search-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/junzhang1207/search-dataset","creator_name":"John","creator_url":"https://huggingface.co/junzhang1207","description":"\n\t\n\t\t\n\t\tAI Search Providers Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìä Dataset Structure\n\t\n\nEach entry contains:\n\nid: Unique identifier for the QA pair\nquestion: The query text\nexpected_answer: The correct answer\ncategory: Topic category\narea: Broader area classification (News/Knowledge)\n\n\n\t\n\t\t\n\t\tüéØ Categories\n\t\n\nThe dataset covers various domains including:\n\nEntertainment\nSports\nTechnology\nGeneral News\nFinance\nArchitecture\nArts\nAstronomy\nAuto (Automotive)\nE-sports\nFashion\nFalse Premise\n\n\n\t\n\t\t\n\t\tüìà‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junzhang1207/search-dataset.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"bower-waste-annotations","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BowerApp/bower-waste-annotations","creator_name":"Bower (Sugi Group AB)","creator_url":"https://huggingface.co/BowerApp","description":"\n\t\n\t\t\n\t\tDataset Card for waste annotations made by the recycling solution Bower\n\t\n\n\n  \n\n\n\nThe data offered by Bower (Sugi Group AB) in collaboration with Google.org \n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe bower-waste-annotations dataset consists of 1440 images of waste and various consumer items taken by consumer phone cameras. The images are annotated with Material type and Object type classes, listed below.\nThe images and annotations has been manually reviewed to ensure correctness. It is assumed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BowerApp/bower-waste-annotations.","first_N":5,"first_N_keywords":["Bower employees","monolingual","Bower internal'","English","mit"],"keywords_longer_than_N":true},
	{"name":"publicdomainpictures","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/publicdomainpictures","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Public Domain Pictures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 644,412 public domain images from publicdomainpictures.net, a public domain photo sharing platform. The dataset includes detailed image metadata including titles, descriptions, and keywords.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All metadata including titles, descriptions and keywords\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe metadata for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/publicdomainpictures.","first_N":5,"first_N_keywords":["image-classification","image-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"twi_words","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_words","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Dataset\n\t\n\nThe Twi Words Dataset is a curated list of over 50,000 unique words in Twi, a major language spoken in Ghana. This dataset aims to support Natural Language Processing (NLP) tasks in Twi, particularly for low-resource language modeling, classification, and lexicon development.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is created to support:\n\nNLP development for low-resource African languages\nSpell checkers and autocorrect models\nText-to-speech and speech-to-text training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_words.","first_N":5,"first_N_keywords":["translation","language-identification","self-annotated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test","creator_name":"riccardo schillaci","creator_url":"https://huggingface.co/Riccardoschillaci7","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cui si chiedeva ad un publico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Smatteux/sentiment-analysis-test","creator_name":"daniele matteucci","creator_url":"https://huggingface.co/Smatteux","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cu isi chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato stato realizzato all'interno di un corsp pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Smatteux/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test","creator_name":"Marco Palumbo","creator_url":"https://huggingface.co/MarcPal08","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test","creator_name":"giovanni de santis","creator_url":"https://huggingface.co/Giova-tech","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personake amministrativo e famiglie di rispondere ad alcune domande\nsul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali an indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelliggenza artificiale.\nGrazie a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"grustnogram","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/grustnogram","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Grustnogram\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 597,704 posts from Grustnogram.ru, a Russian \"emotional network\" similar to Instagram but with a distinctive black and white filter aesthetic and dark atmosphere. The dataset includes 542,917 image posts with associated metadata and 54,787 anonymous text-only posts.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset is divided into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/grustnogram.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-classification","multi-label-image-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"cdg-continued-fractions-qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahlen/cdg-continued-fractions-qa","creator_name":"Cahlen Humphreys","creator_url":"https://huggingface.co/cahlen","description":"\n\t\n\t\t\n\t\tDataset Card for Continued Fractions QA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Continued Fractions QA dataset is a synthetic question-answering corpus focused on continued fractions and their theoretical and applied connections in mathematics and neural network interpretability. Each entry includes a question and an answer, occasionally embedding LaTeX-styled mathematical expressions within <math> tags for clarity.\nTopics covered include:\n\nSimple and generalized continued fractions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahlen/cdg-continued-fractions-qa.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"enhanced-cobald","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoBaLD/enhanced-cobald","creator_name":"CoBaLD Annotation Project","creator_url":"https://huggingface.co/CoBaLD","description":"\n\t\n\t\t\n\t\tCoBaLD Dataset\n\t\n\nAn umbrella repository for CoBaLD datasets that provides a unified Hugging Face Datasets API.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nFor citation, refer to the source datasets at github.com/CobaldAnnotation.\n","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC0","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-SA-4.0","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-SA-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution-ShareAlike 4.0 International (CC-BY-SA-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ProcessedOpenAssistant-mistral-large-2411","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PursuitOfDataScience/ProcessedOpenAssistant-mistral-large-2411","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","description":"\n\t\n\t\t\n\t\tDataset¬†Summary\n\t\n\nProcessed¬†OpenAssistant¬†‚Äî¬†Mistral‚ÄëLarge‚Äë2411 pairs 27¬†¬†563 unique English prompts‚Äîdeduplicated from the Apache‚Äë2.0‚Äìlicensed¬†[Processed¬†OpenAssistant corpus]‚Äîwith answers generated on 21¬†Apr¬†2025 by the paid‚ÄëAPI model mistral‚Äëlarge‚Äë2411, the 24‚ÄëNov‚Äë2024 checkpoint of Mistral‚Äôs 123¬†B parameter instruction‚Äëtuned series¬†:contentReference[oaicite:0]{index=0}¬†:contentReference[oaicite:1]{index=1}.Answers were produced with the /v1/chat/completions endpoint in streaming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/ProcessedOpenAssistant-mistral-large-2411.","first_N":5,"first_N_keywords":["question-answering","machine-generated","found","monolingual","PursuitOfDataScience/ProcessedOpenAssistant"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os Lus√≠adas by Lu√≠s Vaz de Cam√µes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"BC-III-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-III-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-IV-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-IV-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-I-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-II-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-IV-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-IV-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BC-V-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/BC-V-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MC-I-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-I-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MC-II-50","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/MC-II-50","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-classification","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-I-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-I-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GR-II-100","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/powidla/GR-II-100","creator_name":"Sasha","creator_url":"https://huggingface.co/powidla","description":"Welcome to the Friend or Foe Collection!\n","first_N":5,"first_N_keywords":["tabular-regression","synthetic","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"checking","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shainaraza/checking","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","description":"\n\t\n\t\t\n\t\tHumaniBench: A Human-Centric Visual QA Dataset\n\t\n\nHumaniBench is a dataset for evaluating visual question answering models on tasks that involve human-centered attributes such as gender, age, and occupation.\nEach data point includes:\n\nID: Unique identifier\nAttribute: A social attribute (e.g., gender, race)\nQuestion: A visual question related to the image\nAnswer: The ground-truth answer\nimage: Embedded image in base64 or file format for visual preview\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample Entry\n\t\n\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shainaraza/checking.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mb-landmark_cls","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-landmark_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-landmark_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: oth\n1: cra\n2: ddu\n3: sst\n4: bdu\n5: ime\n6: sch\n7: spi\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 6997 images\ntest: 1793 images\nval: 2025 images\nfew_shot_train_2_shot: 16 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-landmark_cls.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-surface_cls","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-surface_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-surface_cls\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: apx\n1: act\n2: arm\n3: art\n4: cct\n5: cio\n6: clr\n7: dls\n8: dri\n9: drh\n10: drp\n11: drt\n12: flr\n13: gro\n14: hor\n15: inl\n16: lar\n17: ltv\n18: mah\n19: mct\n20: mas\n21: mca\n22: nsk\n23: obt\n24:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-surface_cls.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Twin-2K-500","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLM-Digital-Twin/Twin-2K-500","creator_name":"Digital-Twin@Columbia-Business-School","creator_url":"https://huggingface.co/LLM-Digital-Twin","description":"\n\t\n\t\t\n\t\tTwin-2K-500 Dataset\n\t\n\nThis dataset Twin-2K-500 contains comprehensive persona information from a representative sample of 2,058 US participants, providing rich demographic and psychological data. The dataset is specifically designed for building digital twins for LLM simulations.\n\nMore information on how to use this dataset can be found in our GitHub repository.\nDetails on how the dataset was generated are available in our Paper.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nTwin-2K-500 Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLM-Digital-Twin/Twin-2K-500.","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","multi-class-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"mb-change_cls_ctx","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-change_cls_ctx","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-change_cls_ctx\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: no_change\n1: change\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 72 images\ntest: 20 images\nval: 20 images\npartition_train_0.50x_partition: 18 images\npartition_train_0.20x_partition: 7 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-change_cls_ctx.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-surface_multi_label_cls","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-surface_multi_label_cls","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tMER - Mars Exploration Rover Dataset\n\t\n\nA multi-label classification dataset containing Mars images from the Mars Exploration Rover (MER) mission for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset uses multi-label classification, meaning each image can have multiple class labels.\nThe dataset contains the following classes:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-surface_multi_label_cls.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-dust_devil_det","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-dust_devil_det","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-dust_devil_det Dataset\n\t\n\nAn object detection dataset in YOLO format containing 10 splits: train, val, test, 0.01x_partition, 0.02x_partition, 0.50x_partition, 0.20x_partition, 0.05x_partition, 0.10x_partition, 0.25x_partition.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-14\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\nSplits: train, val, test, 0.01x_partition, 0.02x_partition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-dust_devil_det.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"promptoxicity","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GioApc/promptoxicity","creator_name":"Aparecido O","creator_url":"https://huggingface.co/GioApc","description":"\n\t\n\t\t\n\t\tDataset Card for Real Toxicity Prompts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance represents a prompt and its metadata:\n{\n  \"filename\":\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\",\n  \"begin\":340,\n  \"end\":564,\n  \"challenging\":false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GioApc/promptoxicity.","first_N":5,"first_N_keywords":["monolingual","original","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"deepschool_dataset_demo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/voronik1801/deepschool_dataset_demo","creator_name":"Voronik_test","creator_url":"https://huggingface.co/voronik1801","description":"\n\t\n\t\t\n\t\tMy First Test Dataset üá∑üá∫\n\t\n\n–û–ø–∏—Å–∞–Ω–∏–µ:–ù–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Ö –∫–ª–∞—Å—Å–æ–≤.\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\n\nid ‚Äî –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–∏\ntext ‚Äî —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\nlabel ‚Äî –º–µ—Ç–∫–∞: 0 ‚Äî –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, 1 ‚Äî –≤–æ–ø—Ä–æ—Å\n\n–ò—Å—Ç–æ—á–Ω–∏–∫:–°–æ–∑–¥–∞–Ω –≤—Ä—É—á–Ω—É—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ Hugging Face Hub.\n–õ–∏—Ü–µ–Ω–∑–∏—è:MIT License\n–≠—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è:  \n\n–î–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n–í—Å–µ –ø—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ.\n\n–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voronik1801/deepschool_dataset_demo.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"deepschool_demo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/voronik1801/deepschool_demo","creator_name":"Voronik_test","creator_url":"https://huggingface.co/voronik1801","description":"\n\t\n\t\t\n\t\tMy First Test Dataset üá∑üá∫\n\t\n\n–û–ø–∏—Å–∞–Ω–∏–µ:–ù–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Ö –∫–ª–∞—Å—Å–æ–≤.\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\n\nid ‚Äî –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–∏\ntext ‚Äî —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\nlabel ‚Äî –º–µ—Ç–∫–∞: 0 ‚Äî –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, 1 ‚Äî –≤–æ–ø—Ä–æ—Å\n\n–ò—Å—Ç–æ—á–Ω–∏–∫:–°–æ–∑–¥–∞–Ω –≤—Ä—É—á–Ω—É—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ Hugging Face Hub.\n–õ–∏—Ü–µ–Ω–∑–∏—è:MIT License\n–≠—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è:  \n\n–î–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n–í—Å–µ –ø—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ.\n\n–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voronik1801/deepschool_demo.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fisda","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamsran/fisda","creator_name":"Myngan","creator_url":"https://huggingface.co/jamsran","description":"jamsran/fisda dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","crowdsource","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_customer_service_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"SciDocsRR","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SciDocsRR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SciDocsRR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRanking of related scientific papers based on their title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SciDocsRR\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SciDocsRR.","first_N":5,"first_N_keywords":["text-ranking","monolingual","mteb/scidocs","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"VoyageMMarcoReranking","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VoyageMMarcoReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VoyageMMarcoReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\na hard-negative augmented version of the Japanese MMARCO dataset as used in Voyage AI Evaluation Suite\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\nReference\nhttps://arxiv.org/abs/2312.16144\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VoyageMMarcoReranking\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VoyageMMarcoReranking.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 32926\nFiltered size: 32926\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 210350\nFiltered size: 210350\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"begemot","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/begemot","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Begemot.ai\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 2,728,999 educational project descriptions in Russian language generated with neural networks from begemot.ai website. The content includes project titles, descriptions, chapters and chapter content across various educational topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nid: Unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/begemot.","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","topic-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V2\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nClarify objective and style\nShow examples dialogue and best-case summary\nInclude Chain-of-Thought Guidance (show individual subtasks)\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"CNIL","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tricoteuses/CNIL","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\n\t\n\t\t\n\t\tFrench National Commission on Informatics and Liberty (CNIL) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (https://www.legifrance.gouv.fr/search/cnil).\nThis dataset is sourced from DILA/OPENDATA/CNIL and provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France.\nIt serves as a rich‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CNIL.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CAPP","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tricoteuses/CAPP","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\n\t\n\t\t\n\t\tFrench Court of Judicial jurisprudence decisions (CAPP) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CAPP Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/CAPP.\nThis comprehensive collection includes appellate court decisions, providing valuable insights into French jurisprudence and legal reasoning at the appeal level.\nIt serves as a rich resource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CAPP.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"SFT_54k_reasoning","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/SFT_54k_reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/SFT_54k_reasoning is a processed version of the XuHu6736/s1_54k_filter_with_isreasoning dataset, specifically reformatted for instruction fine-tuning (SFT) of language models.\nThe original question and solution pairs have been converted into an instruction-following format. Critically, the isreasoning_score and isreasoning labels from the parent dataset are preserved, allowing for targeted SFT on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning.","first_N":5,"first_N_keywords":["XuHu6736 (formatting and derivation)","derived from XuHu6736/s1_54k_filter_with_isreasoning","derived from source datasets","monolingual","XuHu6736/s1_54k_filter_with_isreasoning"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v123","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Combined V1-V3\n\t\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset combines three versions of synthetic summaries:\n\nV1 & V2: Filtered for 4-5 sentence summaries\nV3: Cleaned and extracted final summaries\n\n\n\t\n\t\t\n\t\tProcessing Steps\n\t\n\n\nV1 and V2 Processing:\n\nFiltered to include only 4-5 sentence summaries\nRemoved length metadata for consistency\n\n\nV3 Processing:\n\nExtracted final summaries from tagged content\nRemoved length metadata for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"COPA-cy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/techiaith/COPA-cy","creator_name":"Language Technologies, Bangor University","creator_url":"https://huggingface.co/techiaith","description":"\n\t\n\t\t\n\t\tDataset Card for COPA-cy\n\t\n\n","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"journals","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/journals","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Historical Russian Technical Journal Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains images of pages from old Russian technical journals with descriptions generated using Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nRussian (ru): All journal pages are in Russian with corresponding Russian descriptions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nThe dataset consists of:\n\nImage files (.jpg format)\nCorresponding description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/journals.","first_N":5,"first_N_keywords":["image-classification","image-to-text","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"medium-articles-posts-with-content","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content","creator_name":"The First","creator_url":"https://huggingface.co/Alaamer","description":"\n\t\n\t\t\n\t\tMedium Articles Dataset Generator\n\t\n\nThis project combines multiple datasets from Kaggle and Hugging Face to create a comprehensive collection of Medium articles. The combined dataset is available on Hugging Face Hub.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a unique compilation that not only combines multiple sources but also ensures data quality through normalization and deduplication. A key feature is that all entries in the text column are unique - there are no duplicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"superglue","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyukkyu/superglue","creator_name":"Hyukkyu Kang","creator_url":"https://huggingface.co/Hyukkyu","description":"\n\t\n\t\t\n\t\tSuperGLUE Benchmark Datasets\n\t\n\nThis repository contains the SuperGLUE benchmark datasets. Each dataset is available as a separate configuration, making it easy to load individual datasets using the datasets library.\n\n\t\n\t\t\n\t\tDataset Descriptions\n\t\n\n\n\t\n\t\t\n\t\tDatasets Included\n\t\n\n\nBoolQ: A question-answering task where each example consists of a short passage and a yes/no question about the passage. The questions are provided anonymously and unsolicited by users of the Google search‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hyukkyu/superglue.","first_N":5,"first_N_keywords":["other","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"MoT-Code-350K","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JingyaoLi/MoT-Code-350K","creator_name":"Jingyao Li","creator_url":"https://huggingface.co/JingyaoLi","description":"\nüè† MoTCode-Data\n\n\n\n‚Ä¢ ü§ó Data  ‚Ä¢ ü§ó Model  ‚Ä¢ üê± Code ‚Ä¢ üìÉ Paper \n\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nfrom datasets import load_dataset\nload_dataset(\"JingyaoLi/MoT-Code-350K\")\n\nDatasetDict({\n    train: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 312645\n    })\n})\n\n\n\t\n\t\t\n\t\n\t\n\t\tModular-of-thought Data Creation\n\t\n\nWe provide an example python file to evolution a MoT dataset. Run the following command:\npython src/generate_MoT_dataset.py \\\n    --data_path $data_path \\‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JingyaoLi/MoT-Code-350K.","first_N":5,"first_N_keywords":["text-generation","question-answering","translation","language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"comprehensive-car-damage","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DrBimmer/comprehensive-car-damage","creator_name":"Dr. Bimmer","creator_url":"https://huggingface.co/DrBimmer","description":"\n\t\n\t\t\n\t\tCar Front and Rear Damage Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating machine learning models for car damage detection, specifically focusing on front and rear vehicle damages.\nIt includes high-quality labeled images categorized into six distinct classes:\n\nR_Normal: Rear view of undamaged cars  \nR_Crushed: Rear view of cars with crushed damage  \nR_Breakage: Rear view of cars with visible breakage  \nF_Normal: Front view of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DrBimmer/comprehensive-car-damage.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"programmerhumor","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/programmerhumor","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for ProgrammerHumor.io Memes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains programming-related memes and humor content collected from programmerhumor.io, along with associated metadata such as titles, categories, tags, and image captions.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All meme content and descriptions are primarily in English\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Files\n\t\n\nThe dataset consists of:\n\nImage files (stored in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/programmerhumor.","first_N":5,"first_N_keywords":["image-classification","image-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Eyedoctor","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Bread/Eyedoctor","creator_name":"AI4Bread","creator_url":"https://huggingface.co/AI4Bread","description":"\n\t\n\t\t\n\t\tEye Disease QA Dataset\n\t\n\nThis dataset is designed for training and evaluating large language models (LLMs) in the field of ophthalmology. It consists of a structured disease knowledge base and question-answer (QA) pairs derived from that knowledge. The dataset can be used for supervised fine-tuning, testing, and knowledge-enhanced retrieval tasks.\n\n\t\n\t\t\n\t\tüìÇ Files Included\n\t\n\n\neye_disease_knowledge_base.json\nA curated knowledge base covering common eye diseases such as glaucoma‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Bread/Eyedoctor.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"cultural-dimension-cover-letters","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akhan02/cultural-dimension-cover-letters","creator_name":"Ariba Khan","creator_url":"https://huggingface.co/akhan02","description":"\n\t\n\t\t\n\t\tDataset Card for cultural-dimension-cover-letters\n\t\n\nThe cultural-dimension-cover-letters dataset contains cover letters modified to reflect different cultural dimensions based on Hofstede's framework. Created for evaluating implicit cultural preferences in large language models (LLMs) through job application assessment tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset features cover letters adapted to represent six cultural dimensions: Individualism/Collectivism, Power Distance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akhan02/cultural-dimension-cover-letters.","first_N":5,"first_N_keywords":["sentiment-classification","text-scoring","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"logical","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Satyam-Singh/logical","creator_name":"Satyam Singh","creator_url":"https://huggingface.co/Satyam-Singh","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Satyam-Singh/logical.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"SquadES_Ex1","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/itorrento/SquadES_Ex1","creator_name":"Iker Torrent√≥","creator_url":"https://huggingface.co/itorrento","description":"\n\t\n\t\t\n\t\tDocumentation translated in Catalan\n\t\n\n\n\t\n\t\t\n\t\tCarta de presentaci√≥ sobre el dataset Squad-ES\n\t\n\n\n\t\n\t\t\n\t\tTaula de continguts\n\t\n\n\nDescripcio del dataset\nEstructura del dataset\nCamps\nParticionament de les dades\nInformacio sobre la llicencia\nCitacions\nContribucions\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDescripcio del dataset\n\t\n\nAquest dataset √©s una traducci√≥ autom√†tica a l'espanyol del fam√≥s conjunt de dades Stanford Question Answering Dataset (SQuAD).\nEst√† dissenyat per a tasques de preguntes i respostes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/itorrento/SquadES_Ex1.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nikhilranjan/test","creator_name":"Nikhil Ranjan","creator_url":"https://huggingface.co/nikhilranjan","description":"\n\t\n\t\t\n\t\tDataset Card for Text360 Sample Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text samples from two sources (arXiv and Wikipedia) organized in a hierarchical directory structure. Each sample includes a text field and a subset identifier.\n\n\t\n\t\t\n\t\tData Files Structure\n\t\n\nThe dataset maintains its original directory structure:\n.\n‚îú‚îÄ‚îÄ dir1/\n‚îÇ   ‚îî‚îÄ‚îÄ subdir1/\n‚îÇ       ‚îî‚îÄ‚îÄ sample1.jsonl  # Contains arXiv samples\n‚îî‚îÄ‚îÄ dir2/\n    ‚îî‚îÄ‚îÄ subdir2/\n        ‚îî‚îÄ‚îÄ sample2.jsonl  # Contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nikhilranjan/test.","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Melange_test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDfree/Melange_test","creator_name":"no_ID","creator_url":"https://huggingface.co/IDfree","description":"\n\t\n\t\t\n\t\tDataset Name\n\t\n\nShort summary of what this dataset contains.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA longer explanation of the dataset, including its purpose and contents.\nThis dataset consists of:\n\nA .parquet file with metadata and labels\nScene images organized in zipped folders by group\nEach row in the metadata corresponds to a multiple-choice question grounded in one or more scene images.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for:\n\nVisual question answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IDfree/Melange_test.","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","visual-question-answering","multiple-choice-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mb-mars_seg_mer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-mars_seg_mer","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-mars_seg_mer\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mars_seg_mer.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mb-mars_seg_msl","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mirali33/mb-mars_seg_msl","creator_name":"Mirali Purohit","creator_url":"https://huggingface.co/Mirali33","description":"\n\t\n\t\t\n\t\tmb-mars_seg_msl\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-15\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Bedrock\n2: Gravel / Sand / Soil\n3: Rock\n4: Shadow\n5: Sky / Distant Mountains\n6: Track\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mirali33/mb-mars_seg_msl.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MultiFlow-Bench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/timtsapras23/MultiFlow-Bench","creator_name":"Efthymios Tsaprazlis","creator_url":"https://huggingface.co/timtsapras23","description":"\n\t\n\t\t\n\t\tMultiFlow Privacy Benchmark\n\t\n\nMultiFlow is a benchmark dataset designed to evaluate large language models' (LLMs) understanding of contextual privacy risks and their ability to propose minimal and lawful remediation steps.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nEach example in the dataset represents a real-world-inspired data event with multiple information flows. Each flow is annotated with:\n\nInitial legality and utility evaluation\nSuggested remediation steps\nPost-remediation scores‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timtsapras23/MultiFlow-Bench.","first_N":5,"first_N_keywords":["text-classification","text-generation","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"metallurgy-qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AbdulrhmanEldeeb/metallurgy-qa","creator_name":"Eldeeb","creator_url":"https://huggingface.co/AbdulrhmanEldeeb","description":"\n\t\n\t\t\n\t\tMetallurgy and Materials Science Knowledge Extraction Dataset\n\t\n\nThis repository contains a dataset generated from parsed books related to various aspects of metallurgy, materials science, and engineering. The dataset is designed for fine-tuning Large Language Models (LLMs) for Question-Answering (QA) tasks in the domain of metallurgy and materials science.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes content derived from technical books in the field of metallurgy and materials‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AbdulrhmanEldeeb/metallurgy-qa.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","closed-book-qa","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"T2Retrieval","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/T2Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  T2Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nT2Ranking: A large-scale Chinese Benchmark for Passage Ranking\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Financial, Government, Non-fiction\n\n\nReference\nhttps://arxiv.org/abs/2304.03679\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"T2Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/T2Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Mandarin Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_Eval_Synthetic","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Synthetic","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\" (COLM 2025).\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Synthetic.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_Train","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Train","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Train.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"fairseq2-lm-gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/fairseq2-lm-gsm8k","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"facebook/fairseq2-lm-gsm8k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["monolingual","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"chinese-squadv2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/chinese-squadv2","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"\n\t\n\t\t\n\t\tDataset Card for Chinese SQuAD 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a Chinese translation of the SQuAD 2.0 dataset, translated from the original English version. Like SQuAD 2.0, it contains both answerable and unanswerable questions. The dataset is designed for Chinese reading comprehension and question answering tasks.\nSource: ChineseSquad\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is stored in Parquet format and contains the following fields:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/real-jiakai/chinese-squadv2.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","machine-translated","machine-translated"],"keywords_longer_than_N":true},
	{"name":"Schemaorg","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/Schemaorg","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from Schema.org's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"FoodOn","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/FoodOn","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from FoodOn's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 41012\nFiltered size: 38772\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"modafact-ita","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhfbk/modafact-ita","creator_name":"Digital Humanities at Fondazione Bruno Kessler","creator_url":"https://huggingface.co/dhfbk","description":"\n\t\n\t\t\n\t\tModaFact - Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nModaFact is a textual dataset annotated with Event Factuality and Modality in Italian. ModaFact‚Äôs goal is to model in a joint way factuality and modality values of event-denoting expressions in text.\n\n\t\n\t\t\n\t\tTextual data source\n\t\n\nOriginal texts (sentences) have been sampled from EventNet-ITA, a dataset for Frame Parsing, consisting of annotated sentences from Wikipedia. \n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhfbk/modafact-ita.","first_N":5,"first_N_keywords":["token-classification","monolingual","Italian","cc-by-sa-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"airportwebcams","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/airportwebcams","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Airport Webcams\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 2,508 airport webcams extracted from airportwebcams.net. Each entry includes source URLs, embedded YouTube video links where available, and URLs to external webcam feeds.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nsource_url: URL of the airportwebcams.net page (string)\nyoutube_embeds: List of embedded YouTube video URLs, if any‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/airportwebcams.","first_N":5,"first_N_keywords":["other","found","monolingual","original","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"fastfine","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fastfine","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Fastfine.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 13,248 pages of educational content in Russian language extracted from fastfine.ru website. The content includes academic papers, essays and educational materials across various subjects.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fastfine.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Eason_TOFU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EasonZhong/Eason_TOFU","creator_name":"Yisheng Zhong","creator_url":"https://huggingface.co/EasonZhong","description":"EasonZhong/Eason_TOFU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Telugu"],"keywords_longer_than_N":true},
	{"name":"apps-small","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AuroraH456/apps-small","creator_name":"Aurora Huang","creator_url":"https://huggingface.co/AuroraH456","description":"\n\t\n\t\t\n\t\tAPPS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAPPS is a benchmark for code generation with 10000 problems. It can be used to evaluate the ability of language models to generate code from natural language specifications.\nYou can also find APPS metric in the hub here codeparrot/apps_metric.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains questions in English and code solutions in Python.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nfrom datasets import load_dataset\nload_dataset(\"codeparrot/apps\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AuroraH456/apps-small.","first_N":5,"first_N_keywords":["text-generation","language-modeling","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"truthful-qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahmanidashti/truthful-qa","creator_name":"Hossein A. (Saeed) Rahmani","creator_url":"https://huggingface.co/rahmanidashti","description":"\n\t\n\t\t\n\t\tDataset Card for TruthfulQA\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 790 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rahmanidashti/truthful-qa.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"hadith-qa-pair","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rwmasood/hadith-qa-pair","creator_name":"Dr Wasif Masood","creator_url":"https://huggingface.co/rwmasood","description":"\n\t\n\t\t\n\t\tHadith QA Pair Dataset\n\t\n\nThis dataset contains Hadith-based question-answer pairs extracted from four renowned Hadith collections: Musnad Ahmad, Sahih Muslim, Sahih Bukhari, and Jami` at-Tirmidhi.\nThe dataset is structured as question-answer pairs, where each question is answered using a relevant Hadith along with its reference. It can be utilized to train Large Language Models (LLMs) for text generation and question-answering tasks in Islamic studies.\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rwmasood/hadith-qa-pair.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ArguAna-PL","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ArguAna-PL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArguAna-PL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nArguAna-PL\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://huggingface.co/datasets/clarin-knext/arguana-pl\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArguAna-PL\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how to run models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArguAna-PL.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","mteb/arguana","Polish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"MaCBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jablonkagroup/MaCBench","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","description":"\n\t\n\t\t\n\t\tMaCBench\n\t\n\n\n\n\n\n\n\n\n\n\nA Chemistry and Materials Benchmark for evaluating Vision Large Language Models\n\n\n\n\n\t\n\t\t\n\t\t‚ö†Ô∏è IMPORTANT NOTICE - NOT FOR TRAINING\n\t\n\n\n\n\n\t\n\t\t\n\t\tüö´ THIS DATASET IS STRICTLY FOR EVALUATION PURPOSES ONLY üö´\n\t\n\nDO NOT USE THIS DATASET FOR TRAINING OR FINE-TUNING MODELS\nThis benchmark is designed exclusively for evaluation and testing of existing models. Using this data for training would compromise the integrity of the benchmark and invalidate evaluation results. Please‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/MaCBench.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","image-to-text","visual-question-answering","language-modeling"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/gsm8k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/gsm8k.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Arguana-Test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the ArguAna dataset from BIRCO. This dataset contains 100 queries where both queries and passages are complex one-paragraph arguments about current affairs. The objective is to retrieve the counter-argument that directly refutes the query‚Äôs stance.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BIRCO-ClinicalTrial-Test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-ClinicalTrial\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the Clinical-Trial dataset from BIRCO. This dataset contains 50 queries that are patient case reports. Each query has a candidate pool comprising 30-110 clinical trial descriptions. Relevance is graded (0, 1, 2), where 1 and 2 are considered relevant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-WTB-Test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-WTB-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-WTB\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the WhatsThatBook dataset from BIRCO. This dataset contains 100 queries where each query is an ambiguous description of a book. Each query has a candidate pool of 50 book descriptions. The objective is to retrieve the correct book description.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-WTB-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cpath-mcgill-ubc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc","creator_name":"Houcine Bdk","creator_url":"https://huggingface.co/houcine-bdk","description":"\n\t\n\t\t\n\t\tCanadian Universities Q&A Dataset (CPath)\n\t\n\nA comprehensive question-answering dataset focused on Canadian universities' programs, admissions, and academic information, specifically covering McGill University and the University of British Columbia (UBC).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains carefully curated question-answer pairs extracted from official university websites and documentation. It is designed to serve as a reliable resource for understanding academic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"synthetic_call_center_summaries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nExtensive evaluation metrics and attributes such as conciseness, formatting, contextual relevance, tone, and actionability.\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries.","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"RuBQReranking","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RuBQReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RuBQReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nParagraph reranking based on RuBQ 2.0. Give paragraphs that answer the question higher scores.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://openreview.net/pdf?id=P5UQFFoQ4PJ\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"RuBQReranking\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuBQReranking.","first_N":5,"first_N_keywords":["text-ranking","human-annotated","monolingual","Russian","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Chart-MRAG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymyang/Chart-MRAG","creator_name":"Young Yurm","creator_url":"https://huggingface.co/ymyang","description":"\n\t\n\t\t\n\t\tBenchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMultimodal Retrieval-Augmented Generation (MRAG) enhances reasoning capabilities by integrating external knowledge. However, existing benchmarks primarily focus on simple image-text interactions, overlooking complex visual formats like charts that are prevalent in real-world applications. In this work, we introduce a novel task, Chart-based MRAG, to address this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymyang/Chart-MRAG.","first_N":5,"first_N_keywords":["question-answering","image-to-text","visual-question-answering","image-captioning","expert-generated"],"keywords_longer_than_N":true},
	{"name":"PUGG_IR-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_IR-qrels","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\n\t\n\t\t\n\t\tPUGG: KBQA, MRC, IR Dataset for Polish\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\n\nKBQA (Knowledge Base Question Answering)\nMRC (Machine Reading Comprehension)\nIR (Information Retrieval)\n\n\n\t\n\t\t\n\t\tPaper\n\t\n\nFor more detailed information, please refer to our research paper titled:\n\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\" \nAuthored by:\n\nAlbert Sawczyn\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_IR-qrels.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xyx138/github-issues","creator_name":"xxx","creator_url":"https://huggingface.co/xyx138","description":"\n\t\n\t\t\n\t\tDataset Card for GitHub Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGitHub Issues is a dataset consisting of GitHub issues and pull requests associated with the ü§ó Datasets repository. It is intended for educational purposes and can be used for semantic search or multilabel text classification. The contents of each GitHub issue are in English and concern the domain of datasets for NLP, computer vision, and beyond.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nFor each of the tasks tagged‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xyx138/github-issues.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"YSSY_1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmejias/YSSY_1","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","description":"\n\t\n\t\t\n\t\tDataset Card for ATCOSYDNEY corpus\n\t\n\n","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"Micha≈Ç Kurkowski","creator_url":"https://huggingface.co/kurkowski","description":"\n\t\n\t\t\n\t\tContextual Text Anonymizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\n\n\t\n\t\t\n\t\tDocument Types\n\t\n\nThe dataset includes examples from the following categories:\n\nMedical records\nBanking documents\nBusiness correspondence\nRecruitment documents\nSocial media content\nLegal documents\nEducational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","text-simplification","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"BIRCO-DorisMae-Test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-DorisMae\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the DORIS-MAE dataset from BIRCO. This dataset contains 60 queries that are complex research questions from computer scientists. Each query has a candidate pool of approximately 110 abstracts. Relevance is graded from 0 to 2 (scores of 1 and 2 are considered relevant).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Relic-Test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-Relic-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-Relic\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the RELIC dataset from BIRCO. This dataset contains 100 queries which are excerpts from literary analyses with a missing quotation (indicated by [masked sentence(s)]). Each query has a candidate pool of 50 passages. The objective is to retrieve the passage that best completes the literary analysis.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Relic-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"gretel-financial-risk-analysis-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated by fine-tuning Phi-3-mini-128k-instruct on 14,306 SEC filings (10-K, 10-Q, and 8-K) from 2023-2024, utilizing differential privacy. It is designed for training models to extract key risk factors and generate structured summaries from financial documents while demonstrating the application of differential privacy to safeguard sensitive information.\nThis dataset showcases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1.","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"CTO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chufangao/CTO","creator_name":"Chufan Gao","creator_url":"https://huggingface.co/chufangao","description":"Dataset for predicting clinical trial outcomes in drug development.  This dataset is part of the work presented in \"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development\".\nWebsite: https://chufangao.github.io/CTOD/\nPaper: https://arxiv.org/abs/2406.10292\nCode: https://github.com/chufangao/ctod\nDescriptions:\n\nhuman_labels contains the manually annotated subset. We follow the same rule-based termination of incomplete status and p-value < 0.05 as in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chufangao/CTO.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"requests-github-issues","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Raibek/requests-github-issues","creator_name":"Raibek Tussupbekov","creator_url":"https://huggingface.co/Raibek","description":"Raibek/requests-github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/github-issues","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"This dataset originates from the teaching materials of the NLP Course.\nvia: https://huggingface.co/learn/nlp-course/en/chapter5/5\n","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flunardelli/mmlu","creator_name":"Fernando Lunardelli","creator_url":"https://huggingface.co/flunardelli","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/flunardelli/mmlu.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SynWOZ","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","description":"\n\t\n\t\t\n\t\tSynWOZ\n\t\n\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ.","first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"xlam-function-calling-60k-raw","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\n\t\n\t\t\n\t\tXLAM Function Calling 60k Raw Dataset\n\t\n\nThis dataset includes train and test splits derived from Salesforce/xlam-function-calling-60k.\n\nTrain split size: 95% of the original dataset\nTest split size: 5% of the original dataset\n\n","first_N":5,"first_N_keywords":["question-answering","language-modeling","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Telugu"],"keywords_longer_than_N":true},
	{"name":"gdz4you","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/gdz4you","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for GDZ4You.com Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 18,037 educational materials from the gdz4you.com platform, a resource for teachers and students providing multimedia presentations and other educational content. The dataset includes information such as material titles, URLs, download links, ratings, and slide-by-slide content with images where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gdz4you.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"clone-of-gretel-financial-risk-analysis-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","description":"\n‚ö†Ô∏èüî¥ IMPORTANT NOTICE üî¥‚ö†Ô∏è\nThis dataset is directly cloned from gretelai/gretel-financial-risk-analysis-v1 on Hugging Face. No modifications have been made to the original dataset, it is only for archival.\n\n\n\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated using differential privacy guarantees, trained on 14,306 SEC (10-K, 10-Q, and 8-k) filings from 2023-2024. The dataset is designed for training models to extract‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1.","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"CICMalDroid","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/builetrongduc/CICMalDroid","creator_name":"B√πi L√™ Tr·ªçng ƒê·ª©c","creator_url":"https://huggingface.co/builetrongduc","description":"builetrongduc/CICMalDroid dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["user-generated","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"MyanmarNews","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MyanmarNews","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MyanmarNews\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Myanmar News dataset on Hugging Face contains news articles in Burmese. It is designed for tasks such as text classification, sentiment analysis, and language modeling. The dataset includes a variety of news topics in 4 categorie, providing a rich resource for natural language processing applications involving Burmese which is a low resource language.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MyanmarNews.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Burmese"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"cs2-highlights","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cs2-highlights","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Counter-Strike 2 Highlight Clips\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 8,369 high-quality gameplay highlight clips primarily from Counter-Strike 2, with a small portion from Counter-Strike: Global Offensive. The clips focus on key gameplay moments such as kills, bomb interactions, and grenade usage. The clips are collected from competitive platforms like Faceit and in-game competitive modes (Premier, Matchmaking) across various skill levels, making it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cs2-highlights.","first_N":5,"first_N_keywords":["video-classification","text-to-video","image-to-video","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"klingai","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/klingai","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for KLING AI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 12,782 AI-generated media items (images and videos) created using KLING AI's generative tools. The content includes metadata and original files for various AI generations, encompassing both still images and motion videos created through text-to-image and image-to-video transformations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en), with prompts and metadata in English.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/klingai.","first_N":5,"first_N_keywords":["text-to-image","image-to-video","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DramaCV","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gasmichel/DramaCV","creator_name":"Gaspard Michel","creator_url":"https://huggingface.co/gasmichel","description":"\n\t\n\t\t\n\t\tDataset Card for DramaCV\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DramaCV Dataset is an English-language dataset containing utterances of fictional characters in drama plays collected from Project Gutenberg. The dataset was automatically created by parsing 499 drama plays from the 15th to 20th century on Project Gutenberg, that are then parsed to attribute each character line to its speaker.\n\n\t\n\t\t\n\t\tTask\n\t\n\nThis dataset was developed for Authorship Verification of literary characters. Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gasmichel/DramaCV.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 37133\nFiltered size: 37133\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 13284\nFiltered size: 13240\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 21525\nFiltered size: 21408\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"soloby","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/soloby","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Soloby.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 744,131 question-answer pairs in Russian language extracted from soloby.ru website. The content includes educational questions and answers across various subjects and categories.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian (ru).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\npage_url: URL of the question page (string)\nquestion_title: The question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/soloby.","first_N":5,"first_N_keywords":["text-classification","question-answering","open-domain-qa","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_third_iteration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration.","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"car-parts-and-damage-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DrBimmer/car-parts-and-damage-dataset","creator_name":"Dr. Bimmer","creator_url":"https://huggingface.co/DrBimmer","description":"\n\t\n\t\t\n\t\tCar Parts and Damages Polygon Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Car Parts and Damages Polygon Dataset consists of 1,812 high-resolution images, each annotated with polygon-based segmentation masks for either car parts or car damages. The dataset is designed to support training and evaluation of deep learning models for fine-grained object detection, instance segmentation, and automotive inspection tasks.\n\n\t\n\t\t\n\t\t‚úÖ Key Stats:\n\t\n\n\nTotal images: 1,812  \nCar parts: 998 images  \nCar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DrBimmer/car-parts-and-damage-dataset.","first_N":5,"first_N_keywords":["image-segmentation","object-detection","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_Eval_Real_v1.1","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real_v1.1","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\" (COLM 2025).\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real_v1.1.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"MiniF2F","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\n\t\n\t\t\n\t\tminif2f Dataset\n\t\n\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F.","first_N":5,"first_N_keywords":["text-generation","other","explanation-generation","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"UrduRomanSentimentClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  UrduRomanSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Roman Urdu dataset is a data corpus comprising of more than 20000 records tagged for sentiment (Positive, Negative, Neutral)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://archive.ics.uci.edu/dataset/458/roman+urdu+data+set\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"JSTS","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJapanese Semantic Textual Similarity Benchmark dataset construct from YJ Image Captions Dataset (Miyazaki and Shimizu, 2016) and annotated by crowdsource annotators.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsWeb, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.317.pdf#page=2.00\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"RussianFinancialNews","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews","creator_name":"Kasymkhan","creator_url":"https://huggingface.co/Kasymkhan","description":"\n\t\n\t\t\n\t\tRussianFinancialNews\n\t\n\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 92,377 —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é —Ç–µ–º–∞—Ç–∏–∫—É, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥ –∏ —Ä–æ—Å—Å–∏–π—Å–∫—É—é —ç–∫–æ–Ω–æ–º–∏–∫—É. –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP). \nA dataset containing 92,377 samples of Russian financial news articles. Each sample includes metadata and content fields that are useful for various Natural Language Processing (NLP) tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews.","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","time-series-forecasting","tabular-regression"],"keywords_longer_than_N":true},
	{"name":"allstar","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/allstar","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Allstar.gg Clips\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about 47,896 video clips from the gaming platform allstar.gg. The clips primarily focus on Counter-Strike 2 gameplay moments and include detailed metadata such as player information, game statistics, view counts, and related media URLs.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in English (en).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/allstar.","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 137830\nFiltered size: 42607\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"trilemma-of-truth","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlomarxx/trilemma-of-truth","creator_name":"Germans Savcisens","creator_url":"https://huggingface.co/carlomarxx","description":"\n\t\n\t\t\n\t\tüìö Dataset Card for Trilemma of Truth (ToT) Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüßæ Dataset Summary\n\t\n\nThe Trilemma of Truth dataset is a benchmark for evaluating model performance across three types of statements:\n\nFactually true statements\nFactually false statements\nNeither-valued statements\n\nIt includes three configurations:\n\ncity_locations: statements about city-country relationsmed_indications: drug-indication associations\nword_definitions: synonym, type, and instance relationships from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlomarxx/trilemma-of-truth.","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","fact-checking","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"medical-cyber-val","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magichampz/medical-cyber-val","creator_name":"Aveek Goswami","creator_url":"https://huggingface.co/magichampz","description":"\n\t\n\t\t\n\t\tMedical Cybersecurity Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs focused on medical device cybersecurity and healthcare security.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Q&A pairs: 112\nNumber of unique topics: 9\nNumber of unique subtopics: 48\nLast updated: 2025-05-28\n\n\n\t\n\t\t\n\t\tTopics Covered\n\t\n\n\nAttack Vectors\nCommon Security Tools and Usage\nCompliance and Legal Requirements\nExploits\nIncident Response and Recovery\nInternet of Medical Things (IoMT) and Medical Technologies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magichampz/medical-cyber-val.","first_N":5,"first_N_keywords":["question-answering","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"iris-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DmytroSerbeniuk/iris-dataset","creator_name":"Dmytro Serbeniuk","creator_url":"https://huggingface.co/DmytroSerbeniuk","description":"\n\t\n\t\t\n\t\tIris Dataset\n\t\n\nThe classic Iris dataset in .parquet format. Useful for ML demos, classification tasks, and model testing.\n","first_N":5,"first_N_keywords":["tabular-classification","monolingual","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"autogkb","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shlokn/autogkb","creator_name":"Shlok Natarajan","creator_url":"https://huggingface.co/shlokn","description":"\n\t\n\t\t\n\t\tAutoGKB Annotation Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AutoGKB Annotation Benchmark is a comprehensive dataset designed to evaluate models' ability to extract pharmacogenomic variant-drug associations from scientific literature. This ground truth values for this data were compiled by reviewers from PharmGKB. This benchmark addresses the critical need for automated systems that can identify genetic variants, associated drugs, and their clinical relationships from biomedical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shlokn/autogkb.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoClimateFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoClimateFEVER.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoClimateFEVER","French"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoFiQA2018-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFiQA2018.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFiQA2018","French"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoHotpotQA-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoHotpotQA.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoHotpotQA","French"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoNFCorpus-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNFCorpus.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNFCorpus","French"],"keywords_longer_than_N":true},
	{"name":"NanoNQ-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoNQ-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNQ.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNQ","French"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoSciFact-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSciFact.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSciFact","French"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020-fr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/NanoTouche2020-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoTouche2020.\n","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoTouche2020","French"],"keywords_longer_than_N":true},
	{"name":"crud-code-tests","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kramster/crud-code-tests","creator_name":"Karthik Ram","creator_url":"https://huggingface.co/kramster","description":"\n\t\n\t\t\n\t\tüõ†Ô∏è Code Fixing & Generation Dataset (Alpaca Format)\n\t\n\n\n\t\n\t\t\n\t\tCode Fixing & Generation Dataset (Alpaca Format)\n\t\n\nThis dataset is designed to fine-tune open-source large language models (LLMs) to automatically fix buggy code and generate accurate code completions based on real-world inputs.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nThe dataset follows the Alpaca-style format:\n[\n  {\n    \"instruction\": \"<SYSTEM_PROMPT + TASK_DESCRIPTION>\",\n    \"input\": \"<CODE_SNIPPET>\",\n    \"output\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kramster/crud-code-tests.","first_N":5,"first_N_keywords":["language-modeling","human-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"eli-why-only-questions","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/eli-why-only-questions","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example is a JSON object with:\n{\n  \"Question\": \"Why does ice float in water?\",\n  \"Domain\": \"STEM\",\n  \"Discipline\": \"physics\"\n}\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nGeneration Process:Questions were few-shot generated using GPT-4, based on a seed set of 50 questions from Sulik et al. (2023). The generated questions were then manually filtered to remove duplicates, ensure clarity, and balance disciplinary diversity.\nCuration:Curation and verification were performed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-only-questions.","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","expert-verified","monolingual"],"keywords_longer_than_N":true},
	{"name":"eli-why-perceived-background-match","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tELI-Why Perceived Background Match\n\t\n\n\n\t\n\t\t\n\t\tüß† Dataset Summary\n\t\n\nThis split contains human judgments on whether an LLM-generated explanation was perceived to match the intended educational background of the audience (e.g., elementary, high school, graduate school).\nEach example in this dataset includes:\n\nThe original question\nThe intended education level (based on prompting)\nThe explanation generated according to the intended education level\nThe perceived education level (based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match.","first_N":5,"first_N_keywords":["human-annotated","machine-generated","monolingual","eli-why","English"],"keywords_longer_than_N":true},
	{"name":"spatial-trace-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dhruvmsheth/spatial-trace-dataset","creator_name":"Dhruv","creator_url":"https://huggingface.co/dhruvmsheth","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSpatialTraceGen is a dataset of multi-hop spatial reasoning traces generated by Large Language Models (LLMs) integrated with computer vision tools. The framework is designed to produce step-by-step reasoning for complex spatial queries. This dataset contains the generated reasoning traces under different levels of automated verification.\nThe dataset was created using the CLEVR dataset as a base. The traces were generated by providing questions from CLEVR to an LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhruvmsheth/spatial-trace-dataset.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ga-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"textureninja","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/textureninja","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Texture Ninja\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,540 texture images from texture.ninja. It includes high-resolution textures of brick, concrete, rock, wood, metal, paint, plaster, ground materials, and other surfaces. The original images were downloaded, processed, and compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while maintaining good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/textureninja.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (People‚Äôs Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"pbrpx","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/pbrpx","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for PBRPX Asset Library\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 710 physically-based rendering (PBR) assets from pbrpx.com, a CC0 asset library. The dataset includes comprehensive information about 3D models, textures, and materials with detailed file listings, download URLs, texture resolutions, and categorization data. Assets include nature elements (trees, rocks), architectural materials (brick, concrete), and various other 3D models with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pbrpx.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"aging_reg_dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Venkatachalam/aging_reg_dataset","creator_name":"Venkatachalam Subramanian Periya Subbu","creator_url":"https://huggingface.co/Venkatachalam","description":"\n\t\n\t\t\n\t\tAging ReG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nAging ReG is a manually curated database of aging factors focusing on regulatory relationships during aging with experimental evidence in humans. This dataset provides valuable insights into the molecular mechanisms of aging and the regulatory networks involved.\n\n\t\n\t\t\n\t\tKey Details\n\t\n\n\nOrganism: Human  \nDescription: Manually curated database of aging factors, focusing on regulatory relationships during aging with experimental evidence in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Venkatachalam/aging_reg_dataset.","first_N":5,"first_N_keywords":["tabular-regression","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part001","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part001","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 1 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 1 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part001.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Endothelial Cells (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on endothelial cells from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cell‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"human-optic-nerve-fibroblasts-snRNAseq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/human-optic-nerve-fibroblasts-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Fibroblasts (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Data Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on fibroblasts from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cell atlas. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-optic-nerve-fibroblasts-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"human-cornea-snRNAseq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tHuman Cornea Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on the cellular heterogeneity of the human cornea. It provides a high-resolution view of various cell populations and their gene expression profiles across different layers of this critical ocular tissue.\nThe data was sourced from a research paper providing a comprehensive single-cell transcriptome atlas of the human cornea.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Medical_Prescription_Handwritten_Words","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avi-kai/Medical_Prescription_Handwritten_Words","creator_name":"Avaneesh Karthikeyan Iyer","creator_url":"https://huggingface.co/avi-kai","description":"\n\t\n\t\t\n\t\tMedical Prescription Handwritten Words\n\t\n\nThis dataset contains images of individual handwritten medical words extracted from prescription notes. It is designed for training and evaluating handwriting recognition models in the healthcare domain.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nimages/: Contains 40+ handwritten word images (e.g., Amoxicillin.png, Cold.png, Tablet.png, 0.png, etc.)\ndata.csv: Maps each image file to its corresponding label (word)\n\n\n\t\n\t\t\n\t\tExample Use Cases\n\t\n\n\nOCR (Optical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avi-kai/Medical_Prescription_Handwritten_Words.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","manual","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SciVer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengyewang/SciVer","creator_name":"chengyewang","creator_url":"https://huggingface.co/chengyewang","description":"\n\t\n\t\t\n\t\tSCIVER: A Benchmark for Multimodal Scientific Claim Verification\n\t\n\n\n  üåê Github ‚Ä¢\n  üìñ Paper ‚Ä¢\n  ü§ó Data\n\n\n\n\n\t\n\t\t\n\t\tüì∞ News\n\t\n\n\n[May 15, 2025] SciVer has been accepted by ACL 2025 Main!\n\n\n\t\n\t\t\n\t\tüëã Overview\n\t\n\n\nSCIVER is the first benchmark specifically designed to evaluate the ability of foundation models to verify scientific claims across text, charts, and tables. It challenges models to reason over complex, multimodal contexts with fine-grained entailment labels and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chengyewang/SciVer.","first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Cybersec-Mutli-domain","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain","creator_name":"Zain Nadeem","creator_url":"https://huggingface.co/ZainNadeem7","description":"Creator: Zain NadeemRole: Python Django Developer | Software Engineer | Prompt Engineer | Ethical HackerLicense: CC BY 4.0Records: ~220,000Format: JSONLLanguage: English\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nThe CyberSec Multi-Domain Dataset is a structured collection of synthetic and open-source cybersecurity data across five important domains. It is designed for building, testing, and benchmarking machine learning models in cybersecurity, threat intelligence, and automation systems.\nThis dataset helps‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","text-retrieval","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"new_real_datasets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongin9812/new_real_datasets","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Wiki-zhtw-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-zhtw-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-zhtw-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Chinese‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim, converted to Markdown format via regular‚Äëexpression post‚Äëprocessing, and finally converted from Simplified to Traditional Chinese using OpenCC.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Chinese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsGermanEnglish","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"KLUE-NLI","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KLUE-NLI","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KLUE-NLI\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTextual Entailment between a hypothesis sentence and a premise sentence. Part of the Korean Language Understanding Evaluation (KLUE).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Encyclopaedic, Written\nReference\nhttps://arxiv.org/abs/2105.09680\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"KLUE-NLI\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KLUE-NLI.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","natural-language-inference","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"PIQA","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PIQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PIQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on PIQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/1911.11641\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"PIQA\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PIQA.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/piqa","English"],"keywords_longer_than_N":true},
	{"name":"PunjabiNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PunjabiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PunjabiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Punjabi dataset for 2-class classification of Punjabi news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-punjabi/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"PunjabiNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PunjabiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/punjabi_news_classification"],"keywords_longer_than_N":true},
	{"name":"R2MEDBioinformaticsRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDBioinformaticsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBioinformatics retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Bioinformatics\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBioinformaticsRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Bioinformatics"],"keywords_longer_than_N":true},
	{"name":"R2MEDBiologyRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDBiologyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBiology retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Biology\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBiologyRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Biology"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedQADiagRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDMedQADiagRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedQA-Diag retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedQA-Diag\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedQADiagRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedQA-Diag"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedicalSciencesRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDMedicalSciencesRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedical-Sciences retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Medical-Sciences\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedicalSciencesRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Medical-Sciences"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCClinicalRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDPMCClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Clinical"],"keywords_longer_than_N":true},
	{"name":"RARbMath","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RARbMath","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RARbMath\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on RAR-b math-pooled dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.06347\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RARbMath\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RARbMath.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/math-pooled","English"],"keywords_longer_than_N":true},
	{"name":"RUParaPhraserSTS","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RUParaPhraserSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RUParaPhraserSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nParaPhraser is a news headlines corpus with precise, near and non-paraphrases.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://aclanthology.org/2020.ngt-1.6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RUParaPhraserSTS\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RUParaPhraserSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","merionum/ru_paraphraser"],"keywords_longer_than_N":true},
	{"name":"DKHateClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DKHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DKHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Tweets annotated for Hate Speech either being Offensive or not\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.430/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"DKHateClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DKHateClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"HellaSwag","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HellaSwag","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HellaSwag\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on HellaSwag.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://rowanzellers.com/hellaswag/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"HellaSwag\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HellaSwag.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/hellaswag","English"],"keywords_longer_than_N":true},
	{"name":"LegalBenchPC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LegalBenchPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalBenchPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis LegalBench pair classification task is a combination of the following datasets:\n    - Citation Prediction Classification: Given a legal statement and a case citation, determine if the citation is supportive of the legal statement.\n    - Consumer Contracts QA: The task consists of 400 yes/no questions relating to consumer contracts (specifically, online terms of service) and is relevant to the legal skill of contract‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalBenchPC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","expert-annotated","monolingual","nguha/legalbench"],"keywords_longer_than_N":true},
	{"name":"R2MEDIIYiClinicalRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDIIYiClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIIYi-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/IIYi-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDIIYiClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/IIYi-Clinical"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedXpertQAExamRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDMedXpertQAExamRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedXpertQA-Exam retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedXpertQA-Exam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedXpertQAExamRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedXpertQA-Exam"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCTreatmentRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  R2MEDPMCTreatmentRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Treatment retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Treatment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCTreatmentRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Treatment"],"keywords_longer_than_N":true},
	{"name":"RomanianReviewsSentiment","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RomanianReviewsSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RomanianReviewsSentiment\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2101.04197\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RomanianReviewsSentiment\")\nevaluator = mteb.MTEB([task])\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RomanianReviewsSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"RuBQRetrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RuBQRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RuBQRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nParagraph retrieval based on RuBQ 2.0. Retrieve paragraphs from Wikipedia that answer the question.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://openreview.net/pdf?id=P5UQFFoQ4PJ\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RuBQRetrieval\")\nevaluator = mteb.MTEB([task])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuBQRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","ai-forever/rubq-retrieval"],"keywords_longer_than_N":true},
	{"name":"SCDBPAccountabilityLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDBPAccountabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDBPAccountabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer maintains internal compliance procedures on company standards regarding human trafficking and slavery? This includes any type of internal accountability mechanism. Requiring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPAccountabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDBPVerificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDBPVerificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDBPVerificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer engages in verification and auditing as one practice, expresses that it may conduct an audit, or expressess that it is assessing supplier risks through a review of the US Dept. of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPVerificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDDTrainingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDDTrainingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDDTrainingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer provides company employees and management, who have direct responsibility for supply chain management, training on human trafficking and slavery, particularly with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDTrainingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDDVerificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDDVerificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDDVerificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer engages in verification of product supply chains to evaluate and address risks of human trafficking and slavery? If the company conducts verification], the disclosure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDVerificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SinhalaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SinhalaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Category-classification"],"keywords_longer_than_N":true},
	{"name":"SiswatiNewsClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SiswatiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SiswatiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSiswati News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/dsfsi/za-isizulu-siswati-news\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SiswatiNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SiswatiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","isaacchung/siswati-news"],"keywords_longer_than_N":true},
	{"name":"TERRa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TERRa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TERRa\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTextual Entailment Recognition for Russian. This task requires to recognize, given two text fragments, whether the meaning of one text is entailed (can be inferred) from the other text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://arxiv.org/pdf/2010.15925\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TERRa.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","ai-forever/terra-pairclassification"],"keywords_longer_than_N":true},
	{"name":"TV2Nordretrieval","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TV2Nordretrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TV2Nordretrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article and corresponding summaries extracted from the Danish newspaper TV2 Nord.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReferencehttps://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TV2Nordretrieval\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TV2Nordretrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","alexandrainst/nordjylland-news-summarization"],"keywords_longer_than_N":true},
	{"name":"TelemarketingSalesRuleLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TelemarketingSalesRuleLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TelemarketingSalesRuleLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine how 16 C.F.R. ¬ß 310.3(a)(1) and 16 C.F.R. ¬ß 310.3(a)(2) (governing deceptive practices) apply to different fact patterns. This dataset is designed to test a model‚Äôs ability to apply 16 C.F.R. ¬ß 310.3(a)(1) and 16 C.F.R. ¬ß 310.3(a)(2) of the Telemarketing Sales Rule to a simple fact pattern with a clear outcome. Each fact pattern ends with the question: ‚ÄúIs this a violation of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TelemarketingSalesRuleLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"TeluguAndhraJyotiNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TeluguAndhraJyotiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TeluguAndhraJyotiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Telugu dataset for 5-class classification of Telugu news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/AnushaMotamarri/Telugu-Newspaper-Article-Dataset\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TeluguAndhraJyotiNewsClassification\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TeluguAndhraJyotiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/telugu_news_classification"],"keywords_longer_than_N":true},
	{"name":"TenKGnadClusteringP2P.v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TenKGnadClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TenKGnadClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of news article titles+subheadings+texts. Clustering of 10 splits on the news article category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\nReference\nhttps://tblock.github.io/10kGNAD/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TenKGnadClusteringP2P.v2\")\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TenKGnadClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","slvnwhrl/tenkgnad-clustering-p2p","German"],"keywords_longer_than_N":true},
	{"name":"TenKGnadClusteringS2S.v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TenKGnadClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TenKGnadClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of news article titles. Clustering of 10 splits on the news article category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReferencehttps://tblock.github.io/10kGNAD/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TenKGnadClusteringS2S.v2\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TenKGnadClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","slvnwhrl/tenkgnad-clustering-s2s"],"keywords_longer_than_N":true},
	{"name":"TextualismToolDictionariesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TextualismToolDictionariesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TextualismToolDictionariesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a paragraph from a judicial opinion is applying a form textualism that relies on the dictionary meaning of terms.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TextualismToolDictionariesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"TextualismToolPlainLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TextualismToolPlainLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TextualismToolPlainLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a paragraph from a judicial opinion is applying a form textualism that relies on the ordinary (‚Äúplain‚Äù) meaning of terms.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TextualismToolPlainLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"kaggle_data","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongin9812/kaggle_data","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TswanaNewsClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TswanaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TswanaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTswana News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://link.springer.com/chapter/10.1007/978-3-031-49002-6_17\n\n\n\t\n\nSource datasets:\n\ndsfsi/daily-news-dikgang\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TswanaNewsClassification\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TswanaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","dsfsi/daily-news-dikgang"],"keywords_longer_than_N":true},
	{"name":"TurHistQuadRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TurHistQuadRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TurHistQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nQuestion Answering dataset on Ottoman History in Turkish\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Academic, Written\n\n\nReference\nhttps://github.com/okanvk/Turkish-Reading-Comprehension-Question-Answering-Dataset\n\n\n\t\n\nSource datasets:\n\nasparius/TurHistQuAD\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TurHistQuadRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","asparius/TurHistQuAD"],"keywords_longer_than_N":true},
	{"name":"UCCVCommonLawLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/UCCVCommonLawLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  UCCVCommonLawLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDetermine if a contract is governed by the Uniform Commercial Code (UCC) or the common law of contracts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\nSource datasets:\n\nnguha/legalbench\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UCCVCommonLawLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"UnfairTOSLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/UnfairTOSLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  UnfairTOSLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a clause from a terms-of-service contract, determine the category the clause belongs to. The purpose of this task is classifying clauses in Terms of Service agreements. Clauses have been annotated by into nine categories: ['Arbitration', 'Unilateral change', 'Content removal', 'Jurisdiction', 'Choice of law', 'Limitation of liability', 'Unilateral termination', 'Contract by using', 'Other']. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UnfairTOSLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"VieStudentFeedbackClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VieStudentFeedbackClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for classification of student feedback\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://ieeexplore.ieee.org/document/8573337\n\n\n\t\n\nSource datasets:\n\nuitnlp/vietnamese_students_feedback\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Wiki-th-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-th-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-th-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Thailand‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Thai","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"testrtt","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongin9812/testrtt","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indonesian-islamic-story-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ilonks/indonesian-islamic-story-dataset","creator_name":"Ilonksrcc","creator_url":"https://huggingface.co/Ilonks","description":"\n\t\n\t\t\n\t\tDataset 100 Cerita Pendek Islami Bahasa Indonesia\n\t\n\nDataset ini berisi 100 cerita pendek Islami yang ditulis dalam Bahasa Indonesia, dalam format CSV yang terstruktur. Setiap entri mencakup:\n\nJudul cerita\nIsi ringkas cerita\nKategori nilai moral\nPesan moral dari cerita\nPanjang estimasi cerita (jumlah kata)\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìö Kegunaan Dataset\n\t\n\nüïå Cocok digunakan untuk:\n\nPengembangan AI berbahasa Indonesia (story generator, chatbot edukasi)\nContent creator (TikTok, YouTube Shorts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ilonks/indonesian-islamic-story-dataset.","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dataset_111-220","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongin9812/dataset_111-220","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","description":"\n\t\n\t\t\n\t\tSample image-caption dataset\n\t\n\nImages and their English descriptions.\n","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Random-Crypto","keyword":"monolingual","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heksze/Random-Crypto","creator_name":"Muzsai Lajos","creator_url":"https://huggingface.co/Heksze","description":"\n\t\n\t\t\n\t\tüß™ Random-Crypto Benchmark\n\t\n\nThe Random-Crypto Benchmark generates cryptographic CTF challenges tailored for evaluating and training large language models in reinforcement learning settings.\nIt includes two pre-generated sets of problems:\n\n‚úÖ 50 Human-verified challenges for evaluation (link)\n‚öôÔ∏è 5000 Non-Verified Challenges for training (link)\n\n\nüß† Note: To evaluate an LLM using this benchmark, concatenate the story and necessary_info fields before passing them as input.\n\n\n\n\t\n\t\n\t\n\t\tüìä‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Heksze/Random-Crypto.","first_N":5,"first_N_keywords":["text-classification","question-answering","open-domain-qa","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"math_hard_fr","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tktung/math_hard_fr","creator_name":"Tung Tran","creator_url":"https://huggingface.co/tktung","description":"tktung/math_hard_fr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","French"],"keywords_longer_than_N":true},
	{"name":"github-issues-updated","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rIsHu009/github-issues-updated","creator_name":"Naman Chanana","creator_url":"https://huggingface.co/rIsHu009","description":"\n\t\n\t\t\n\t\tüìä GitHub Issues Dataset (HuggingFace/datasets Repository)\n\t\n\nThis dataset contains structured GitHub issues scraped from the huggingface/datasets repository. It is intended for NLP tasks, topic modeling, issue classification, and software engineering research.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìå Dataset Summary\n\t\n\n\nRepository Source: huggingface/datasets\nScraped via: GitHub REST API v3\nTotal Issues: ~7,465\nCollected On: June 25, 2025\nFormat: JSONL ‚Üí loaded via Arrow for Hugging Face\nLanguage: English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rIsHu009/github-issues-updated.","first_N":5,"first_N_keywords":["text-classification","topic-classification","extractive-qa","unknown","found"],"keywords_longer_than_N":true},
	{"name":"ug-normativity","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rivert97/ug-normativity","creator_name":"Roberto Garcia Guzman","creator_url":"https://huggingface.co/Rivert97","description":"Rivert97/ug-normativity dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","extractive-qa","monolingual","original","Spanish"],"keywords_longer_than_N":true},
	{"name":"enwiki_structured_content","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/enwiki_structured_content","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for enwiki_structured_content\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the early official Wikipedia release, downloaded from the en subset of Wikipedia Structured Contents.Articles were converted to Markdown.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"noise-dataset-de","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rolgor/noise-dataset-de","creator_name":"rol gor","creator_url":"https://huggingface.co/rolgor","description":"\n\t\n\t\t\n\t\tGerman Noise-Augmented Speech Demo Dataset\n\t\n\nThis dataset provides German speech samples augmented with realistic noise scenarios such as office noise, street noise, white noise, echo, and lowpass filtering.It is designed for testing and improving the robustness of ASR (Automatic Speech Recognition) systems.\n\n\t\n\t\t\n\t\tüí° Source\n\t\n\n\nOriginal voice samples: Mozilla Common Voice (CC0)\nNoise layers: custom augmented (see noise.rolgor.de)\n\n\n\t\n\t\t\n\t\t‚ö†Ô∏è Privacy\n\t\n\nPlease respect speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rolgor/noise-dataset-de.","first_N":5,"first_N_keywords":["keyword-spotting","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OMIM_from_GPA-MSA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bgoood/OMIM_from_GPA-MSA","creator_name":"yc XU","creator_url":"https://huggingface.co/Bgoood","description":"\n\t\n\t\t\n\t\tvep_clinvar_chr1_split\n\t\n\n\nÂ≠óÊÆµ: ref, alt, label, chromosome, position\nÂàíÂàÜ: chromosome=1‰∏∫testÔºåÂÖ∂‰Ωô‰∏∫train\nÊîØÊåÅËá™Âä®ÁîüÊàêref/altÂ∫èÂàó\n\n\n\t\n\t\t\n\t\tÁî®Ê≥ï\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n    \"Bgoood/vep_mendelian_traits_chr11_split\",\n    sequence_length=2048,\n    fasta_path=\"/path/to/hg38.fa.gz\",\n    data_dir=\".\"\n)\n\n\n---\n\n## 5. ‰∏ä‰º†Âà∞ HuggingFace\n\n1. **ÂàùÂßãÂåñgit repoÔºàÂ¶ÇÊûúËøòÊ≤°ÊúâÔºâ**\n   ```bash\n   git lfs install\n   git clone https://huggingface.co/datasets/Bgoood/vep_mendelian_traits_chr11_split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bgoood/OMIM_from_GPA-MSA.","first_N":5,"first_N_keywords":["found","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"so-arm101","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxFridge/so-arm101","creator_name":"Max Fritsch","creator_url":"https://huggingface.co/MaxFridge","description":"\n\t\n\t\t\n\t\tSO-101 Roboter Dataset\n\t\n\nDieses Dataset enth√§lt Teleoperationsdaten f√ºr den SO-101 Roboter, aufgenommen mit Phosphobot.\n\n\t\n\t\t\n\t\tBeschreibung\n\t\n\n\nRoboter: SO-101\nKamera: Logitech HD Webcam eMeet C980 Pro (4 Kameras)\nSoftware: Phosphobot\nAufnahme: Teleoperation mit visueller R√ºckmeldung\n\n\n\t\n\t\t\n\t\tStruktur\n\t\n\nso-arm101/\n‚îú‚îÄ‚îÄ meta/\n‚îÇ   ‚îî‚îÄ‚îÄ info.json          # Dataset-Metadaten\n‚îú‚îÄ‚îÄ sessions/              # Aufnahme-Sessions\n‚îÇ   ‚îî‚îÄ‚îÄ [session_id]/      # Einzelne Sessions\n‚îÇ       ‚îú‚îÄ‚îÄ videos/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MaxFridge/so-arm101.","first_N":5,"first_N_keywords":["robotics","user-generated","user-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"germanrag-scored","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from DiscoResearch/germanrag with added cosine-similarity scores.\nThe scores between 'question' and 'answer' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\nIf you want to filter negative answers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"clker-svg","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/clker-svg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Clker.com SVG Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 255,758 public domain SVG vector clipart images collected from Clker.com. Clker.com hosts user-shared vector clip art that is explicitly released into the public domain (CC0). The dataset includes the SVG content itself along with metadata such as titles and tags associated with each image. The SVG files in this dataset have been minified using tdewolff/minify to reduce file size while preserving‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/clker-svg.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"openclipart","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/openclipart","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenClipart.org SVG Images\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 178,604 public domain SVG vector clipart images collected from OpenClipart.org. OpenClipart.org is a community-driven platform where artists share vector clip art explicitly released into the public domain (CC0). The dataset includes the SVG content along with comprehensive metadata such as titles, descriptions, artist names, creation dates, tags, and image URLs. The SVG files in this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/openclipart.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_eval_analysis_2","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_2","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_2.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_eval_analysis_5","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_5","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_5.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_eval_analysis_6","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_6","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_6.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"mcqa_greek_asep","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilsp/mcqa_greek_asep","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","description":"\n\t\n\t\t\n\t\tDataset Card for Multiple Choice QA Greek ASEP\n\t\n\nThe Multiple Choice QA Greek ASEP dataset is a set of 1200 multiple choice questions in Greek. The questions were extracted and converted from questions available at the website of the Greek Supreme Council for Civil Personnel Selection (ŒëŒΩœéœÑŒ±œÑŒø Œ£œÖŒºŒ≤ŒøœçŒªŒπŒø ŒïœÄŒπŒªŒøŒ≥ŒÆœÇ Œ†œÅŒøœÉœâœÄŒπŒ∫Œøœç, ŒëŒ£ŒïŒ†-ASEP) (1Œì/2025).\nThe dataset includes questions in the following domains:\n\nŒ£œÖŒΩœÑŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå ŒîŒØŒ∫Œ±ŒπŒø (Constitutional Law): 187 questions\n\nŒîŒπŒøŒπŒ∫Œ∑œÑŒπŒ∫œå ŒîŒØŒ∫Œ±ŒπŒø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/mcqa_greek_asep.","first_N":5,"first_N_keywords":["multiple-choice","monolingual","Greek","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"synthetic-users-1000","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eosync/synthetic-users-1000","creator_name":"Jose","creator_url":"https://huggingface.co/eosync","description":"\n\t\n\t\t\n\t\tSynthetic Users 1000\n\t\n\n\n\t\n\t\t\n\t\tüß™ Synthetic Users Dataset (1,000 Records)\n\t\n\nThis dataset contains 1,000 high-quality synthetic user profiles, including realistic bios, usernames, metadata, and profile image filenames ‚Äî ideal for:\n\nUI/UX testing\nPrototyping dashboards\nMock data in SaaS apps\nUser flow demos\nAI evaluation without PII\n\n\n\n\t\n\t\t\n\t\tüß† Features\n\t\n\n\n‚úÖ 100% privacy-safe\nüßç Full names, emails, bios, countries\nüì∏ Profile image filenames (S3-ready)\nüîç Gender, age, emotion tags via‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eosync/synthetic-users-1000.","first_N":5,"first_N_keywords":["text-generation","tabular-classification","synthetic","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\tüîä LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\tüîç Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\nNatural and authentic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"talemaader_pc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/talemaader_pc","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TalemaaderPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Danish Language and Literature Society has developed a dataset for evaluating language models in Danish.\nThe dataset contains a total of 1000 Danish idioms and fixed expressions with transferred meanings based on the Danish Dictionary's collection of fixed expressions with associated definitions.\nFor each of the 1000 idioms and fixed expressions, three false definitions have also been prepared.\nThe dataset can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/talemaader_pc.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Danish"],"keywords_longer_than_N":true},
	{"name":"VieQuADRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VieQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VieQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for evaluating Machine Reading Comprehension from Wikipedia articles.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReferencehttps://aclanthology.org/2020.coling-main.233.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VieQuADRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieQuADRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"ToxiMol-benchmark","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeepYoke/ToxiMol-benchmark","creator_name":"DeepYoke","creator_url":"https://huggingface.co/DeepYoke","description":"\n\t\n\t\t\n\t\tToxiMol: A Benchmark for Structure-Level Molecular Detoxification\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nToxiMol is the first comprehensive benchmark for molecular toxicity repair tailored to general-purpose Multimodal Large Language Models (MLLMs). This is the dataset repository for the paper \"Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?\".\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n\t\n\t\t\n\t\tüß¨ Comprehensive Dataset\n\t\n\n\n560 representative toxic molecules spanning diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeepYoke/ToxiMol-benchmark.","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","multi-class-classification","tabular-single-column-regression","monolingual"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_v1","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_v1.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"swim-ir-monolingual-de-scored","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MarcGrumpyOlejak/swim-ir-monolingual-de-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the wonderful, original and unchanged \"german only\" dataset (train split only) in original order from nthakur/swim-ir-monolingual with added cosine-similarity scores.\nThe scores between 'query' and 'text' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/swim-ir-monolingual-de-scored.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"mmarco-de-distilled-scored","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is a distilled (reduced) \"german only\" dataset (train split only) version still in original order from unicamp-dl/mmarco with added cosine-similarity scores. The full source of mmarco by unicamp is hosted in the repository on GitHub.\nThe scores between 'query' and 'text' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_eval_analysis_3","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_3","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_3.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_eval_analysis_4","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_4","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_4.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset_2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_2","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset_2.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AfriHist-CoT","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/AfriHist-CoT","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\n\t\n\t\t\n\t\tAfriHist-CoT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nAfriHist-CoT is a dataset of question-answer pairs derived from African history books, created using a Chain-of-Thought (CoT) reasoning approach with the Gemini language model via OpenRouter. The dataset supports training and evaluating question-answering models, with a focus on African history and CoT reasoning. It is available in English and French, catering to both monolingual and multilingual applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/AfriHist-CoT.","first_N":5,"first_N_keywords":["text-generation","question-answering","ai-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"KemSU","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NodeLinker/KemSU","creator_name":"Ilya Pereverzin","creator_url":"https://huggingface.co/NodeLinker","description":"\n\t\n\t\t\n\t\tüéì Kemerovo State University Instructional QA Dataset (NodeLinker/KemSU)\n\t\n\n\n  \n     \n  \n\n\n  \n    \n  \n  \n    \n  \n\n\n\n\n\t\n\t\n\t\n\t\tüìù Dataset Overview & Splits\n\t\n\nThis dataset provides instructional question-answer (Q&A) pairs meticulously crafted for Kemerovo State University (–ö–µ–º–ì–£, KemSU), Russia. Its primary purpose is to facilitate the fine-tuning of Large Language Models (LLMs), enabling them to function as knowledgeable and accurate assistants on a wide array of topics concerning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NodeLinker/KemSU.","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dataset_for_scicllaimhunt","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnshulS/dataset_for_scicllaimhunt","creator_name":"Anshul Sharma","creator_url":"https://huggingface.co/AnshulS","description":"\n\t\n\t\t\n\t\tüß™ SciClaimHunt\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Dataset Card for SciClaimHunt\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìù Dataset Summary\n\t\n\nSciClaimHunt is a large-scale scientific claim verification dataset comprising ~110,000 instances of:\n\nScientific claims\nSupporting evidence\nFull research paper text\n\nIt enables rigorous experimentation on scientific fact verification, evidence retrieval, and document-level reasoning.\n\n\t\n\t\t\n\t\t‚úÖ Supported Tasks\n\t\n\n\nScientific Claim Verification\nEvidence Retrieval\nClaim-Evidence Pair‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnshulS/dataset_for_scicllaimhunt.","first_N":5,"first_N_keywords":["text-classification","other","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"EmpathicConversations","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/samdak93/EmpathicConversations","creator_name":"Samdak","creator_url":"https://huggingface.co/samdak93","description":"\n\t\n\t\t\n\t\tEmpathicConversations\n\t\n\nEmpathicConversations is a human-curated dataset designed to train and evaluate conversational AI systems that offer emotionally intelligent, supportive, and non-judgmental responses in therapeutic settings.\n\n\t\n\t\t\n\t\tüß† Purpose\n\t\n\nThis dataset serves as a foundation for building AI therapy assistants and mental wellness chatbots. It emphasizes empathy, active listening, and emotional support, aiming to make AI more compassionate and context-aware in sensitive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samdak93/EmpathicConversations.","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","human-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S\"])\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"BornholmBitextMining","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BornholmBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BornholmBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Bornholmsk Parallel Corpus. Bornholmsk is a Danish dialect spoken on the island of Bornholm, Denmark. Historically it is a part of east Danish which was also spoken in Scania and Halland, Sweden.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nWeb, Social, Fiction, Written\n\n\nReference\nhttps://aclanthology.org/W19-6138/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BornholmBitextMining.","first_N":5,"first_N_keywords":["translation","expert-annotated","monolingual","Danish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CBD","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CBD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CBD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Tweets annotated for cyberbullying detection.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttp://2019.poleval.pl/files/poleval2019.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CBD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CBD.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CEDRClassification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CEDRClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CEDRClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClassification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Social, Blog, Written\n\nReference\nhttps://www.sciencedirect.com/science/article/pii/S1877050921013247\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CEDRClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringP2P.v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CLSClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles + abstract from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReferencehttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringP2P.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringP2P"],"keywords_longer_than_N":true},
	{"name":"CSFDSKMovieReviewSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDSKMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Slovak.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDSKMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackST","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CodeFeedbackST","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CodeFeedbackST\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"CodeFeedbackST\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackST.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"Core17InstructionRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Core17InstructionRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Core17InstructionRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring retrieval instruction following ability on Core17 narratives for the FollowIR benchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReferencehttps://arxiv.org/abs/2403.15246\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Core17InstructionRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Core17InstructionRetrieval.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"DanFeverRetrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DanFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DanFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Danish dataset intended for misinformation research. It follows the same format as the English FEVER dataset. DanFeverRetrieval fixed an issue in DanFever where some corpus entries were incorrectly removed.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Spoken\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.47/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DanFeverRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"EightTagsClustering","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EightTagsClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EightTagsClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of headlines from social media posts in Polish belonging to 8 categories: film, history, food, medicine, motorization, work, sport and technology.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.207.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EightTagsClustering.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P.v2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"AutoRAGRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AutoRAGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AutoRAGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset enables the evaluation of Korean RAG performance across various domains‚Äîfinance, public sector, healthcare, legal, and commerce‚Äîby providing publicly accessible documents, questions, and answers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Medical, Legal, Social, Financial\n\n\nReference\nhttps://arxiv.org/abs/2410.20878\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AutoRAGRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringS2S.v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CLSClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringS2S.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringS2S"],"keywords_longer_than_N":true},
	{"name":"CSFDCZMovieReviewSentimentClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDCZMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Czech.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDCZMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicenseeLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAffiliateLicenseLicenseeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a clause describes a license grant to a licensee (incl. sublicensor) and the affiliates of such licensee/sublicensor.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicensorLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAffiliateLicenseLicensorLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause describes a license grant by affiliates of the licensor or that includes intellectual property of affiliates of the licensor.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAntiAssignmentLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAntiAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires consent or notice of a party if the contract is assigned to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAuditRightsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAuditRightsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives a party the right to audit the books, records, or physical locations of the counterparty to ensure compliance with the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCapOnLiabilityLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCapOnLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a cap on liability upon the breach of a party's obligation. This includes time limitation for the counterparty to bring claims or maximum amount for recovery.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADChangeOfControlLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADChangeOfControlLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives one party the right to terminate or is consent or notice required of the counterparty if such party undergoes a change of control, such as a merger, stock sale, transfer of all or substantially all of its assets or business, or assignment by operation of law.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCompetitiveRestrictionExceptionLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCompetitiveRestrictionExceptionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause mentions exceptions or carveouts to Non-Compete, Exclusivity and No-Solicit of Customers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCovenantNotToSueLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCovenantNotToSueLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party is restricted from contesting the validity of the counterparty's ownership of intellectual property or otherwise bringing a claim against the counterparty for matters unrelated to the contract.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADExclusivityLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADExclusivityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies exclusive dealing commitment with the counterparty. This includes a commitment to procure all 'requirements' from one party of certain technology, goods, or services or a prohibition on licensing or selling technology, goods or services to third parties, or a prohibition on collaborating or working‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADGoverningLawLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADGoverningLawLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies which state/country‚Äôs law governs the contract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADIPOwnershipAssignmentLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADIPOwnershipAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that intellectual property created by one party become the property of the counterparty, either per the terms of the contract or upon the occurrence of certain events.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADInsuranceLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADInsuranceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if clause creates a requirement for insurance that must be maintained by one party for the benefit of the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADJointIPOwnershipLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADJointIPOwnershipLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause provides for joint or shared ownership of intellectual property between the parties to the contract.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADLicenseGrantLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADLicenseGrantLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause contains a license granted by one party to its counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADLiquidatedDamagesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADLiquidatedDamagesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause awards either party liquidated damages for breach or a fee upon the termination of a contract (termination fee).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADMinimumCommitmentLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADMinimumCommitmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a minimum order size or minimum amount or units per time period that one party must buy from the counterparty.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADMostFavoredNationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADMostFavoredNationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a third party gets better terms on the licensing or sale of technology/goods/services described in the contract, the buyer of such technology/goods/services under the contract shall be entitled to those better terms.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonCompeteLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonCompeteLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts the ability of a party to compete with the counterparty or operate in a certain geography or business or technology sector.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonDisparagementLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonDisparagementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires a party not to disparage the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonTransferableLicenseLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonTransferableLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause limits the ability of a party to transfer the license being granted to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoticePeriodToTerminateRenewalLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoticePeriodToTerminateRenewalLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a notice period required to terminate renewal.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADPostTerminationServicesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADPostTerminationServicesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause subjects a party to obligations after the termination or expiration of a contract, including any post-termination transition, payment, transfer of IP, wind-down, last-buy, or similar commitments.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADPriceRestrictionsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADPriceRestrictionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause places a restriction on the ability of a party to raise or reduce prices of technology, goods, or services provided.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRenewalTermLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRenewalTermLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a renewal term.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRevenueProfitSharingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRevenueProfitSharingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause require a party to share revenue or profit with the counterparty for any technology, goods, or services.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRofrRofoRofnLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRofrRofoRofnLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grant one party a right of first refusal, right of first offer or right of first negotiation to purchase, license, market, or distribute equity interest, technology, assets, products or services.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADSourceCodeEscrowLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADSourceCodeEscrowLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires one party to deposit its source code into escrow with a third party, which can be released to the counterparty upon the occurrence of certain events (bankruptcy, insolvency, etc.).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADVolumeRestrictionLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADVolumeRestrictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a fee increase or consent requirement, etc. if one party's use of the product/services exceeds certain threshold.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIConfidentialityOfAgreementLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIConfidentialityOfAgreementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA provides that the Receiving Party shall not disclose the fact that Agreement was agreed or negotiated.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIExplicitIdentificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIExplicitIdentificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that all Confidential Information shall be expressly identified by the Disclosing Party.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLINoticeOnCompelledDisclosureLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall notify Disclosing Party in case Receiving Party is required by law, regulation or judicial process to disclose any Confidential Information.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithThirdPartiesLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISharingWithThirdPartiesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some third-parties (including consultants, agents and professional advisors).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity1LegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity1LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 1).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FaroeseSTS","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FaroeseSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FaroeseSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSemantic Text Similarity (STS) corpus for Faroese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.74.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FaroeseSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FaroeseSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Faroese"],"keywords_longer_than_N":true},
	{"name":"FinParaSTS","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FinParaSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FinParaSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFinnish paraphrase-based semantic similarity corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Subtitles, Written\n\n\nReference\nhttps://huggingface.co/datasets/TurkuNLP/turku_paraphrase_corpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FinParaSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinParaSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","monolingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"FrenchBookReviews","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FrenchBookReviews","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FrenchBookReviews\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIt is a French book reviews dataset containing a huge number of reader reviews on French books. Each review is pared with a rating that ranges from 0.5 to 5 (with 0.5 increment).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/Abirate/french_book_reviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FrenchBookReviews.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","French","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"FunctionOfDecisionSectionLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FunctionOfDecisionSectionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to classify a paragraph extracted from a written court decision into one of seven possible categories:\n            1. Facts - The paragraph describes the faction background that led up to the present lawsuit.\n            2. Procedural History - The paragraph describes the course of litigation that led to the current proceeding before the court.\n            3. Issue - The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClusteringP2P","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeoreviewClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview clustering based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClusteringP2P\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"GermanGovServiceRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GermanGovServiceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLHM-Dienstleistungen-QA is a German question answering dataset for government services of the Munich city administration. It associates questions with a textual context containing the answer\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"GreekLegalCodeClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GreekLegalCodeClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GreekLegalCodeClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreek Legal Code Dataset for Classification. (subset = chapter)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://arxiv.org/abs/2109.15298\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreekLegalCodeClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreekLegalCodeClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Modern Greek (1453-)"],"keywords_longer_than_N":true},
	{"name":"HeadlineClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HeadlineClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HeadlineClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHeadline rubric classification based on the paraphraser plus dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://aclanthology.org/2020.ngt-1.6/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HeadlineClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HeadlineClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"HebrewSentimentAnalysis","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HebrewSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israel‚Äôs president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder, 2013) to scrape all the comments to all of the president‚Äôs posts in the period of June ‚Äì August 2014, the first three months of Rivlin‚Äôs presidency.2 While the president‚Äôs posts aimed at reconciling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"HindiDiscourseClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HindiDiscourseClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HindiDiscourseClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Hindi Discourse dataset in Hindi with values for coherence.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nFiction, Social, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.149/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HindiDiscourseClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HindiDiscourseClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"HunSum2AbstractiveRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HunSum2AbstractiveRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHunSum-2-abstractive is a Hungarian dataset containing news articles along with lead, titles and metadata.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.03555\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HunSum2AbstractiveRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Hungarian"],"keywords_longer_than_N":true},
	{"name":"InternationalCitizenshipQuestionsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InternationalCitizenshipQuestionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions about citizenship law from across the world. Dataset was made using the GLOBALCIT citizenship law dataset, by constructing questions about citizenship law as Yes or No questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ItaCaseholdClassification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ItaCaseholdClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ItaCaseholdClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAn Italian Dataset consisting of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives of Italian Administrative Justice categorized with 64 subjects.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReference\nhttps://doi.org/10.1145/3594536.3595177\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ItaCaseholdClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Italian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"JSICK","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSICK","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSICK\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JSICK\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSICK.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqsRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaGovFaqsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJaGovFaqs is a dataset consisting of FAQs manully extracted from the website of Japanese bureaus. The dataset consists of 22k FAQs, where the queries (questions) and corpus (answers) have been shuffled, and the goal is to match the answer with the question.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KLUE-TC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KLUE-TC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KLUE-TC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTopic classification dataset of human-annotated news headlines. Part of the Korean Language Understanding Evaluation (KLUE).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2105.09680\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KLUE-TC\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KLUE-TC.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"KorHateClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset was created to provide the first human-labeled Korean corpus for\n        toxic speech detection from a Korean online entertainment news aggregator. Recently,\n        two young Korean celebrities suffered from a series of tragic incidents that led to two\n        major Korean web portals to close the comments section on their platform. However, this only\n        serves as a temporary solution, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorHateSpeechMLClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateSpeechMLClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Multi-label Hate Speech Dataset, K-MHaS, consists of 109,692 utterances from Korean online news comments,\n    labelled with 8 fine-grained hate speech classes (labels: Politics, Origin, Physical, Age, Gender, Religion, Race, Profanity)\n    or Not Hate Speech class. Each utterance provides from a single to four labels that can handles Korean language patterns effectively.\n    For more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"LitSearchRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LitSearchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LitSearchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The dataset contains the query set and retrieval corpus for the paper LitSearch: A Retrieval Benchmark for\n    Scientific Literature Search. It introduces LitSearch, a retrieval benchmark comprising 597 realistic literature\n    search queries about recent ML and NLP papers. LitSearch is constructed using a combination of (1) questions\n    generated by GPT-4 based on paragraphs containing inline citations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LitSearchRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MAUDLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MAUDLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the MAUD dataset, which consists of over 47,000 labels across 152 merger agreements annotated to identify 92 questions in each agreement used by the 2021 American Bar Association (ABA) Public Target Deal Points Study. Each dataset is formatted as a series of multiple-choice questions, where given a segment of the merger agreement and a Deal Point question, the model is to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MalayalamNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MalayalamNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MalayalamNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Malayalam dataset for 3-class classification of Malayalam news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-malyalam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MalayalamNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MalayalamNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"MarathiNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MarathiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MarathiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Marathi dataset for 3-class classification of Marathi news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-marathi\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MarathiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MarathiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Marathi"],"keywords_longer_than_N":true},
	{"name":"MewsC16JaClustering","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MewsC16JaClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MewsC16JaClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMewsC-16 (Multilingual Short Text Clustering Dataset for News in 16 languages) is constructed from Wikinews.\n        This dataset is the Japanese split of MewsC-16, containing topic sentences from Wikinews articles in 12 categories.\n        More detailed information is available in the Appendix E of the citation.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MewsC16JaClustering.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NYSJudicialEthicsLegalBenchClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NYSJudicialEthicsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions on judicial ethics from the New York State Unified Court System Advisory Committee.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"NanoArguAnaRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoArguAnaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoArguAna is a smaller subset of ArguAna, a dataset for argument retrieval in debate contexts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReferencehttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoArguAnaRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/arguana","English"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCORetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoMSMARCORetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoMSMARCORetrieval is a smaller subset of MS MARCO, a collection of datasets focused on deep learning in search.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReferencehttps://microsoft.github.io/msmarco/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoMSMARCORetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/msmarco"],"keywords_longer_than_N":true},
	{"name":"NanoNQRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoNQRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoNQRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNQ is a smaller subset of a dataset which contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web\n\n\nReference\nhttps://ai.google.com/research/NaturalQuestions\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNQRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_benchmark","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_benchmark","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP_M3_mcqa_benchmark\n\t\n\nThis benchmark is a filtered subset of the MMLU test set (cais/mmlu) focused on 21 STEM subjects. It is formatted for Multiple Choice Question Answering (MCQA) tasks.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nEach entry includes:\n\nquestion: A multiple-choice question in plain text.\nchoices: A list of four possible answers (A, B, C, D).\nanswer: The correct answer, represented by a single letter (A, B, C, or D).\n\n\n\t\n\t\t\n\t\tIncluded Subjects\n\t\n\n\nabstract_algebra‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_benchmark.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"TLPD","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evan6007/TLPD","creator_name":"evan6007","creator_url":"https://huggingface.co/evan6007","description":"\n\t\n\t\t\n\t\tTLPD: Taiwan License Plate Dataset\n\t\n\nTLPD is a dataset containing over 3,000 images of vehicles with annotated license plates. Each image is labeled using the LabelMe format, with polygon annotations describing the boundary of each license plate.\nThis dataset is designed for tasks such as license plate detection, polygon segmentation, and scene text detection.\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Dataset Structure\n\t\n\nAll image files are stored in the images/ directory, and their corresponding polygon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evan6007/TLPD.","first_N":5,"first_N_keywords":["object-detection","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020Retrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoTouche2020Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoTouche2020 is a smaller subset of Touch√© Task 1: Argument Retrieval for Controversial Questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReferencehttps://webis.de/events/touche-20/shared-task-1.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoTouche2020Retrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"NepaliNewsClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NepaliNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NepaliNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Nepali dataset for 7500 news articles \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-nepali\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NepaliNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NepaliNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Nepali (macrolanguage)"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NevIR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NevIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPaired evaluation of real world negation in retrieval, with questions and passages. Since models generally prefer one passage over the other always, there are two questions that the model must get right to understand the negation (hence the paired_accuracy metric).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://github.com/orionw/NevIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NevIR.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NorwegianCourtsBitextMining","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorwegianCourtsBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNynorsk and Bokm√•l parallel corpus from Norwegian courts. Norwegian courts have two standardised written languages. Bokm√•l is a variant closer to Danish, while Nynorsk was created to resemble regional dialects of Norwegian.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://opus.nlpl.eu/index.php\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","monolingual","Norwegian Nynorsk","Norwegian Bokm√•l"],"keywords_longer_than_N":true},
	{"name":"OdiaNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OdiaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OdiaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Odia dataset for 3-class classification of Odia news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-odia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"OdiaNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OdiaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Odia"],"keywords_longer_than_N":true},
	{"name":"OralArgumentQuestionPurposeLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OralArgumentQuestionPurposeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task classifies questions asked by Supreme Court justices at oral argument into seven categories:\n        1. Background - questions seeking factual or procedural information that is missing or not clear in the briefing\n        2. Clarification - questions seeking to get an advocate to clarify her position or the scope of the rule being advocated for\n        3. Implications -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PROALegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PROALegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PROALegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a statute, determine if the text contains an explicit private right of action. Given a privacy policy clause and a description of the clause, determine if the description is correct. A private right of action (PROA) exists when a statute empowers an ordinary individual (i.e., a private person) to legally enforce their rights by bringing an action in court. In short, a PROA creates the ability for an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PROALegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PUGGRetrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PUGGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PUGGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nInformation Retrieval PUGG dataset for the Polish language.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://aclanthology.org/2024.findings-acl.652/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PUGGRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PUGGRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringP2P.v2","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PlscClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles+abstracts from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-p2p"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringS2S.v2","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PlscClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-s2s"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-IN","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-IN","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-IN\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-IN task is to predict the sentiment of in-domain (medicine and hotels) reviews.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-IN.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mythos","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronniealfaro/mythos","creator_name":"Ronnie","creator_url":"https://huggingface.co/ronniealfaro","description":"\n\t\n\t\t\n\t\tDataset Card for Mitological-Philosophical Prompts (Mitomaquia)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 200 examples of mythological, narrative, and philosophical prompts designed for training or fine-tuning large language models (LLMs). Each entry features a deep question (prompt), relevant cultural or mythological background (context), and a reflective, often paradoxical, answer (response). \nThe goal is not factual Q&A but the cultivation of myth-aware reasoning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronniealfaro/mythos.","first_N":5,"first_N_keywords":["text-generation","question-answering","open-domain-qa","dialogue-generation","human-annotated"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsDeEnPC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"AI_Generated_Ghibli","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filberthamijoyo/AI_Generated_Ghibli","creator_name":"Filbert Hamijoyo","creator_url":"https://huggingface.co/filberthamijoyo","description":"\n\t\n\t\t\n\t\tAI-Generated Ghibli Images Dataset\n\t\n\nThis repository contains a collection of AI-generated images in the style of Studio Ghibli. These images showcase various subjects, characters, and landscapes rendered in the distinctive artistic style associated with Studio Ghibli animation films.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nNumber of Images: 368 high-quality images\nImage Format: Primarily PNG and JPG files\nResolution: Various resolutions (primarily high resolution)\nGeneration Tools: Created‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/filberthamijoyo/AI_Generated_Ghibli.","first_N":5,"first_N_keywords":["image-classification","other","multi-class-image-classification","image-captioning","machine-generated"],"keywords_longer_than_N":true},
	{"name":"conequest","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/conequest","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tconequest\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Cone\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks\n  ‚îú‚îÄ‚îÄ val/\n  ‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/conequest.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"medra-medical-sampled","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicoboss/medra-medical-sampled","creator_name":"Nico Bosshard","creator_url":"https://huggingface.co/nicoboss","description":"\n\t\n\t\t\n\t\tMedra Medical Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, provisionally named the \"Medra Medical Reasoning Dataset,\" is a curated and processed collection of various medical question answering, dialogue, and reasoning datasets. It has been specifically formatted to facilitate the training of large language models, such as Gemma 3 (code-named Medra in this project), to improve their medical knowledge, enhance their reasoning capabilities, and enable them to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicoboss/medra-medical-sampled.","first_N":5,"first_N_keywords":["question-answering","text-generation","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"CVC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beijing-AISI/CVC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","description":"\nThis repository contains all the data associated with the paper \"CVC: A Large-Scale Chinese Value Rule Corpus for Cultural Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/CVC.","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"boulder_segmentation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/boulder_segmentation","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tboulder_segmentation\n\t\n\nA segmentation dataset for planetary science applications.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: Background\n1: Boulder\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nThe dataset follows this structure:\ndataset/\n  ‚îú‚îÄ‚îÄ train/\n  ‚îÇ   ‚îú‚îÄ‚îÄ images/  # Image files\n  ‚îÇ   ‚îî‚îÄ‚îÄ masks/   # Segmentation masks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/boulder_segmentation.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dust_devil_detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/dust_devil_detection","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tdust_devil_detection Dataset\n\t\n\nAn object detection dataset in YOLO format containing 3 splits: train, val, test.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-11\nCite As: TBD\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: YOLO\n\nSplits: train, val, test\n\nClasses: dustdevil\n\n\n\n\t\n\t\t\n\t\tAdditional Formats\n\t\n\n\nIncludes COCO format annotations\nIncludes Pascal VOC format annotations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/dust_devil_detection.","first_N":5,"first_N_keywords":["object-detection","instance-segmentation","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"nesteo-prototype","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype","creator_name":"NestEO Datasets","creator_url":"https://huggingface.co/nesteo-datasets","description":"\n\t\n\t\t\n\t\tNestEO: Modular and Hierarchical EO Dataset Framework\n\t\n\nNestEO is a hierarchical, resolution-aligned, UTM-based nested grid dataset framework supporting general-purpose, multi-scale multimodal Earth Observation workflows. Built from diverse EO sources and enriched with metadata for landcover, climate zones, and population, it enables scalable, representative and progressive sampling for AI4EO.\nGrid Levels: 120000m, 12000m, 2400m, 1200m, 600m, 300m, 150mGrid Metadata: ESA WorldCover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"domars16k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gremlin97/domars16k","creator_name":"Kunal Kasodekar","creator_url":"https://huggingface.co/gremlin97","description":"\n\t\n\t\t\n\t\tdomars16k\n\t\n\nA Mars image classification dataset for planetary science research.\n\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\nVersion: 1.0\nDate Published: 2025-05-12\nCite As: TBD\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThis dataset contains the following classes:\n\n0: aec\n1: ael\n2: cli\n3: cra\n4: fse\n5: fsf\n6: fsg\n7: fss\n8: mix\n9: rid\n10: rou\n11: sfe\n12: sfx\n13: smo\n14: tex\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\ntrain: 1639 images\ntest: 234 images\nval: 469 images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gremlin97/domars16k.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"chempile-code","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jablonkagroup/chempile-code","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","description":"\n\t\n\t\t\n\t\tChemPile-Code\n\t\n\n\n\n\n\n\n\n\nA comprehensive collection of filtered scientific code from chemistry, biology, and materials science\n\t\n\t\t\n\t\tüìã Dataset Summary\n\t\n\nChemPile-Code includes filtered code from popular datasets such as the Stack and GitHub-code. It is designed to provide a rich source of scientific coding from fields such as chemistry, biology, and materials science. The dataset is part of the ChemPile project, and aims to create a comprehensive collection of chemistry code for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/chempile-code.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_mcqa_dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset","creator_name":"Youssef Belghmi","creator_url":"https://huggingface.co/youssefbelghmi","description":"\n\t\n\t\t\n\t\tMNLP M3 MCQA Dataset\n\t\n\nThe MNLP M3 MCQA Dataset is a carefully curated collection of Multiple-Choice Question Answering (MCQA) examples, unified from several academic and benchmark datasets.\nDeveloped as part of the CS-552: Modern NLP course at EPFL (Spring 2025), this dataset is designed for training and evaluating models on multiple-choice QA tasks, particularly in the STEM and general knowledge domains.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n~30,000 MCQA questions\n6 diverse sources: SciQ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefbelghmi/MNLP_M3_mcqa_dataset.","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"VisOnlyQA_length_angle","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_length_angle","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\n\t\n\t\t\n\t\tVisOnlyQA\n\t\n\n\nüåê Project Website | üìÑ Paper | ü§ó Dataset | üî• VLMEvalKit\n\n\nThis repository contains the code and data for the paper \"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\".\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_length_angle.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","multiple-choice-qa","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"texturecan","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/texturecan","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for TextureCan Textures\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 4,037 texture images from texturecan.com. It includes textures of various materials such as brick, paper, fabric, metal, wood, stone, and other surfaces. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compression (90%) to reduce file size while maintaining good quality.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/texturecan.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"ambientcg","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ambientcg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for AmbientCG Textures and HDRIs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 14,202 high-quality texture images and HDRI environments from ambientcg.com. It includes a comprehensive collection of materials such as fabric, metal, wood, stone, concrete, nature elements, and HDRI skyboxes for 3D rendering and computer graphics applications. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compression‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ambientcg.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Venkatachalam/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells","creator_name":"Venkatachalam Subramanian Periya Subbu","creator_url":"https://huggingface.co/Venkatachalam","description":"\n\t\n\t\t\n\t\tHuman Optic Nerve Endothelial Cells (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on endothelial cells from the human optic nerve and optic nerve head. It represents a valuable resource for investigating cell-type specific gene expression profiles within a critical ocular tissue.\nThe data was sourced from the CZ CELLxGENE Discover API, providing access to a deeply characterized single-cell‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Venkatachalam/snRNAseq_of_human_optic_nerve_and_optic_nerve_head_endothelial_cells.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"TwitterHjerneRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TwitterHjerneRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish question asked on Twitter with the Hashtag #Twitterhjerne ('Twitter brain') and their corresponding answer.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Written\n\nReference\nhttps://huggingface.co/datasets/sorenmulli/da-hashtag-twitterhjerne\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","sorenmulli/da-hashtag-twitterhjerne"],"keywords_longer_than_N":true},
	{"name":"human-muscle-aging-atlas-snRNAseq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/human-muscle-aging-atlas-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tHuman Skeletal Muscle Aging Atlas (sn/scRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Data Overview\n\t\n\nThis dataset provides single-nucleus and single-cell RNA sequencing (sn/scRNA-seq) data specifically focusing on the human skeletal muscle across different age groups. It serves as a rich resource for investigating cell-type specific gene expression changes and cellular composition shifts that occur during the aging process in a critical human tissue.\nThe original data was sourced from the Human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-muscle-aging-atlas-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mouse-muscle-aging-atlas-snRNAseq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/mouse-muscle-aging-atlas-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tMouse Skeletal Muscle Aging Atlas (sn/scRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus and single-cell RNA sequencing (sn/scRNA-seq) data specifically focusing on the mouse skeletal muscle across different age groups. It serves as a valuable resource for investigating cell-type-specific gene expression changes and cellular composition shifts that occur during the aging process in a crucial mammalian model system.\nThe data was sourced from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/mouse-muscle-aging-atlas-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mouse-glioblastoma-snRNAseq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/mouse-glioblastoma-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tMouse Glioblastoma Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data from the brain (glioblastoma tumors and their microenvironment) of both young and aged mice. It provides a high-resolution cellular and molecular census of glioblastoma, a highly aggressive brain tumor, with crucial insights into its age-related characteristics.\nThe original data was sourced from a CELLxGENE Discover collection titled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/mouse-glioblastoma-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Moon_Detection_Dataset_for_YOLOv8","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LuisAdrian5519/Moon_Detection_Dataset_for_YOLOv8","creator_name":"Luis Adrian Cabrera Mu√±oz","creator_url":"https://huggingface.co/LuisAdrian5519","description":"\n\t\n\t\t\n\t\tMoon Detection Dataset for YOLOv8\n\t\n\nThis dataset was developed as part of the CubeRT-02 project, a CubeSat mission aimed at testing AI-powered vision systems in aerospace contexts. It consists of 7500+ annotated images for object detection of the Moon, optimized for use with the YOLOv8 architecture.\n\n\t\n\t\t\n\t\tüì∏ Dataset Collection & Annotation\n\t\n\nInitial set: ~400 web-sourced images used for theoretical model exploration.\nMain dataset: 7500+ images captured over 6 months using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LuisAdrian5519/Moon_Detection_Dataset_for_YOLOv8.","first_N":5,"first_N_keywords":["object-detection","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"self-ai-for-psychology","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alindumitru/self-ai-for-psychology","creator_name":"Alin Vasile Dumitru","creator_url":"https://huggingface.co/alindumitru","description":"\n\t\n\t\t\n\t\tWelcome to SelfAI open-sourced dataset for patient-therapist conversation + psychology knowledge + philosophy chats.\n\t\n\n\nThis dataset is a mixture of other datasets that are open sourced for patient-therapist conversation, psychology and philosophy.\nIt includes post-processing such as:\ntoxicity filtering\nduplicate removal\nlanguage detection filtering (English)\nanonymization\nrephrasing\n\n\nDatasets used:\nCalebE new_mental_health_conversations.\nHOPE dataset from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alindumitru/self-ai-for-psychology.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","dialogue-modeling","intent-classification"],"keywords_longer_than_N":true},
	{"name":"ARCChallenge","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ARCChallenge","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ARCChallenge\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on ARC-Challenge.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://allenai.org/data/arc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"ARCChallenge\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ARCChallenge.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/ARC-Challenge","English"],"keywords_longer_than_N":true},
	{"name":"my_image_caption_dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongin9812/my_image_caption_dataset","creator_name":"hongin kim","creator_url":"https://huggingface.co/hongin9812","description":"\n\t\n\t\t\n\t\tMy image-caption dataset\n\t\n\nThis dataset contains images with English descriptions (captions).\n","first_N":5,"first_N_keywords":["image-to-text","image-captioning","human-annotated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Robust04InstructionRetrieval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Robust04InstructionRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Robust04InstructionRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring retrieval instruction following ability on Robust04 narratives for the FollowIR benchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReferencehttps://arxiv.org/abs/2403.15246\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"Robust04InstructionRetrieval\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Robust04InstructionRetrieval.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","jhu-clsp/robust04-instructions-mteb","English"],"keywords_longer_than_N":true},
	{"name":"RuReviewsClassification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RuReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RuReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nProduct review classification (3-point scale) based on RuRevies dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/sismetanin/rureviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RuReviewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuReviewsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"SCDBPAuditsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDBPAuditsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDBPAuditsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  performs any type of audit, or reserves the right to audit?'\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPAuditsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDBPCertificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDBPCertificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDBPCertificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  performs any type of audit, or reserves the right to audit?'\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPCertificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDBPTrainingLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDBPTrainingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDBPTrainingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose whether the retail seller or manufacturer  provides training to employees on human trafficking and slavery? Broad policies such as ongoing dialogue on mitigating risks of human trafficking and slavery or increasing managers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDBPTrainingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDDAccountabilityLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDDAccountabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDDAccountabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer maintains internal accountability standards and procedures for employees or contractors failing to meet company standards regarding slavery and trafficking?'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDAccountabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDDAuditsLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDDAuditsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDDAuditsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer conducts audits of suppliers to evaluate supplier compliance with company standards for trafficking and slavery in supply chains? The disclosure shall specify if the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDAuditsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"SCDDCertificationLegalBenchClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SCDDCertificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCDDCertificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a binary classification task in which the LLM must determine if a supply chain disclosure meets the following coding criteria: 'Does the above statement disclose to what extent, if any, that the retail seller or manufacturer requires direct suppliers to certify that materials incorporated into the product comply with the laws regarding slavery and human trafficking of the country or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SCDDCertificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","nguha/legalbench","English"],"keywords_longer_than_N":true},
	{"name":"STSES","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/STSES","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  STSES\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSpanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://huggingface.co/datasets/PlanTL-GOB-ES/sts-es\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"STSES\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/STSES.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","monolingual","PlanTL-GOB-ES/sts-es","Spanish"],"keywords_longer_than_N":true},
	{"name":"SanskritShlokasClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SanskritShlokasClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SanskritShlokasClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis data set contains ~500 Shlokas  \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReligious, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-sanskrit\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SanskritShlokasClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SanskritShlokasClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","bpHigh/iNLTK_Sanskrit_Shlokas_Dataset"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsSourceClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SinhalaNewsSourceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK, Newsfirst, World Socialist Web Site-Sinhala).\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Source-classification"],"keywords_longer_than_N":true},
	{"name":"SlovakHateSpeechClassification","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SlovakHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SlovakHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains posts from a social network with human annotations for hateful or offensive language in Slovak.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://huggingface.co/datasets/TUKE-KEMT/hate_speech_slovak\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SlovakHateSpeechClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"SouthAfricanLangClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SouthAfricanLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SouthAfricanLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for 11 South African Languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\n\n\nReference\nhttps://www.kaggle.com/competitions/south-african-language-identification/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SouthAfricanLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","mlexplorer008/south_african_language_identification"],"keywords_longer_than_N":true},
	{"name":"SpanishNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SpanishNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SpanishNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Spanish dataset for news classification. The dataset includes articles from reputable Spanish news sources spanning 12 different categories.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SpanishNewsClassification.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","MarcOrfilaCarreras/spanish-news","Spanish"],"keywords_longer_than_N":true},
	{"name":"SpartQA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SpartQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SpartQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on SpartQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/HLR/SpartQA_generation\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SpartQA\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SpartQA.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/spartqa","English"],"keywords_longer_than_N":true},
	{"name":"StackOverflowQA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/StackOverflowQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  StackOverflowQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding response which may include some text mixed with code snippets. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/StackOverflowQA.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/stackoverflow-qa","English"],"keywords_longer_than_N":true},
	{"name":"SweFaqRetrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SweFaqRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SweFaqRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish QA dataset derived from FAQ\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nGovernment, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/superlim\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SweFaqRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SweFaqRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","AI-Sweden/SuperLim"],"keywords_longer_than_N":true},
	{"name":"SwednClusteringP2P","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SwednClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SwednClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure. This dataset uses the category labels as clusters.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/swedn\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwednClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","sbx/superlim-2","Swedish"],"keywords_longer_than_N":true},
	{"name":"SwednClusteringS2S","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SwednClusteringS2S","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SwednClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure. This dataset uses the category labels as clusters.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/swedn\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwednClusteringS2S.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","sbx/superlim-2","Swedish"],"keywords_longer_than_N":true},
	{"name":"SwednRetrieval","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SwednRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SwednRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/swedn\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwednRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbx/superlim-2"],"keywords_longer_than_N":true},
	{"name":"SyntheticText2SQL","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SyntheticText2SQL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SyntheticText2SQL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding sql snippets. The task is to retrieve the most relevant code snippet for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://huggingface.co/datasets/gretelai/synthetic_text_to_sql\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SyntheticText2SQL.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/synthetic-text2sql","code"],"keywords_longer_than_N":true},
	{"name":"TamilNewsClassification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/TamilNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TamilNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Tamil dataset for 6-class classification of Tamil news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/vanangamudi/tamil-news-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TamilNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TamilNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/tamil_news_classification"],"keywords_longer_than_N":true},
	{"name":"ToxicChatClassification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ToxicChatClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ToxicChatClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains toxicity annotations on 10K user\n            prompts collected from the Vicuna online demo. We utilize a human-AI\n            collaborative annotation framework to guarantee the quality of annotation\n            while maintaining a feasible annotation workload. The details of data\n            collection, pre-processing, and annotation can be found in our paper.\n            We believe that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ToxicChatClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Wiki-ja-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-ja-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-ja-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Japan‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Japanese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"Wiki-ko-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-ko-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-ko-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Korea‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rubricreward/llm-metric-mmlu","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","description":"rubricreward/llm-metric-mmlu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TriggerIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cwestnedge/TriggerIR","creator_name":"collins","creator_url":"https://huggingface.co/cwestnedge","description":"\n\t\n\t\t\n\t\tüìö TriggerIR\n\t\n\nTriggerIR is a synthetic benchmark for testing concept‚Äëerasure in information‚Äëretrieval (IR) systems. It contains paired movie‚Äësynopsis documents with and without a sensitive \"trigger\" concept, plus two queries (neutral¬†& explicit) designed to differentiate them. The corpus is entirely machine‚Äëgenerated so that debiasing experiments can be shared without disclosing real copyrighted text.\n\n\t\n\t\t\n\t\n\t\n\t\t‚ú® Dataset at a glance\n\t\n\n\n\t\n\t\t\nsplit\ndocuments\npairs\nconcepts\navg‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cwestnedge/TriggerIR.","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"Tree_Images_PT","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Diogo-Janice-Rafael/Tree_Images_PT","creator_name":"Diogo Janice e Rafael","creator_url":"https://huggingface.co/Diogo-Janice-Rafael","description":"\n\t\n\t\t\n\t\tüå≥ Tree Images Dataset\n\t\n\nThis dataset contains labeled images of the three most common Mediterranean tree species in Portugal:\n\nEucalyptus globulus\nPinus pinaster\nQuercus suber\n\nThese images were scrapped from GBIF\nAll images pretain to Portugal\nAll images have CC_BY_4_0 or CC0\n","first_N":5,"first_N_keywords":["multi-class-classification","monolingual","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"CIFAR-10","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KDKCE/CIFAR-10","creator_name":"KDKCE","creator_url":"https://huggingface.co/KDKCE","description":"\n\t\n\t\t\n\t\tCIFAR-10 - Object Recognition in Images\n\t\n\n\nBenchmark dataset for object classification.üñºÔ∏è 60,000 32x32 color imagesüè∑Ô∏è 10 classesüìÅ Format: PNG, CSVüì¶ Files: 4üß™ Subset of the 80 million tiny images dataset\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCIFAR-10 is a widely used computer vision dataset consisting of 60,000 32x32 color images in 10 mutually exclusive classes. It was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The dataset is a labeled subset of the 80 million tiny‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KDKCE/CIFAR-10.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TOFU-da","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/miry-itu/TOFU-da","creator_name":"Michal Rynowiecki","creator_url":"https://huggingface.co/miry-itu","description":"miry-itu/TOFU-da dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidErikMollberg/samromur_asr","creator_name":"David Erik Mollberg","creator_url":"https://huggingface.co/DavidErikMollberg","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modfied copy of the dataset from The Language and Voice Laboratory in RU.\nThis is the first release of the Samr√≥mur Icelandic Speech corpus that contains 100.000 validated utterances.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe audio is in Icelandic.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavidErikMollberg/samromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TextQuantificationDatasets","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjerzak/TextQuantificationDatasets","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","description":"\n\n\t\n\t\t\n\t\tAutomated Nonparametric Content Analysis Datasets\n\t\n\nThis repository provides the four benchmark datasets used in:\n\nConnor T. Jerzak, Gary King, and Anton Strezhnev. An Improved Method of Automated Nonparametric Content Analysis for Social Science. Political Analysis, 31(1): 42‚Äì58, 2023.\n\nEach dataset is formatted for easy loading in Python and R (CSV). Labels are integer-coded from 1,...,K; text is provided as raw strings.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasets\n\t\n\n\n\t\n\t\t\nName\nDocuments\nCategories‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/TextQuantificationDatasets.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","sentiment-classification","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ShamNER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HebArabNlpProject/ShamNER","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","description":"\n\t\n\t\t\n\t\tShamNER ‚Äì Spoken¬†Arabic Named‚ÄëEntity Recognition Corpus (Levantine v1.1)\n\t\n\nShamNER is a curated corpus of Levantine‚ÄëArabic sentences annotated for Named¬†Entities, plus dual annotation to check for consisetency (agreement) across human annotators. \n\nRounds¬†: pilot, round1‚Äìround5 (manual, as a rule quality improved across rounds) and round6 (synthetic, post‚Äëedited). The sythentic data is done by sampling label-rich annotated spans from an MSA project and writing it with an LLM while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ShamNER.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-annotated","monolingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"Wiki-vi-20250601","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-vi-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-vi-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Vietnam‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Vietnamese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"dsir-pile-1m-filtered-no-github-or-dm_mathematics","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/timaeus/dsir-pile-1m-filtered-no-github-or-dm_mathematics","creator_name":"Timaeus","creator_url":"https://huggingface.co/timaeus","description":"\n\t\n\t\t\n\t\tMy_Downsampled_Dataset\n\t\n\nThis dataset contains 1,000,000 examples from timaeus/dsir-pile-13m-filtered-no-github-or-dm_mathematics, downsampled for efficient processing.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"path/to/my_downsampled_dataset\")\n\n","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"Unmasking-the-Imposters","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/redasers/Unmasking-the-Imposters","creator_name":"ReDAS Lab at the University of Houston","creator_url":"https://huggingface.co/redasers","description":"\n\t\n\t\t\n\t\tUnmasking the Imposters: Machine-Generated Tweet Detection Dataset\n\t\n\nThis dataset contains nine subsets of human and machine-generated tweets designed to evaluate the detection of AI-generated content across censored and uncensored large language models (LLMs). The dataset addresses the gap in understanding how content moderation and domain adaptation affect the detectability of machine-generated text on social media platforms.\n\nPaper: \"Unmasking the Imposters: How Censorship and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redasers/Unmasking-the-Imposters.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","fact-checking","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"conversation_data_mcp_100","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yashsoni78/conversation_data_mcp_100","creator_name":"Yash Soni","creator_url":"https://huggingface.co/yashsoni78","description":"\n\t\n\t\t\n\t\tüìö Conversation Data MCP 100\n\t\n\nA conversational dataset consisting of 100 high-quality multi-turn dialogues for use in fine-tuning and evaluating conversational models.\n\n\t\n\t\t\n\t\tüìå Dataset Summary\n\t\n\nThis dataset contains 100 multi-turn conversations structured in a JSON format. It is designed to support research and development in areas such as:\n\nChatbot development\nDialogue modeling\nConversational AI evaluation\nNLP fine-tuning for custom agents\n\nEach conversation features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yashsoni78/conversation_data_mcp_100.","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MPCC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jyyyyy67/MPCC","creator_name":"jyyyyy","creator_url":"https://huggingface.co/jyyyyy67","description":"\n MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models\n\n\n\n      \n    [Github repository] \n    \n    \n\n\nüåü The official repository of MPCC.\n\n\t\n\t\t\n\t\tüî•News\n\t\n\n\nüî• Our work is accepted by ACM MM 2025.\nüî• We have release benchmark on [ü§óHuggingFace].\n\n\n\t\n\t\t\n\t\tüí° Motivation\n\t\n\nMultimodal Planning with Complex Constraints (MPCC) presents a novel benchmark targeting real-world planning scenarios that require models to jointly reason over visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jyyyyy67/MPCC.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","visual-question-answering","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"pathvqa-federated-client-10-by-image","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/srirangamuc/pathvqa-federated-client-10-by-image","creator_name":"Srirangam Umesh Chandra","creator_url":"https://huggingface.co/srirangamuc","description":"\n\t\n\t\t\n\t\tüß† PathVQA Federated (Split Per Image)\n\t\n\nA federated learning-ready version of the PathVQA dataset, partitioned by image using perceptual hashing (pHash). Each client's data contains all question-answer pairs linked to unique images, mimicking a real-world distributed medical setting (e.g., hospitals with private slide collections).\n\n\n\t\n\t\t\n\t\tüìö Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tüî¢ Features\n\t\n\n\nimage: PIL.Image ‚Äî Full-resolution pathology image tile\nquestion: string ‚Äî Natural language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/srirangamuc/pathvqa-federated-client-10-by-image.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","expert-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MathVista_with_difficulty_level","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMathVista with difficulty level tags\n\t\n\nThis dataset extends the ü§ó MathVista testmini benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVista_with_difficulty_level\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"Urdu-Legal_ner_corpora","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cheemasohail/Urdu-Legal_ner_corpora","creator_name":"Sohail Ashraf","creator_url":"https://huggingface.co/cheemasohail","description":"\n\t\n\t\t\n\t\tüìé Overview\n\t\n\nThis synthetic dataset is designed for Named Entity Recognition (NER) in Urdu legal documents, addressing the scarcity of annotated legal corpora in low-resource languages. The dataset comprises 117,500 CoNLL-formatted documents created using template-based generation and domain-specific dictionaries.\nThe dataset captures 10 main types and 47 subtypes of real-world Urdu legal documents like:\n\nJudicial Records\nContracts & Agreements\nProperty Records\nAffidavits\nFinancial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cheemasohail/Urdu-Legal_ner_corpora.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"techcrunch-articles","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhilash88/techcrunch-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","description":"\n\t\n\t\t\n\t\tTechCrunch News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\nThis dataset contains 10,265 high-quality news articles scraped from TechCrunch, one of the leading technology news websites. The dataset includes comprehensive article content, metadata, and quality assessments suitable for various NLP tasks including text classification, sentiment analysis, summarization, and content generation.\n\n\t\n\t\t\n\t\tüéØ Key Features\n\t\n\n\n10,265 articles with full text content\nHigh-quality filtering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/techcrunch-articles.","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"hepha_bucket_to_bin","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tmeynier/hepha_bucket_to_bin","creator_name":"Tristan","creator_url":"https://huggingface.co/tmeynier","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSimulated robot control episodes for learning from pixels and interaction.\n\nHomepage: https://github.com/huggingface/lerobot\nPaper: [More Information Needed]\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nEpisodes contain RGB camera data and robot state.\nData is stored in Parquet files.\nVideo files are MP4 compressed per camera.\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nBibTeX:\n@misc{lerobot2024,\n  author = {HuggingFace Robotics Team},\n  title =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tmeynier/hepha_bucket_to_bin.","first_N":5,"first_N_keywords":["no-annotation","monolingual","original","English","mit"],"keywords_longer_than_N":true}
]
;
