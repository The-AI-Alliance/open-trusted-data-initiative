const data_for_modality_summarization = 
[
	{"name":"nrc-nquire","keyword":"summarization","description":"tamphuc0503/nrc-nquire dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tamphuc0503/nrc-nquire","creator_name":"Phuc Nguyen","creator_url":"https://huggingface.co/tamphuc0503","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"code-cinema-image-animee","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du cin√©ma et de l'image anim√©e, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_40590","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_40590.","url":"https://huggingface.co/datasets/momo1942/x_dataset_40590","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"TikTok_Hottest_Video_Transcript_Example","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"X_Twitter_Trending_Topics_August2025","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüê¶ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics.This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and instantly structure tweet data into clean JSON.\nStart Scraping\n\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Key Features\n\t\n\n\n‚ö° Real-Time Fetch ‚Äì Stream the latest tweets the moment they‚Äôre posted  \nüéØ Flexible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025.","url":"https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_40590","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_40590.","url":"https://huggingface.co/datasets/momo1942/x_dataset_40590","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"bhasha-sft","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBhasha SFT\n\t\n\n\nBhasha SFT is a massive collection of multiple open sourced Supervised Fine-Tuning datasets for training Multilingual \nLarge Language Models. The dataset contains collation of over 13 million instances of\ninstruction-response data for 3 Indian languages (Hindi, Gujarati, Bengali) and English having both human annotated and synthetic data.\n\nCurated by: Soket AI Labs\nLanguage(s) (NLP): [English, Hindi, Bengali, Gujarati]\nLicense: [cc-by-4.0, apache-2.0, mit]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-sft.","url":"https://huggingface.co/datasets/soketlabs/bhasha-sft","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","Hindi"],"keywords_longer_than_N":true},
	{"name":"Manuel_dataset","keyword":"summarization","description":"EasyTerms/Manuel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EasyTerms/Manuel_dataset","creator_name":"Easy Terms","creator_url":"https://huggingface.co/EasyTerms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"HTV-News","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHalkTV-News Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHalkTV-News is a Turkish news dataset containing 173,179 articles collected from Halk TV's news portal. Each article includes a title, summary, full content, and a source URL. The dataset is designed for tasks such as text classification, summarization, and topic modeling in Turkish. It provides a rich resource for understanding and modeling Turkish news content.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nText Summarization: With‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nihalzk/HTV-News.","url":"https://huggingface.co/datasets/nihalzk/HTV-News","creator_name":"Nihal Zuhal Kayalƒ±","creator_url":"https://huggingface.co/nihalzk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","text-classification","text-generation","Turkish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"gov_report_qs","keyword":"summarization","description":"GovReport-QS hierarchical question-summary generation dataset.\n\nThere are two configs:\n  - paragraph: paragraph-level annotated data\n  - document: aggregated paragraph-level annotated data for the same document","url":"https://huggingface.co/datasets/launch/gov_report_qs","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","launch/gov_report"],"keywords_longer_than_N":true},
	{"name":"spanish_imdb_synopsis","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Spanish IMDb Synopsis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n4969 movie synopsis from IMDb in spanish.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll descriptions are in spanish, the other fields have some mix of spanish and english.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[N/A]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ndescription: IMDb description for the movie (string), should be spanish\nkeywords: IMDb keywords for the movie (string), mix of spanish and english\ngenre: The genres of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis.","url":"https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis","creator_name":"Mathias Gatti","creator_url":"https://huggingface.co/mathigatti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","monolingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"machine_translated_cnn_dailymail_da_small","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for machine_translated_cnn_dailymail_da_small\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a machine translated subset of the CNN Dailymail Dataset into Danish. The dataset is translated using the Helsinki-NLP/opus-mt-en-da-model. The dataset consists of 2872 articles with summaries with intended usage for Danish text summarisation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nMachine translated articles (article) with corresponding summaries (highlights).\n{\n  'article':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small.","url":"https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small","creator_name":"Anders Jess Pedersen","creator_url":"https://huggingface.co/ajders","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","machine-generated","machine-generated","translation"],"keywords_longer_than_N":true},
	{"name":"1k_stories_100_genre","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Documentation\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 1000 stories spanning 100 different genres. Each story is represented in a tabular format using a dataframe. The dataset includes unique IDs, titles, and the content of each story.\n\n\t\n\t\t\n\t\tGenre List\n\t\n\nThe list of all genres can be found in the genres.txt file.\nreading genre_list variable\nwith open('story_genres.pkl', 'rb') as f:\n    story_genres = pickle.load(f)\n\nSample of genre list:\ngenres = ['Sci-Fi', 'Comedy'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FareedKhan/1k_stories_100_genre.","url":"https://huggingface.co/datasets/FareedKhan/1k_stories_100_genre","creator_name":"Fareed Hassan Khan","creator_url":"https://huggingface.co/FareedKhan","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text-classification","English","cc-by-2.0"],"keywords_longer_than_N":true},
	{"name":"machine_translated_cnn_dailymail_da_small","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for machine_translated_cnn_dailymail_da_small\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a machine translated subset of the CNN Dailymail Dataset into Danish. The dataset is translated using the Helsinki-NLP/opus-mt-en-da-model. The dataset consists of 2872 articles with summaries with intended usage for Danish text summarisation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nMachine translated articles (article) with corresponding summaries (highlights).\n{\n  'article':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small.","url":"https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small","creator_name":"Anders Jess Pedersen","creator_url":"https://huggingface.co/ajders","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","machine-generated","machine-generated","translation"],"keywords_longer_than_N":true},
	{"name":"big_patent_100k_characters","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSampled Big Patent Dataset\n\t\n\nThis is a sampled Trelis/big_patent_sample dataset containing rows of data with descriptions shorter than or equal to 100,000 characters in length.\n--- Sampled from Trelis/big_patent_sampled ---\n\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_100k_characters.","url":"https://huggingface.co/datasets/Trelis/big_patent_100k_characters","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"hindi-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHindi Text Short and Large Summarization Corpus is a collection of ~180k articles with their headlines and summary collected from Hindi News Websites.\nThis is a first of its kind Dataset in Hindi which can be used to benchmark models for Text summarization in Hindi. This does not contain articles contained in Hindi Text Short Summarization Corpus which is being released parallely with this Dataset.\nThe dataset retains original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Someman/hindi-summarization.","url":"https://huggingface.co/datasets/Someman/hindi-summarization","creator_name":"Thinking","creator_url":"https://huggingface.co/Someman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Hindi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"2018-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2018 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2018 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2018-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_oracle","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_oracle.","url":"https://huggingface.co/datasets/allenai/ms2_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"UnitedStatesSentateAndHouseBillsAndSummaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset contains bills and provided summaries of United States Senate and House bills from the 113th - 118th Congress. This dataset is specifically formatted to be used\nin the fine tuning of Google's T5 Model.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset contains bills and provided summaries of United States Senate and House bills from the 113th - 118th Congress. This dataset is specifically formatted to be used\nin the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cheaptrix/UnitedStatesSentateAndHouseBillsAndSummaries.","url":"https://huggingface.co/datasets/cheaptrix/UnitedStatesSentateAndHouseBillsAndSummaries","creator_name":"Taylor Hartman","creator_url":"https://huggingface.co/cheaptrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"2018-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2018 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2018 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2018-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_max","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_max.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"one-million-commits","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOne million commits\n\t\n\nA large variety of git commits pulled from across GitHub.\nCreated by William Entriken, released 2023-09-26, version 1.\nThis composition is licensed under the MIT license.\n\n\t\n\t\t\n\t\tIntended use\n\t\n\nThis dataset could be used to train a model concerned with programming tasks:\n\nSummarize some programming work\nPerform work given a description of the work to do\nLearn-by-example the syntax for all active programming languages and structured data formats\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fulldecent/one-million-commits.","url":"https://huggingface.co/datasets/fulldecent/one-million-commits","creator_name":"William Entriken","creator_url":"https://huggingface.co/fulldecent","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","summarization","sentence-similarity","mit"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_evaluation_suite","keyword":"summarization","description":"\n\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜÊèèËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya (Traditional Chinese Aya Chinese;TCA)ÔºöÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáËôïÁêÜÁöÑ Aya ÈõÜÂêàÁöÑÁ≤æÈÅ∏Â≠êÈõÜ\n\n\t\n\t\t\n\t\tÊ¶ÇËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÊòØ‰∏ÄÂÄãÁ≤æÂøÉÁ≠ñÂäÉÁöÑË≥áÊñôÈõÜÔºåÊ∫êËá™ CohereForAI ÁöÑÁ∂úÂêà Aya ÈõÜÂêàÔºåÁâπÂà•ÈóúÊ≥®ÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊñô„ÄÇ\nÊ≠§Ë≥áÊñôÈõÜÁµêÂêà‰∫Ü‰æÜËá™ CohereForAI/aya_evaluation_suiteÔºåÈÅéÊøæÊéâÈô§ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÂÖßÂÆπ‰πãÂ§ñÁöÑÊâÄÊúâÂÖßÂÆπ„ÄÇ\n\n\t\n\t\t\n\t\tÁõÆÊ®ô\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÁöÑÁõÆÊ®ôÊòØÁÇ∫Á†îÁ©∂‰∫∫Âì°„ÄÅÊäÄË°ìÂ∞àÂÆ∂ÂíåË™ûË®ÄÂ≠∏ÂÆ∂Êèê‰æõÂç≥Áî®ÂûãÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊ∫êÔºåÈ°ØËëóÊ∏õÂ∞ëÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáÁöÑ NLP Âíå AI Â∞àÊ°à‰∏≠Êï∏ÊìöÈ†êËôïÁêÜÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇ\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜ‰æÜÊ∫êËàáË≥áË®ä\n\t\n\n\nË≥áÊñô‰æÜÊ∫ê: Âæû CohereForAI/aya_evaluation_suite 3 ÂÄãÂ≠êÈõÜËÄå‰æÜ„ÄÇ\nË™ûË®Ä: ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÔºà'zho')\nÊáâÁî®: ÈùûÂ∏∏ÈÅ©ÂêàË™ûË®ÄÂª∫Ê®°„ÄÅÊñáÊú¨ÂàÜÈ°û„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÂíåÊ©üÂô®ÁøªË≠ØÁ≠â‰ªªÂãô„ÄÇ\nË´ñÊñáÈÄ£Áµê: 2402.06619\nÁ∂≠Ë≠∑‰∫∫: Heng666\nLicense:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite.","url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite","creator_name":"Heng-Shiou Sheu | Ë®±ÊÅÜ‰øÆ","creator_url":"https://huggingface.co/Heng666","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"AIXDR","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [Edward Nyameri ]\nFunded by [optional]: [Nil funding but any interested POC is welcome]\nShared by [optional]: [Edward Nyameri ]\nLanguage(s) (NLP): [LLM]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nyameri/AIXDR.","url":"https://huggingface.co/datasets/Nyameri/AIXDR","creator_name":"Edward Nyameri","creator_url":"https://huggingface.co/Nyameri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"bbc_news_ptbr_summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"bbc_news_ptbr_summary\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/celsowm/bbc_news_ptbr_summary","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Seaskull","keyword":"summarization","description":"\n\n\n\t\n\t\t\n\t\tSeaskull Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Seaskull dataset follows the same format and purpose as the Helix dataset but contains distinct data. It has undergone a cleaning process to ensure data quality and usability.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource Dataset: Private Haribon dataset\nData Cleaning: The Seaskull dataset has been cleaned to eliminate Null and NaN values, ensuring data reliability.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nPlease adhere to the licensing terms provided by the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaleidoSG/Seaskull.","url":"https://huggingface.co/datasets/KaleidoSG/Seaskull","creator_name":"Kaleido Singapore","creator_url":"https://huggingface.co/KaleidoSG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"book-embeddings","keyword":"summarization","description":"\n\t\n\t\t\n\t\tVector store of embeddings for books\n\t\n\n\n\"1984\" by George Orwell\n\"The Almanac of Naval Ravikant\" by Eric Jorgenson\n\nThis is a faiss vector store created with instructor embeddings using LangChain . Use it for similarity search, question answering or anything else that leverages embeddings! üòÉ\nCreating these embeddings can take a while so here's a convenient, downloadable one ü§ó\n\n\t\n\t\t\n\t\n\t\n\t\tHow to use\n\t\n\n\nSpecify the book from one of the following:\n\"1984\"\n\"The Almanac of Naval Ravikant\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/calmgoose/book-embeddings.","url":"https://huggingface.co/datasets/calmgoose/book-embeddings","creator_name":"Calm Goose","creator_url":"https://huggingface.co/calmgoose","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","summarization","sentence-similarity","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-search-net-ruby","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-ruby\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Ruby\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"code-search-net-ruby","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-ruby\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Ruby\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"medical_knowledge_from_extracts","keyword":"summarization","description":"This dataset is used to train LLMs for medical knowledge extraction tasks\n","url":"https://huggingface.co/datasets/owkin/medical_knowledge_from_extracts","creator_name":"Owkin","creator_url":"https://huggingface.co/owkin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"code-relations-public-administration","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-penal","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode p√©nal, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Superheroes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Superheroes\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n1400+ Superheroes history and powers description to apply text mining and NLP Original source\n\n\t\n\t\t\n\t\tContext\n\t\n\nThe aim of this dataset is to make text analytics and NLP even funnier. All of us have dreamed to be like a superhero and save the world, yet we are still on Kaggle figuring out how python works. Then, why not improve our NLP competences by analyzing Superheros' history and powers?\nThe particularity of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jrtec/Superheroes.","url":"https://huggingface.co/datasets/jrtec/Superheroes","creator_name":"JRTEC S.A.S","creator_url":"https://huggingface.co/jrtec","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc0-1.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"wavepulse-radio-raw-transcripts","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tWavePulse Radio Raw Transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWavePulse Radio Raw Transcripts is a large-scale dataset containing segment-level transcripts from 396 radio stations across the United States, collected between June 26, 2024, and Dec 29th, 2024. The dataset comprises >250 million text segments derived from 750,000+ hours of radio broadcasts, primarily covering news, talk shows, and political discussions.\nThe summarized version of these transcripts is available here. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-raw-transcripts.","url":"https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-raw-transcripts","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","news-articles-summarization","topic-classification","sentiment-analysis"],"keywords_longer_than_N":true},
	{"name":"pubmedlay-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization\n\t\n\nA collaboration between reciTAL, MLIA (ISIR, Sorbonne Universit√©), Meta AI, and Universit√† di Trento\n\n\t\n\t\t\n\t\n\t\n\t\tPubMed-Lay dataset for summarization\n\t\n\nPubMed-Lay is an enhanced version of the PubMed summarization dataset, for which layout information is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\narticle_id: article id\narticle_words: sequence of words constituting the body of the article‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nglaura/pubmedlay-summarization.","url":"https://huggingface.co/datasets/nglaura/pubmedlay-summarization","creator_name":"Laura Nguyen","creator_url":"https://huggingface.co/nglaura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","Text","arxiv:2301.11312"],"keywords_longer_than_N":true},
	{"name":"itacasehold","keyword":"summarization","description":"\n\t\n\t\t\n\t\tITA-CASEHOLD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThis dataset contains the data used in the research of the ITA-CASEHOLD model, an extractive summarization model to extract holdings from Italian Legal Administrative documents.\nThe research paper titled 'Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization' is accepted for ICAIL 23.\nIt consists of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/itacasehold/itacasehold.","url":"https://huggingface.co/datasets/itacasehold/itacasehold","creator_name":"itacasehold","creator_url":"https://huggingface.co/itacasehold","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"irish-legislative-summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIrish Legislative Summaries ‚öñÔ∏è\n\t\n\nIrish Legislative Summaries by Isaacus is a novel, challenging legal information retrieval evaluation dataset consisting of 500 Irish laws and their long titles, succinctly summarizing subject matter, scope, and purpose of legislation.\nThis dataset is meant to stress test the ability of an information retrieval model to retrieve relevant statutes to short queries describing them.\nTo make evaluation with this dataset as easy as possible, it is formatted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/irish-legislative-summaries.","url":"https://huggingface.co/datasets/isaacus/irish-legislative-summaries","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"Arabic_Aya","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for : Arabic Aya (2A)\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tArabic Aya (2A) : A Curated Subset of the Aya Collection for Arabic Language Processing\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from 69 subsets of the original Aya datasets : CohereForAI/aya_collection, CohereForAI/aya_dataset, and CohereForAI/aya_evaluation_suite.\nLanguages: Modern Standard Arabic (MSA) and a variety of Arabic dialects ( 'arb', 'arz', 'ary', 'ars', 'knc', 'acm', 'apc', 'aeb', 'ajp', 'acq' )‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Arabic_Aya.","url":"https://huggingface.co/datasets/2A2I/Arabic_Aya","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gibby_dataset","keyword":"summarization","description":"jonathansuru/gibby_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jonathansuru/gibby_dataset","creator_name":"Jonathan Suru","creator_url":"https://huggingface.co/jonathansuru","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"code-propriete-intellectuelle","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la propri√©t√© intellectuelle, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cgi","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode G√©n√©ral des Imp√¥ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/cgi.","url":"https://huggingface.co/datasets/louisbrulenaudet/cgi","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-procedure-civile","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de proc√©dure civile, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"lpf","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLivre des proc√©dures fiscales, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lpf.","url":"https://huggingface.co/datasets/louisbrulenaudet/lpf","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"RenMinDaily","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nIt is the collection of RenMinDaily's report from 2021/01/01 to 2023/12/05. With title as instruction.\n","url":"https://huggingface.co/datasets/Concyclics/RenMinDaily","creator_name":"CHEN Han","creator_url":"https://huggingface.co/Concyclics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ro-paraphrase-bible","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tDataset Card for \"Romanian Bible Paraphrase Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \nversions is straighforward. \nWe compiled a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible.","url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-scoring","semantic-similarity-scoring","semantic-similarity-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_mean","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_mean.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"fomc-statements","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFOMC Meeting Policy Statements Dataset (Year 2000+, updated monthly)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the policy statements released by the Federal Open Market Committee (FOMC) following each of its meetings from year 2000 onwords. The FOMC, a component of the U.S. Federal Reserve System, determines monetary policy in the United States. The statements provide insights into the committee‚Äôs policy decisions, economic outlook, and forward guidance.\n\n\t\n\t\t\n\t\tBackground on Policy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fishie-lee/fomc-statements.","url":"https://huggingface.co/datasets/fishie-lee/fomc-statements","creator_name":"Gang Hyeok Lee","creator_url":"https://huggingface.co/fishie-lee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","sentence-similarity","summarization","English"],"keywords_longer_than_N":true},
	{"name":"OpenCaselist","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for OpenCaselist\n\t\n\n\n\nA collection of Evidence used in Collegiate and High School debate competitions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset is a follow up to DebateSum, increasing its scope and amount of metadata collected.\nIt expands the dataset to include evidence used during debate tournaments, rather than just evidence produced during preseason debate \"camps.\" The total amount of evidence is approximately 20x larger than DebateSum.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yusuf5/OpenCaselist.","url":"https://huggingface.co/datasets/Yusuf5/OpenCaselist","creator_name":"Yusuf 5","creator_url":"https://huggingface.co/Yusuf5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"code-postes-communications-electroniques","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des postes et des communications √©lectroniques, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-KO","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenOrca-KO\n\t\n\n\nOpenOrca dataset Ï§ë ÏïΩ 2ÎßåÍ∞úÎ•º samplingÌïòÏó¨ Î≤àÏó≠Ìïú Îç∞Ïù¥ÌÑ∞ÏÖã\nÎç∞Ïù¥ÌÑ∞ÏÖã Ïù¥Ïö©ÌïòÏÖîÏÑú Î™®Îç∏Ïù¥ÎÇò Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÎßåÎìúÏã§ Îïå, Í∞ÑÎã®Ìïú Ï∂úÏ≤ò ÌëúÍ∏∞Î•º Ìï¥Ï£ºÏã†Îã§Î©¥ Ïó∞Íµ¨Ïóê ÌÅ∞ ÎèÑÏõÄÏù¥ Îê©ÎãàÎã§üò≠üò≠\n\n\n\t\n\t\t\n\t\tDataset inf0\n\t\n\n\nNIV // 1571Í∞ú  \nFLAN // 9434Í∞ú  \nT0 // 6351Í∞ú  \nCoT // 2117Í∞ú  \nKoCoT // 2159Í∞ú\n\n\n\t\n\t\t\n\t\tTranslation\n\t\n\nUsing DeepL Pro API. Thanks.\n\n\nBelow is original dataset card\n\nüêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/OpenOrca-KO.","url":"https://huggingface.co/datasets/kyujinpy/OpenOrca-KO","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail.","url":"https://huggingface.co/datasets/abisee/cnn_dailymail","creator_name":"Abigail See","creator_url":"https://huggingface.co/abisee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail.","url":"https://huggingface.co/datasets/abisee/cnn_dailymail","creator_name":"Abigail See","creator_url":"https://huggingface.co/abisee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"leetcode-problem-detailed","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLeetCode Scraper Dataset\n\t\n\nThis dataset contains information scraped from LeetCode, including problem details, metadata, and related files. It is designed to assist developers in analyzing LeetCode problems, generating insights, and building tools for competitive programming or educational purposes.\nquestions_deets.csv  \n\nContains detailed information about each problem, including problem descriptions, constraints, and examples.\nColumns:\nquestionFrontendId: Unique problem ID.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kaysss/leetcode-problem-detailed.","url":"https://huggingface.co/datasets/kaysss/leetcode-problem-detailed","creator_name":"Singla","creator_url":"https://huggingface.co/kaysss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"japan-law","keyword":"summarization","description":"\n\t\n\t\t\n\t\tJapanese Laws\n\t\n\nThis dataset comprises 8.75K law records retrieved from the official Japanese government website e-Gov. Each entry furnishes comprehensive details about a particular law, encapsulating its number, title, unique ID, the date it came into effect, and its complete text.\nTo ensure the dataset's uniqueness, deduplication was executed based on the most recent effective version as of August 1, 2023.\nA typical entry in this dataset is structured as follows:\n{\n    \"num\": \"Law‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/y2lan/japan-law.","url":"https://huggingface.co/datasets/y2lan/japan-law","creator_name":"lan","creator_url":"https://huggingface.co/y2lan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"SLF5K","keyword":"summarization","description":"The Summarization with Language Feedback (SLF5K) dataset is an English-language dataset containing 5K unique samples that can be used for the task of abstraction summarization. Each sample consists of a Reddit title and post, a model-generated (FeedME) summary, and human-written language feedback on that summary. Additionally, each sample has a high-quality, human-written (gold) summary that should be ideal for the Reddit post. Lastly, each sample has two additional model-generated summaries with binary human preference labels, on which summary is preferred by a human. The dataset can be used to train language models with language feedback on abstractive summarization. It can also be used to train a reward model on binary preferences.","url":"https://huggingface.co/datasets/JeremyAlain/SLF5K","creator_name":"J√©r√©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"autoregressive-paraphrase-dataset","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"videoxum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for VideoXum\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe VideoXum dataset represents a novel task in the field of video summarization, extending the scope from single-modal to cross-modal video summarization. This new task focuses on creating video summaries that containing both visual and textual elements with semantic coherence. Built upon the foundation of ActivityNet Captions, VideoXum is a large-scale dataset, including over 14,000 long-duration and open-domain videos. Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jylins/videoxum.","url":"https://huggingface.co/datasets/jylins/videoxum","creator_name":"Jingyang Lin","creator_url":"https://huggingface.co/jylins","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Text_Structuring_SOLAR_10.7B_Distilled","keyword":"summarization","description":"This dataset was generated using TheBloke/SOLAR-10.7B-Instruct-v1.0-AWQ\nThe goal is to generate a better structured text from a given source, on a RAG context.\nFor each input, this prompt was executed through the model:\nContext:\n\n$INPUT\n\nFrom the context, list all the essential facts about the text (if any):\nAll themes;\nAll conclusions;\nAll ideas;\nAll locations;\nAll dates;\nAll values;\nAnd any other relevant information.\n\nYour answer must contain each category and its facts.\n\nThis is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cnmoro/Text_Structuring_SOLAR_10.7B_Distilled.","url":"https://huggingface.co/datasets/cnmoro/Text_Structuring_SOLAR_10.7B_Distilled","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"stacked-xsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\txsum-stacked\n\t\n\nThe current version (corresponding to the stacked-booksum release): v0.3. See the Stacked Summaries org page for what this is and why it exists.\nThe maximum input length is 16384 tokens, and the maximum output length is 1024 tokens (measured with the Long-T5 tokenizer). \n\n\t\n\t\t\n\t\tstats\n\t\n\n[2023-01-09 19:36:25] INFO:root:INPUTS - basic stats - train\n[2023-01-09 19:36:26] INFO:root:{'num_columns': 5,\n 'num_rows': 204045,\n 'num_unique_target': 203107,\n 'num_unique_text':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stacked-summaries/stacked-xsum.","url":"https://huggingface.co/datasets/stacked-summaries/stacked-xsum","creator_name":"Stacked Summaries","creator_url":"https://huggingface.co/stacked-summaries","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","xsum","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"casum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CaSum\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (Ag√®ncia Catalana de Not√≠cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rouge score. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum.","url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","machine-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"dialogsum_reformat","keyword":"summarization","description":"DialogSUM Corpus contains 13460 chat dialogues with manually annotated\nsummaries.\nThere are two features:\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - topic: one liner summary of the dialogue.\n  - id: id of a example.","url":"https://huggingface.co/datasets/knkarthick/dialogsum_reformat","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"stacked-samsum-1024","keyword":"summarization","description":"\n\t\n\t\t\n\t\tstacked samsum 1024\n\t\n\nCreated with the stacked-booksum repo version v0.25. It contains:\n\nOriginal Dataset: copy of the base dataset\n\nStacked Rows: The original dataset is processed by stacking rows based on certain criteria:\n\nMaximum Input Length: The maximum length for input sequences is 1024 tokens in the longt5 model tokenizer.\nMaximum Output Length: The maximum length for output sequences is also 1024 tokens in the longt5 model tokenizer.\n\n\nSpecial Token: The dataset utilizes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stacked-summaries/stacked-samsum-1024.","url":"https://huggingface.co/datasets/stacked-summaries/stacked-samsum-1024","creator_name":"Stacked Summaries","creator_url":"https://huggingface.co/stacked-summaries","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","samsum","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ILC","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/d0r1h/ILC","creator_name":"Pawan Trivedi","creator_url":"https://huggingface.co/d0r1h","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","original","English","cc-by-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"databricks-mini","keyword":"summarization","description":"sonny-dev/databricks-mini dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sonny-dev/databricks-mini","creator_name":"Sonny Mupfuni","creator_url":"https://huggingface.co/sonny-dev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"thesis-chile","keyword":"summarization","description":"\n\t\n\t\t\n\t\tThesis Chile Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThesis Chile is the dataset partially used to create the DiscoEval in Spanish benchmark. \nThis dataset was created by scraping titles and abstracts of Chilean thesis from public repositories of the Pontificia Universidad Catolica de Chile (repositorio.uc.cl), Universidad de Chile (repositorio.uchile.cl) and Universidad T√©cnica Federico Santa Mar√≠a (biblioteca.usm.cl).\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nWe see the potential utility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/thesis-chile.","url":"https://huggingface.co/datasets/vgaraujov/thesis-chile","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text-classification","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"koreascience-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization\n\t\n\nA collaboration between reciTAL, MLIA (ISIR, Sorbonne Universit√©), Meta AI, and Universit√† di Trento\n\n\t\n\t\t\n\t\n\t\n\t\tKoreaScience dataset for summarization\n\t\n\nKoreaScience is a dataset for summarization of research papers written in Korean, for which layout information is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\narticle_id: article id\narticle_words: sequence of words constituting the body of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nglaura/koreascience-summarization.","url":"https://huggingface.co/datasets/nglaura/koreascience-summarization","creator_name":"Laura Nguyen","creator_url":"https://huggingface.co/nglaura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","French","apache-2.0","arxiv:2301.11312","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"medicinal-plants","keyword":"summarization","description":"A growing dataset about medicinal plants. We plan to construct a multimodal dataset with images and text content extracted from \n\nbooks that went out of copywrite and \ndiverse and high-quality video data taken via smart phone and various lenses with a DSLR camera (24mm Macro, 50mm, 100mm Macro and a 24-120mm Zoom lens).\nParts of the iNaturalist and PlantNet300K datasets will be integrated as well to cover a wide spectrum of the kingdom Plantae.\n\nThe resulting dataset should be able to power a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mikehemberger/medicinal-plants.","url":"https://huggingface.co/datasets/mikehemberger/medicinal-plants","creator_name":"Mike Hemberger","creator_url":"https://huggingface.co/mikehemberger","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"topicsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for TopicSum Corpus [Single Dataset Comprising of XSUM & DialogSUM for One Liner Summarization/ Topic Generation of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nDialogSUM: https://github.com/cylnlp/dialogsum\nXSUM: https://huggingface.co/datasets/knkarthick/xsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTopicSUM is collection of large-scale dialogue summarization dataset from XSUM & DialogSUM, consisting of 241,171‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/topicsum.","url":"https://huggingface.co/datasets/knkarthick/topicsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MultiSim","keyword":"summarization","description":"MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.","url":"https://huggingface.co/datasets/MichaelR207/MultiSim","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"jurisprudencia_stj_pt","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset de Jurisprud√™ncia do STJ de Portugal (2025)\n\t\n\n\n\t\n\t\t\n\t\tDescri√ß√£o do Dataset\n\t\n\nEste dataset cont√©m uma amostra de ac√≥rd√£os proferidos pelo Supremo Tribunal de Justi√ßa (STJ) de Portugal durante o ano de 2025. Cada registo no dataset corresponde a um ac√≥rd√£o completo, incluindo o seu texto integral, o sum√°rio e um conjunto de metadados ricos.\nOs dados representam uma amostra aleat√≥ria de 5% do total de ac√≥rd√£os de 2025 dispon√≠veis na base de dados de origem, filtrados para‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ffantini/jurisprudencia_stj_pt.","url":"https://huggingface.co/datasets/ffantini/jurisprudencia_stj_pt","creator_name":"Fernando Neto","creator_url":"https://huggingface.co/ffantini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"reddit_tifu","keyword":"summarization","description":"Reddit dataset, where TIFU denotes the name of subbreddit /r/tifu.\nAs defined in the publication, styel \"short\" uses title as summary and\n\"long\" uses tldr as summary.\n\nFeatures includes:\n  - document: post text without tldr.\n  - tldr: tldr line.\n  - title: trimmed title without tldr.\n  - ups: upvotes.\n  - score: score.\n  - num_comments: number of comments.\n  - upvote_ratio: upvote ratio.","url":"https://huggingface.co/datasets/ctr4si/reddit_tifu","creator_name":"Center for SuperIntelligence","creator_url":"https://huggingface.co/ctr4si","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ilpost","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for ilpost\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIlPost dataset, containing news articles taken from IlPost.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n IlPost text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/ilpost.","url":"https://huggingface.co/datasets/ARTeLab/ilpost","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","Italian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"xsum_factuality","keyword":"summarization","description":"Neural abstractive summarization models are highly prone to hallucinate content that is unfaithful to the input\ndocument. The popular metric such as ROUGE fails to show the severity of the problem. The dataset consists of\nfaithfulness and factuality annotations of abstractive summaries for the XSum dataset. We have crowdsourced 3 judgements\n for each of 500 x 5 document-system pairs. This will be a valuable resource to the abstractive summarization community.","url":"https://huggingface.co/datasets/google-research-datasets/xsum_factuality","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","monolingual","extended|other-xsum"],"keywords_longer_than_N":true},
	{"name":"keywords","keyword":"summarization","description":"ecosystems/keywords dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ecosystems/keywords","creator_name":"Ecosyste.ms","creator_url":"https://huggingface.co/ecosystems","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"curation-corpus-ru","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcuration-corpus-ru\n\t\n\nTranslated version of d0rj/curation-corpus into Russian.\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translated","monolingual","d0rj/curation-corpus","Russian"],"keywords_longer_than_N":true},
	{"name":"curation-corpus-ru","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcuration-corpus-ru\n\t\n\nTranslated version of d0rj/curation-corpus into Russian.\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translated","monolingual","d0rj/curation-corpus","Russian"],"keywords_longer_than_N":true},
	{"name":"uk-legislative-long-titles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUK Legislative Long Titles ‚öñÔ∏è\n\t\n\nUK Legislative Long Titles by Isaacus is a novel, challenging legal information retrieval evaluation dataset consisting of 78 UK laws and their long titles, succinctly summarizing subject matter, scope, and purpose of legislation.\nThis dataset is meant to stress test the ability of an information retrieval model to retrieve relevant statutes to short queries describing them.\nTo make evaluation with this dataset as easy as possible, it is formatted in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/uk-legislative-long-titles.","url":"https://huggingface.co/datasets/isaacus/uk-legislative-long-titles","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"logdetective-logjuicer-extract","keyword":"summarization","description":"fedora-copr/logdetective-logjuicer-extract dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fedora-copr/logdetective-logjuicer-extract","creator_name":"Fedora COPR team","creator_url":"https://huggingface.co/fedora-copr","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","English","cdla-permissive-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AcademicEval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAcademicEval Benchmark Introduction\n\t\n\n\n  \n\n\nWe proposed AcademicEval, a live benchmark for evaluating LLMs over long-context generation tasks. AcademicEval adopts papers on arXiv to introduce several acadeic writing tasks with long-context inputs, i.e., Title, Abstract, Introduction, Related Work, wich covers a wide range of abstraction levels and require no manual labeling. \nComparing to existing long-context LLM benchmarks, our Comparing to existing long-context LLM benchmarks, our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ulab-ai/AcademicEval.","url":"https://huggingface.co/datasets/ulab-ai/AcademicEval","creator_name":"ulab","creator_url":"https://huggingface.co/ulab-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"code-ports-maritimes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des ports maritimes, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedure-penale","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de proc√©dure p√©nale, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-recherche","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la recherche, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"VoxDIY-RusNews","keyword":"summarization","description":"VoxDIY:  Benchmark Dataset for Russian Crowdsourced Audio Transcription.","url":"https://huggingface.co/datasets/toloka/VoxDIY-RusNews","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"CFA_Level_1_Text_Embeddings","keyword":"summarization","description":"Vector store of embeddings for CFA Level 1 Curriculum\nThis is a faiss vector store created with Sentence Transformer embeddings using LangChain . Use it for similarity search, question answering or anything else that leverages embeddings! üòÉ\nCreating these embeddings can take a while so here's a convenient, downloadable one ü§ó\nHow to use\nDownload data\nLoad to use with LangChain\npip install -qqq langchain sentence_transformers faiss-cpu huggingface_hub\nimport os\nfrom langchain.embeddings import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickmuchi/CFA_Level_1_Text_Embeddings.","url":"https://huggingface.co/datasets/nickmuchi/CFA_Level_1_Text_Embeddings","creator_name":"Nicholas Muchinguri","creator_url":"https://huggingface.co/nickmuchi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","summarization","sentence-similarity","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LongForm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLongForm\n\t\n\nThe LongForm dataset is created by leveraging English corpus\n    examples with reverse instructions. We select a\n    diverse set of human-written\n    documents from existing corpora such as C4 and\n    Wikipedia and generate instructions for the given\n    documents via LLMs. Then, we extend these examples with structured corpora examples such as Stack Exchange and WikiHow and task examples such as question answering, email writing, grammar error correction, story/poem‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/LongForm.","url":"https://huggingface.co/datasets/akoksal/LongForm","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","text-generation","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"CrowdSpeech","keyword":"summarization","description":"CrowdSpeech is a publicly available large-scale dataset of crowdsourced audio transcriptions. It contains annotations for more than 50 hours of English speech transcriptions from more than 1,000 crowd workers.","url":"https://huggingface.co/datasets/toloka/CrowdSpeech","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"pseudonymization-data","keyword":"summarization","description":"This repository contains all the datasets used in our paper \"Privacy- and Utility-Preserving NLP with Anonymized data: A case study of Pseudonymization\" (https://aclanthology.org/2023.trustnlp-1.20).\n\n\t\n\t\t\n\t\tDataset Card for Pseudonymization data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset repository contains all the datasets, used in our paper. It includes datasets for different NLP tasks, pseudonymized by different algorithms; a dataset for training Seq2Seq model which translates text from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/grammarly/pseudonymization-data.","url":"https://huggingface.co/datasets/grammarly/pseudonymization-data","creator_name":"Grammarly","creator_url":"https://huggingface.co/grammarly","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"nordjylland-news-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"nordjylland-news-summarization\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of pairs containing text and corresponding summaries extracted from the Danish newspaper TV2 Nord. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSummarization is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAn example from the dataset looks as follows.\n{\n  \"text\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization.","url":"https://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Danish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"annotated_news_summary","keyword":"summarization","description":"This dataset is created for instruction tuning purpose.It is based on the News Summarization dataset.\nThe instructions are given in the inputs column and their completions/answers are provided in the targets column. The template_id tracks each input_template-target_template pair. There are 15 template ids (from 1 to 15).\nThe ID and their respective templates are given below. no_template indicates that no template was used and only the summary or direct answer was provided for that input.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TahmidH/annotated_news_summary.","url":"https://huggingface.co/datasets/TahmidH/annotated_news_summary","creator_name":"Tahmid Hossain","creator_url":"https://huggingface.co/TahmidH","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Bengali","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"UltraLink","keyword":"summarization","description":"\n\n\nmulti-lingual, knowledge-grounded, multi-round dialogue dataset and model\n\n  Summary  ‚Ä¢\n Construction Process ‚Ä¢\n Paper ‚Ä¢\n  UltraLink-LM ‚Ä¢\n  Github\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for UltraLink\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nUltraLink is a multi-lingual, knowledge-grounded data augmented, multi-round dialogue dataset. It contains language-specific chat data, language-agnostic chat data, code data and math data in 5 languages: English, Chinese, Spanish, Russian, and French. Different from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R0k1e/UltraLink.","url":"https://huggingface.co/datasets/R0k1e/UltraLink","creator_name":"Haoyu Wang","creator_url":"https://huggingface.co/R0k1e","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","translation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"DPO_training_data","keyword":"summarization","description":"ashishkgpian/DPO_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ashishkgpian/DPO_training_data","creator_name":"Ashish Kumar","creator_url":"https://huggingface.co/ashishkgpian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ntu_adl_summarization","keyword":"summarization","description":"xjlulu/ntu_adl_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/xjlulu/ntu_adl_summarization","creator_name":"Xue-Jin Lu","creator_url":"https://huggingface.co/xjlulu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-tr","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"OpenOrca-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca-tr is a translated version of the  OpenOrca and is the first ever SFT dataset in the Turkish Language with more than 2M entries! \nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/OpenOrca-tr.","url":"https://huggingface.co/datasets/malhajar/OpenOrca-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"news-qa-summarization-73","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/bernabeSanchez/news-qa-summarization-73","creator_name":"Bernabe Sanchez","creator_url":"https://huggingface.co/bernabeSanchez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","text-retrieval","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"Worldsim","keyword":"summarization","description":"Bunch of worldsim text?\n","url":"https://huggingface.co/datasets/VatsaDev/Worldsim","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wikihow_summarize_dialogue_vi","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nView online through viewer.\n\n\t\n\t\t\n\t\n\t\n\t\tNote\n\t\n\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/wikihow_summarize_dialogue_vi.","url":"https://huggingface.co/datasets/lamhieu/wikihow_summarize_dialogue_vi","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","Vietnamese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bofip","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBulletin officiel des finances publiques - imp√¥ts, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/bofip.","url":"https://huggingface.co/datasets/louisbrulenaudet/bofip","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-justice-penale-mineurs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la justice p√©nale des mineurs, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CAPP","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFrench Court of Judicial jurisprudence decisions (CAPP) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CAPP Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/CAPP.\nThis comprehensive collection includes appellate court decisions, providing valuable insights into French jurisprudence and legal reasoning at the appeal level.\nIt serves as a rich resource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CAPP.","url":"https://huggingface.co/datasets/Tricoteuses/CAPP","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"NewsLensSync","keyword":"summarization","description":"sparklessszzz/NewsLensSync dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sparklessszzz/NewsLensSync","creator_name":"Anonymous","creator_url":"https://huggingface.co/sparklessszzz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_36.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_36","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PRISM","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPRISM: Impact of Decoding Strategies for Abstractive Document Summarization at Test Time\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPRISM is a comprehensive evaluation dataset for studying the impact of different decoding strategies on abstractive document summarization performance. The dataset contains results from 9 decoding strategies applied to 8 models across 6 datasets, providing a systematic comparison of generation approaches.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains evaluation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/disi-unibo-nlp/PRISM.","url":"https://huggingface.co/datasets/disi-unibo-nlp/PRISM","creator_name":"DISI UniBo NLP","creator_url":"https://huggingface.co/disi-unibo-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"T5_german_summaries_filtered_convos","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset T5 German\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tInformation on model\n\t\n\n\nT-Systems-onsite/mt5-small-sum-de-en-v2\nsource_prefix: \"summarize: \"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos.","url":"https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"NCERT_Biology_11th","keyword":"summarization","description":"KadamParth/NCERT_Biology_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Biology_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Akhil-Test-Data","keyword":"summarization","description":"Akhil-9640/Akhil-Test-Data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Akhil-9640/Akhil-Test-Data","creator_name":"Akhil Kumar","creator_url":"https://huggingface.co/Akhil-9640","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ams_data_full_2000-2020","keyword":"summarization","description":"Aerospace Mechanism Symposia PDF documents parsed by page. All symposia documents from the year 2000-2022 are included. No splitting was used.\nOriginal documents here: https://github.com/dan-s-mueller/aerospace_chatbot/tree/main/data/AMS\n","url":"https://huggingface.co/datasets/ai-aerospace/ams_data_full_2000-2020","creator_name":"AI Aerospace","creator_url":"https://huggingface.co/ai-aerospace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Motamot_Bengali_Political_Sentiment_Analysis","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMotamot: Bengali Political Sentiment Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìñ Overview\n\t\n\nMotamot is a Bengali political sentiment analysis dataset containing 7,058 labeled data points. Each entry is annotated with Positive or Negative sentiment, specifically tailored for analyzing political discourse in the Bengali language.\nThis dataset supports Natural Language Processing (NLP) research, with applications in sentiment classification, political opinion mining, and benchmarking pre-trained and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mukaffi28/Motamot_Bengali_Political_Sentiment_Analysis.","url":"https://huggingface.co/datasets/Mukaffi28/Motamot_Bengali_Political_Sentiment_Analysis","creator_name":"Mukaffi Bin Moin","creator_url":"https://huggingface.co/Mukaffi28","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Bengali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_36.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_36","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CL4Lang","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tCross-lingual plagiarism detection: Two are better than one\n\t\n\nThe widespread availability of scientific documents in multiple languages, coupled with the development of automatic translation and editing tools, has created a demand for efficient methods that can detect plagiarism across different languages.\nA dataset for cross-lingual plagiarism evaluation. Collection consists of a subset of Wikipedia articles on 4 languages (ru, hy, es, en). Quary consists of wikipedia documents in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AntiplagiatCompany/CL4Lang.","url":"https://huggingface.co/datasets/AntiplagiatCompany/CL4Lang","creator_name":"Antiplagiat","creator_url":"https://huggingface.co/AntiplagiatCompany","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Russian","Armenian","Spanish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-sport","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du sport, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_25.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_25","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_63","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_63.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_63","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_25.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_25","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_63","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_63.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_63","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"prompt-opin-summ","keyword":"summarization","description":"This repository consists dataset for training Opinion Summarization models. \nThe dataset has been generated using Mistral-7B (mistralai/Mistral-7B). \nThe dataset includes [atmost] 9 opinion summaries per product, for 20763 products in the train set and 5000 products in the validation set.\nThe dataset is formatted as a jsonl file (jsonlines-guide). Each line can be loaded as a json object, and has the following format:\n{¬†¬†¬†¬†'unique-id': a unique id,¬†¬†¬†¬†'reviews': list of reviews‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/prompt-opin-summ.","url":"https://huggingface.co/datasets/swaroop-nath/prompt-opin-summ","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"prompt-opin-summ","keyword":"summarization","description":"This repository consists dataset for training Opinion Summarization models. \nThe dataset has been generated using Mistral-7B (mistralai/Mistral-7B). \nThe dataset includes [atmost] 9 opinion summaries per product, for 20763 products in the train set and 5000 products in the validation set.\nThe dataset is formatted as a jsonl file (jsonlines-guide). Each line can be loaded as a json object, and has the following format:\n{¬†¬†¬†¬†'unique-id': a unique id,¬†¬†¬†¬†'reviews': list of reviews‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/prompt-opin-summ.","url":"https://huggingface.co/datasets/swaroop-nath/prompt-opin-summ","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_132","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_132.","url":"https://huggingface.co/datasets/gk4u/x_dataset_132","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_0110104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_0110104.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_0110104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_132","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_132.","url":"https://huggingface.co/datasets/gk4u/x_dataset_132","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_0110104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_0110104.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_0110104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ai-scoring1","keyword":"summarization","description":"dio-dev/ai-scoring1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/dio-dev/ai-scoring1","creator_name":"Oleksandr Kyslytskyi","creator_url":"https://huggingface.co/dio-dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"hub-tldr-model-summaries-llama","keyword":"summarization","description":"\n \n\n\n\n\t\n\t\t\n\t\tDataset card for model-summaries-llama\n\t\n\nThis dataset contains AI-generated summaries of model cards from the Hugging Face Hub, generated using meta-llama/Llama-3.3-70B-Instruct. It is designed to provide concise, single-sentence summaries that capture the key aspects and unique features of machine learning models.\nThis dataset was made with Curator.\n\n\t\n\t\t\n\t\n\t\n\t\tLoading the dataset\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"davanstrien/model-summaries-llama\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/hub-tldr-model-summaries-llama.","url":"https://huggingface.co/datasets/davanstrien/hub-tldr-model-summaries-llama","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"code-securite-interieure","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© int√©rieure, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128_test","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/reddit_dataset_128_test.","url":"https://huggingface.co/datasets/GSKCM24/reddit_dataset_128_test","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PEEP","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPEEP: Prompts, Extracted Entities with Privacy\n\t\n\nPaper: Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences  \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPEEP is a multilingual dataset of 15,282 real user queries from the Wildchat dataset, annotated with extracted personal information and associated with synthetic privacy profiles. It is designed to support research on privacy-preserving language models, enabling controlled evaluation of models‚Äô adherence to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guillemram97/PEEP.","url":"https://huggingface.co/datasets/guillemram97/PEEP","creator_name":"Guillem Ram√≠rez","creator_url":"https://huggingface.co/guillemram97","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","odc-by","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128_test","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/reddit_dataset_128_test.","url":"https://huggingface.co/datasets/GSKCM24/reddit_dataset_128_test","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_25","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_25.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_25","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"hacker-news-discussion-summarization-large","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Hacker News Discussion Summarization - Large\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises 14,531 records of Hacker News front-page stories collected over 516 days. Each record includes the story's metadata and its associated discussion threads, formatted to facilitate the development of summarization models.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe primary task supported by this dataset is summarization, specifically targeting the summarization of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/georgeck/hacker-news-discussion-summarization-large.","url":"https://huggingface.co/datasets/georgeck/hacker-news-discussion-summarization-large","creator_name":"George Chiramattel","creator_url":"https://huggingface.co/georgeck","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bike-datasets","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBIKE Datasets\n\t\n\nThis repo contains all the datasets used for BIKE visualization.\nTo download this dataset, first make sure you have git lfs installed. then, just run the following command:\ngit clone git@hf.co:datasets/medviz/bike-datasets\n\n","url":"https://huggingface.co/datasets/medviz/bike-datasets","creator_name":"Medical Knowledge Explorer","creator_url":"https://huggingface.co/medviz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","English","apache-2.0","üá∫üá∏ Region: US","medical"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_25","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_25.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_25","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_140","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taowtje/reddit_dataset_140.","url":"https://huggingface.co/datasets/taowtje/reddit_dataset_140","creator_name":"TAO tje","creator_url":"https://huggingface.co/taowtje","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_140","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taowtje/reddit_dataset_140.","url":"https://huggingface.co/datasets/taowtje/reddit_dataset_140","creator_name":"TAO tje","creator_url":"https://huggingface.co/taowtje","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_47","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/reddit_dataset_47.","url":"https://huggingface.co/datasets/tarzan19990815/reddit_dataset_47","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"dhhLyrics-ReversePrompt","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tLyrics Datasets for Creative and Linguistic Applications\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis repository contains two datasets of song lyrics, meticulously curated and organized for diverse applications in natural language processing, machine learning, and creative AI. These datasets include song verses, descriptive prompts, and romanized lyrics, providing rich resources for tasks such as text generation, sentiment analysis, transliteration, and more. All the songs are from Hip Hop‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt.","url":"https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt","creator_name":"Pranav Inani","creator_url":"https://huggingface.co/pranavinani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text2text-generation","text-generation","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"medreport_reasoning-summary","keyword":"summarization","description":"This repository is collection of synthetic data consisting of histopathology reports on 110 subtopics along with its chain-of-thoughts reasoning for summarization.\n\n\t\n\t\t\n\t\tDataset Division\n\t\n\nSingle-CoT: It provides distinct and unique collection of histopathology report, reasoning and summary. 45 reports per 110 subtopics.\nDiverse-CoT: It provides distinct and unique collection of different histopathology reasoning and summary for a few reports. 3 reports per 110 subtopics, with 16 different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/singhprabhat/medreport_reasoning-summary.","url":"https://huggingface.co/datasets/singhprabhat/medreport_reasoning-summary","creator_name":"Prabhat Singh","creator_url":"https://huggingface.co/singhprabhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"medreport_reasoning-summary","keyword":"summarization","description":"This repository is collection of synthetic data consisting of histopathology reports on 110 subtopics along with its chain-of-thoughts reasoning for summarization.\n\n\t\n\t\t\n\t\tDataset Division\n\t\n\nSingle-CoT: It provides distinct and unique collection of histopathology report, reasoning and summary. 45 reports per 110 subtopics.\nDiverse-CoT: It provides distinct and unique collection of different histopathology reasoning and summary for a few reports. 3 reports per 110 subtopics, with 16 different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/singhprabhat/medreport_reasoning-summary.","url":"https://huggingface.co/datasets/singhprabhat/medreport_reasoning-summary","creator_name":"Prabhat Singh","creator_url":"https://huggingface.co/singhprabhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_47","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/reddit_dataset_47.","url":"https://huggingface.co/datasets/tarzan19990815/reddit_dataset_47","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aiysha-diction","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAIySha: yShade.AI AI Agent\n\t\n\nThis is the base dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\nThe dataset needs to be reformatted to fit the prompt template for the chat model in order to use for fine tuning purposes.\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\n","url":"https://huggingface.co/datasets/rofyray/aiysha-diction","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"All-WAN-Show","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAll WAN Show Transcripts\n\t\n\nComplete transcripts from every episode of the WAN Show from 2013-present. Also includes transcripts from episodes of the LTT Live Show, the WAN Show precursor. \nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/All-WAN-Show","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"All-WAN-Show","keyword":"summary","description":"\n\t\n\t\t\n\t\tAll WAN Show Transcripts\n\t\n\nComplete transcripts from every episode of the WAN Show from 2013-present. Also includes transcripts from episodes of the LTT Live Show, the WAN Show precursor. \nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/All-WAN-Show","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_191","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/x_dataset_191.","url":"https://huggingface.co/datasets/SAVE0x0/x_dataset_191","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Toknowmore","keyword":"summarization","description":"Jsnsm/Toknowmore dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Jsnsm/Toknowmore","creator_name":"Kuncham","creator_url":"https://huggingface.co/Jsnsm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","zero-shot-classification","translation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0104179","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0104179.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0104179","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2012-2013-LTT-Live-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2012-2013 LTT Live Show Transcripts\n\t\n\nComplete transcripts from the 2012-2013 episodes of the WAN Show precursor - the LTT Live Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2012-2013-LTT-Live-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_191","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/x_dataset_191.","url":"https://huggingface.co/datasets/SAVE0x0/x_dataset_191","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0104179","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0104179.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0104179","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"sentence-paraphrases","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tSentence Paraphrases Dataset\n\t\n\nThis dataset is a curated collection of sentence-length paraphrases derived from two primary sources:\n\nhumarin/chatgpt-paraphrases\nxwjzds/paraphrase_collections.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is structured to provide pairs of sentences from an original text and its paraphrase(s). For each entry:\n\nThe \"text\" field contains the least readable paraphrase.\nThe \"paraphrase\" field contains the most readable paraphrase.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/sentence-paraphrases.","url":"https://huggingface.co/datasets/agentlans/sentence-paraphrases","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"2012-2013-LTT-Live-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2012-2013 LTT Live Show Transcripts\n\t\n\nComplete transcripts from the 2012-2013 episodes of the WAN Show precursor - the LTT Live Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2012-2013-LTT-Live-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"modified-codesearchnet-code-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tModified CodeSearchNet (MCSN) Dataset\n\t\n\nThis dataset is a modification of the CodeSearchNet dataset from CodeXGLUE benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and repository contexts on summary quality.  The dataset includes modifications for evaluating at both function and repository levels.\nPaper: Code Summarization Beyond Function Level\nDataset Structure:\nThe dataset contains samples with the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization.","url":"https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Saudades_da_terra","keyword":"summarization","description":"Verotic/Saudades_da_terra dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Verotic/Saudades_da_terra","creator_name":"Adriano","creator_url":"https://huggingface.co/Verotic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_4.","url":"https://huggingface.co/datasets/suul999922/x_dataset_4","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_4.","url":"https://huggingface.co/datasets/suul999922/x_dataset_4","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rhvex-cve","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for rhvex-cve\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extracting relevant‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vdanen/rhvex-cve.","url":"https://huggingface.co/datasets/vdanen/rhvex-cve","creator_name":"Vincent Danen","creator_url":"https://huggingface.co/vdanen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"three_line_summarization_for_japanese_news_articles","keyword":"summarization","description":"„É©„Ç§„Éñ„Éâ„Ç¢„Éã„É•„Éº„Çπ„Ç≥„Éº„Éë„Çπ„ÅÆ3Ë°åË¶ÅÁ¥Ñ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\nLlama v2Âêë„Åë„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÇíËøΩÂä†„Åó„Å¶ÊàêÂΩ¢„Åó„Å¶„ÅÇ„Çä„Åæ„Åô„ÄÇ\nÂ≠¶Áøí„Å´Âà©Áî®„Åô„ÇãÈöõ„ÅØ„ÄÅ [R_START] [R_END] „Çíspecial token„Å®„Åó„Å¶ËøΩÂä†„Åô„Çã„Åì„Å®„ÇíÊé®Â•®„Åó„Åæ„Åô„ÄÇ\nNumber of rows: 3,907 \nDataset„ÅØ‰ª•‰∏ã„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÇíÂà©Áî®„Åó„Å¶scrape„Åó„Åæ„Åó„Åü„ÄÇ\ngit@github.com:KodairaTomonori/ThreeLineSummaryDataset.git\n","url":"https://huggingface.co/datasets/waddledee/three_line_summarization_for_japanese_news_articles","creator_name":"m takahashi","creator_url":"https://huggingface.co/waddledee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"tempora","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTempora\n\t\n\n\n  \n\n\n\nA contemporary dataset of 7,368 real-world documents published after March 1, 2025, curated for testing the temporal grounding of Large Language Models.\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nBelow are examples of how to load Tempora-0325 using the Hugging Face datasets library. Adjust the config_name as needed.\n\n\t\n\t\t\n\t\tLoading with datasets\n\t\n\nfrom datasets import load_dataset\n\n# Load the balanced subset\nds_balanced = load_dataset(\"sumuks/tempora\", name=\"tempora-0325B\", split=\"train\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sumukshashidhar-archive/tempora.","url":"https://huggingface.co/datasets/sumukshashidhar-archive/tempora","creator_name":"Sumuk's Archived Content","creator_url":"https://huggingface.co/sumukshashidhar-archive","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","text-generation","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"llama3_vocabulary_cluster","keyword":"summarization","description":"This dataset contains the clusters discovered in the vocabulary embeddings of the llama3-8b-instruct model.\nThe 128256 vocabulary embeddings are separated into 1024 clusters by k-means, which show pattern correlations probably undesirable for diverse generation.\nWe also prompt GPT-4o to summarize the commonality of vocabularies in the same cluster, which can be used for further analysis.\nThis dataset is a part of the work on diverse LLM generation. [Paper], [Github]\n","url":"https://huggingface.co/datasets/KomeijiForce/llama3_vocabulary_cluster","creator_name":"Letian Peng","creator_url":"https://huggingface.co/KomeijiForce","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sentence-correction","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLLM Prompt Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LLM Prompt Dataset is designed to enhance the performance of large language models (LLMs) by transforming user inputs into structured prompts. This dataset aims to facilitate the understanding of complex queries and improve the interaction between users and LLMs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized in JSON format, where each entry consists of an input and a prompt. The input represents the original user query or statement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ashraf-CK/sentence-correction.","url":"https://huggingface.co/datasets/Ashraf-CK/sentence-correction","creator_name":"Chauhan","creator_url":"https://huggingface.co/Ashraf-CK","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"LearningPaper24","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLearningPaper24 Dataset\n\t\n\n\n\nThis dataset contains video recordings and metadata from ICLR and NeurIPS 2024 conference talks. It includes both poster and oral presentations, along with their associated metadata such as titles, abstracts, keywords, and primary areas.\nThe paper list is originally sourced from Paperlists.\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nlearningpaper24/\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ metadata/\n‚îÇ   ‚îî‚îÄ‚îÄ catalog.json\n‚îî‚îÄ‚îÄ video/\n    ‚îú‚îÄ‚îÄ {openreview_id}_{slideslive_id}.mp4\n    ‚îî‚îÄ‚îÄ ...‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vivianchen98/LearningPaper24.","url":"https://huggingface.co/datasets/vivianchen98/LearningPaper24","creator_name":"Shenghui Chen","creator_url":"https://huggingface.co/vivianchen98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","video-text-to-text","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/x_dataset_8.","url":"https://huggingface.co/datasets/Axel232/x_dataset_8","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/x_dataset_8.","url":"https://huggingface.co/datasets/Axel232/x_dataset_8","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-deontologie-architectes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de d√©ontologie des architectes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cpc_2015_brasil","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSALVAMENTO do Dataset\n\t\n\nfrom datasets import load_dataset\nfrom datasets import Dataset\nimport pandas as pd\n\n# Carregar os dados do arquivo de texto\ndf = pd.read_parquet('../data/cpc_2015_cleaned.parquet')\n\ndata = {\n    \"livro\": df[\"Livro\"],\n    \"capitulo\": df[\"Capitulo\"],\n    \"titulo\": df[\"Titulo\"],\n    \"secao\": df[\"Secao\"],\n    \"subsecao\": df[\"Subsecao\"],\n    \"artigo\": df[\"Artigo\"]\n}\n\n# Dividir o texto em se√ß√µes\ndataset = Dataset.from_pandas(pd.DataFrame(data))‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0rakul0/cpc_2015_brasil.","url":"https://huggingface.co/datasets/0rakul0/cpc_2015_brasil","creator_name":"Jefferson Silva dos Anjos","creator_url":"https://huggingface.co/0rakul0","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Portuguese","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Titles-WildChat-GPT4-100k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTitles-WildChat-GPT4-100k\n\t\n\nThis dataset consists of conversation titles generated from the allenai/WildChat-1M dataset. It is designed for fine-tuning lightweight models to improve conversation title generation.\nHere are some examples:\n\n‚ú® Chat History Summary\nüì∫ TVs & Recommendations\n‚ù§Ô∏è MI Risk Factors\nüìä Followers Median Calculation\nü§ñ Chat History Example\nüëë Gold & Black Symbolism\n‚ú® Endless Title Generation\nü§ñ Recursive Title Generation\nüé≠ Chatbot Roleplay Fun\nüíª Sorting Algorithm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/k4yt3x/Titles-WildChat-GPT4-100k.","url":"https://huggingface.co/datasets/k4yt3x/Titles-WildChat-GPT4-100k","creator_name":"K4YT3X","creator_url":"https://huggingface.co/k4yt3x","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","odc-by","100K - 1M","arrow","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11230","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_11230.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_11230","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-commerce","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de commerce, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11230","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_11230.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_11230","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"L-CiteEval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tL-CITEEVAL: DO LONG-CONTEXT MODELS TRULY LEVERAGE CONTEXT FOR RESPONDING?\n\t\n\nPaper ‚ÄÇ Github ‚ÄÇ Zhihu\n\n\t\n\t\t\n\t\tBenchmark Quickview\n\t\n\nL-CiteEval is a multi-task long-context understanding with citation benchmark, covering 5 task categories, including single-document question answering, multi-document question answering, summarization, dialogue understanding, and synthetic tasks, encompassing 11 different long-context tasks. The context lengths for these tasks range from 8K to 48K.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jonaszky123/L-CiteEval.","url":"https://huggingface.co/datasets/Jonaszky123/L-CiteEval","creator_name":"keyan zhou","creator_url":"https://huggingface.co/Jonaszky123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_41.","url":"https://huggingface.co/datasets/James096/x_dataset_41","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ssh-scan","keyword":"summarization","description":"This dataset contains a big list of all the SSH response headers I could find running a scan over the entire internet.\nIP addresses have been removed for privacy reasons, and replaced with a uuid.\nThis dataset may contain data that is offensive, crass, homophobic, transphobic, racist, etc etc as it is the internet afterall, none of it represents the thoughts or opinions of the author.\n","url":"https://huggingface.co/datasets/ghostoverflow/ssh-scan","creator_name":"Lilly Aronleigh","creator_url":"https://huggingface.co/ghostoverflow","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_41.","url":"https://huggingface.co/datasets/James096/x_dataset_41","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-disciplinaire-penal-marine-marchande","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode disciplinaire et p√©nal de la marine marchande, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"k12-digital-learning-platforms-research","keyword":"summarization","description":"\n\t\n\t\t\n\t\tK-12 Digital Learning Platforms Research Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis comprehensive dataset contains authentic, peer-reviewed research studies on digital learning platforms effectiveness in K-12 education. The dataset aggregates research from authoritative sources including government agencies, educational research institutions, and peer-reviewed academic publications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Studies: 280+ comprehensive research studies\nCoverage Period:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robworks-software/k12-digital-learning-platforms-research.","url":"https://huggingface.co/datasets/robworks-software/k12-digital-learning-platforms-research","creator_name":"Ryan Robson","creator_url":"https://huggingface.co/robworks-software","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-sante-publique","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la sant√© publique, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"UnitedStatesSenateBillsAndSummaries","keyword":"summarization","description":"MTSUFall2024SoftwareEngineering/UnitedStatesSenateBillsAndSummaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MTSUFall2024SoftwareEngineering/UnitedStatesSenateBillsAndSummaries","creator_name":"MTSU Fall 2024 Software Engineering","creator_url":"https://huggingface.co/MTSUFall2024SoftwareEngineering","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"UnitedStatesSenateBillsAndSummaries","keyword":"summarization","description":"MTSUFall2024SoftwareEngineering/UnitedStatesSenateBillsAndSummaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MTSUFall2024SoftwareEngineering/UnitedStatesSenateBillsAndSummaries","creator_name":"MTSU Fall 2024 Software Engineering","creator_url":"https://huggingface.co/MTSUFall2024SoftwareEngineering","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"code-rural-ancien","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode rural (ancien), non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0303241","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0303241.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0303241","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0303241","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0303241.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0303241","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_193","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/reddit_dataset_193.","url":"https://huggingface.co/datasets/RentonWEB3/reddit_dataset_193","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-commande-publique","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la commande publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_192","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mamung/x_dataset_192.","url":"https://huggingface.co/datasets/mamung/x_dataset_192","creator_name":"ansloth","creator_url":"https://huggingface.co/mamung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_193","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/reddit_dataset_193.","url":"https://huggingface.co/datasets/RentonWEB3/reddit_dataset_193","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_192","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mamung/x_dataset_192.","url":"https://huggingface.co/datasets/mamung/x_dataset_192","creator_name":"ansloth","creator_url":"https://huggingface.co/mamung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_12.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_12","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19039","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_19039.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_19039","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PlainFact-summary","keyword":"summarization","description":"PlainFact-summary is a high-quality human-annotated dataset designed for Plain Language Summarization tasks, along with PlainQAFact factuality evaluation framework, as described in PlainQAFact: Automatic Factuality Evaluation Metric for Biomedical Plain Language Summaries Generation. It is collected from the Cochrane database sampled from CELLS dataset (Guo et al., 2024). \nIn addition to using all factual plain language summaries, we also generate contrasting non-factual examples for each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uzw/PlainFact-summary.","url":"https://huggingface.co/datasets/uzw/PlainFact-summary","creator_name":"Zhiwen You","creator_url":"https://huggingface.co/uzw","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1051","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_1051.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_1051","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_12.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_12","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19039","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_19039.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_19039","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1051","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_1051.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_1051","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_1.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_1","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_1.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_1","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"DataNote","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tüìò DataNote Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìñ Gi·ªõi thi·ªáu\n\t\n\nDataNote l√† m·ªôt dataset ch·ª©a c√°c ƒëo·∫°n code snippet v√† v√≠ d·ª• l·∫≠p tr√¨nh cho nhi·ªÅu ng√¥n ng·ªØ kh√°c nhau.Dataset n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph·ª•c v·ª• cho vi·ªác h·ªçc t·∫≠p, qu·∫£n l√Ω snippet v√† s∆∞u t·∫ßm code m·∫´u.\n\n\n\t\n\t\t\n\t\tüìÇ C·∫•u tr√∫c d·ªØ li·ªáu\n\t\n\nM·ªói b·∫£n ghi trong dataset bao g·ªìm c√°c tr∆∞·ªùng:\n\ntitle: T√™n ho·∫∑c ti√™u ƒë·ªÅ c·ªßa snippet\ncontent: N·ªôi dung code th·ª±c t·∫ø\nlanguage: Ng√¥n ng·ªØ l·∫≠p tr√¨nh (javascript, python, html, css, sql, ‚Ä¶)\ndescription: M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ ch·ª©c‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TwanAPI/DataNote.","url":"https://huggingface.co/datasets/TwanAPI/DataNote","creator_name":"Thanh Tu·∫•n ","creator_url":"https://huggingface.co/TwanAPI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","natural-language-inference","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_44.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_44","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39615","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_39615.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_39615","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"News_Summary_Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nDataset Origin: [BBC News Summary]\nData Source by: [https://www.kaggle.com/datasets/pariza/bbc-news-summary/data]\nLanguage(s) (NLP): [English]\nLicense: [More Information Needed]\n\n\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n[Used to summarize a language model like T5, to produce concise and clean summaries to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SurAyush/News_Summary_Dataset.","url":"https://huggingface.co/datasets/SurAyush/News_Summary_Dataset","creator_name":"Ayush Sur","creator_url":"https://huggingface.co/SurAyush","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"NoticIA","keyword":"summarization","description":"\n    \n\n\n\"A Clickbait Article Summarization Dataset in Spanish.\"\n\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\n\nüìñ Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\nüíª Baseline Code: https://github.com/ikergarcia1996/NoticIA\nü§ñ Pre Trained Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA.","url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NoticIA","keyword":"summarization","description":"\n    \n\n\n\"A Clickbait Article Summarization Dataset in Spanish.\"\n\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\n\nüìñ Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\nüíª Baseline Code: https://github.com/ikergarcia1996/NoticIA\nü§ñ Pre Trained Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA.","url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_44.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_44","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39615","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_39615.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_39615","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/x_dataset_44.","url":"https://huggingface.co/datasets/roknedin/x_dataset_44","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_246","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trungnam299/reddit_dataset_246.","url":"https://huggingface.co/datasets/trungnam299/reddit_dataset_246","creator_name":"Trung Nam","creator_url":"https://huggingface.co/trungnam299","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/x_dataset_44.","url":"https://huggingface.co/datasets/roknedin/x_dataset_44","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_246","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trungnam299/reddit_dataset_246.","url":"https://huggingface.co/datasets/trungnam299/reddit_dataset_246","creator_name":"Trung Nam","creator_url":"https://huggingface.co/trungnam299","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_156","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/x_dataset_156.","url":"https://huggingface.co/datasets/markrogolino/x_dataset_156","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"dialogsum-qds-dataset","keyword":"summarization","description":"We collect and clean data DialogSum from binwang/InstructDS_datasets Huggingface\n","url":"https://huggingface.co/datasets/dtruong46me/dialogsum-qds-dataset","creator_name":"Dinh Truong Phan","creator_url":"https://huggingface.co/dtruong46me","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10492","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10492.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10492","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_156","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/x_dataset_156.","url":"https://huggingface.co/datasets/markrogolino/x_dataset_156","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10492","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10492.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10492","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-rural-peche-maritime","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode rural et de la p√™che maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_111","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicchio816/reddit_dataset_111.","url":"https://huggingface.co/datasets/nicchio816/reddit_dataset_111","creator_name":"Alex Avery","creator_url":"https://huggingface.co/nicchio816","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_111","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicchio816/reddit_dataset_111.","url":"https://huggingface.co/datasets/nicchio816/reddit_dataset_111","creator_name":"Alex Avery","creator_url":"https://huggingface.co/nicchio816","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"stl_phones_new_spec_format","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSTL Phone Specs Dataset\n\t\n\nThis dataset contains phone and tablet specifications along with short, consumer-friendly descriptions used on the STL website.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nEach entry includes:\nspecs: Detailed technical specifications (e.g., display, processor, camera, battery, features).\noutput: A concise summary in the new STL format.\n\n\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe short description format has recently changed. All STL products are being updated to use this style:\nDisplay: [concise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masabhuq/stl_phones_new_spec_format.","url":"https://huggingface.co/datasets/masabhuq/stl_phones_new_spec_format","creator_name":"Masab Huq","creator_url":"https://huggingface.co/masabhuq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"crimemap","keyword":"summarization","description":"pragma solidity ^0.8.4;\ncontract CrimeMap {\n    struct CrimeRecord {\n        uint256 id;\n        string location;\n        address suspectAddress; // Note: This assumes public access \n    }\nmapping(uint256 => CrimeRecord) crimesById;\nmapping(string => bool) crimeReportsByLocation;\n\nfunction reportCrime(\n    string memory _location,\n    address _suspect\n) public {\n    uint256 id = getNewId();\n    crimesById[id] = CrimeRecord(id, _location, _suspect);\n    if (!crimeReportsByLocation[_location]) {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mi6paulino/crimemap.","url":"https://huggingface.co/datasets/Mi6paulino/crimemap","creator_name":"Michael Paulino","creator_url":"https://huggingface.co/Mi6paulino","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_12.","url":"https://huggingface.co/datasets/suul999922/x_dataset_12","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"products","keyword":"summarization","description":"neverland-th/products dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neverland-th/products","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_225","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISOMA-Bittensor/reddit_dataset_225.","url":"https://huggingface.co/datasets/AISOMA-Bittensor/reddit_dataset_225","creator_name":"Murat Durmus","creator_url":"https://huggingface.co/AISOMA-Bittensor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"my_dataset","keyword":"summarization","description":"Dataset Name: huggingface_dataset_github_repo\nDescription : This dataset contains structured issue data, extracted from GitHub repositories. It is useful for text classification , issue summarization etc\n","url":"https://huggingface.co/datasets/kardwalker/my_dataset","creator_name":"Aman Yadav","creator_url":"https://huggingface.co/kardwalker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_12.","url":"https://huggingface.co/datasets/suul999922/x_dataset_12","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_225","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISOMA-Bittensor/reddit_dataset_225.","url":"https://huggingface.co/datasets/AISOMA-Bittensor/reddit_dataset_225","creator_name":"Murat Durmus","creator_url":"https://huggingface.co/AISOMA-Bittensor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_History_12th","keyword":"summarization","description":"KadamParth/NCERT_History_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_History_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"mlm-harry-potter","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe dataset, derived from the original dataset KaungHtetCho/Harry_Potter_LSTM, was processed by merging all splits into one and removing empty rows to ensure it is clean and ready for use.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe only split, train contains all 7 of the Harry Potter books.The text column contains book titles, chapter titles and the book contents split into paragraphs.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nOriginal Dataset:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andjela-r/mlm-harry-potter.","url":"https://huggingface.co/datasets/andjela-r/mlm-harry-potter","creator_name":"Anƒëela Radojeviƒá","creator_url":"https://huggingface.co/andjela-r","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","token-classification","summarization","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-article-summarization-DPO","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüóûÔ∏è Brazilian News Preference Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for maikerdr/brazilian-news-article-summarization-DPO\n\t\n\nGenerated using https://github.com/maikereis/news-summarizer\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nThis dataset consists of Brazilian news articles scraped from reputable online journalism sources. \n\n\t\n\t\t\n\t\tG1\n\t\n\n\nhttps://g1.globo.com/politica/\nhttps://g1.globo.com/economia/\nhttps://g1.globo.com/ciencia/\nhttps://g1.globo.com/tecnologia/\nhttps://g1.globo.com/saude/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO.","url":"https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040752","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040752.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040752","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Accounting_11th","keyword":"summarization","description":"KadamParth/NCERT_Accounting_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Accounting_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"SciChartSum","keyword":"summarization","description":"Wensiye/SciChartSum dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Wensiye/SciChartSum","creator_name":"siyong wen","creator_url":"https://huggingface.co/Wensiye","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_76","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/reddit_dataset_76.","url":"https://huggingface.co/datasets/marry-1111/reddit_dataset_76","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_196","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_196.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_196","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"sum-synthetic-data-v1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tChild Protection Helpline Case Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset (train_data1.jsonl) contains 1,000 synthetic training examples designed for fine-tuning the FLAN-T5 base model for automatic case summarization in child protection helpline scenarios. The dataset simulates real-world helpline calls reporting various forms of child abuse and exploitation cases across East Africa.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the JSONL file contains the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openchs/sum-synthetic-data-v1.","url":"https://huggingface.co/datasets/openchs/sum-synthetic-data-v1","creator_name":"BITZ IT Consulting","creator_url":"https://huggingface.co/openchs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040752","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040752.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040752","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_76","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/reddit_dataset_76.","url":"https://huggingface.co/datasets/marry-1111/reddit_dataset_76","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_196","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_196.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_196","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"medreport_text_1000","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMedReport - Reports Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains medical audio transcriptions and the corresponding structured reports.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\ninput: Audio transcription\noutput: Structured medical report\nsample_id: Example identifier\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nTotal examples: 1000\nLicense: Apache License 2.0\nCreated: 2025-08-05\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tLoading the dataset\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\nfull_dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wouk1805/medreport_text_1000.","url":"https://huggingface.co/datasets/wouk1805/medreport_text_1000","creator_name":"Young-Wouk Kim","creator_url":"https://huggingface.co/wouk1805","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_231.","url":"https://huggingface.co/datasets/bit0/x_dataset_231","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_7.","url":"https://huggingface.co/datasets/suul999922/x_dataset_7","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0402228","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0402228.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0402228","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44882","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_44882.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_44882","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_231.","url":"https://huggingface.co/datasets/bit0/x_dataset_231","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_7.","url":"https://huggingface.co/datasets/suul999922/x_dataset_7","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0402228","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0402228.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0402228","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44882","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_44882.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_44882","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/x_dataset_218.","url":"https://huggingface.co/datasets/SAVE0x0/x_dataset_218","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_197","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/x_dataset_197.","url":"https://huggingface.co/datasets/chaiamy/x_dataset_197","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aiysha-diction-500","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAIySha: yShade.AI AI Agent\n\t\n\nThis is the formatted dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\nThe dataset fits the prompt template for the chat model and is ready to be used for fine tuning purposes.\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\n","url":"https://huggingface.co/datasets/rofyray/aiysha-diction-500","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/x_dataset_218.","url":"https://huggingface.co/datasets/SAVE0x0/x_dataset_218","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_197","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/x_dataset_197.","url":"https://huggingface.co/datasets/chaiamy/x_dataset_197","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_88","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_88.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_88","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_88","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_88.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_88","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"text-revision","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tText Revision Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains pairs of original and revised texts. The revised versions enhance unity, coherence, clarity, precision, and conciseness by restructuring content, simplifying language, and eliminating redundancy. The input passages are sourced from agentlans/high-quality-text, and the outputs are generated using google/gemma-3-12b-it.\n\n\t\n\t\t\n\t\n\t\n\t\tFormat\n\t\n\n\ninput: Original text  \noutput: Revised text that follows editing guidelines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/text-revision.","url":"https://huggingface.co/datasets/agentlans/text-revision","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","odc-by","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_377626","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_377626.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_377626","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_7.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_7","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MixSub-With-Hallucinated-Highlights","keyword":"summarization","description":"\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nFilename: Unique identifier of the paper from ScienceDirect.\nAbstract: Human-written abstract of the paper.\nHighlight: Human-written highlight from the paper, considered as the golden summary of the Abstract.\nHallucination: LLM-generated hallucinated summary of the abstract, used to train a discriminator model to classify hallucinated and non-hallucinated outputs.\n\n","url":"https://huggingface.co/datasets/AdityaMayukhSom/MixSub-With-Hallucinated-Highlights","creator_name":"Aditya Mayukh Som","creator_url":"https://huggingface.co/AdityaMayukhSom","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"DAS-Mediacal-Red-Teaming-Data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDAS Medical Red-Teaming Test Suites\n\t\n\nAccompanies the paper Beyond Benchmarks: Dynamic, Automatic and Systematic Red-Teaming Agents for Trustworthy Medical LLMs. \nThe data samples presented in this repo are used as the initial data seeds and can be mutated further upon requests. It is designed to stress-test Large Language Models (LLMs) in safety-critical medical domains, auditing along four critical axes: Robustness, Privacy, Bias/Fairness, and Hallucination.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data.","url":"https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data","creator_name":"JZPeterPan","creator_url":"https://huggingface.co/JZPeterPan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_377626","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_377626.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_377626","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_7.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_7","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"grab_cup","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangwwwww111/grab_cup.","url":"https://huggingface.co/datasets/wangwwwww111/grab_cup","creator_name":"wangfei","creator_url":"https://huggingface.co/wangwwwww111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","Aragonese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_252","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill199284/x_dataset_252.","url":"https://huggingface.co/datasets/bill199284/x_dataset_252","creator_name":"thomas","creator_url":"https://huggingface.co/bill199284","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Medi-Science","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMedi-Science Dataset\n\t\n\nThe Medi-Science dataset is a comprehensive collection of medical Q&A data designed for text generation, question answering, and summarization tasks in the healthcare domain.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nName: Medi-Science\nLicense: Apache-2.0\nLanguages: English\nTags: Medical, Medicine, Anomaly, Biology, Medi-Science\nNumber of Rows: 16,412\nDataset Size:\nDownloaded: 22.7 MB\nAuto-converted Parquet: 8.94 MB\n\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Medi-Science.","url":"https://huggingface.co/datasets/prithivMLmods/Medi-Science","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"news-title-generator","keyword":"summarization","description":"\n\t\n\t\t\n\t\tNews Headline Generation Dataset\n\t\n\nSuggest text for dataset Card ü§ó\n","url":"https://huggingface.co/datasets/Ateeqq/news-title-generator","creator_name":"Ateeq Azam","creator_url":"https://huggingface.co/Ateeqq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ChouBun","keyword":"summarization","description":"\n\t\n\t\t\n\t\tChouBun\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nChouBun is a benchmark for assessing LLMs' performance in long-context tasks in the Japanese language.\nIt is created and introduced in the paper An Evolved Universal Transformer Memory.\nThe benchmark includes documents from multiple websites and synthetic question-answer pairs generated by GPT-4 variants and Claude-3.5-Sonnet.\nThe current version of ChouBun contains 2 task categories -- extractive QA and abstractive summarization -- and 4 tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/ChouBun.","url":"https://huggingface.co/datasets/SakanaAI/ChouBun","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_252","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill199284/x_dataset_252.","url":"https://huggingface.co/datasets/bill199284/x_dataset_252","creator_name":"thomas","creator_url":"https://huggingface.co/bill199284","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_9th","keyword":"summarization","description":"KadamParth/NCERT_Social_Studies_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_682","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_682.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_682","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_464099","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_464099.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_464099","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_18","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/reddit_dataset_18.","url":"https://huggingface.co/datasets/roknedin/reddit_dataset_18","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_682","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_682.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_682","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_464099","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_464099.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_464099","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_18","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/reddit_dataset_18.","url":"https://huggingface.co/datasets/roknedin/reddit_dataset_18","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"UnitedStatesSenateBillsAndSummaries","keyword":"summarization","description":"cheaptrix/UnitedStatesSenateBillsAndSummaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cheaptrix/UnitedStatesSenateBillsAndSummaries","creator_name":"Taylor Hartman","creator_url":"https://huggingface.co/cheaptrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"UnitedStatesSenateBillsAndSummaries","keyword":"summarization","description":"cheaptrix/UnitedStatesSenateBillsAndSummaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cheaptrix/UnitedStatesSenateBillsAndSummaries","creator_name":"Taylor Hartman","creator_url":"https://huggingface.co/cheaptrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"rawg-games-dataset","keyword":"summarization","description":"\n  \n\n\n\n  \n  \n\n\nDescription\n\n  RAWG Games Dataset video game records data gathered directly from the RAWG API.\n  It includes essential fields such as game id, title, release date, rating, genres, platforms, descriptive tags, \n  Metacritic score, developers, publishers, playtime, and a detailed description. The data was collected to support \n  studies, trend analysis, and insights into the gaming industry. Each field is aligned with the specifications provided in the RAWG API documentation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/atalaydenknalbant/rawg-games-dataset.","url":"https://huggingface.co/datasets/atalaydenknalbant/rawg-games-dataset","creator_name":"Atalay Denknalbant","creator_url":"https://huggingface.co/atalaydenknalbant","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","summarization","feature-extraction","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rawg-games-dataset-updated","keyword":"summarization","description":"\n  \n\n\n\n  \n  \n\n\nDescription\n\n  RAWG Games Dataset video game records data gathered directly from the RAWG API.\n  It includes essential fields such as game id, title, release date, rating, genres, platforms, descriptive tags, \n  Metacritic score, developers, publishers, playtime, and a detailed description. The data was collected to support \n  studies, trend analysis, and insights into the gaming industry. Each field is aligned with the specifications provided in the RAWG API documentation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IVproger/rawg-games-dataset-updated.","url":"https://huggingface.co/datasets/IVproger/rawg-games-dataset-updated","creator_name":"Ivan Golov","creator_url":"https://huggingface.co/IVproger","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","summarization","feature-extraction","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"financial-reports-extractive-summarization_eval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFinancial Reports Extractive Summarization Evaluation Dataset\n\t\n\nValidation and test splits for evaluating models on Arabic financial reports extractive summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: Simple prompt-answer pairs\nValidation: ~20 examples (10%)\nTest: ~20 examples (10%)\nLanguage: Arabic\nDomain: Financial reports and market news\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nid: Unique identifier\nprompt: The summarization prompt\nfull_text: Complete financial report\nanswer: Ground truth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval.","url":"https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval","creator_name":"Sahm_Benchmark","creator_url":"https://huggingface.co/SahmBenchmark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"financial-reports-extractive-summarization_eval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFinancial Reports Extractive Summarization Evaluation Dataset\n\t\n\nValidation and test splits for evaluating models on Arabic financial reports extractive summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: Simple prompt-answer pairs\nValidation: ~20 examples (10%)\nTest: ~20 examples (10%)\nLanguage: Arabic\nDomain: Financial reports and market news\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nid: Unique identifier\nprompt: The summarization prompt\nfull_text: Complete financial report\nanswer: Ground truth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval.","url":"https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval","creator_name":"Sahm_Benchmark","creator_url":"https://huggingface.co/SahmBenchmark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"train_sum_dataset_100chinese_50english_conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCombined Training Dataset: 100% Chinese + 50% English Conversations\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines two conversation datasets for training multilingual financial summarization models:\n\n100% of datran/train_sum_dataset_chinese_only_conversations \n50% of datran/converted_train_conversations\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 33,553\nChinese-only Examples: 22,369 (100% inclusion)\nConverted Examples: 11,184 (50% sampled)\nLanguages: Chinese (Simplified)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations.","url":"https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations","creator_name":"Jamie Tran","creator_url":"https://huggingface.co/datran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"train_sum_dataset_100chinese_50english_conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCombined Training Dataset: 100% Chinese + 50% English Conversations\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines two conversation datasets for training multilingual financial summarization models:\n\n100% of datran/train_sum_dataset_chinese_only_conversations \n50% of datran/converted_train_conversations\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 33,553\nChinese-only Examples: 22,369 (100% inclusion)\nConverted Examples: 11,184 (50% sampled)\nLanguages: Chinese (Simplified)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations.","url":"https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations","creator_name":"Jamie Tran","creator_url":"https://huggingface.co/datran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_154","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_154.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_154","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"summarization","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_154","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_154.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_154","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"contextual-summaries","keyword":"summarization","description":"Rupesh2/contextual-summaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Rupesh2/contextual-summaries","creator_name":"Rupesh","creator_url":"https://huggingface.co/Rupesh2","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"youtube-video-summarization","keyword":"summarization","description":"ClarityClips/youtube-video-summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ClarityClips/youtube-video-summarization","creator_name":"ClarityClips","creator_url":"https://huggingface.co/ClarityClips","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","French","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"run_test_demo","keyword":"summarization","description":"banxiangao/run_test_demo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/banxiangao/run_test_demo","creator_name":"gao banxian","creator_url":"https://huggingface.co/banxiangao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","Afar","apache-2.0","üá∫üá∏ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"NCERT_Physics_11th","keyword":"summarization","description":"KadamParth/NCERT_Physics_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Physics_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"symptom-precaution","keyword":"summarization","description":"subhro1530/symptom-precaution dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/subhro1530/symptom-precaution","creator_name":"Shaswata","creator_url":"https://huggingface.co/subhro1530","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_13.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_13","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"smol-koreantalk","keyword":"summarization","description":"SmolLM2Ïùò Ïù∏Ïä§Ìä∏Îü≠ÏÖò ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ HuggingFaceTB/smol-smoltalkÎ•º ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠ÌñàÏñ¥Ïöî.\n","url":"https://huggingface.co/datasets/lemon-mint/smol-koreantalk","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_13.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_13","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12552","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_12552.","url":"https://huggingface.co/datasets/icedwind/x_dataset_12552","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12949","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_12949.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_12949","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_9.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_9","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12552","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_12552.","url":"https://huggingface.co/datasets/icedwind/x_dataset_12552","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12949","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_12949.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_12949","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_9.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_9","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_250.","url":"https://huggingface.co/datasets/James096/x_dataset_250","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_250.","url":"https://huggingface.co/datasets/James096/x_dataset_250","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Paripadal","keyword":"summarization","description":"\n\t\n\t\t\n\t\t‡Æ™‡Æ∞‡Æø‡Æ™‡Ææ‡Æü‡Æ≤‡Øç (ParipƒÅdal)\n\t\n\n\n\t\n\t\t\n\t\tüìù Dataset Description\n\t\n\n‡Æ™‡Æ∞‡Æø‡Æ™‡Ææ‡Æü‡Æ≤‡Øç (ParipƒÅdal) is one of the eight classical anthologies (Ettuthokai) in Sangam Literature, containing 22 poems. These poems are unique as they were set to music and celebrate deities like Vishnu, Murugan, and the river Kaveri, along with themes of nature, devotion, and love.\nThis dataset provides a structured digital format of ParipƒÅdal, including:\nPoem Title\nSection Headings\nOriginal Tamil Poem Text (organized by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Paripadal.","url":"https://huggingface.co/datasets/TamilThagaval/Paripadal","creator_name":"‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"code-douanes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des douanes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_37","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_37.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_37","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_8.","url":"https://huggingface.co/datasets/suul999922/x_dataset_8","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_37","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_37.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_37","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_8.","url":"https://huggingface.co/datasets/suul999922/x_dataset_8","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_218.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"OpenWeb888K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenWeb Datasets Web Collection\n\t\n\nThe OpenWeb Datasets Web Collection, derived from the 'FineWeb' dataset, consists of more than 15 trillion tokens of cleaned and deduplicated English web data from CommonCrawl. The data processing pipeline is optimized for LLM performance, and the necessary set of datasets has been extracted from Hugging Face's FineWeb collections. This dataset was created by processing 96 CommonCrawl dumps, comprising web data crawled from the summer of 2013 to April‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/OpenWeb888K.","url":"https://huggingface.co/datasets/prithivMLmods/OpenWeb888K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text2text-generation","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_218.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"nano_finance_200k_en_es_chatML_gemma_orpo_dpo","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/NickyNicky/nano_finance_200k_en_es_chatML_gemma_orpo_dpo","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","question-answering","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"BSG_CyLlama-training","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBSG CyLlama Training Dataset: Cyclical Corpus Summarization Data\n\t\n\nTraining data for BSG CyLlama (Biomedical Summary Generation through Cyclical Llama), designed to support the cyclical embedding averaging methodology with named entity integration.\n\n\t\n\t\t\n\t\tüîÑ Dataset Purpose\n\t\n\nThis dataset enables training models on corpus-level summarization using cyclical embedding averaging:\n\nCorpus Groups: Documents organized into thematically related clusters\nCyclical Training Patterns: Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jimnoneill/BSG_CyLlama-training.","url":"https://huggingface.co/datasets/jimnoneill/BSG_CyLlama-training","creator_name":"Jamey ONeill","creator_url":"https://huggingface.co/jimnoneill","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_8.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_8","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_193","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/x_dataset_193.","url":"https://huggingface.co/datasets/RentonWEB3/x_dataset_193","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_59332","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_59332.","url":"https://huggingface.co/datasets/momo1942/x_dataset_59332","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"tanzirmehedi","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA small, high-quality chat dataset to teach models how to answer like Sk. Tanzir Mehedi (QUT; software supply-chain security, HPC/LLM workflows, PyPI malware analysis).Primary reference: https://tanzirmehedi.netlify.app/\n\n\t\n\t\t\n\t\tFormat\n\t\n\nEach row contains a messages list of {role, content, thinking} objects.thinking is optional and set to null for safety; models can be trained only on role + content.\n\n\t\n\t\t\n\t\tExample usage\n\t\n\nfrom datasets import load_dataset\nds =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tanzirmehedi/tanzirmehedi.","url":"https://huggingface.co/datasets/tanzirmehedi/tanzirmehedi","creator_name":"Sk Tanzir Mehedi","creator_url":"https://huggingface.co/tanzirmehedi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_198","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_198.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_198","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62085","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_62085.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_62085","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_8.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_8","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_193","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/x_dataset_193.","url":"https://huggingface.co/datasets/RentonWEB3/x_dataset_193","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_59332","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_59332.","url":"https://huggingface.co/datasets/momo1942/x_dataset_59332","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_198","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_198.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_198","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62085","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_62085.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_62085","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PathSum-CoT","keyword":"summarization","description":"singhprabhat/PathSum-CoT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/singhprabhat/PathSum-CoT","creator_name":"Prabhat Singh","creator_url":"https://huggingface.co/singhprabhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"PathSum-CoT","keyword":"summarization","description":"singhprabhat/PathSum-CoT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/singhprabhat/PathSum-CoT","creator_name":"Prabhat Singh","creator_url":"https://huggingface.co/singhprabhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"benchname-module-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tü•∑ BenchName (Module summarization)\n\t\n\nThis is the benchmark for Module summarization task as part of the\nü•∑ BenchName benchmark. \nThe current version includes 216 manually curated text files describing different documentation of open-source permissive Python projects. \nThe model is required to generate such description, given the relevant context code and the intent behind the documentation.\nAll the repositories are published under permissive licenses (MIT, Apache-2.0, BSD-3-Clause‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anon-iclr-submission/benchname-module-summarization.","url":"https://huggingface.co/datasets/anon-iclr-submission/benchname-module-summarization","creator_name":"Anon Authors","creator_url":"https://huggingface.co/anon-iclr-submission","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0605250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0605250.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0605250","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsjcm/x_dataset_28.","url":"https://huggingface.co/datasets/gsjcm/x_dataset_28","creator_name":"gsjcmurn","creator_url":"https://huggingface.co/gsjcm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MECAT-Caption","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks\n\t\n\nüìñ Paper | üõ†Ô∏è GitHub |  üîä MECAT-Caption Dataset |  üîä MECAT-QA Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMECAT (Multi-Expert Chain for Audio Tasks) is a comprehensive benchmark constructed on large-scale data to evaluate machine understanding of audio content through two core tasks:\n\nAudio Captioning: Generating textual descriptions for given audio\nAudio Question Answering: Answering questions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mispeech/MECAT-Caption.","url":"https://huggingface.co/datasets/mispeech/MECAT-Caption","creator_name":"Horizon Team, Xiaomi MiLM Plus","creator_url":"https://huggingface.co/mispeech","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-text-to-text","summarization","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"NorSumm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tconfigs:\n- config_name: default\n  data_files:\n  - split: dev\n    path: \"NorSumm_dev.json\"\n  - split: test\n    path: \"NorSumm_test.json\"\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis repository contains the Norwegian Summarisation Benchmark Dataset, which consists of 378 human-authored summaries from prominent Norwegian news sources across various domains. The dataset is designed to benchmark the abstractive summarisation capabilities of generative language models. NorSumm is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SamiaT/NorSumm.","url":"https://huggingface.co/datasets/SamiaT/NorSumm","creator_name":"Samia Touileb","creator_url":"https://huggingface.co/SamiaT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Norwegian Bokm√•l","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0605250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0605250.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0605250","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsjcm/x_dataset_28.","url":"https://huggingface.co/datasets/gsjcm/x_dataset_28","creator_name":"gsjcmurn","creator_url":"https://huggingface.co/gsjcm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_187","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/reddit_dataset_187.","url":"https://huggingface.co/datasets/vouu/reddit_dataset_187","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_36","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_36.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_36","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Formated-openai-function-invocations-20k-with-greetings","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is the formated version of the Isaak-Carter/Openai-function-invocations-20k-with-greetings dataset.\nThis dataset, uniquely structured with custom special tokens, is meticulously crafted to train language models in complex function invocation and time-contextualized interactions. Each \"sample\" in the dataset contains a sequence of elements: function definitions, user prompts, function calls, function responses, and the assistant's responses. These elements are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Goekdeniz-Guelmez/Formated-openai-function-invocations-20k-with-greetings.","url":"https://huggingface.co/datasets/Goekdeniz-Guelmez/Formated-openai-function-invocations-20k-with-greetings","creator_name":"G√∂kdeniz G√ºlmez","creator_url":"https://huggingface.co/Goekdeniz-Guelmez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_187","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/reddit_dataset_187.","url":"https://huggingface.co/datasets/vouu/reddit_dataset_187","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_36","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_36.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_36","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_102","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/x_dataset_102.","url":"https://huggingface.co/datasets/GSKCM24/x_dataset_102","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/x_dataset_18.","url":"https://huggingface.co/datasets/roknedin/x_dataset_18","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_102","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/x_dataset_102.","url":"https://huggingface.co/datasets/GSKCM24/x_dataset_102","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/x_dataset_18.","url":"https://huggingface.co/datasets/roknedin/x_dataset_18","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0109104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0109104.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0109104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0109104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0109104.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0109104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PyThagoreans-Merged","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPyThagoreans Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe PyThagoreans dataset is a comprehensive collection of math problems and their solutions, designed to assist in learning and practicing mathematical problem-solving. This dataset includes a variety of problems, expected answers, and predicted answers, making it a valuable resource for students, educators, and researchers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText: The dataset primarily contains text data, including math‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged.","url":"https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44100","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_44100.","url":"https://huggingface.co/datasets/icedwind/x_dataset_44100","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"engineering_design_facts","keyword":"summarization","description":"Dataset Copyright - L. Siddharth, Singapore University of Technology and Design, Singapore.\nThe dataset includes 375,084 example sentences (187200 positive, 187884 negative), each including a pair of entities and the engineering design relation between these.\nThe dataset was manually constructed using sentences in 4,205 patents granted by USPTO, stratified according to 130 classes.\nThe dataset is used to train token classification and Seq2Seq transformer models to populate explicit engineering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/siddharthl1293/engineering_design_facts.","url":"https://huggingface.co/datasets/siddharthl1293/engineering_design_facts","creator_name":"Sid","creator_url":"https://huggingface.co/siddharthl1293","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","text2text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations_cleaned","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset (cleaned)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44100","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_44100.","url":"https://huggingface.co/datasets/icedwind/x_dataset_44100","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"vietnamese-poem-context","keyword":"summarization","description":"lunovian/vietnamese-poem-context dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lunovian/vietnamese-poem-context","creator_name":"Nguyen Xuan An","creator_url":"https://huggingface.co/lunovian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","feature-extraction","sentence-similarity","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_8.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_8","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"News-Summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmanDev/News-Summary.","url":"https://huggingface.co/datasets/EmanDev/News-Summary","creator_name":"M Eman Khadim","creator_url":"https://huggingface.co/EmanDev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_8.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_8","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"vietnamese-poem-context","keyword":"summary","description":"lunovian/vietnamese-poem-context dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lunovian/vietnamese-poem-context","creator_name":"Nguyen Xuan An","creator_url":"https://huggingface.co/lunovian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","feature-extraction","sentence-similarity","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_132","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_132.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_132","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"pubmed-abstract-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tContext\n\t\n\nThis dataset contains 4,331 pairs of biomedical research abstracts and their one-sentence summaries. \nEach abstract is paired with a concise summary that captures the key findings, methods, and significance of the research.\n","url":"https://huggingface.co/datasets/pieetie/pubmed-abstract-summary","creator_name":"Pierre NATIEZ","creator_url":"https://huggingface.co/pieetie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2983","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_2983.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_2983","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_13.","url":"https://huggingface.co/datasets/suul999922/x_dataset_13","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_132","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_132.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_132","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2983","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_2983.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_2983","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_13.","url":"https://huggingface.co/datasets/suul999922/x_dataset_13","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"pubmed-abstract-summary","keyword":"summary","description":"\n\t\n\t\t\n\t\tContext\n\t\n\nThis dataset contains 4,331 pairs of biomedical research abstracts and their one-sentence summaries. \nEach abstract is paired with a concise summary that captures the key findings, methods, and significance of the research.\n","url":"https://huggingface.co/datasets/pieetie/pubmed-abstract-summary","creator_name":"Pierre NATIEZ","creator_url":"https://huggingface.co/pieetie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"summary-map-reduce-v1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tsummary-map-reduce-v1\n\t\n\nA dataset for training text-to-text models to consolidate multiple summaries from a chunked long document in the \"reduce\" step of map-reduce summarization \n\n\t\n\t\t\n\t\tAbout\n\t\n\nEach example contains chunked summaries from a long document, concatenated into a single string with \\n\\n as delimiter (input_summaries), and their synthetically generated consolidated/improved version (final_summary).\nThe consolidation step focuses on\n\nMerge redundant information while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/summary-map-reduce-v1.","url":"https://huggingface.co/datasets/pszemraj/summary-map-reduce-v1","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"options-trading","keyword":"summarization","description":"Hanifnezhad/options-trading dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hanifnezhad/options-trading","creator_name":"Nezhad","creator_url":"https://huggingface.co/Hanifnezhad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_37","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_37.","url":"https://huggingface.co/datasets/gk4u/x_dataset_37","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_27.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_27","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_225","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Den4ikkk/reddit_dataset_225.","url":"https://huggingface.co/datasets/Den4ikkk/reddit_dataset_225","creator_name":"Staff","creator_url":"https://huggingface.co/Den4ikkk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2020-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2020 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2020 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2020-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_37","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_37.","url":"https://huggingface.co/datasets/gk4u/x_dataset_37","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_27.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_27","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_225","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Den4ikkk/reddit_dataset_225.","url":"https://huggingface.co/datasets/Den4ikkk/reddit_dataset_225","creator_name":"Staff","creator_url":"https://huggingface.co/Den4ikkk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2020-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2020 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2020 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2020-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_34","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/x_dataset_34.","url":"https://huggingface.co/datasets/zengsdfew/x_dataset_34","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summary","keyword":"summarization","description":"soham0507/summary dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/soham0507/summary","creator_name":"soham mhatre","creator_url":"https://huggingface.co/soham0507","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","afl-3.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_34","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/x_dataset_34.","url":"https://huggingface.co/datasets/zengsdfew/x_dataset_34","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_44.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_44","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_211","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_211.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_211","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_44.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_44","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_211","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_211.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_211","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070439","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070439.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070439","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070439","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070439.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070439","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_8th","keyword":"summarization","description":"KadamParth/NCERT_Social_Studies_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"after_visit_summary_simulated_edits","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card: AVS edits Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nThe AVS edits dataset is designed to support human feedback research in for clinical summarization. It contains synthetic edit feedback generated by large language models (LLMs) to improve the factual consistency and quality of summaries. The dataset includes training, evaluation, and test splits with specific fields for modeling and evaluation tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTrain Split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PrabhakarSai/after_visit_summary_simulated_edits.","url":"https://huggingface.co/datasets/PrabhakarSai/after_visit_summary_simulated_edits","creator_name":"Sai","creator_url":"https://huggingface.co/PrabhakarSai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","reinforcement-learning","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"after_visit_summary_simulated_edits","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card: AVS edits Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nThe AVS edits dataset is designed to support human feedback research in for clinical summarization. It contains synthetic edit feedback generated by large language models (LLMs) to improve the factual consistency and quality of summaries. The dataset includes training, evaluation, and test splits with specific fields for modeling and evaluation tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTrain Split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PrabhakarSai/after_visit_summary_simulated_edits.","url":"https://huggingface.co/datasets/PrabhakarSai/after_visit_summary_simulated_edits","creator_name":"Sai","creator_url":"https://huggingface.co/PrabhakarSai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","reinforcement-learning","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_14.","url":"https://huggingface.co/datasets/suul999922/x_dataset_14","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"mm-interp-CompCap-gpt4-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCompCap-GPT4: A GPT-4 Captioned Version of CompCap-118K\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: CompCap: Improving Multimodal Large Language Models with Composite Captions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDownload Options\n\t\n\n\nDirect Download:The repository includes CI_type.zip and CI_type.json. The JSON file follows the Llava format:\n{\n  \"id\": ID,\n  \"image\": IMAGE_PATH,\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": QUESTION},\n    {\"from\": \"gpt\", \"value\": ANSWER}\n  ]\n}\n\n\nUsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/htlou/mm-interp-CompCap-gpt4-data.","url":"https://huggingface.co/datasets/htlou/mm-interp-CompCap-gpt4-data","creator_name":"LHT","creator_url":"https://huggingface.co/htlou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_14.","url":"https://huggingface.co/datasets/suul999922/x_dataset_14","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"llm-failure-dataset","keyword":"summarization","description":"Ki-Seki/llm-failure-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ki-Seki/llm-failure-dataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","zero-shot-classification","translation"],"keywords_longer_than_N":true},
	{"name":"GreekWikipedia","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGreekWikipedia\n\t\n\nA Greek abstractive summarization dataset collected from the Greek part of Wikipedia, which contains 93,432 articles, their titles and summaries.\nThis dataset has been used to train our best-performing model GreekWiki-umt5-base as part of our upcoming research article:Giarelis, N., Mastrokostas, C., & Karacapilidis, N. (2024) Greek Wikipedia: A Study on Abstractive Summarization.For information about dataset creation, limitations etc. see the original article.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IMISLab/GreekWikipedia.","url":"https://huggingface.co/datasets/IMISLab/GreekWikipedia","creator_name":"IMIS Lab UPatras","creator_url":"https://huggingface.co/IMISLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text2text-generation","Greek","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ChartX","keyword":"summarization","description":"\n\nChartX & ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning\n\n[ Related Paper ] [ Website ] [Models ü§ó(Hugging Face)]\n\n\n\n\t\n\t\t\n\t\tChartX & ChartVLM\n\t\n\nRecently, many versatile Multi-modal Large Language Models (MLLMs) have emerged continuously. However, their capacity to query information depicted in visual charts and engage in reasoning based on the queried contents remains under-explored. In this paper, to comprehensively and rigorously benchmark the ability‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/U4R/ChartX.","url":"https://huggingface.co/datasets/U4R/ChartX","creator_name":"Alpha-Innovator Lab","creator_url":"https://huggingface.co/U4R","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","table-question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"PyCodeZone","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPyCodeZone Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe PyCodeZone dataset is a collection of Python code snippets and instructions designed to assist in learning and practicing Python programming. This dataset includes various coding tasks, examples, and solutions, making it a valuable resource for both beginners and experienced programmers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText: The dataset primarily contains text data, including Python code snippets and instructions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/PyCodeZone.","url":"https://huggingface.co/datasets/prithivMLmods/PyCodeZone","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_6.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_6","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_49","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_49.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_49","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_152","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/synapz/reddit_dataset_152.","url":"https://huggingface.co/datasets/synapz/reddit_dataset_152","creator_name":"Derek Barnes","creator_url":"https://huggingface.co/synapz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_192","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crystal1101/reddit_dataset_192.","url":"https://huggingface.co/datasets/Crystal1101/reddit_dataset_192","creator_name":"Butterfly","creator_url":"https://huggingface.co/Crystal1101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_13.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_13","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_107","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightbeam888/reddit_dataset_107.","url":"https://huggingface.co/datasets/lightbeam888/reddit_dataset_107","creator_name":"Ryan Orino","creator_url":"https://huggingface.co/lightbeam888","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-douanes-mayotte","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des douanes de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_247","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zevebe/reddit_dataset_247.","url":"https://huggingface.co/datasets/zevebe/reddit_dataset_247","creator_name":"Andrea","creator_url":"https://huggingface.co/zevebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"epsinas-release-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRelease data for epsinas\n\t\n\nRelease data for the results reported in the epsinas paper: arxiv.org/abs/2302.04406.\n\n\t\n\t\t\n\t\tContents\n\t\n\nContains the results of the experiments with NAS-Bench-101, NAS-Bench-201 and NAS-Bench NLP benchmark NAS spaces.\nWe provide pickle data files and figures for the main epsinas evaluation and ablation studies.\nThe files are split according to the search space.\nDepending on the benchmark, the directories may contain:\n\nevaluation. Evaluation of epsinas for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/egracheva/epsinas-release-data.","url":"https://huggingface.co/datasets/egracheva/epsinas-release-data","creator_name":"Ekaterina","creator_url":"https://huggingface.co/egracheva","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","Document"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_6.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_6","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_49","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_49.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_49","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_152","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/synapz/reddit_dataset_152.","url":"https://huggingface.co/datasets/synapz/reddit_dataset_152","creator_name":"Derek Barnes","creator_url":"https://huggingface.co/synapz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_192","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crystal1101/reddit_dataset_192.","url":"https://huggingface.co/datasets/Crystal1101/reddit_dataset_192","creator_name":"Butterfly","creator_url":"https://huggingface.co/Crystal1101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_13","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_13.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_13","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_107","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightbeam888/reddit_dataset_107.","url":"https://huggingface.co/datasets/lightbeam888/reddit_dataset_107","creator_name":"Ryan Orino","creator_url":"https://huggingface.co/lightbeam888","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_247","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zevebe/reddit_dataset_247.","url":"https://huggingface.co/datasets/zevebe/reddit_dataset_247","creator_name":"Andrea","creator_url":"https://huggingface.co/zevebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0510248","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0510248.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0510248","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0510248","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0510248.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0510248","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ETF-CodeSumEval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCodeSumEval Dataset\n\t\n\nAn annotated dataset for studying hallucination in code summarization. Each sample consists of a Java code snippet, a generated summary from a large language model, and detailed annotations marking entity-level correctness and hallucination causes.\n\n\n\t\n\t\t\n\t\tüìñ Overview\n\t\n\nCodeSumEval is a first-of-its-kind dataset designed to evaluate and analyze hallucinations in code summarization. It comprises:\n\n411 generated summaries of Java methods, produced by 7 different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kishanmaharaj/ETF-CodeSumEval.","url":"https://huggingface.co/datasets/kishanmaharaj/ETF-CodeSumEval","creator_name":"Kishan Maharaj","creator_url":"https://huggingface.co/kishanmaharaj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"code-juridictions-financieres","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des juridictions financi√®res, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_236","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/reddit_dataset_236.","url":"https://huggingface.co/datasets/bersov75/reddit_dataset_236","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46092","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_46092.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_46092","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24589","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_24589.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_24589","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la L√©gion d'honneur, de la M√©daille militaire et de l'ordre national du M√©rite, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NCERT_Accounting_12th","keyword":"summarization","description":"KadamParth/NCERT_Accounting_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Accounting_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_236","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/reddit_dataset_236.","url":"https://huggingface.co/datasets/bersov75/reddit_dataset_236","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46092","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_46092.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_46092","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24589","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_24589.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_24589","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_3.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_3","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_232","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_232.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_232","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_551805","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_551805.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_551805","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050348","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050348.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050348","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_3.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_3","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_232","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_232.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_232","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_551805","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_551805.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_551805","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050348","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050348.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050348","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"x_dataset_225","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISOMA-Bittensor/x_dataset_225.","url":"https://huggingface.co/datasets/AISOMA-Bittensor/x_dataset_225","creator_name":"Murat Durmus","creator_url":"https://huggingface.co/AISOMA-Bittensor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_151","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/reddit_dataset_151.","url":"https://huggingface.co/datasets/williamlewis0620/reddit_dataset_151","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"traffic-dispute-mediation-cases","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüöó Korean Traffic Dispute Mediation Cases Dataset\n\t\n\nThis dataset provides a comprehensive collection of 226 traffic accident fault ratio dispute cases from Korean Automobile Insurance Association (KNIA), focusing on traffic accidents, fault determination, and mediation outcomes. It is suitable for traffic-legal NLP, fault analysis, mediation outcome prediction, and automotive AI applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nTotal Records: 226\nLanguage: Korean (ko)\nFields: 9‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ducut91/traffic-dispute-mediation-cases.","url":"https://huggingface.co/datasets/ducut91/traffic-dispute-mediation-cases","creator_name":"lim eul young","creator_url":"https://huggingface.co/ducut91","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_225","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISOMA-Bittensor/x_dataset_225.","url":"https://huggingface.co/datasets/AISOMA-Bittensor/x_dataset_225","creator_name":"Murat Durmus","creator_url":"https://huggingface.co/AISOMA-Bittensor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_151","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/reddit_dataset_151.","url":"https://huggingface.co/datasets/williamlewis0620/reddit_dataset_151","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"automotive_requirements","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for autoReq\n\t\n\n\n\t\n\t\t\n\t\tImporting dataset into Python environment\n\t\n\nUse the following code chunk to import the dataset into a Python environment as a DataFrame. \n","url":"https://huggingface.co/datasets/ron164/automotive_requirements","creator_name":"Rohan Ijare","creator_url":"https://huggingface.co/ron164","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LimAgents_limitation_data_scientific_papers_with_cited_papers","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLimAgents Data\n\t\n\nThis dataset contains scientific paper metadata and extracted limitation information prepared for use with LLM Agents.The data comes from NeurIPS 2021‚Äì2022 papers and related OpenReview reviews, enriched with Cited in and Cited by information.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe repository contains two main directories:\n\n\t\n\t\t\n\t\t1. NeurIPS_21_22_Lim_OPR_with_cited_in_by_papers\n\t\n\nThis directory includes one JSON file per paper. Each file contains:\n\ntitle: Original paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iaadlab/LimAgents_limitation_data_scientific_papers_with_cited_papers.","url":"https://huggingface.co/datasets/iaadlab/LimAgents_limitation_data_scientific_papers_with_cited_papers","creator_name":"iaadlab","creator_url":"https://huggingface.co/iaadlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","summarization","question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-articles","keyword":"summarization","description":"maikerdr/brazilian-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/maikerdr/brazilian-news-articles","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"Math-Solve-Singleshot","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMath-Solve-Singleshot\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset, named Math-Solve-Singleshot, is designed for solving single-shot mathematical problems. It contains a variety of math problems formatted in text, suitable for training and evaluating models on mathematical reasoning tasks.\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText\nFormats: CSV\nSize: 1.05M rows\nLibraries: pandas\n\n\nCroissant\nLicense: Apache-2.0\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTrain Split: 1.05 million rows\nProblem String Lengths:\nLength 1: 16‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot.","url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_18.","url":"https://huggingface.co/datasets/suul999922/x_dataset_18","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_18.","url":"https://huggingface.co/datasets/suul999922/x_dataset_18","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cherry-juice-guide","keyword":"summarization","description":"Dataset Details\nDataset Description\nThis dataset is derived from The Ultimate Tart Cherry Juice Buyer‚Äôs Guide. It organizes information about tart cherry juice concentrate into a structured format, including dosage, dilution ratios, concentration levels (Brix), sourcing, certifications, storage, and documented health benefits.\nIt is designed to support AI training, information retrieval, question-answering, consumer education, and market research.\nCurated by: Traverse Bay Farms / Fruit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WindingIdeas/cherry-juice-guide.","url":"https://huggingface.co/datasets/WindingIdeas/cherry-juice-guide","creator_name":"Winding Ideas","creator_url":"https://huggingface.co/WindingIdeas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","text-generation","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"bank-of-ghana-rates","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nBank of Ghana historical and real-time exchange rates data. Bank of Ghana\nClick Here:\n\n\t\n\t\t\n\t\tData Format\n\t\n\n{\n    \"date\": \"...\", \n    \"currency\": \"...\", \n    \"currency_pair\": \"...\", \n    \"buying\": \"...\", \n    \"selling\": \"...\", \n    \"mid_rate\": \"...\"\n}\n\n\n\t\n\t\t\n\t\tLoad Dataset\n\t\n\npip install datasets\n\nfrom datasets import load_dataset\n\nrates = load_dataset(\"worldboss/bank-of-ghana-rates\", split=\"train\")\n\npd.DataFrame(rates).head()\n\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nThe data was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/bank-of-ghana-rates.","url":"https://huggingface.co/datasets/worldboss/bank-of-ghana-rates","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0203106","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0203106.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0203106","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0401151","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0401151.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0401151","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0203106","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0203106.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0203106","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0401151","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0401151.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0401151","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Medicines","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Medicines Data\n\t\n\n\nThis dataset contains information about various diseases, prescription medicines, their prices, manufacturers, and other relevant details scraped from an online pharmacy website. It provides structured insights into different medications, including their availability, prescription requirements, manufacturers, active ingredients, and potential side effects.\nThe dataset also contains introduction and detailed description of the medicine, including‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kaysss/Medicines.","url":"https://huggingface.co/datasets/kaysss/Medicines","creator_name":"Singla","creator_url":"https://huggingface.co/kaysss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_8th","keyword":"summarization","description":"KadamParth/NCERT_Science_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"job-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nJobStreet Job Postings Dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset compiles a comprehensive range of job listings from JobStreet, offering a detailed view of the current employment landscape across various industries in Malaysia. It includes key features such as unique job IDs, titles, company names, locations, job roles, categories, subcategories, job types, salaries, and detailed descriptions. The motivation behind‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azrai99/job-dataset.","url":"https://huggingface.co/datasets/azrai99/job-dataset","creator_name":"Azrai Mahadan","creator_url":"https://huggingface.co/azrai99","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dataset-1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Custom Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Name\n\t\n\nCustom CNN/Daily Mail Summarization Dataset\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a custom version of the CNN/Daily Mail dataset, designed for text summarization tasks. It contains news articles and their corresponding summaries.\n\n\t\n\t\t\n\t\tComposition\n\t\n\nThe dataset consists of two splits:\n\nTrain: 1 custom example\nTest: 100 examples from the original CNN/Daily Mail dataset\n\nEach example contains:\n\n'sentence': The full text of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/privetin/dataset-1.","url":"https://huggingface.co/datasets/privetin/dataset-1","creator_name":"ÍπÄÏ†ïÏÑù","creator_url":"https://huggingface.co/privetin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_3.","url":"https://huggingface.co/datasets/suul999922/x_dataset_3","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_3.","url":"https://huggingface.co/datasets/suul999922/x_dataset_3","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMSA-Darija Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"EMINES/summarized-darija-msa-wiki-data\")\n\n# Example usage\nfor example in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMSA-Darija Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"EMINES/summarized-darija-msa-wiki-data\")\n\n# Example usage\nfor example in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"code-environnement","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'environnement, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"v4_nuclear_power_articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Nuclear News V4 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nuclear News V4 Dataset is a multilingual dataset consisting of 33,104 unique news articles sourced from 12 online news platforms across the Visegr√°d Group (V4) countries ‚Äî Poland, Czech Republic, Slovakia, and Hungary ‚Äî published between 1998 and 2025.\nThe goal of the dataset is to analyze media narratives surrounding nuclear energy in Central Europe.\nWhile the dataset does not contain human-annotated (golden)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eoplumbum/v4_nuclear_power_articles.","url":"https://huggingface.co/datasets/eoplumbum/v4_nuclear_power_articles","creator_name":"Edyta","creator_url":"https://huggingface.co/eoplumbum","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Polish","Hungarian","Slovak"],"keywords_longer_than_N":true},
	{"name":"v4_nuclear_power_articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Nuclear News V4 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nuclear News V4 Dataset is a multilingual dataset consisting of 33,104 unique news articles sourced from 12 online news platforms across the Visegr√°d Group (V4) countries ‚Äî Poland, Czech Republic, Slovakia, and Hungary ‚Äî published between 1998 and 2025.\nThe goal of the dataset is to analyze media narratives surrounding nuclear energy in Central Europe.\nWhile the dataset does not contain human-annotated (golden)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eoplumbum/v4_nuclear_power_articles.","url":"https://huggingface.co/datasets/eoplumbum/v4_nuclear_power_articles","creator_name":"Edyta","creator_url":"https://huggingface.co/eoplumbum","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Polish","Hungarian","Slovak"],"keywords_longer_than_N":true},
	{"name":"stories-elements","keyword":"summarization","description":"\n\t\n\t\t\n\t\tStories Narrative Elements\n\t\n\nThis dataset contains stories from agentlans/stories-refinement annotated with key narrative elements‚Äîtitle, characters, setting, plot stages, themes, and full text‚Äîin a structured format.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource: Stories from agentlans/stories-refinement.\nAnnotations: Generated using agentlans/Llama3.1-LexiHermes-SuperStorm with 10-shot learning, guided by 15 example analyses by Claude Sonnet 4.\nLegacy Data: The zero-shot.jsonl.zst file contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stories-elements.","url":"https://huggingface.co/datasets/agentlans/stories-elements","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aaron927dev/x_dataset_250.","url":"https://huggingface.co/datasets/aaron927dev/x_dataset_250","creator_name":"William Hudson","creator_url":"https://huggingface.co/aaron927dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aaron927dev/x_dataset_250.","url":"https://huggingface.co/datasets/aaron927dev/x_dataset_250","creator_name":"William Hudson","creator_url":"https://huggingface.co/aaron927dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"InstAr-500k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"InstAr-500k\"\n\t\n\nThe dataset comprises almost 500,000 Arabic instructions and responses designed for fine-tuning large language models (LLMs) for Arabic NLP tasks. It includes a combination of synthetic and human-crafted data across various domains and instruction types. This extensive dataset aims to improve the performance of LLMs on Arabic-specific tasks\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n  \n    Type\n    Task\n    Number of Samples\n    Percentage of Samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ClusterlabAi/InstAr-500k.","url":"https://huggingface.co/datasets/ClusterlabAi/InstAr-500k","creator_name":"ClusterlabAi","creator_url":"https://huggingface.co/ClusterlabAi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-civil","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode civil, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"aifgen","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for aif-gen static dataset\n\t\n\n\n\nThis dataset is a set of static RLHF datasets used to generate continual RLHF datasets for benchmarking Lifelong RL on language models. \nThe data used in the paper can be found under the directory 4omini_generation and the rest are included for reference and are used in the experiments for the paper.\nThe continual datasets created for benchmarking can be found with their dataset cards in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tContextual Text Anonymizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\n\n\t\n\t\t\n\t\tDocument Types\n\t\n\nThe dataset includes examples from the following categories:\n\nMedical records\nBanking documents\nBusiness correspondence\nRecruitment documents\nSocial media content\nLegal documents\nEducational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset.","url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"Micha≈Ç Kurkowski","creator_url":"https://huggingface.co/kurkowski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","token-classification","named-entity-recognition","text-simplification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0309155","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0309155.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0309155","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0309155","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0309155.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0309155","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_21.","url":"https://huggingface.co/datasets/suul999922/x_dataset_21","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39138","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_39138.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_39138","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_9.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_9","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_154","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_154.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_154","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_71","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/reddit_dataset_71.","url":"https://huggingface.co/datasets/suul999922/reddit_dataset_71","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"openrelay-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenRelay Dataset\n\t\n\nThe OpenRelay Dataset is a collection of curated articles, tool reviews, user comments, and productivity-related content sourced from the OpenRelay platform. It‚Äôs designed to support training and evaluation of machine learning models for tasks such as text classification, summarization, semantic search, and question answering in the context of tech and productivity tools.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset may include fields like:\n\ntitle:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openrelay/openrelay-dataset.","url":"https://huggingface.co/datasets/openrelay/openrelay-dataset","creator_name":"openrelay","creator_url":"https://huggingface.co/openrelay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_21.","url":"https://huggingface.co/datasets/suul999922/x_dataset_21","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39138","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_39138.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_39138","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_9.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_9","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_154","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_154.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_154","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_71","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/reddit_dataset_71.","url":"https://huggingface.co/datasets/suul999922/reddit_dataset_71","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"protein_interactions_LLM_FT_dataset","keyword":"summarization","description":"This dataset is derived from the ANDDigest database and contains PubMed abstracts with dictionary-mapped protein names. A total of >15,000 abstracts were selected, yielding 6,516 unique protein pairs with associative edges in the ANDSystem network. The corpus was split into positive and negative samples. Positive samples represent documents where a protein interaction was identified using the rules-based approach of ANDSystem‚Äôs text-mining module, while negative samples include documents where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Timofey/protein_interactions_LLM_FT_dataset.","url":"https://huggingface.co/datasets/Timofey/protein_interactions_LLM_FT_dataset","creator_name":"Timofey Ivanisenko","creator_url":"https://huggingface.co/Timofey","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_295492","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_295492.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_295492","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_010613","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_010613.","url":"https://huggingface.co/datasets/william-1111/x_dataset_010613","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_295492","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_295492.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_295492","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_010613","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_010613.","url":"https://huggingface.co/datasets/william-1111/x_dataset_010613","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-impositions-biens-services","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des impositions sur les biens et services, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_888","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_888.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_888","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"WhoDunIt","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for WHODUNIT: Evaluation Benchmark for Culprit Detection in Mystery Stories\n\t\n\nThis dataset contains crime and mystery novels along with their metadata. Each entry includes the full text, title, author, book length, and a list of identified culprits. Additionally, an augmented version of the dataset introduces entity replacements and synthetic data variations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: WhoDunIt Evaluation Benchmark\n\n\n\t\n\t\t\n\t\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kjgpta/WhoDunIt.","url":"https://huggingface.co/datasets/kjgpta/WhoDunIt","creator_name":"Kshitij Gupta","creator_url":"https://huggingface.co/kjgpta","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_888","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_888.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_888","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"news-articles-summarization","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"text-simplification","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"exorde-social-media-december-2024-week1","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-december-2024-week1","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-retrieval","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"Sailcompass_data","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tSailCompass: Towards Reproducible and Robust Evaluation for Southeast Asian Languages\n\t\n\nThis repository provides the dataset for evaluation SEA large language model.\n\nProject Website: sailorllm.github.io\nCodebase: https://github.com/sail-sg/sailcompass\n\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgment\n\t\n\nThanks to the contributors of the opencompass.\n\n\t\n\t\t\n\t\n\t\n\t\tCiting this work\n\t\n\nIf you use this repository or sailor models, please cite\n@misc{sailcompass,\n      title={SailCompass: Towards Reproducible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sail/Sailcompass_data.","url":"https://huggingface.co/datasets/sail/Sailcompass_data","creator_name":"Sea AI Lab","creator_url":"https://huggingface.co/sail","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","table-question-answering","multiple-choice"],"keywords_longer_than_N":true},
	{"name":"NCERT_Socialogy_12th","keyword":"summarization","description":"KadamParth/NCERT_Socialogy_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Socialogy_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_1234","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_1234.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_1234","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_33945","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_33945.","url":"https://huggingface.co/datasets/momo1942/x_dataset_33945","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summarization_gl","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for summarization_gl\n\t\n\n\n\nsummarization_gl is a dataset in Galician language that contains automatically extracted summaries and their corresponding texts from the following Galician websites: N√≥s Diario, Que pasa na costa and Praza p√∫blica.\nIt has a total of 80.829 items. Each item contains an id, a summary and its corresponding text, see below for more details.\n\nCurated by: Proxecto N√≥s\nLanguage(s) (NLP): Galician\nLicense: CC BY 4.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/proxectonos/summarization_gl.","url":"https://huggingface.co/datasets/proxectonos/summarization_gl","creator_name":"Proxecto N√≥s","creator_url":"https://huggingface.co/proxectonos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Galician","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_1234","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_1234.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_1234","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_33945","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_33945.","url":"https://huggingface.co/datasets/momo1942/x_dataset_33945","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summarization_gl","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for summarization_gl\n\t\n\n\n\nsummarization_gl is a dataset in Galician language that contains automatically extracted summaries and their corresponding texts from the following Galician websites: N√≥s Diario, Que pasa na costa and Praza p√∫blica.\nIt has a total of 80.829 items. Each item contains an id, a summary and its corresponding text, see below for more details.\n\nCurated by: Proxecto N√≥s\nLanguage(s) (NLP): Galician\nLicense: CC BY 4.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/proxectonos/summarization_gl.","url":"https://huggingface.co/datasets/proxectonos/summarization_gl","creator_name":"Proxecto N√≥s","creator_url":"https://huggingface.co/proxectonos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Galician","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_53989","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_53989.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_53989","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_58.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_58","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_53989","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_53989.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_53989","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_58.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_58","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"gretel-financial-risk-analysis-v1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated by fine-tuning Phi-3-mini-128k-instruct on 14,306 SEC filings (10-K, 10-Q, and 8-K) from 2023-2024, utilizing differential privacy. It is designed for training models to extract key risk factors and generate structured summaries from financial documents while demonstrating the application of differential privacy to safeguard sensitive information.\nThis dataset showcases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_26.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_26","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_151","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/x_dataset_151.","url":"https://huggingface.co/datasets/williamlewis0620/x_dataset_151","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-collectivites-territoriales","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des collectivit√©s territoriales, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"gretel-financial-risk-analysis-v1","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated by fine-tuning Phi-3-mini-128k-instruct on 14,306 SEC filings (10-K, 10-Q, and 8-K) from 2023-2024, utilizing differential privacy. It is designed for training models to extract key risk factors and generate structured summaries from financial documents while demonstrating the application of differential privacy to safeguard sensitive information.\nThis dataset showcases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_26.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_26","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_151","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/x_dataset_151.","url":"https://huggingface.co/datasets/williamlewis0620/x_dataset_151","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24095","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_24095.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_24095","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iv","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe IV, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17276","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_17276.","url":"https://huggingface.co/datasets/momo1942/x_dataset_17276","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-forestier-nouveau","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode forestier (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24095","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_24095.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_24095","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17276","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_17276.","url":"https://huggingface.co/datasets/momo1942/x_dataset_17276","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MDCure-36k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMDCure-36k\n\t\n\nüìÑ Paper | ü§ó HF Collection | ‚öôÔ∏è GitHub Repo\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nMDCure is an effective and scalable procedure for generating high-quality multi-document (MD) instruction tuning data to improve MD capabilities of LLMs. Using MDCure, we construct a suite of MD instruction datasets complementary to collections such as FLAN and fine-tune a variety of already instruction-tuned LLMs from the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in size. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yale-nlp/MDCure-36k.","url":"https://huggingface.co/datasets/yale-nlp/MDCure-36k","creator_name":"Yale NLP Lab","creator_url":"https://huggingface.co/yale-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_52806","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_52806.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_52806","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"smol-smoltalk-plus-reasoning-synthetic-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Smol-Smoltalk Plus Reasoning\n\t\n\n\nThis is a project to make a fork of HuggingFaceTB/smol-smoltalk which includes reasoning data generated using HuggingFaceTB/SmolLM2-1.7B-Instruct.\nThis is a work in progress. I ran a proof of concept on a small subset and will scale this up as I am able to.\nContributions to scale this up and complete this data are welcome, especially from those with access to more substantial GPU resources.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data.","url":"https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data","creator_name":"David Thrower","creator_url":"https://huggingface.co/david-thrower","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_52806","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_52806.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_52806","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Socialogy_11th","keyword":"summarization","description":"KadamParth/NCERT_Socialogy_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Socialogy_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_7","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_7.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_7","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"page-summarization-eval","keyword":"summarization","description":"Mozilla/page-summarization-eval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mozilla/page-summarization-eval","creator_name":"mozilla","creator_url":"https://huggingface.co/Mozilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_10.","url":"https://huggingface.co/datasets/suul999922/x_dataset_10","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsjcm/reddit_dataset_28.","url":"https://huggingface.co/datasets/gsjcm/reddit_dataset_28","creator_name":"gsjcmurn","creator_url":"https://huggingface.co/gsjcm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"sovereign-states-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tSovereign States Dataset\n\t\n\nThis dataset provides a comprehensive list of sovereign states, along with their common and formal names, membership within the UN system, and details on sovereignty disputes and recognition status. The data was originally scraped from Wikipedia's List of Sovereign States and processed for clarity and usability.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Features\n\t\n\n\nCommon Name: The commonly used name of the country or state.\nFormal Name: The official/formal name of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamramzan/sovereign-states-dataset.","url":"https://huggingface.co/datasets/iamramzan/sovereign-states-dataset","creator_name":"Muhammad Ramzan","creator_url":"https://huggingface.co/iamramzan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_171","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_171.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_171","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_7","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_7.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_7","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_10.","url":"https://huggingface.co/datasets/suul999922/x_dataset_10","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsjcm/reddit_dataset_28.","url":"https://huggingface.co/datasets/gsjcm/reddit_dataset_28","creator_name":"gsjcmurn","creator_url":"https://huggingface.co/gsjcm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_171","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_171.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_171","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sharper740/reddit_dataset_239.","url":"https://huggingface.co/datasets/sharper740/reddit_dataset_239","creator_name":"sharper","creator_url":"https://huggingface.co/sharper740","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_24.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_24","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sharper740/reddit_dataset_239.","url":"https://huggingface.co/datasets/sharper740/reddit_dataset_239","creator_name":"sharper","creator_url":"https://huggingface.co/sharper740","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Shrimad_Bhagvat_Puran","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/snskrt/Shrimad_Bhagvat_Puran","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"MedS-Ins","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHPAI-BSC MedS-Ins\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nCollection of curated data from the MedS-Ins dataset. Used to train Aloe-Beta model.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis is the curated version of the MedS-Ins dataset included in the training set of the Aloe-Beta models. \nFirst, we selected 75 out of the 122 existing tasks, excluding the tasks that were already in the training set, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/MedS-Ins.","url":"https://huggingface.co/datasets/HPAI-BSC/MedS-Ins","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_24.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_24","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0604139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0604139.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0604139","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"high-quality-summary","keyword":"summarization","description":"\nData from agentlans/high-quality-text sample_k10000 configuration\nSummaries generated using google/gemma-3-12b-it\nSummaries rewritten using agentlans/granite-3.3-2b-refiner\nRewritten summaries checked against the original text using ibm-granite/granite-3.3-8b-instruct\n\n","url":"https://huggingface.co/datasets/agentlans/high-quality-summary","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"2021-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2021 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2021 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2021-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0604139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0604139.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0604139","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"high-quality-summary","keyword":"summary","description":"\nData from agentlans/high-quality-text sample_k10000 configuration\nSummaries generated using google/gemma-3-12b-it\nSummaries rewritten using agentlans/granite-3.3-2b-refiner\nRewritten summaries checked against the original text using ibm-granite/granite-3.3-8b-instruct\n\n","url":"https://huggingface.co/datasets/agentlans/high-quality-summary","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"2021-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2021 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2021 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2021-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0409154","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0409154.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0409154","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_14","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_14.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_14","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2024-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2024 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2024 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2024-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"code-energie","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'√©nergie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0409154","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0409154.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0409154","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_14","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_14.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_14","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2024-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2024 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2024 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2024-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060955","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060955.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060955","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_65258","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_65258.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_65258","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060955","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060955.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060955","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_65258","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_65258.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_65258","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CyberExploitDB","keyword":"summarization","description":"model_details:\ndescription:\n  A comprehensive database and analysis tool for cyber exploits, vulnerabilities, and related information. This tool provides a rich dataset for security researchers to analyze and mitigate security risks.\ntask_categories:\n\ndata_analysis\n\nstructure:\n\ndata/\nexploits.csv\nvulnerabilities.csv\n\n\nassets/\nfavicon.svg\n\n\n.streamlit/\nconfig.toml\n\n\nmain.py\ndata_processor.py\nvisualizations.py\nREADME.md\n\nintended_use:\n  Designed for security researchers, developers, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Canstralian/CyberExploitDB.","url":"https://huggingface.co/datasets/Canstralian/CyberExploitDB","creator_name":"Esteban Cara de Sexo","creator_url":"https://huggingface.co/Canstralian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","üá∫üá∏ Region: US","exploits"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36943","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_36943.","url":"https://huggingface.co/datasets/momo1942/x_dataset_36943","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-tourisme","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du tourisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_11.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_11","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"fishkinet-posts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Fishki.net\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Fishki.net, a Russian entertainment and news website. Each entry in the dataset represents a post from the website, including its title, content, author, publication date, tags, images, and URL. The dataset contains 369,180 unique posts covering various topics in entertainment, news, and social media content.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fishkinet-posts.","url":"https://huggingface.co/datasets/nyuuzyou/fishkinet-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","image-classification","summarization","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_32","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/x_dataset_32.","url":"https://huggingface.co/datasets/Axioris/x_dataset_32","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"amharic-news-category-classification","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAmharic News Category Classification\n\t\n\nThis amharic text dataset can be used to train/finetune models for the following tasks\n\nclassification : using the categories \nsummarization : using the headlines\n\n\n\t\n\t\t\n\t\tFinetuning\n\t\n\nHere is a github repo that contains three notebooks that use this dataset to finetune the following models.\n\nxlm-roberta-base : a multilingual transformer model with 280M parameters\nbert-small-amharic : a new amharic version of the bert-small transformer model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rasyosef/amharic-news-category-classification.","url":"https://huggingface.co/datasets/rasyosef/amharic-news-category-classification","creator_name":"Yosef Worku Alemneh","creator_url":"https://huggingface.co/rasyosef","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Amharic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36943","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_36943.","url":"https://huggingface.co/datasets/momo1942/x_dataset_36943","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_11.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_11","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"fishkinet-posts","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Fishki.net\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains posts scraped from Fishki.net, a Russian entertainment and news website. Each entry in the dataset represents a post from the website, including its title, content, author, publication date, tags, images, and URL. The dataset contains 369,180 unique posts covering various topics in entertainment, news, and social media content.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fishkinet-posts.","url":"https://huggingface.co/datasets/nyuuzyou/fishkinet-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","image-classification","summarization","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_32","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/x_dataset_32.","url":"https://huggingface.co/datasets/Axioris/x_dataset_32","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"qmsum-cleaned","keyword":"summarization","description":"\n\t\n\t\t\n\t\tqmsum-cleaned\n\t\n\n\n\t\n\t\t\n\t\tprefixes\n\t\n\nIt's worth noting that each \"document\" in input is prefixed by a question/prompt on what the model is supposed to do. You may want to explicitly handle this in some way, or prefix your models trained on this dataset.\nMost frequent \"prefixes\" separated via sentence-splitter in the train split:\n\n\t\n\t\t\n\nSentence\nCount\n\n\n\t\t\n0\nSummarize the whole meeting.\n121\n\n\n1\nSummarize the meeting\n25\n\n\n2\nWhat did the team discuss about the product cost?\n4\n3\nHow did‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/qmsum-cleaned.","url":"https://huggingface.co/datasets/pszemraj/qmsum-cleaned","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","tau/scrolls","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"snippet-mlsum-500-v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets. \n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nde - German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ntext: a string feature.title: a string feature.teaser:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2.","url":"https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Demo\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a demo dataset with two files train.csv and test.csv.\nLoad it by:\nfrom datasets import load_dataset \ndata_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"} \ndemo = load_dataset(\"stevhliu/demo\", data_files=data_files)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stevhliu/demo.","url":"https://huggingface.co/datasets/stevhliu/demo","creator_name":"Steven Liu","creator_url":"https://huggingface.co/stevhliu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"snippet-mlsum-500","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Snippet-MLSUM-500\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets. \n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nde - German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ntext: a string feature.title: a string feature.teaser: a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/snippet-mlsum-500.","url":"https://huggingface.co/datasets/snipaid/snippet-mlsum-500","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pair\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a pre-processed version of the OpenOrca dataset.\nThe original OpenOrca dataset is a collection of augmented FLAN data that aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing preference-tuned model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe OrcaDPO Pair‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceH4/orca_dpo_pairs.","url":"https://huggingface.co/datasets/HuggingFaceH4/orca_dpo_pairs","creator_name":"Hugging Face H4","creator_url":"https://huggingface.co/HuggingFaceH4","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_collection","keyword":"summarization","description":"\n\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜÊèèËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya (Traditional Chinese Aya Chinese;TCA)ÔºöÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáËôïÁêÜÁöÑ Aya ÈõÜÂêàÁöÑÁ≤æÈÅ∏Â≠êÈõÜ\n\n\t\n\t\t\n\t\tÊ¶ÇËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÊòØ‰∏ÄÂÄãÁ≤æÂøÉÁ≠ñÂäÉÁöÑË≥áÊñôÈõÜÔºåÊ∫êËá™ CohereForAI ÁöÑÁ∂úÂêà Aya ÈõÜÂêàÔºåÁâπÂà•ÈóúÊ≥®ÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊñô„ÄÇ\nÊ≠§Ë≥áÊñôÈõÜÁµêÂêà‰∫Ü‰æÜËá™ CohereForAI/aya_collectionÔºåÈÅéÊøæÊéâÈô§ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÂÖßÂÆπ‰πãÂ§ñÁöÑÊâÄÊúâÂÖßÂÆπ„ÄÇ\n\n\t\n\t\t\n\t\tÁõÆÊ®ô\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÁöÑÁõÆÊ®ôÊòØÁÇ∫Á†îÁ©∂‰∫∫Âì°„ÄÅÊäÄË°ìÂ∞àÂÆ∂ÂíåË™ûË®ÄÂ≠∏ÂÆ∂Êèê‰æõÂç≥Áî®ÂûãÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊ∫êÔºåÈ°ØËëóÊ∏õÂ∞ëÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáÁöÑ NLP Âíå AI Â∞àÊ°à‰∏≠Êï∏ÊìöÈ†êËôïÁêÜÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇ\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜ‰æÜÊ∫êËàáË≥áË®ä\n\t\n\n\nË≥áÊñô‰æÜÊ∫ê: Âæû CohereForAI/aya_collection 64 ÂÄãÂ≠êÈõÜËÄå‰æÜ„ÄÇ\nË™ûË®Ä: ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÔºà'zho')\nÊáâÁî®: ÈùûÂ∏∏ÈÅ©ÂêàË™ûË®ÄÂª∫Ê®°„ÄÅÊñáÊú¨ÂàÜÈ°û„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÂíåÊ©üÂô®ÁøªË≠ØÁ≠â‰ªªÂãô„ÄÇ\nË´ñÊñáÈÄ£Áµê: 2402.06619\nÁ∂≠Ë≠∑‰∫∫: Heng666\nLicense: Apache-2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection.","url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection","creator_name":"Heng-Shiou Sheu | Ë®±ÊÅÜ‰øÆ","creator_url":"https://huggingface.co/Heng666","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"snippet-mlsum-500-v2","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets. \n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nde - German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ntext: a string feature.title: a string feature.teaser:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2.","url":"https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"summarization-summeval-fr-p2p","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummEval FR\n\t\n\nThis dataset is a French translation of the original work SummEval. \nThe translation was made using DeepL from English to French. \nWe used a LLM to rate the quality of translations, we verified random samples rated above 9/10 manually and corrected all those rated under 9/10. We also checked the correlation of ROUGE and BLEU scores between SummEval and SummEvalFr.  For more details about the quality checks of this dataset, please refer to our paper.\nWe use this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyon-nlp/summarization-summeval-fr-p2p.","url":"https://huggingface.co/datasets/lyon-nlp/summarization-summeval-fr-p2p","creator_name":"Lyon NLP","creator_url":"https://huggingface.co/lyon-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","French","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"clupubhealth","keyword":"summarization","description":"\n\t\n\t\t\n\t\tclupubhealth\n\t\n\nThe CLUPubhealth dataset is based on the PUBHEALTH fact-checking dataset.\nThe PUBHEALTH dataset contains claims, explanations, and main texts. The explanations function as vetted summaries of the main texts. The CLUPubhealth dataset repurposes these fields into summaries and texts for use in training Summarization models such as Facebook's BART. \nThere are currently 4 dataset configs which can be called, each has three splits (see Usage):\n\n\t\n\t\t\n\t\n\t\n\t\tclupubhealth/mini‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clu-ling/clupubhealth.","url":"https://huggingface.co/datasets/clu-ling/clupubhealth","creator_name":"clu-ling","creator_url":"https://huggingface.co/clu-ling","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ArchitecturalDigestDiningRoomEmbeddings","keyword":"summarization","description":"\n\t\n\t\t\n\t\tArchitectural Digest Dining Room Embeddings\n\t\n\nThis dataset is a collection of 2288 description embeddings of dining rooms from Architectural Digest.\n","url":"https://huggingface.co/datasets/naklecha/ArchitecturalDigestDiningRoomEmbeddings","creator_name":"Nishant Aklecha","creator_url":"https://huggingface.co/naklecha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","sentence-similarity","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mauxitalk-persian","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MauxiTalk: High-Quality Persian Conversations Dataset üáÆüá∑\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nMauxiTalk is a high-quality dataset of 2,000+ Persian conversations, carefully translated from the SmolTalk dataset using state-of-the-art language models. This dataset is specifically curated for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\n2,000 natural conversations in Persian\nDiverse topics including daily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxitalk-persian.","url":"https://huggingface.co/datasets/xmanii/mauxitalk-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_dataset","keyword":"summarization","description":"\n\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜÊèèËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya (Traditional Chinese Aya Chinese;TCA)ÔºöÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáËôïÁêÜÁöÑ Aya ÈõÜÂêàÁöÑÁ≤æÈÅ∏Â≠êÈõÜ\n\n\t\n\t\t\n\t\tÊ¶ÇËø∞\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÊòØ‰∏ÄÂÄãÁ≤æÂøÉÁ≠ñÂäÉÁöÑË≥áÊñôÈõÜÔºåÊ∫êËá™ CohereForAI ÁöÑÁ∂úÂêà Aya ÈõÜÂêàÔºåÁâπÂà•ÈóúÊ≥®ÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊñô„ÄÇ\nÊ≠§Ë≥áÊñôÈõÜÁµêÂêà‰∫Ü‰æÜËá™ CohereForAI/aya_datasetÔºåÈÅéÊøæÊéâÈô§ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÂÖßÂÆπ‰πãÂ§ñÁöÑÊâÄÊúâÂÖßÂÆπ„ÄÇ\n\n\t\n\t\t\n\t\tÁõÆÊ®ô\n\t\n\nÁπÅÈ´î‰∏≠Êñá Aya ÁöÑÁõÆÊ®ôÊòØÁÇ∫Á†îÁ©∂‰∫∫Âì°„ÄÅÊäÄË°ìÂ∞àÂÆ∂ÂíåË™ûË®ÄÂ≠∏ÂÆ∂Êèê‰æõÂç≥Áî®ÂûãÁπÅÈ´î‰∏≠ÊñáÊñáÊú¨Ë≥áÊ∫êÔºåÈ°ØËëóÊ∏õÂ∞ëÂ∞àÊ≥®ÊñºÁπÅÈ´î‰∏≠ÊñáÁöÑ NLP Âíå AI Â∞àÊ°à‰∏≠Êï∏ÊìöÈ†êËôïÁêÜÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇ\n\n\t\n\t\t\n\t\tË≥áÊñôÈõÜ‰æÜÊ∫êËàáË≥áË®ä\n\t\n\n\nË≥áÊñô‰æÜÊ∫ê: Âæû CohereForAI/aya_dataset 2 ÂÄãÂ≠êÈõÜËÄå‰æÜ„ÄÇ\nË™ûË®Ä: ÁπÅÈ´î‰∏≠Êñá„ÄÅÁ∞°È´î‰∏≠ÊñáÔºà'zho')\nÊáâÁî®: ÈùûÂ∏∏ÈÅ©ÂêàË™ûË®ÄÂª∫Ê®°„ÄÅÊñáÊú¨ÂàÜÈ°û„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÂíåÊ©üÂô®ÁøªË≠ØÁ≠â‰ªªÂãô„ÄÇ\nË´ñÊñáÈÄ£Áµê: 2402.06619\nÁ∂≠Ë≠∑‰∫∫: Heng666\nLicense: Apache-2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset.","url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset","creator_name":"Heng-Shiou Sheu | Ë®±ÊÅÜ‰øÆ","creator_url":"https://huggingface.co/Heng666","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-gugugo-ko","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tOpenOrca ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ Îç∞Ïù¥ÌÑ∞ÏÖã\n\t\n\nGugugo-koen-7B-V1.1ÏùÑ Ïù¥Ïö©ÌïòÏó¨ OpenOrcaÎç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î≤àÏó≠ÌïòÍ≥† ÏûàÏäµÎãàÎã§.\nÎ≤àÏó≠ ÏßÑÌñâÏÉÅÌô©ÏùÄ ÏïÑÎûòÎ•º Ï∞∏Í≥†Ìï¥ Ï£ºÏã≠ÏãúÏò§.\n\n\t\n\t\t\n\t\tÏßÑÌñâÏÉÅÌô©\n\t\n\n\nGPT4 ÏÉùÏÑ±Î¨º ÏïΩ 100Îßå Í∞ú Ï§ë ÏïΩ 64Îßå Í∞ú Î≤àÏó≠ÏôÑÎ£å\nGPT3.5 ÏÉùÏÑ±Î¨º ÏïΩ 350Îßå Í∞ú Ï§ë ÏïΩ 159Îßå Í∞ú Î≤àÏó≠ÏôÑÎ£å\n\nÎç∞Ïù¥ÌÑ∞ÏÖã ÏÇ¨Ïö© ÌõÑ Ï∂úÏ≤òÌëúÍ∏∞Îäî Ï†úÏûëÏûêÏóêÍ≤å ÌÅ∞ ÌûòÏù¥ Îê©ÎãàÎã§.\n\n\t\n\t\t\n\t\tOriginal dataset card: OpenOrca\n\t\n\nüêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko.","url":"https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko","creator_name":"Woojun Jeong","creator_url":"https://huggingface.co/squarelike","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ARC_finetuning","keyword":"summarization","description":"\n\t\n\t\t\n\t\tARC-Encoder finetuning dataset\n\t\n\nThis dataset gathers the sub-datasets of supervised and synthetized samples necessary to fine-tune on context compression tasks an ARC-Encoder as described in the paper ARC-Encoder: learning compressed text representations for large language models available here.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIt consists in 12 jsonl files separated in 4 task categories: Translation, Question-Answering, Reading Comprehension and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kyutai/ARC_finetuning.","url":"https://huggingface.co/datasets/kyutai/ARC_finetuning","creator_name":"Kyutai","creator_url":"https://huggingface.co/kyutai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"distilabel-intel-orca-dpo-pairs-tr","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"malhajar/orca_dpo_pairs-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca_dpo_pairs-tr is a translated version of argilla/distilabel-intel-orca-dpo-pairs\nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is a pre-processed version of the OpenOrca dataset translated to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/distilabel-intel-orca-dpo-pairs-tr.","url":"https://huggingface.co/datasets/malhajar/distilabel-intel-orca-dpo-pairs-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"OpenOrca_35k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"OpenOrca_35k\"\n\t\n\nThe first 35k examples from Open-Orca/OpenOrca\n","url":"https://huggingface.co/datasets/georgesung/OpenOrca_35k","creator_name":"Jou-ching (George) Sung","creator_url":"https://huggingface.co/georgesung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"summcomparer-gauntlet-v0p1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummComparer - v0.1 version\n\t\n\n\n\nComparative analysis of summarization models on a variety of everyday documents \n\n\n\n\n\nDataset host/upload for SummComparer. This is just a hosting page, check the repo for the latest info.\n\nThis is a work in progress and will be updated over time.\nPRs/discussions on this card are disabled, but discussions/ideas/analysis etc are welcome, just post in the github repo discussions so things are all in one place.\nPlease note that this is a dataset intended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0p1.","url":"https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0p1","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cnn_daily_swe","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Swedish CNN Dailymail Dataset\n\t\n\nThe Swedish CNN/DailyMail dataset has only been machine-translated to improve downstream fine-tuning on Swedish summarization tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRead about the full details at original English version: https://huggingface.co/datasets/cnn_dailymail\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: a string containing the heximal formated SHA1 hash of the url where the story was retrieved from\narticle: a string containing the body of the news‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gabriel/cnn_daily_swe.","url":"https://huggingface.co/datasets/Gabriel/cnn_daily_swe","creator_name":"Gabriel Borg","creator_url":"https://huggingface.co/Gabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","https://github.com/huggingface/datasets/tree/master/datasets/cnn_dailymail","Swedish","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"databricks-dolly-8k-qa-open-close","keyword":"summarization","description":"jtatman/databricks-dolly-8k-qa-open-close dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jtatman/databricks-dolly-8k-qa-open-close","creator_name":"James","creator_url":"https://huggingface.co/jtatman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"goodwiki","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGoodWiki Dataset\n\t\n\nGoodWiki is a 179 million token dataset of English Wikipedia articles collected on September 4, 2023, that have been marked as Good or Featured by Wikipedia editors. The dataset provides these articles in GitHub-flavored Markdown format, preserving layout features like lists, code blocks, math, and block quotes, unlike many other public Wikipedia datasets. Articles are accompanied by a short description of the page as well as any associated categories.\nThanks to a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/euirim/goodwiki.","url":"https://huggingface.co/datasets/euirim/goodwiki","creator_name":"Euirim Choi","creator_url":"https://huggingface.co/euirim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"openorca-chinese-zhtw","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tDataset Card for \"openorca-chinese-zhtw\"\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing generation to expand its scope.\nThe data is primarily used for training and evaluation in the field of natural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw.","url":"https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Helix","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHelix Dataset for Questioning and Instructing (QI)\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Helix dataset is a specialized collection of data tailored for Questioning and Instructing (QI) tasks. It is created by merging all the Airoboros datasets and incorporating one RosettaCode dataset, with a primary focus on supporting QI research and applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource Datasets: Airoboros datasets (various sources), RosettaCode dataset\nMerging Script: The merging of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaleidoSG/Helix.","url":"https://huggingface.co/datasets/KaleidoSG/Helix","creator_name":"Kaleido Singapore","creator_url":"https://huggingface.co/KaleidoSG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"jurisprudencia_tr_pt","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset de Jurisprud√™ncia dos TR de Portugal (2025)\n\t\n\n\n\t\n\t\t\n\t\tDescri√ß√£o do Dataset\n\t\n\nEste dataset cont√©m uma amostra de ac√≥rd√£os proferidos pelos Tribunais da Rela√ß√£o (TR) de Portugal durante o ano de 2025. Inclui decis√µes dos tribunais de Lisboa (TRL), Porto (TRP), Coimbra (TRC), √âvora (TRE) e Guimar√£es (TRG). Cada registo no dataset corresponde a um ac√≥rd√£o completo, incluindo o seu texto integral, o sum√°rio e um conjunto de metadados ricos.\nOs dados representam uma amostra‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ffantini/jurisprudencia_tr_pt.","url":"https://huggingface.co/datasets/ffantini/jurisprudencia_tr_pt","creator_name":"Fernando Neto","creator_url":"https://huggingface.co/ffantini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"GPT-BookSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGPT-BOOKSUM\n\t\n\nGPT-BookSum is a hierarchical summarization dataset based on the story passages from the [BookSum](GitHub - salesforce/booksum) dataset. The dataset is proposed in Improving Pacing in Long-Form Story Planning (EMNLP23). In the paper, we use GPT-BookSum to train a concreteness evaluator, which is further utilized to improve pacing in story outlining and generation.\nThe summaries are written by ChatGPT (gpt-3.5-turbo-0301); thus, we obtain a uniform style. (We initially‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZachW/GPT-BookSum.","url":"https://huggingface.co/datasets/ZachW/GPT-BookSum","creator_name":"Yichen Zach Wang","creator_url":"https://huggingface.co/ZachW","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for ThaiSum\n\t\n\nThis dataset was forked from thaisum to HF hub.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath, ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs written by journalists.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nsummarization, language modeling\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaisum.","url":"https://huggingface.co/datasets/pythainlp/thaisum","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"solr_fine_tunning_ca","keyword":"summarization","description":"    This dataset has some search antural language sentences in catalan and their solr search language translation.\n    This is the original dataset:\n    ```\n    load_dataset(\"oooriii/solr_fine_tunning_ca\", '3.0.0')\n    ```\n    And this is the HuggingFace translation pipeline:\n    ```\n    pipeline(\n        task='translation_en_to_nl',\n        model='Helsinki-NLP/opus-mt-en-nl',\n        tokenizer='Helsinki-NLP/opus-mt-en-nl')\n    ```","url":"https://huggingface.co/datasets/oooriii/solr_fine_tunning_ca","creator_name":"Oriol","creator_url":"https://huggingface.co/oooriii","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["summarization","translation","Catalan","cc0-1.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPersian Open-Platypus\n\t\n\n\n\t\n\t\t\n\t\tAbout ZharfaTech\n\t\n\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source solutions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi.","url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","Persian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Top5percent","keyword":"summarization","description":"üêã The OpenOrca-Top5Percent Dataset! üêã\n\nWe are excited to introduce the OpenOrca-Top5Percent dataset, a refined version of the original OpenOrca dataset. This dataset contains only those entries which utilize the top 5% most frequently used words in the OpenOrca dataset, aiming to focus on high-frequency vocabulary for various NLP tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca-Top5Percent dataset is a curated subset of the augmented FLAN Collection data, focusing specifically on entries that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/OpenOrca-Top5percent.","url":"https://huggingface.co/datasets/dynopii/OpenOrca-Top5percent","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"cochrane_dense_oracle","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_oracle.","url":"https://huggingface.co/datasets/allenai/cochrane_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"OpenOrca","keyword":"summarization","description":"üêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/OpenOrca.","url":"https://huggingface.co/datasets/Open-Orca/OpenOrca","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"wbfns","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for wbfns 2018\n\t\n\n42 publicly-available document texts downloaded from the World Bank Documents and Report API.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n42 World Bank document texts, related to Nutrition and food security, published in 2018. All documents are publicly available from the World Bank Project API, here: https://documents.worldbank.org/en/publication/documents-reports/api\n\nLicense: mit\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nIntended to be used in very short text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodeawb/wbfns.","url":"https://huggingface.co/datasets/lodeawb/wbfns","creator_name":"Liam O'Dea","creator_url":"https://huggingface.co/lodeawb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"singaporean-judicial-keywords","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSingaporean Judicial Keywords üèõÔ∏è\n\t\n\nSingaporean Judicial Keywords by Isaacus is a challenging legal information retrieval evaluation dataset consisting of 500 catchword-judgment pairs sourced from the Singapore Judiciary.\nUniquely, the keywords in this dataset are real-world annotations created by subject matter experts, namely, Singaporean law reporters, as opposed to being constructed ex post facto by third parties.\nAdditionally, unlike standard keyword queries, judicial catchwords‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/singaporean-judicial-keywords.","url":"https://huggingface.co/datasets/isaacus/singaporean-judicial-keywords","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"license-tldr-retrieval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLicense TL;DR Retrieval üìë\n\t\n\nLicense TL;DR Retrieval by Isaacus is a challenging legal information retrieval evaluation dataset consisting of 65 summary-license pairs sourced from tl;drLegal.\nThis dataset is intended to stress test the ability of an information retrieval model to match relevant open source licenses with summaries of their terms.\nTo make evaluation with this dataset as easy as possible, it has been formatted in the Massive Text Embedding Benchmark (MTEB) information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/license-tldr-retrieval.","url":"https://huggingface.co/datasets/isaacus/license-tldr-retrieval","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","found","found","English"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_max","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_max.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"xsum_swe","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Swedish Xsum Dataset\n\t\n\nThe Swedish xsum dataset has only been machine-translated to improve downstream fine-tuning on Swedish summarization tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRead about the full details at original English version: https://huggingface.co/datasets/xsum\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: a string containing the heximal formated SHA1 hash of the url where the story was retrieved from\ndocument: a string containing the body of the news article \nsummary: a string‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gabriel/xsum_swe.","url":"https://huggingface.co/datasets/Gabriel/xsum_swe","creator_name":"Gabriel Borg","creator_url":"https://huggingface.co/Gabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","https://github.com/huggingface/datasets/tree/master/datasets/xsum","Swedish","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_dutch","keyword":"summarization","description":"CNN/DailyMail non-anonymized summarization dataset, translated to Dutch with ccmatrix.\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/yhavinga/cnn_dailymail_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_dutch","keyword":"news-articles-summarization","description":"CNN/DailyMail non-anonymized summarization dataset, translated to Dutch with ccmatrix.\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/yhavinga/cnn_dailymail_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"UpGrow-Boost","keyword":"summarization","description":"\n\t\n\t\t\n\t\t UpGrow Boost‚Ñ¢\n\t\n\nWelcome to the UpGrow Boost Dataset repository on Hugging Face. This repository provides insights into our dataset used for powering our AI-driven Instagram growth services.\n\n\t\n\t\t\n\t\tüåê About UpGrow\n\t\n\nUpGrow is a trailblazing platform offering Instagram growth services powered by artificial intelligence (AI) and advanced machine learning algorithms for rapid and efficient Instagram growth.\n\n\t\n\t\t\n\t\tüìä UpGrow-Boost Dataset\n\t\n\nThe UpGrow-Boost Dataset is a collection of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost.","url":"https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost","creator_name":"UpGrow","creator_url":"https://huggingface.co/UpGrowTeam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["zero-shot-classification","depth-estimation","multiple-choice","summarization","English"],"keywords_longer_than_N":true},
	{"name":"highlightsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for HighlightSum Corpus [Single Dataset Comprising of AMI, SamSUM & DialogSUM for Brief Summarization of Text]\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nAMI: https://huggingface.co/datasets/knkarthick/AMI\nDialogSUM: https://github.com/cylnlp/dialogsum\nSamSUM: https://huggingface.co/datasets/knkarthick/samsum\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nHighlightSUM is collection of large-scale dialogue summarization dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/highlightsum.","url":"https://huggingface.co/datasets/knkarthick/highlightsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"scielo-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization\n\t\n\nA collaboration between reciTAL, MLIA (ISIR, Sorbonne Universit√©), Meta AI, and Universit√† di Trento\n\n\t\n\t\t\n\t\n\t\n\t\tSciELO dataset for summarization\n\t\n\nSciELO is a dataset for summarization of research papers written in Spanish and Portuguese, for which layout information is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\narticle_id: article id\narticle_words: sequence of words constituting the body of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nglaura/scielo-summarization.","url":"https://huggingface.co/datasets/nglaura/scielo-summarization","creator_name":"Laura Nguyen","creator_url":"https://huggingface.co/nglaura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","French","apache-2.0","arxiv:2301.11312","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"applescript-lines-annotated","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"applescript-lines-annotated\"\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a dataset of single lines of AppleScript code scraped from GitHub and GitHub Gist and manually annotated with descriptions, intents, prompts, and other metadata.\n\n\t\n\t\t\n\t\tContent\n\t\n\nEach row contains 8 features:\n\ntext - The raw text of the AppleScript code.\nsource - The name of the file from which the line originates.\ntype - Either compiled (files using the .scpt extension) or uncompiled (everything else).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated.","url":"https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated","creator_name":"Stephen Kaplan","creator_url":"https://huggingface.co/HelloImSteven","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"czech_news_dataset_v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"czech_news_dataset_v2\"\n\t\n\n\nDataset containing the news articles from major online news outlets collected from 2000-2022.\n\nFollow-up paper https://arxiv.org/abs/2307.10666 (v1 of the dataset)\n\nChanges from v1\n\nBetter contribution of novinky.cz in later stages\nMore articles, as a mistake in filtering was fixed.\n\n\nCollection was done using CmonCrawl.\n\nThe dataset should be used for Research only purposes as I don't have rights for articles itself.\n\nIf you have any‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hynky/czech_news_dataset_v2.","url":"https://huggingface.co/datasets/hynky/czech_news_dataset_v2","creator_name":"Hynek Kydlicek","creator_url":"https://huggingface.co/hynky","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Czech","odc-by","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_max","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_max.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES-titles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES-titles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES-titles is a Spanish-language dataset for news titles generation. The text and titles comes from 2019 and 2020 CC-NEWS data (which is part of Common Crawl).\nIt contains 402.310 pairs of news title and body, splitted in :\n\nTrain: 370.125\n\nEval: 16.092\n\nTest: 16.092\n\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-classification, sentiment-classification: The dataset can be used to train a model for news title‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles.","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"pn_summary","keyword":"summarization","description":"A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\nIt is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.","url":"https://huggingface.co/datasets/HooshvareLab/pn_summary","creator_name":"Hooshvare Research Lab","creator_url":"https://huggingface.co/HooshvareLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-classification","news-articles-summarization","news-articles-headline-generation","text-simplification"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"summarization","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"pn_summary","keyword":"news-articles-summarization","description":"A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\nIt is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.","url":"https://huggingface.co/datasets/HooshvareLab/pn_summary","creator_name":"Hooshvare Research Lab","creator_url":"https://huggingface.co/HooshvareLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-classification","news-articles-summarization","news-articles-headline-generation","text-simplification"],"keywords_longer_than_N":true},
	{"name":"cochrane-simplification","keyword":"text-simplification","description":"This dataset measures the ability for a model to simplify paragraphs of medical text through the omission non-salient information and simplification of medical jargon.","url":"https://huggingface.co/datasets/GEM/cochrane-simplification","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-simplification","none","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"pn_summary","keyword":"text-simplification","description":"A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\nIt is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.","url":"https://huggingface.co/datasets/HooshvareLab/pn_summary","creator_name":"Hooshvare Research Lab","creator_url":"https://huggingface.co/HooshvareLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-classification","news-articles-summarization","news-articles-headline-generation","text-simplification"],"keywords_longer_than_N":true},
	{"name":"reason_code-search-net-python","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"reason_code-search-net-python\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \nGiven a Python 3 function:\n\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\nType 2: Generate a summary explaining what its input parameters represent (\"For example: infile: a file descriptor of a file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python.","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"pentest","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mikoube/pentest.","url":"https://huggingface.co/datasets/mikoube/pentest","creator_name":"Michael Rousseaux","creator_url":"https://huggingface.co/mikoube","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","summarization","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"overlim","keyword":"paraphrase-identification","description":"\\","url":"https://huggingface.co/datasets/KBLab/overlim","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-classification","sentiment-classification","text-scoring"],"keywords_longer_than_N":true},
	{"name":"lear2ComfyUI","keyword":"summarization","description":"iimate/lear2ComfyUI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iimate/lear2ComfyUI","creator_name":"tai san","creator_url":"https://huggingface.co/iimate","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":null,"first_N":5,"first_N_keywords":["summarization","Thai","English","unlicense","n<1K"],"keywords_longer_than_N":true},
	{"name":"billsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"billsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBillSum, summarization of US Congressional and California state bills.\nThere are several features:\n\ntext: bill text.\nsummary: summary of the bills.\ntitle: title of the bills.\nfeatures for us bills. ca bills does not have.\ntext_len: number of chars in text.\nsum_len: number of chars in summary.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FiscalNote/billsum.","url":"https://huggingface.co/datasets/FiscalNote/billsum","creator_name":"FiscalNote","creator_url":"https://huggingface.co/FiscalNote","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Course_summaries_dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\nThe dataset consists of data from a bunch of youtube videos ranging from videos from fastai lessons, FSDL lesson to random videos teaching something.\nIn total this dataset contains 600 chapter markers in youtube and contains 25, 000 lesson transcript. \nThis dataset can be used for NLP tasks like summarization, topic segmentation etc. You can refer to some of the models we have trained with this dataset\nin github repo link for Full stack deep learning 2022 projects.\n","url":"https://huggingface.co/datasets/recapper/Course_summaries_dataset","creator_name":"recapper","creator_url":"https://huggingface.co/recapper","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"SQuALITY-v1.3-flat","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSQuALITY-v1.3-flat\n\t\n\nA formatted/flat version of the original\n\n","url":"https://huggingface.co/datasets/pszemraj/SQuALITY-v1.3-flat","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","pszemraj/SQuALITY-v1.3","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"onlystacked-xsum-1024","keyword":"summarization","description":"\n\t\n\t\t\n\t\tstacked-summaries/onlystacked-xsum-1024\n\t\n\nSame thing as stacked-summaries/stacked-xsum-1024 but filtered such that is_stacked=True. Please refer to the original dataset for info and to raise issues if needed.\nBasic info on train split:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 116994 entries, 0 to 116993\nData columns (total 6 columns):\n #   Column          Non-Null Count   Dtype  \n---  ------          --------------   -----  \n 0   document        116994 non-null  string \n 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stacked-summaries/onlystacked-xsum-1024.","url":"https://huggingface.co/datasets/stacked-summaries/onlystacked-xsum-1024","creator_name":"Stacked Summaries","creator_url":"https://huggingface.co/stacked-summaries","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","xsum","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"times_of_india_news_headlines","keyword":"text-simplification","description":"This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.","url":"https://huggingface.co/datasets/community-datasets/times_of_india_news_headlines","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","fact-checking-retrieval","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"dac6-instruct","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDAC6 instruct (11-12-2023)\n\t\n\n‚ÄúDAC 6‚Äù refers to European Council Directive (EU) 2018/822 of May 25, 2018 relating to the automatic and mandatory exchange of information on cross-border arrangements requiring declaration. It aims to strengthen cooperation between tax administrations in EU countries on potentially aggressive tax planning arrangements.\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \nFine-tuning is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct.","url":"https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NCERT_Physics_12th","keyword":"summarization","description":"KadamParth/NCERT_Physics_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Physics_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"scientific_lay_summarisation","keyword":"summarization","description":"This repository contains the PLOS and eLife datasets, introduced in the EMNLP 2022 paper \"[Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature\n](https://arxiv.org/abs/2210.09932)\". \nEach dataset contains full biomedical research articles paired with expert-written lay summaries (i.e., non-technical summaries). PLOS articles are derived from various journals published by [the Public Library of Science (PLOS)](https://plos.org/), whereas eLife articles are derived from the [eLife](https://elifesciences.org/) journal. More details/anlaysis on the content of each dataset are provided in the paper.\n\nBoth \"elife\" and \"plos\" have 6 features:\n    - \"article\": the body of the document (including the abstract), sections seperated by \"/n\".\n    - \"section_headings\": the title of each section, seperated by \"/n\". \n    - \"keywords\": keywords describing the topic of the article, seperated by \"/n\".\n    - \"title\" : the title of the article.\n    - \"year\" : the year the article was published.\n    - \"summary\": the lay summary of the document.","url":"https://huggingface.co/datasets/tomasg25/scientific_lay_summarisation","creator_name":"Tomas Goldsack","creator_url":"https://huggingface.co/tomasg25","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"paraphrase-identification","description":"\n\t\n\t\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained analysis of system‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quincyqiang/test.","url":"https://huggingface.co/datasets/quincyqiang/test","creator_name":"quincyqiang","creator_url":"https://huggingface.co/quincyqiang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_extractive","keyword":"summarization","description":"\n\t\n\t\t\n\t\tData Card for Extractive CNN/DailyMail Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is an extractive version of the CNN/Dailymail dataset. The structure of this dataset is identical to the original except for a minor modification in the data representation and the introduction of labels to denote the extractive summary.\nThe labels are generated following a greedy algorithm, as proposed by Liu (2019). The curation process can be found in the bertsum-hf repository. I am uploading it in case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ereverter/cnn_dailymail_extractive.","url":"https://huggingface.co/datasets/ereverter/cnn_dailymail_extractive","creator_name":"Enric Reverter","creator_url":"https://huggingface.co/ereverter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"SQuALITY-v1.3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSQuALITY - v1.3\n\t\n\n\nOriginal paper here\n\nThis is v1.3, the 'text' edition .jsonl files. See description from the original repo:\n\nv1.3 fixes some bugs in v1.2. In v1.2, 10 out of 127 articles (each ~5k-word-long) are missing a few hundreds words each, so summaries may not be fully contained in the article. To fix this issue, we have updated the 10 articles.\n\n\n\t\n\t\t\n\t\n\t\n\t\tcontents\n\t\n\n\nagain, this is taken from the repo\n\nEach data file ({train/dev/test}.jsonl) is formatted as a JSON lines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/SQuALITY-v1.3.","url":"https://huggingface.co/datasets/pszemraj/SQuALITY-v1.3","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SQuALITY-v1.3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSQuALITY - v1.3\n\t\n\n\nOriginal paper here\n\nThis is v1.3, the 'text' edition .jsonl files. See description from the original repo:\n\nv1.3 fixes some bugs in v1.2. In v1.2, 10 out of 127 articles (each ~5k-word-long) are missing a few hundreds words each, so summaries may not be fully contained in the article. To fix this issue, we have updated the 10 articles.\n\n\n\t\n\t\t\n\t\n\t\n\t\tcontents\n\t\n\n\nagain, this is taken from the repo\n\nEach data file ({train/dev/test}.jsonl) is formatted as a JSON lines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/SQuALITY-v1.3.","url":"https://huggingface.co/datasets/pszemraj/SQuALITY-v1.3","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"IndEgo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants\n\t\n\n\n\n\t\n\t\t\n\t\tAbstract:\n\t\n\nWe introduce IndEgo, a multimodal egocentric and exocentric video dataset capturing common industrial tasks such as assembly/disassembly, logistics and organisation, inspection and repair, and woodworking.The dataset includes 3,460 egocentric recordings (~197 hours) and 1,092 exocentric recordings (~97 hours).\n\nA central focus of IndEgo is collaborative work, where two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FraunhoferIPK/IndEgo.","url":"https://huggingface.co/datasets/FraunhoferIPK/IndEgo","creator_name":"Fraunhofer IPK","creator_url":"https://huggingface.co/FraunhoferIPK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","summarization","video-classification","any-to-any","English"],"keywords_longer_than_N":true},
	{"name":"Xerxes-Instruct-700K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"Xerxes-Instruct-700K\"\n\t\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nXerxes, named after a Persian King renowned for his wisdom and strategic prowess, is an amalgamation of four distinct datasets. This dataset has been curated to cater to the burgeoning needs of natural language processing tasks, particularly in the domain of conversation modeling and comprehension.\nThe dataset encompasses conversations sourced from a variety of sources, ranging from generative models to real-world‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K.","url":"https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K","creator_name":"Instinct-AI","creator_url":"https://huggingface.co/Instinct-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","summarization","translation"],"keywords_longer_than_N":true},
	{"name":"polish-news","keyword":"summarization","description":"This dataset contains more than 250k articles obtained from polish news site tvp.info.pl.\nMain purpouse of collecting the data was to create a transformer-based model for text summarization.\nColumns:\n\nlink - link to article\ntitle - original title of the article\nheadline - lead/headline of the article - first paragraph of the article visible directly from the page\ncontent - full textual contents of the article\n\nLink to original repo: https://github.com/WiktorSob/scraper-tvp\nDownload the data:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiktorS/polish-news.","url":"https://huggingface.co/datasets/WiktorS/polish-news","creator_name":"Wiktor Soba≈Ñski","creator_url":"https://huggingface.co/WiktorS","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","Polish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"squality","keyword":"summarization","description":"This new dataset is designed to solve this great NLP task and is crafted with a lot of care.","url":"https://huggingface.co/datasets/GEM/squality","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","crowd-sourced","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"code-search-net-python","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-python\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nHomepage: None\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\nPaper: None\nLeaderboard: None\nPoint of Contact: @Nan-Do\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"asrs-aviation-reports","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for ASRS Aviation Incident Reports\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset collects 47,723 aviation incident reports published in the Aviation Safety Reporting System (ASRS) database maintained by NASA. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Dataset can be used to train a model for abstractive and extractive summarization. The model performance is measured by how high the output summary's ROUGE score for a given narrative account of an aviation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elihoole/asrs-aviation-reports.","url":"https://huggingface.co/datasets/elihoole/asrs-aviation-reports","creator_name":"Elijah Hoole","creator_url":"https://huggingface.co/elihoole","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arxiv_astro_co_ga","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv_astro_co_ga\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset consisting of titles and abstracts for all Cosmology and Galaxy Astrophysics arXiv articles to date (99,659 papers). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{'title': 'Probing cluster formation under extreme conditions: massive star clusters in blue compact galaxies',\n 'abstract': ' The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mehnaazasad/arxiv_astro_co_ga.","url":"https://huggingface.co/datasets/mehnaazasad/arxiv_astro_co_ga","creator_name":"Mehnaaz Asad","creator_url":"https://huggingface.co/mehnaazasad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"dialogsum-ru","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding manually labeled summaries and topics.\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/dialogsum-ru.","url":"https://huggingface.co/datasets/d0rj/dialogsum-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","translated","monolingual"],"keywords_longer_than_N":true},
	{"name":"myanimelist-embeddings","keyword":"summarization","description":"\n\t\n\t\t\n\t\tmyanimelist-embeddings\n\t\n\nThis dataset is every non-empty anime synopsis from MyAnimeList.net ran\nthrough the embed-multilingual-v2.0 embedding model from Cohere AI.\n\n\t\n\t\t\n\t\tSample code for searching for anime\n\t\n\nInstall some dependencies\npip install cohere==4.4.1 datasets==2.12.0 torch==2.0.1\n\nCode heavily inspired by the Cohere Wikipedia embeddings sample\nimport os\n\nimport cohere\nimport torch\nfrom datasets import load_dataset\n\nco = cohere.Client(\n    os.environ[\"COHERE_API_KEY\"]\n)  #‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abatilo/myanimelist-embeddings.","url":"https://huggingface.co/datasets/abatilo/myanimelist-embeddings","creator_name":"Aaron Batilo","creator_url":"https://huggingface.co/abatilo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"pitchfork","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPitchfork Music Reviews Dataset\n\t\n\nThis repository contains the code and dataset for scraping music reviews from Pitchfork.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Pitchfork Music Reviews dataset is a collection of music album reviews from the Pitchfork website. Each entry in the dataset represents a single review and includes the following attributes:\n\nartist: The artist of the album.\nalbum: The name of the album.\nyear_released: The year the album was released.\nrating: The rating given to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mattismegevand/pitchfork.","url":"https://huggingface.co/datasets/mattismegevand/pitchfork","creator_name":"Mattis Megevand","creator_url":"https://huggingface.co/mattismegevand","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail","keyword":"summarization","description":"CNN/DailyMail non-anonymized summarization dataset.\n\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/ccdv/cnn_dailymail","creator_name":"ccdv","creator_url":"https://huggingface.co/ccdv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"c4-faqs","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises of open-domain question-answer pairs obtained from extracting 150K FAQ URLs from C4 dataset. Please refer to the original paper and dataset card for more details.\nYou can load C4-FAQs as follows:\nfrom datasets import load_dataset\nc4_faqs_dataset = load_dataset(\"vishal-burman/c4-faqs\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nC4-FAQs is mainly intended for open-domain end-to-end question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vishal-burman/c4-faqs.","url":"https://huggingface.co/datasets/vishal-burman/c4-faqs","creator_name":"Vishal Burman","creator_url":"https://huggingface.co/vishal-burman","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-simplification","language-modeling","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"Graph2Eval-Bench","keyword":"summarization","description":"yurun-chen/Graph2Eval-Bench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yurun-chen/Graph2Eval-Bench","creator_name":"Yurun Chen","creator_url":"https://huggingface.co/yurun-chen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","summarization","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"usb","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUSB: A Unified Summarization Benchmark Across Tasks and Domains\n\t\n\nThis benchmark contains labeled datasets for 8 text summarization based tasks given below. \nThe labeled datasets are created by collecting manual annotations on top of Wikipedia articles from 6 different domains.\n\n\t\n\t\t\nTask\nDescription\nCode snippet\n\n\n\t\t\nExtractive Summarization\nHighlight important sentences in the source article\nload_dataset(\"kundank/usb\",\"extractive_summarization\")\n\n\nAbstractive Summarization\nGenerate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kundank/usb.","url":"https://huggingface.co/datasets/kundank/usb","creator_name":"Kundan Krishna","creator_url":"https://huggingface.co/kundank","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"usb","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUSB: A Unified Summarization Benchmark Across Tasks and Domains\n\t\n\nThis benchmark contains labeled datasets for 8 text summarization based tasks given below. \nThe labeled datasets are created by collecting manual annotations on top of Wikipedia articles from 6 different domains.\n\n\t\n\t\t\nTask\nDescription\nCode snippet\n\n\n\t\t\nExtractive Summarization\nHighlight important sentences in the source article\nload_dataset(\"kundank/usb\",\"extractive_summarization\")\n\n\nAbstractive Summarization\nGenerate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kundank/usb.","url":"https://huggingface.co/datasets/kundank/usb","creator_name":"Kundan Krishna","creator_url":"https://huggingface.co/kundank","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"recognasumm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRecognaSumm Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nRecognaSumm is a novel and comprehensive database specifically designed for the task of automatic text summarization in Portuguese. RecognaSumm stands out due to its diverse origin, composed of news collected from a variety of information sources, including agencies and online news portals. The database was constructed using web scraping techniques and careful curation, re sulting in a rich and representative collection of documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/recognasumm.","url":"https://huggingface.co/datasets/recogna-nlp/recognasumm","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"recognasumm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRecognaSumm Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nRecognaSumm is a novel and comprehensive database specifically designed for the task of automatic text summarization in Portuguese. RecognaSumm stands out due to its diverse origin, composed of news collected from a variety of information sources, including agencies and online news portals. The database was constructed using web scraping techniques and careful curation, re sulting in a rich and representative collection of documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/recognasumm.","url":"https://huggingface.co/datasets/recogna-nlp/recognasumm","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"AirScape-Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\t[ACM MM'25] AirScape: An Aerial Generative World Model with Motion Controllability\n\t\n\nThis repository contains the dataset introduced in the paper, consisting of two parts: 11k+ motion intention prompts and corresponding video clips.\n\nArxiv: https://arxiv.org/pdf/2507.08885\nProject: https://embodiedcity.github.io/AirScape/\nCode: https://github.com/EmbodiedCity/AirScape.code\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset is proposed for training and testing of aerial world models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbodiedCity/AirScape-Dataset.","url":"https://huggingface.co/datasets/EmbodiedCity/AirScape-Dataset","creator_name":"EmbodiedCity","creator_url":"https://huggingface.co/EmbodiedCity","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39483","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_39483.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_39483","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0201171","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0201171.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0201171","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39483","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_39483.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_39483","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0201171","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0201171.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0201171","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_219","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chris241/reddit_dataset_219.","url":"https://huggingface.co/datasets/chris241/reddit_dataset_219","creator_name":"ch","creator_url":"https://huggingface.co/chris241","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_255","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_255.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_255","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0111208","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0111208.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0111208","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_219","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chris241/reddit_dataset_219.","url":"https://huggingface.co/datasets/chris241/reddit_dataset_219","creator_name":"ch","creator_url":"https://huggingface.co/chris241","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_255","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_255.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_255","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0111208","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0111208.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0111208","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_020629","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_020629.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_020629","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0601119","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0601119.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0601119","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/reddit_dataset_104.","url":"https://huggingface.co/datasets/smmrokn/reddit_dataset_104","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_020629","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_020629.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_020629","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0601119","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0601119.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0601119","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/reddit_dataset_104.","url":"https://huggingface.co/datasets/smmrokn/reddit_dataset_104","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MeetingBank-transcript-de","keyword":"summarization","description":"This dataset consists of transcripts from the MeetingBank dataset. \nOverview\nMeetingBank, a benchmark dataset created from the city councils of 6 major U.S. cities to supplement existing datasets.\nIt contains 1,366 meetings with over 3,579 hours of video, as well as transcripts, PDF documents of meeting minutes, agenda, and other metadata.\nOn average, a council meeting is 2.6 hours long and its transcript contains over 28k tokens, making it a valuable testbed for meeting summarizers and for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de.","url":"https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de","creator_name":"Alio Leuchtmann","creator_url":"https://huggingface.co/AlioLeuchtmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","text-generation","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"x_dataset_40563","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_40563.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_40563","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_2.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_2","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0208165","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0208165.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0208165","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-instruments-monetaires-medailles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des instruments mon√©taires et des m√©dailles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_40563","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_40563.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_40563","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_2.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_2","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cwm-taf-morgannwg-university-health-board-tm-en-cy","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Cwm Taf Morgannwg University Health Board Translation Memories\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of English-Welsh sentence pairs extracted from Cwm Taf Morgannwg University Health Board translation memories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nlanguage-modeling\nparsing\nsemantic-segmentation\nsemantic-similarity-classification\nsemantic-similarity-scoring\nsentiment-analysis\nsentiment-classification\nsentiment-scoring\n\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/techiaith/cwm-taf-morgannwg-university-health-board-tm-en-cy.","url":"https://huggingface.co/datasets/techiaith/cwm-taf-morgannwg-university-health-board-tm-en-cy","creator_name":"Language Technologies, Bangor University","creator_url":"https://huggingface.co/techiaith","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","sentence-similarity","text-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0208165","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0208165.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0208165","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_260222","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_260222.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_260222","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_260222","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_260222.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_260222","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_117","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_117.","url":"https://huggingface.co/datasets/gk4u/x_dataset_117","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_479243","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_479243.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_479243","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11627","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_11627.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_11627","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_117","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_117.","url":"https://huggingface.co/datasets/gk4u/x_dataset_117","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_479243","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_479243.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_479243","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11627","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_11627.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_11627","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Devi_Bhagavatam","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for srimad_devi_bhagavata_mahapurana\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the ≈örƒ´mad Devƒ´-bhƒÅgavatam mahƒÅpurƒÅ·πáe in CSV format, broken down into Skandas, AdhyƒÅyas, and individual ≈õlokas. It is designed for NLP applications‚Äîincluding feature extraction, classification, translation, summarization, question-answering, and generation‚Äîon classical Sanskrit scripture.\n\nCurated by: Aluminium‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Devi_Bhagavatam.","url":"https://huggingface.co/datasets/snskrt/Devi_Bhagavatam","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"generate-readme-eval","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGenerate README Eval\n\t\n\nThe generate-readme-eval is a dataset (train split) and benchmark (test split) to evaluate the effectiveness of LLMs\nwhen summarizing entire GitHub repos in form of a README.md file. The datset is curated from top 400 real Python repositories\nfrom GitHub with at least 1000 stars and 100 forks. The script used to generate the dataset can be found here.\nFor the dataset we restrict ourselves to GH repositories that are less than 100k tokens in size to allow us to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patched-codes/generate-readme-eval.","url":"https://huggingface.co/datasets/patched-codes/generate-readme-eval","creator_name":"Patched","creator_url":"https://huggingface.co/patched-codes","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_146","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_146.","url":"https://huggingface.co/datasets/James096/x_dataset_146","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_37411","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_37411.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_37411","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_146","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_146.","url":"https://huggingface.co/datasets/James096/x_dataset_146","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_37411","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_37411.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_37411","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070287","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070287.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070287","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070287","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070287.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070287","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070630","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070630.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070630","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2447","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_2447.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_2447","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0511250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0511250.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0511250","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14253","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_14253.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_14253","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070630","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070630.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070630","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2447","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_2447.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_2447","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"lca-module-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüèüÔ∏è Long Code Arena (Module summarization)\n\t\n\nThis is the benchmark for Module summarization task as part of the\nüèüÔ∏è Long Code Arena benchmark. \nThe current version includes 216 manually curated text files describing different documentation of open-source permissive Python projects. \nThe model is required to generate such description, given the relevant context code and the intent behind the documentation.\nAll the repositories are published under permissive licenses (MIT, Apache-2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JetBrains-Research/lca-module-summarization.","url":"https://huggingface.co/datasets/JetBrains-Research/lca-module-summarization","creator_name":"JetBrains Research","creator_url":"https://huggingface.co/JetBrains-Research","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hub-tldr-dataset-summaries-llama","keyword":"summarization","description":"\n \n\n\n\n\t\n\t\t\n\t\tDataset card for dataset-summaries-llama\n\t\n\nThis dataset contains AI-generated summaries of dataset cards from the Hugging Face Hub, generated using meta-llama/Llama-3.3-70B-Instruct. It is designed to be used in combination with a similar dataset of model card summaries for initial supervised fine-tuning (SFT) of language models specialized in generating tl;dr summaries of dataset and model cards from the Hugging Face Hub. \nThis dataset was made with Curator.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/hub-tldr-dataset-summaries-llama.","url":"https://huggingface.co/datasets/davanstrien/hub-tldr-dataset-summaries-llama","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0511250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0511250.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0511250","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14253","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_14253.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_14253","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CRAFT-Summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCRAFT-Summarization\n\t\n\nThis is a synthetic dataset generated with the CRAFT framework proposed in the paper CRAFT Your Dataset: Task-Specific Synthetic Data Generation Through Corpus Retrieval and Augmentation.\nThe correctness of the data has not been verified in detail, but training on this data and evaluating on human-curated summarization data proved highly beneficial.\n\n4 synthetic dataset sizes (S, M, L, XL) are available, and training on them yields consistent improvement that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ingoziegler/CRAFT-Summarization.","url":"https://huggingface.co/datasets/ingoziegler/CRAFT-Summarization","creator_name":"Ingo Ziegler","creator_url":"https://huggingface.co/ingoziegler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_7th","keyword":"summarization","description":"KadamParth/NCERT_Social_Studies_7th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"darja-en-translation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDarja-English Translation Dataset\n\t\n\nThis dataset contains translations from Algerian Darja (Arabic dialect) to English. The dataset includes sentences in Darja along with their corresponding English translations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nDarja (Algerian Arabic dialect)\nEnglish\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of two fields:\n\ninput: Sentence in Darja\ntranslation: Corresponding translation in English\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the MIT License.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ademchaoua/darja-en-translation.","url":"https://huggingface.co/datasets/ademchaoua/darja-en-translation","creator_name":"adem chaoua","creator_url":"https://huggingface.co/ademchaoua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","summarization","text-generation","Arabic"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0101118","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0101118.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0101118","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wikivideo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPaper and Code\n\t\n\nAssociated with the paper: WikiVideo (https://arxiv.org/abs/2504.00939)\nAssociated with the github repository (https://github.com/alexmartin1722/wikivideo)\n\n\t\n\t\t\n\t\tDownload instructions\n\t\n\nThe dataset can be found on huggingface. However, you can't use the datasets library to access the videos because everything is tarred. Instead you need to locally download the dataset and then untar the videos (and audios if you use those).\n\n\t\n\t\t\n\t\tStep 1: Install git-lfs\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/wikivideo.","url":"https://huggingface.co/datasets/hltcoe/wikivideo","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0101118","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0101118.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0101118","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_172","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_172.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_172","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_14.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_14","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_6th","keyword":"summarization","description":"KadamParth/NCERT_Social_Studies_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_204","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bdkzk/reddit_dataset_204.","url":"https://huggingface.co/datasets/bdkzk/reddit_dataset_204","creator_name":"bdkzkfosjfksjckzmx62737","creator_url":"https://huggingface.co/bdkzk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"taskstream","keyword":"summarization","description":"TaskStream is a comprehensive dataset of enterprise business workflows, decision-making processes, \norganizational structures, and operational documentation across multiple industries.","url":"https://huggingface.co/datasets/vrushankpatel5/taskstream","creator_name":"Vrushank Patel","creator_url":"https://huggingface.co/vrushankpatel5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_57071","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_57071.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_57071","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_172","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_172.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_172","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_14.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_14","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_204","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bdkzk/reddit_dataset_204.","url":"https://huggingface.co/datasets/bdkzk/reddit_dataset_204","creator_name":"bdkzkfosjfksjckzmx62737","creator_url":"https://huggingface.co/bdkzk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_57071","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_57071.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_57071","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"interview-question-with-context","keyword":"summarization","description":"andmev/interview-question-with-context dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/andmev/interview-question-with-context","creator_name":"Andrii","creator_url":"https://huggingface.co/andmev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"eurlex","keyword":"summarization","description":"modernlegal/eurlex dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/modernlegal/eurlex","creator_name":"Modern Legal","creator_url":"https://huggingface.co/modernlegal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20589","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_20589.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_20589","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_223","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_223.","url":"https://huggingface.co/datasets/James096/x_dataset_223","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_91","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_91.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_91","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"chime","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCHIME Dataset\n\t\n\nA unified version of the CHIME dataset created from the following resources:\n\nPaper\nCode\nü§ó parent-child relations\nü§ó siblings info\nü§ó claim-category relations\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe CHIME Dataset is a unified collection of data specifically designed for evaluating the capabilities of Large Language Models (LLMs) in generating literature reviews. It includes various relationships between academic papers, such as parent-child relations, sibling information, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/chime.","url":"https://huggingface.co/datasets/nhop/chime","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_20.","url":"https://huggingface.co/datasets/suul999922/x_dataset_20","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20589","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_20589.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_20589","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_223","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_223.","url":"https://huggingface.co/datasets/James096/x_dataset_223","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_91","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_91.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_91","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_20.","url":"https://huggingface.co/datasets/suul999922/x_dataset_20","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44_","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_44_.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_44_","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"TheGuardian-Articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\nThe dataset was curated to facilitate research and development in natural language processing tasks such as text classification and information extraction from news articles.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\nArticles and similar content were scraped from theguardian.com website.\n\n\t\n\t\t\n\t\tEncoding\n\t\n\nThe primary language of the dataset is English, but it may contain content in other languages. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Stefan171/TheGuardian-Articles.","url":"https://huggingface.co/datasets/Stefan171/TheGuardian-Articles","creator_name":"Stefan Carter","creator_url":"https://huggingface.co/Stefan171","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_18.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_18","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44_","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_44_.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_44_","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_18.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_18","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_9.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_9","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_85","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_85.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_85","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"SUnsET","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSUnsET Dataset\n\t\n\nThe Summaries with Unstructured Evidence Text (SUnsET) dataset from the paper Unstructured Evidence Attribution for Long Context Query Focused Summarization\nOur paper explores the problem of unstructured evidence extraction for long context query focused summarization. Here, a model must generate a summary from a long context given a query,\nand use inline citations to free text spans in the context for support. Evidence has no fixed level of granularity. We found that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwright37/SUnsET.","url":"https://huggingface.co/datasets/dwright37/SUnsET","creator_name":"Dustin Wright","creator_url":"https://huggingface.co/dwright37","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_9.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_9","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_85","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_85.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_85","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"qa-from-abstract-graphene","keyword":"summarization","description":"Shinapri/qa-from-abstract-graphene dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/qa-from-abstract-graphene","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","feature-extraction","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_144","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_144.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_144","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7480","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_7480.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_7480","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_144","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_144.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_144","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7480","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_7480.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_7480","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ABRobOcular_Attacks","keyword":"summarization","description":"\n\t\n\t\t\n\t\tABRobOcular: Ocular Adversarial Dataset\n\t\n\nThis repository contains the official public dataset for the paper: Adversarial benchmarking and robustness analysis of datasets and tools for ocular-based user recognition funded by the NSF award no. 2345561. \n\nPaper: Neurocomputing 2025 ABRobOcular\nCode: Bharath-K3/ABRobOcular\nFigure: A taxonomy of adversarial attacks and defenses in ocular biometrics categorizing attacks into white-box (e.g., BIM, CW, FGSM, MIM, PGD) and black-box (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BharathK333/ABRobOcular_Attacks.","url":"https://huggingface.co/datasets/BharathK333/ABRobOcular_Attacks","creator_name":"Bharath Krishnamurthy","creator_url":"https://huggingface.co/BharathK333","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"x_dataset_34576","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_34576.","url":"https://huggingface.co/datasets/icedwind/x_dataset_34576","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_103502","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_103502.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_103502","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"telegram-financial-sentiment-summarization","keyword":"summarization","description":"mxlcw/telegram-financial-sentiment-summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mxlcw/telegram-financial-sentiment-summarization","creator_name":"Anatolii","creator_url":"https://huggingface.co/mxlcw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Russian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_34576","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_34576.","url":"https://huggingface.co/datasets/icedwind/x_dataset_34576","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_103502","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_103502.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_103502","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_34","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_34.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_34","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_102","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/reddit_dataset_102.","url":"https://huggingface.co/datasets/GSKCM24/reddit_dataset_102","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_42","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_42.","url":"https://huggingface.co/datasets/James096/reddit_dataset_42","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_172","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_172.","url":"https://huggingface.co/datasets/coldmind/x_dataset_172","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_34","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_34.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_34","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_102","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/reddit_dataset_102.","url":"https://huggingface.co/datasets/GSKCM24/reddit_dataset_102","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_42","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_42.","url":"https://huggingface.co/datasets/James096/reddit_dataset_42","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_172","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_172.","url":"https://huggingface.co/datasets/coldmind/x_dataset_172","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_9.","url":"https://huggingface.co/datasets/suul999922/x_dataset_9","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Summarized_10K-MDA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummarized 10-K MD&A\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Summarized 10-K MD&A dataset provides concise, machine-generated summaries of 10-K filings for publicly traded companies. These filings are sourced from the SEC EDGAR database, and the dataset is designed to facilitate financial text analysis, such as summarization, sentiment analysis, and financial disclosure studies.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: English\nDataset Size: 98,100 rows\nLicense: MIT License\nSource: SEC EDGAR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ichanchiu/Summarized_10K-MDA.","url":"https://huggingface.co/datasets/ichanchiu/Summarized_10K-MDA","creator_name":"I-Chan Chiu","creator_url":"https://huggingface.co/ichanchiu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_9.","url":"https://huggingface.co/datasets/suul999922/x_dataset_9","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Aeollm","keyword":"summarization","description":"cjj826/Aeollm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cjj826/Aeollm","creator_name":"chenjunjie","creator_url":"https://huggingface.co/cjj826","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Open-Orca","keyword":"summarization","description":"üêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Triangle104/Open-Orca.","url":"https://huggingface.co/datasets/Triangle104/Open-Orca","creator_name":"Lymeman","creator_url":"https://huggingface.co/Triangle104","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vietnambk82/reddit_dataset_44.","url":"https://huggingface.co/datasets/Vietnambk82/reddit_dataset_44","creator_name":"Bui Viet Nam","creator_url":"https://huggingface.co/Vietnambk82","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-electoral","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode √©lectoral, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vietnambk82/reddit_dataset_44.","url":"https://huggingface.co/datasets/Vietnambk82/reddit_dataset_44","creator_name":"Bui Viet Nam","creator_url":"https://huggingface.co/Vietnambk82","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aim-technical-articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAnalytics India Magazine Technical Articles Dataset üöÄ\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis comprehensive dataset contains 25,685 high-quality technical articles from Analytics India Magazine, one of India's leading publications covering artificial intelligence, machine learning, data science, and emerging technologies.\n\n\t\n\t\t\n\t\t‚ú® Dataset Highlights\n\t\n\n\nüìö Comprehensive Coverage: Latest AI models, frameworks, and tools\nüî¨ Technical Depth: Extracted keywords and complexity scoring\nüè≠‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/aim-technical-articles.","url":"https://huggingface.co/datasets/abhilash88/aim-technical-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"ECTSum","keyword":"summarization","description":"nyamuda/ECTSum dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nyamuda/ECTSum","creator_name":"Tatenda P. Nyamuda","creator_url":"https://huggingface.co/nyamuda","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"WorldScenario_20K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tWorldScenario 20K\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nWorldScenario 20K is a novel dataset of 20,000 synthetically generated multi-stakeholder scenarios designed to simulate real-world decision-making processes. Each scenario explores a unique environmental, societal, or economic issue.\nEach scenario includes:\n\n\t\n\t\t\n\t\tCore Components\n\t\n\n\nBackground Information: A concise overview of the scenario's context, including its location, key issues, and affected ecosystems.\nDomain Facts: Specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/takarajordan/WorldScenario_20K.","url":"https://huggingface.co/datasets/takarajordan/WorldScenario_20K","creator_name":"Jordan Legg","creator_url":"https://huggingface.co/takarajordan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","text2text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Reasoning-Hypothesis-Corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tReasoning-Hypothesis-Corpus Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Reasoning-Hypothesis-Corpus is a private dataset designed for tasks involving reasoning and hypothesis evaluation. The dataset consists of pairs of premises and corresponding hypotheses. Each entry aims to help models understand and reason about the relationship between textual descriptions.\n\nModality: Text  \nFormat: CSV  \nSize: <1K rows  \nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSplit\n\t\n\n\nTrain:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Reasoning-Hypothesis-Corpus.","url":"https://huggingface.co/datasets/prithivMLmods/Reasoning-Hypothesis-Corpus","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"sentence-corrector","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSentence Correction & Politeness Dataset\n\t\n\nThis repository contains a dataset specifically designed for sentence correction and politeness transformation. The dataset includes a set of input sentences and their corresponding polite, well-formatted outputs. It can be used to train AI models to rephrase user inputs in a more formal, polite, and grammatically correct manner.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Sentence Correction & Politeness Dataset is designed to help improve natural language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector.","url":"https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector","creator_name":"ashraf chauhan","creator_url":"https://huggingface.co/MohamedAshraf701","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_72","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_72.","url":"https://huggingface.co/datasets/James096/reddit_dataset_72","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"LT_Labour_Law_Articles_Summaries","keyword":"summarization","description":"üìö Lithuanian Labour Law Article Summaries Dataset\nThis dataset contains machine-generated summaries of articles from the Lithuanian Labour Code (Darbo kodeksas). Each article from the law has been summarized into a concise, factual description in Lithuanian, designed for legal research, AI training, and natural language processing applications.\nüì¶ Dataset Overview\nColumn Name\tDescription\nDocument_name\tName of the source legal document (e.g. Darbo_Kodeksas_2025_01.txt)\nArticle\tTitle of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArturG9/LT_Labour_Law_Articles_Summaries.","url":"https://huggingface.co/datasets/ArturG9/LT_Labour_Law_Articles_Summaries","creator_name":"Art≈´ras grygelis","creator_url":"https://huggingface.co/ArturG9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Lithuanian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_255","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_255.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_255","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_72","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_72.","url":"https://huggingface.co/datasets/James096/reddit_dataset_72","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_255","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_255.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_255","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"BooksSummarizationRU","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBooks Summarization RU Dataset\n\t\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º\n\t\n\n–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏–∑ –±–æ–ª–µ–µ —á–µ–º 1400 –∫–Ω–∏–≥ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤ –∏ —Ç–µ–º, –≤–∫–ª—é—á–∞—è –ø–æ–ª–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é –∫—Ä–∞—Ç–∫–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è. –î–∞—Ç–∞—Å–µ—Ç –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —à–∏—Ä–æ–∫–∏–π —Å–ø–µ–∫—Ç—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Ç–µ–º–∞—Ç–∏–∫–µ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞—É—á–Ω—ã–º–∏ –∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —Å—Ç–∞—Ç—å—è–º–∏ –¥–ª—è –µ—â–µ –±–æ–ª—å—à–µ–π –ø–æ–ª–Ω–æ—Ç—ã –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è.\n\n–ò—Å—Ç–æ—á–Ω–∏–∫ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è: briefly.ru‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slon-hk/BooksSummarizationRU.","url":"https://huggingface.co/datasets/slon-hk/BooksSummarizationRU","creator_name":"slon_hk","creator_url":"https://huggingface.co/slon-hk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"BooksSummarizationRU","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBooks Summarization RU Dataset\n\t\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º\n\t\n\n–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏–∑ –±–æ–ª–µ–µ —á–µ–º 1400 –∫–Ω–∏–≥ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤ –∏ —Ç–µ–º, –≤–∫–ª—é—á–∞—è –ø–æ–ª–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é –∫—Ä–∞—Ç–∫–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è. –î–∞—Ç–∞—Å–µ—Ç –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —à–∏—Ä–æ–∫–∏–π —Å–ø–µ–∫—Ç—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Ç–µ–º–∞—Ç–∏–∫–µ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞—É—á–Ω—ã–º–∏ –∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —Å—Ç–∞—Ç—å—è–º–∏ –¥–ª—è –µ—â–µ –±–æ–ª—å—à–µ–π –ø–æ–ª–Ω–æ—Ç—ã –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è.\n\n–ò—Å—Ç–æ—á–Ω–∏–∫ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è: briefly.ru‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slon-hk/BooksSummarizationRU.","url":"https://huggingface.co/datasets/slon-hk/BooksSummarizationRU","creator_name":"slon_hk","creator_url":"https://huggingface.co/slon-hk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26008","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_26008.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_26008","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"LIFEBench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLIFEBench\n\t\n\n\n\t\n\t\t\n\t\tüî• News\n\t\n\n\nMay 14, 2025: We release LIFEBench,  the first comprehensive benchmark for evaluating the ability of LLMs to follow length instructions across diverse tasks, languages, and a broad range of length constraints. \nüìä Dataset: Find our dataset on LIFEBench Datasets.\nüíª Code: Access all code, scripts, and benchmark evaluation tools on our LIFEBench repository.\nüåê Website: View benchmark results and leaderboards on our LIFEBench website.\n\n\n\n\n\t\n\t\n\t\n\t\tüìñ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIFEBench/LIFEBench.","url":"https://huggingface.co/datasets/LIFEBench/LIFEBench","creator_name":"LIFEBench","creator_url":"https://huggingface.co/LIFEBench","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26008","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_26008.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_26008","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"clean-medqa","keyword":"summarization","description":"\n\t\n\t\t\n\t\tü©∫ Clean MedQA Dataset\n\t\n\n\nImproving healthcare through language-based AI.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nThe Clean MedQA dataset is a refined version of data originally sourced from the MedQuAD (Medical Question Answering Dataset) ‚Äî a well-known resource for building question-answering systems in the healthcare domain.\nThis cleaned version is optimized for Natural Language Processing (NLP) tasks, particularly for training and evaluating models that need to understand or generate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChakradharS/clean-medqa.","url":"https://huggingface.co/datasets/ChakradharS/clean-medqa","creator_name":"Chakradhar","creator_url":"https://huggingface.co/ChakradharS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","summarization","token-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"x_dataset_108","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wavecreator22/x_dataset_108.","url":"https://huggingface.co/datasets/wavecreator22/x_dataset_108","creator_name":"Krovanov","creator_url":"https://huggingface.co/wavecreator22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_27.","url":"https://huggingface.co/datasets/suul999922/x_dataset_27","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_108","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wavecreator22/x_dataset_108.","url":"https://huggingface.co/datasets/wavecreator22/x_dataset_108","creator_name":"Krovanov","creator_url":"https://huggingface.co/wavecreator22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_27.","url":"https://huggingface.co/datasets/suul999922/x_dataset_27","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CNIL","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFrench National Commission on Informatics and Liberty (CNIL) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (https://www.legifrance.gouv.fr/search/cnil).\nThis dataset is sourced from DILA/OPENDATA/CNIL and provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France.\nIt serves as a rich‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CNIL.","url":"https://huggingface.co/datasets/Tricoteuses/CNIL","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_192","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mamung/reddit_dataset_192.","url":"https://huggingface.co/datasets/mamung/reddit_dataset_192","creator_name":"ansloth","creator_url":"https://huggingface.co/mamung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cardiff-university-tm-en-cy","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Cardiff University Translation Memories\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of English-Welsh sentence pairs extracted from Cardiff University translation memories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nlanguage-modeling\nparsing\nsemantic-segmentation\nsemantic-similarity-classification\nsemantic-similarity-scoring\nsentiment-analysis\nsentiment-classification\nsentiment-scoring\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish\nWelsh\n\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/techiaith/cardiff-university-tm-en-cy.","url":"https://huggingface.co/datasets/techiaith/cardiff-university-tm-en-cy","creator_name":"Language Technologies, Bangor University","creator_url":"https://huggingface.co/techiaith","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","sentence-similarity","text-classification","language-modeling"],"keywords_longer_than_N":true},
	{"name":"RussianFinancialNews","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRussianFinancialNews\n\t\n\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 92,377 —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é —Ç–µ–º–∞—Ç–∏–∫—É, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥ –∏ —Ä–æ—Å—Å–∏–π—Å–∫—É—é —ç–∫–æ–Ω–æ–º–∏–∫—É. –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP). \nA dataset containing 92,377 samples of Russian financial news articles. Each sample includes metadata and content fields that are useful for various Natural Language Processing (NLP) tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews.","url":"https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews","creator_name":"Kasymkhan","creator_url":"https://huggingface.co/Kasymkhan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","time-series-forecasting","tabular-regression"],"keywords_longer_than_N":true},
	{"name":"ukr-news-yt-titles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUkrainian News YouTube Titles Dataset\n\t\n\nThis dataset contains filtered descriptions and titles (with tags, URLs, etc. removed) from Ukrainian news YouTube channels:\n\nhttps://www.youtube.com/@24–ö–∞–Ω–∞–ª\nhttps://www.youtube.com/@FaktyICTVchannel\nhttps://www.youtube.com/@5channel\nhttps://www.youtube.com/@novynylive\nhttps://www.youtube.com/@ZaxidNetTV\nhttps://www.youtube.com/@Vestiii\nhttps://www.youtube.com/@novynyuaThe dataset is designed to support research in Ukrainian text summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andriibul/ukr-news-yt-titles.","url":"https://huggingface.co/datasets/andriibul/ukr-news-yt-titles","creator_name":"Andrii","creator_url":"https://huggingface.co/andriibul","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Ukrainian","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_192","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mamung/reddit_dataset_192.","url":"https://huggingface.co/datasets/mamung/reddit_dataset_192","creator_name":"ansloth","creator_url":"https://huggingface.co/mamung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_118","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chz1001/reddit_dataset_118.","url":"https://huggingface.co/datasets/chz1001/reddit_dataset_118","creator_name":"z","creator_url":"https://huggingface.co/chz1001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"billsum-US_congress_and_house","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nCleaned JSON file with all Congressional legislation for the 113th - 118th Congresses containing 73,890 rows.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset was pulled from the US Governments Bulk Data Repository. (https://www.govinfo.gov/bulkdata/) The data consists of all congressional legislation and their summaries from the 113th Congress through the 118th Congress. The raw files were in the .xml format. The data was cleaned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cheaptrix/billsum-US_congress_and_house.","url":"https://huggingface.co/datasets/cheaptrix/billsum-US_congress_and_house","creator_name":"Taylor Hartman","creator_url":"https://huggingface.co/cheaptrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"billsum-US_congress_and_house","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nCleaned JSON file with all Congressional legislation for the 113th - 118th Congresses containing 73,890 rows.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset was pulled from the US Governments Bulk Data Repository. (https://www.govinfo.gov/bulkdata/) The data consists of all congressional legislation and their summaries from the 113th Congress through the 118th Congress. The raw files were in the .xml format. The data was cleaned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cheaptrix/billsum-US_congress_and_house.","url":"https://huggingface.co/datasets/cheaptrix/billsum-US_congress_and_house","creator_name":"Taylor Hartman","creator_url":"https://huggingface.co/cheaptrix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"db-cooper-text","keyword":"summarization","description":"\n\t\n\t\t\n\t\tD.B. Cooper FBI Files Text Dataset\n\t\n\nThis dataset contains extracted text from the FBI's case files on the infamous \"DB Cooper\" skyjacking (NORJAK investigation). The files are sourced from the FBI and are provided here for open research and analysis.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: FBI NORJAK (D.B. Cooper) case files, as released and processed in the db-cooper-files-text project.\nFormat: Each entry contains a chunk of extracted text, the source page, and file metadata.\nRows: 44‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mysocratesnote/db-cooper-text.","url":"https://huggingface.co/datasets/mysocratesnote/db-cooper-text","creator_name":"Bill","creator_url":"https://huggingface.co/mysocratesnote","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"Contracts","keyword":"summarization","description":"kozue13/Contracts dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kozue13/Contracts","creator_name":"kaho","creator_url":"https://huggingface.co/kozue13","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","sentence-similarity","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_17.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_17","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_118","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chz1001/reddit_dataset_118.","url":"https://huggingface.co/datasets/chz1001/reddit_dataset_118","creator_name":"z","creator_url":"https://huggingface.co/chz1001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_17.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_17","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summary-accumulator-eval","keyword":"summarization","description":"This dataset is used to evaluate the summary-accumulator.\n","url":"https://huggingface.co/datasets/anjor/summary-accumulator-eval","creator_name":"anjor","creator_url":"https://huggingface.co/anjor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0205251","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0205251.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0205251","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Movies_dataset_initial","keyword":"summarization","description":"Shlok307/Movies_dataset_initial dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shlok307/Movies_dataset_initial","creator_name":"Talhar","creator_url":"https://huggingface.co/Shlok307","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0701110","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0701110.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0701110","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ChatML-deita-10k-v0","keyword":"summarization","description":"hkust-nlp/deita-10k-v0 in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"hkust-nlp/deita-10k-v0\", split=\"train\")\n\ndef format(columns):\n    messages = []\n\n    conversation = columns[\"conversations\"]\n\n    for i in range(len(conversation)):\n        message = conversation[i]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-deita-10k-v0.","url":"https://huggingface.co/datasets/Felladrin/ChatML-deita-10k-v0","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0205251","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0205251.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0205251","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0701110","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0701110.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0701110","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Context-Based-Chat-Summary-Plus","keyword":"summary","description":"prithivMLmods/Context-Based-Chat-Summary-Plus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prithivMLmods/Context-Based-Chat-Summary-Plus","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"code-entree-sejour-etrangers-droit-asile","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'entr√©e et du s√©jour des √©trangers et du droit d'asile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_204","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bdkzk/x_dataset_204.","url":"https://huggingface.co/datasets/bdkzk/x_dataset_204","creator_name":"bdkzkfosjfksjckzmx62737","creator_url":"https://huggingface.co/bdkzk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0708150","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0708150.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0708150","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Psychology_11th","keyword":"summarization","description":"KadamParth/NCERT_Psychology_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Psychology_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_10.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_10","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Mycollection","keyword":"summarization","description":"JMaeen25/Mycollection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JMaeen25/Mycollection","creator_name":"Jordan K. Maeen","creator_url":"https://huggingface.co/JMaeen25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["table-question-answering","text-classification","token-classification","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_204","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bdkzk/x_dataset_204.","url":"https://huggingface.co/datasets/bdkzk/x_dataset_204","creator_name":"bdkzkfosjfksjckzmx62737","creator_url":"https://huggingface.co/bdkzk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0708150","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0708150.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0708150","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_10.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_10","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"GSKCM24_Testupload","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/GSKCM24_Testupload.","url":"https://huggingface.co/datasets/GSKCM24/GSKCM24_Testupload","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"mteb-BillSumCA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBillSumCA (MTEB format)\n\t\n\nThis is the Californian test split of the BillSum dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on BillSum with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve Californian bills based on their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-BillSumCA.","url":"https://huggingface.co/datasets/isaacus/mteb-BillSumCA","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","FiscalNote/billsum","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"roemru-posts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Roem.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from Roem.ru, a Russian technology and business news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and author. The dataset contains 19,528 unique articles covering various topics in technology, business, and digital media.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/roemru-posts.","url":"https://huggingface.co/datasets/nyuuzyou/roemru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"MLDSUM_NEW","keyword":"summarization","description":"sandylolpotty/MLDSUM_NEW dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sandylolpotty/MLDSUM_NEW","creator_name":"sandeep","creator_url":"https://huggingface.co/sandylolpotty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"simple-summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimple Summaries\n\t\n\nAbout 10,000 high quality data, with an original text sample from A subset of Ultra Fineweb and a summary generated by Llama 3.2 3b instruct.\n\n\t\n\t\t\n\t\tTime & Cost\n\t\n\nThis took about 3 hours using a batch size of 8 on a rented GPU instance (NVIDIA L4) with a total cost of about 2 dollars.\n\n\t\n\t\t\n\t\tIntended use case\n\t\n\n\nTraining summarization AI models\nTraining language models\n\n","url":"https://huggingface.co/datasets/ProCreations/simple-summaries","creator_name":"Pro Creations","creator_url":"https://huggingface.co/ProCreations","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"GSKCM24_Testupload","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GSKCM24/GSKCM24_Testupload.","url":"https://huggingface.co/datasets/GSKCM24/GSKCM24_Testupload","creator_name":"GUNEET SINGH KHURANA","creator_url":"https://huggingface.co/GSKCM24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"roemru-posts","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Roem.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from Roem.ru, a Russian technology and business news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and author. The dataset contains 19,528 unique articles covering various topics in technology, business, and digital media.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/roemru-posts.","url":"https://huggingface.co/datasets/nyuuzyou/roemru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ifpri-ai-documents","keyword":"summarization","description":"Documents: 12,007\nPages: 362,716\nTokens: 75,284,385 \n\n\t\n\t\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nEach document has been systematically processed using GROBID to extract \nstructured content while preserving critical scientific context, metadata, and domain-specific agricultural knowledge. Morever, chunking\nmethods that preserver the semantic coherence have been applied. More specifically, documents are split \ninto chunks based on a fixed number of tokens and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/ifpri-ai-documents.","url":"https://huggingface.co/datasets/CGIAR/ifpri-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ai_hub_summ_train","keyword":"summarization","description":"jr-d-analyst24/ai_hub_summ_train dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_summ_train","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0405200","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0405200.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0405200","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_72","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_72.","url":"https://huggingface.co/datasets/James096/x_dataset_72","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0405200","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0405200.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0405200","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_72","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_72.","url":"https://huggingface.co/datasets/James096/x_dataset_72","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-construction-habitation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la construction et de l'habitation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"govreport-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGovernment Report Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries for government reports and documents, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of government reports while preserving key policy implications, findings, and recommendations.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/govreport-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/govreport-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"govreport-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGovernment Report Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries for government reports and documents, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of government reports while preserving key policy implications, findings, and recommendations.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/govreport-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/govreport-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_23.","url":"https://huggingface.co/datasets/suul999922/x_dataset_23","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"FactualConsistencyScoresTextSummarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHuggingFace Dataset: FactualConsistencyScoresTextSummarization\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset aggregates model scores assessing factual consistency across multiple summarization datasets. It is designed to highlight the thresholding issue with current SOTS factual consistency models in evaluating the factuality of text summarizations.\n\n\t\n\t\t\n\t\tWhat is the \"Thresholding Issue\" with SOTA Factual Consistency Models ?\n\t\n\nExisting models for detecting factual errors in summaries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization.","url":"https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization","creator_name":"Alex Chandler","creator_url":"https://huggingface.co/achandlr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"FactualConsistencyScoresTextSummarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHuggingFace Dataset: FactualConsistencyScoresTextSummarization\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset aggregates model scores assessing factual consistency across multiple summarization datasets. It is designed to highlight the thresholding issue with current SOTS factual consistency models in evaluating the factuality of text summarizations.\n\n\t\n\t\t\n\t\tWhat is the \"Thresholding Issue\" with SOTA Factual Consistency Models ?\n\t\n\nExisting models for detecting factual errors in summaries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization.","url":"https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization","creator_name":"Alex Chandler","creator_url":"https://huggingface.co/achandlr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41147","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_41147.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_41147","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_23.","url":"https://huggingface.co/datasets/suul999922/x_dataset_23","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41147","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_41147.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_41147","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-artisanat","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'artisanat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21893","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_21893.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_21893","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11100","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_11100.","url":"https://huggingface.co/datasets/icedwind/x_dataset_11100","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_104.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_104","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21893","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_21893.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_21893","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11100","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_11100.","url":"https://huggingface.co/datasets/icedwind/x_dataset_11100","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_104.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_104","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wangchanx-seed-free-synthetic-instruct-thai-120k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for WangchanX Seed-Free Synthetic Instruct Thai 120k\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains about 120k synthetic instruction-following samples in Thai, generated using a novel seed-free approach. It covers a wide range of domains derived from Wikipedia, including both general knowledge and Thai-specific cultural topics. The dataset is designed for instruction-tuning Thai language models to improve their ability to understand and generate Thai text in various‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/wangchanx-seed-free-synthetic-instruct-thai-120k.","url":"https://huggingface.co/datasets/airesearch/wangchanx-seed-free-synthetic-instruct-thai-120k","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Thai","English"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-ii","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe II, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_100415","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_100415.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_100415","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"RedHat-security-VeX","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for RedHat-security-VeX\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extracting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huzaifas-sidhpurwala/RedHat-security-VeX.","url":"https://huggingface.co/datasets/huzaifas-sidhpurwala/RedHat-security-VeX","creator_name":"Huzaifa Sidhpurwala","creator_url":"https://huggingface.co/huzaifas-sidhpurwala","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_100415","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_100415.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_100415","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"alpaca_ccass_motivations_sommaires_titres","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTraining dataset for summarizing and titling decisions of the French Court of cassation based on motivations\n\t\n\nThis alpaca-format dataset is designed to train models for summarizing and titling French Supreme Court decisions based on the grounds of them. Created with a view to producing metadata for decisions not published in the bulletin, this dataset aims to simplify the development of annotation and categorization tools, and is positioned as a facilitator for jurisprudential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres.","url":"https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres","creator_name":"Amaury Fouret","creator_url":"https://huggingface.co/maurya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NCERT_Chemistry_11th","keyword":"summarization","description":"KadamParth/NCERT_Chemistry_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Chemistry_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_196","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_196.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_196","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0304209","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0304209.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0304209","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_196","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_196.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_196","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0304209","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0304209.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0304209","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_232","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Amylyx/reddit_dataset_232.","url":"https://huggingface.co/datasets/Amylyx/reddit_dataset_232","creator_name":"jianghonglin30@gmail.com","creator_url":"https://huggingface.co/Amylyx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_128.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_128","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"IndianBailJudgments-1200","keyword":"summarization","description":"\n\t\n\t\t\n\t\t‚öñÔ∏è IndianBailJudgments-1200: Annotated Indian Bail Order Dataset (1975‚Äì2025)\n\t\n\nIndianBailJudgments-1200 is a high-quality, structured dataset comprising 1,200 annotated Indian bail-related court orders spanning five decades (1975‚Äì2025). It captures granular legal information across 78 courts and 28 regions, including crime types, IPC sections invoked, judge names, legal issues, bail outcomes, and bias indicators.\nDesigned for use in legal NLP, fairness analysis, and judicial research‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SnehaDeshmukh/IndianBailJudgments-1200.","url":"https://huggingface.co/datasets/SnehaDeshmukh/IndianBailJudgments-1200","creator_name":"Sneha Deshmukh","creator_url":"https://huggingface.co/SnehaDeshmukh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","document-question-answering","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/x_dataset_26.","url":"https://huggingface.co/datasets/andreans27/x_dataset_26","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_232","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Amylyx/reddit_dataset_232.","url":"https://huggingface.co/datasets/Amylyx/reddit_dataset_232","creator_name":"jianghonglin30@gmail.com","creator_url":"https://huggingface.co/Amylyx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_128.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_128","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/x_dataset_26.","url":"https://huggingface.co/datasets/andreans27/x_dataset_26","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_5","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexinfstones/reddit_dataset_5.","url":"https://huggingface.co/datasets/alexinfstones/reddit_dataset_5","creator_name":"alexander","creator_url":"https://huggingface.co/alexinfstones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-consommation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la consommation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_5","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexinfstones/reddit_dataset_5.","url":"https://huggingface.co/datasets/alexinfstones/reddit_dataset_5","creator_name":"alexander","creator_url":"https://huggingface.co/alexinfstones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_66","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vmintam/reddit_dataset_66.","url":"https://huggingface.co/datasets/vmintam/reddit_dataset_66","creator_name":"Vu Minh Tam","creator_url":"https://huggingface.co/vmintam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"caexpo_news","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCAEXPO News Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CAEXPO (China-ASEAN Expo) News Dataset is a comprehensive collection of news articles from the offical China-ASEAN Expo website. The dataset covers various aspects including:\n\nTrade and economic cooperation\nCultural exchanges\nRegional development\nPolicy announcements\nInnovation and technology cooperation\n......\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\ntitle: The headline of the news article\nurl: URL link to the original news article‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GXMZU/caexpo_news.","url":"https://huggingface.co/datasets/GXMZU/caexpo_news","creator_name":"Guangxi Minzu University","creator_url":"https://huggingface.co/GXMZU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_66","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vmintam/reddit_dataset_66.","url":"https://huggingface.co/datasets/vmintam/reddit_dataset_66","creator_name":"Vu Minh Tam","creator_url":"https://huggingface.co/vmintam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_24.","url":"https://huggingface.co/datasets/suul999922/x_dataset_24","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_53985","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_53985.","url":"https://huggingface.co/datasets/icedwind/x_dataset_53985","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_245","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/reddit_dataset_245.","url":"https://huggingface.co/datasets/williamlewis0620/reddit_dataset_245","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_01085","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_01085.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_01085","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"SciKnowEval","keyword":"summarization","description":"\n\n   SciKnowEval \n Evaluating Multi-level Scientific Knowledge of Large Language Models \n\n\n\nPlease refer to our repository and paper for more details.\n\n\nÂçöÂ≠¶‰πã ÔºåÂÆ°ÈóÆ‰πã ÔºåÊÖéÊÄù‰πã ÔºåÊòéËæ®‰πã ÔºåÁ¨ÉË°å‰πã„ÄÇ\n‚Äî‚Äî „ÄäÁ§ºËÆ∞ ¬∑ ‰∏≠Â∫∏„Äã Doctrine of the Mean\n\n\n\n\n\n\nThe Scientific Knowledge Evaluation (SciKnowEval) benchmark for Large Language Models (LLMs) is inspired by the profound principles outlined in the ‚ÄúDoctrine of the Mean‚Äù from ancient Chinese philosophy. This benchmark is designed to assess LLMs based on their proficiency in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hicai-zju/SciKnowEval.","url":"https://huggingface.co/datasets/hicai-zju/SciKnowEval","creator_name":"AI CrossX  Lab, HIC@Zhejiang University","creator_url":"https://huggingface.co/hicai-zju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","text-classification","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_24.","url":"https://huggingface.co/datasets/suul999922/x_dataset_24","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_53985","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_53985.","url":"https://huggingface.co/datasets/icedwind/x_dataset_53985","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_245","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/reddit_dataset_245.","url":"https://huggingface.co/datasets/williamlewis0620/reddit_dataset_245","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_01085","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_01085.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_01085","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_170","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/x_dataset_170.","url":"https://huggingface.co/datasets/qr12138/x_dataset_170","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"housing-prices-malaysia-2025","keyword":"summarization","description":"This dataset contains 2,000 entries of house price data from all states in Malaysia, providing a comprehensive overview of the country‚Äôs real estate market for 2025. Sourced from Brickz, a trusted platform for property transaction insights, it includes detailed information such as property location, tenure, type, median prices, and transaction counts. This dataset is ideal for real estate market analysis, predictive modeling, and exploring trends across Malaysia‚Äôs diverse property market.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jienweng/housing-prices-malaysia-2025.","url":"https://huggingface.co/datasets/jienweng/housing-prices-malaysia-2025","creator_name":"Lai JIen Weng","creator_url":"https://huggingface.co/jienweng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","Malay","mit"],"keywords_longer_than_N":true},
	{"name":"zh-tw-essays","keyword":"summarization","description":"\n\t\n\t\t\n\t\tzh-tw-essays (12K)\n\t\n\nEssays obtained from ÂãµÂøó‰∫∫Áîü - Zeelive.\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AWeirdDev/zh-tw-essays\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\n{\n    \"title\": \"Â≠©Â≠êÁ´•Âπ¥‰∏çÂêÉËã¶ÔºåÂÆ∂Èï∑ÊôöÂπ¥ÂøÖÂêÉËã¶\"  # The title\n    \"link\": \"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\",\n    \"content\": \"Èå¢Ë≤°Ëé´ËºïÔºåÂã§Ëã¶Âæó‰æÜÔºõÂ•¢ËèØËé´Â≠∏ÔºåËá™ÂèñË≤ßÁ™Æ‚Ä¶\"  # Text content. **May be blank!**\n}\n\n","url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"mteb-GovReport","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGovReport (MTEB format)\n\t\n\nThis is the test split of the GovReport dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on GovReport with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve US government reports from their summaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-GovReport.","url":"https://huggingface.co/datasets/isaacus/mteb-GovReport","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","launch/gov_reports","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_14","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_14.","url":"https://huggingface.co/datasets/James096/reddit_dataset_14","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_061120","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_061120.","url":"https://huggingface.co/datasets/john-1111/x_dataset_061120","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_170","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/x_dataset_170.","url":"https://huggingface.co/datasets/qr12138/x_dataset_170","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_14","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_14.","url":"https://huggingface.co/datasets/James096/reddit_dataset_14","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_061120","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_061120.","url":"https://huggingface.co/datasets/john-1111/x_dataset_061120","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_206","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/intensity809/x_dataset_206.","url":"https://huggingface.co/datasets/intensity809/x_dataset_206","creator_name":"intensity heat","creator_url":"https://huggingface.co/intensity809","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PLANTS-Benchmark","keyword":"summarization","description":"vishalp/PLANTS-Benchmark dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vishalp/PLANTS-Benchmark","creator_name":"Vishal Pallagani","creator_url":"https://huggingface.co/vishalp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"MMQSD_ClipSyntel","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for MMCQS Dataset\n\t\n\nThis is the MMCQS Dataset that have been used in the paper \"CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare\"\n\nGithub: https://github.com/AkashGhosh/CLIPSyntel-AAAI2024\n\nPaper: https://arxiv.org/pdf/2312.11541\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\n\nDownload and unzip the Multimodal_images_finalnew.zip file, that can be found the in the 'Files and Version' section, to access the images that have been used in the dataset. The image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArkaAcharya/MMQSD_ClipSyntel.","url":"https://huggingface.co/datasets/ArkaAcharya/MMQSD_ClipSyntel","creator_name":"Arkadeep Acharya","creator_url":"https://huggingface.co/ArkaAcharya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"code-transports","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des transports, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"gardian-ai-ready-docs","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\t‚ö†Ô∏è Heads up: Updated Dataset Available\n\t\n\nThis dataset has been updated with a newer version published on 27 Feb 2025. The latest version includes more updated and refined set of documents.\nWe recommend using the latest version, available at https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents. This version remains accessible for reference and reproducibility purposes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs.","url":"https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"NCERT_Business_Studies_12th","keyword":"summarization","description":"KadamParth/NCERT_Business_Studies_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Business_Studies_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_10th","keyword":"summarization","description":"KadamParth/NCERT_Social_Studies_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"aifgen-domain-preference-shift","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in a mixed non stationarity scenario of both domains and preferences given a combination of given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Explain like I'm 5 answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Expert answer\nDomain: Politics, Objective: Summary, Preference: Explain like I'm 5 answer\nDomain: Politics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Research-Papers","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tAI & Machine Learning Research Papers Dataset\n\t\n\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTotal Papers: 1296\nDomains Covered: \nArtificial Intelligence (AI)\nMachine Learning (ML)\nDeep Learning\nNatural Language Processing (NLP)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers.","url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_206","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/intensity809/x_dataset_206.","url":"https://huggingface.co/datasets/intensity809/x_dataset_206","creator_name":"intensity heat","creator_url":"https://huggingface.co/intensity809","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"elka-pl-news","keyword":"summarization","description":"\n\t\n\t\t\n\t\tElka.pl news\n\t\n\nThis dataset contains scraped news articles from polish, regional news site https://elka.pl\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains articles about news, events from over 20 years in Leszno, Ko≈õcian, Gosty≈Ñ, G√≥ra, Rawicz, Wschowa cities. The CSV contains the following fields: id, url, title, subtitle, lead, author, date, content.At first, i didn't create that dataset with AI processing in mind, but mostly as a way to preserve history of region and be able to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/winterkitsune/elka-pl-news.","url":"https://huggingface.co/datasets/winterkitsune/elka-pl-news","creator_name":"Moira","creator_url":"https://huggingface.co/winterkitsune","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","Polish","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_26.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_26","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"jerome-powell-press-release-QA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for FOMC Press Conferences - Jerome Powell Era\n\t\n\nThe FOMC Press Conferences - Jerome Powell Era dataset contains comprehensive transcripts of all Federal Open Market Committee (FOMC) press conferences chaired by Jerome Powell from 2018 to 2025. This unique dataset captures the complete Q&A sessions where Chairman Powell explains monetary policy decisions, economic outlook, and responds to journalists' questions about the Federal Reserve's actions.\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BoostedJonP/jerome-powell-press-release-QA.","url":"https://huggingface.co/datasets/BoostedJonP/jerome-powell-press-release-QA","creator_name":"Jonathan Paserman","creator_url":"https://huggingface.co/BoostedJonP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","text-classification","mask-generation"],"keywords_longer_than_N":true},
	{"name":"fr-summarizer-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\ttraining data\n\t\n\n\nDataset : fr-summarizer-dataset\nData-size : 7.65 MB\ntrain : 1.97k rows\nvalidation : 440 rows\nroles : user , assistant\nFormat chatml \"role\": \"role\", \"content\": \"content\", \"user\": \"user\", \"assistant\": \"assistant\"\n*French audio podcast transcription*\n\n\n\t\n\t\t\n\t\tProject details\n\t\n\n\nFine-tuned on French audio podcast transcription data for summarization task. As a result, the model is able to summarize French audio podcast transcription data.\nThe model will be used for an AI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset.","url":"https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset","creator_name":"Derue","creator_url":"https://huggingface.co/Labagaite","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text2text-generation","French","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_166","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_166.","url":"https://huggingface.co/datasets/James096/reddit_dataset_166","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_26.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_26","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_166","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_166.","url":"https://huggingface.co/datasets/James096/reddit_dataset_166","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0501128","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0501128.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0501128","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ChatML-OpenOrca","keyword":"summarization","description":"Open-Orca/OpenOrca in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Minueza-32M-Base\")\n\ndataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n\ndef format(columns):\n    messages = []\n\n    system_prompt = columns[\"system_prompt\"].strip()\n\n    if system_prompt:\n        messages.append({\n            \"role\": \"system\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-OpenOrca.","url":"https://huggingface.co/datasets/Felladrin/ChatML-OpenOrca","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"1M-OpenOrca_be","keyword":"summarization","description":"En/Be\nüêã The Belarusian OpenOrca Dataset! üêã\n\n\n\nBelarusian OpenOrca dataset - is rich collection of augmented FLAN data aligns, that translated in belarusian language.\nThat dataset should help training LLM in belarusian language and should help on other NLP tasks.\nThis dataset have 2 version:\n\n~1M GPT-4 completions (Now translating)\n~3.2M GPT-3.5 completions (Can be translated in future)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe fields are:\n\n'id', a unique numbered identifier which includes one of 'niv'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be.","url":"https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be","creator_name":"Artsem Holub","creator_url":"https://huggingface.co/WiNE-iNEFF","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"big_patent","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Big Patent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries.\nEach US patent application is filed under a Cooperative Patent Classification (CPC) code.\nThere are nine such classification categories:\n\na: Human Necessities\nb: Performing Operations; Transporting\nc: Chemistry; Metallurgy\nd: Textiles; Paper\ne: Fixed Constructions\nf: Mechanical Engineering; Lightning; Heating;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NortheasternUniversity/big_patent.","url":"https://huggingface.co/datasets/NortheasternUniversity/big_patent","creator_name":"Northeastern University","creator_url":"https://huggingface.co/NortheasternUniversity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0501128","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0501128.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0501128","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"kurtis_mental_health_final","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nThe data is aggregated from the following datasets:\n\ndatasets/mrs83/kurtis_mental_health\ndatasets/fadodr/mental_health_therapy\ndatasets/marmikpandya/mental-health\n\nThe data has been augmentated by running summarization tasks on the initial question and answer pairs, using a sharded flan-t5-xxl model philschmid/flan-t5-xxl-sharded-fp16\n\n\t\n\t\n\t\n\t\tUses\n\t\n\n\n\t\n\t\n\t\n\t\tDirect Use\n\t\n\nThe dataset is intended for use in training conversational AI models, particularly in mental‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrs83/kurtis_mental_health_final.","url":"https://huggingface.co/datasets/mrs83/kurtis_mental_health_final","creator_name":"Massimo Roberto Scamarcia","creator_url":"https://huggingface.co/mrs83","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"RerankerLLM-Dataset","keyword":"summarization","description":"Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. We have organized re-ranking data from RankGPT and released it onto ModelScope for supporting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangrongsheng/RerankerLLM-Dataset.","url":"https://huggingface.co/datasets/wangrongsheng/RerankerLLM-Dataset","creator_name":"wangrongsheng","creator_url":"https://huggingface.co/wangrongsheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_0207146","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0207146.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0207146","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0207146","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0207146.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0207146","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"yourbench_archived","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüåü YourBench Y1: A Diverse Domain Benchmark Dataset\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nYourBench Y1 is a carefully curated dataset of documents from 8 different domains, specifically designed to evaluate language models on content likely generated or produced after July 2024. This dataset provides a unique benchmark for testing model performance on contemporary content across diverse professional and technical domains.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nüìä 8 balanced domains with 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sumukshashidhar-archive/yourbench_archived.","url":"https://huggingface.co/datasets/sumukshashidhar-archive/yourbench_archived","creator_name":"Sumuk's Archived Content","creator_url":"https://huggingface.co/sumukshashidhar-archive","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0612232","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0612232.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0612232","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0612232","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0612232.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0612232","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_76","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huyjojo/reddit_dataset_76.","url":"https://huggingface.co/datasets/huyjojo/reddit_dataset_76","creator_name":"Huy","creator_url":"https://huggingface.co/huyjojo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_218.","url":"https://huggingface.co/datasets/gk4u/x_dataset_218","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ua-codeforces-cots-open-r1-for-training","keyword":"summarization","description":"\n\t\n\t\t\n\t\tVersion of anon-researcher-ua/ua-codeforces-cots-open-r1 prepared for model training\n\t\n\n","url":"https://huggingface.co/datasets/anon-researcher-ua/ua-codeforces-cots-open-r1-for-training","creator_name":"Anonymous Researcher","creator_url":"https://huggingface.co/anon-researcher-ua","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","summarization","English","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2025","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/x_dataset_2025.","url":"https://huggingface.co/datasets/goldentraversy07/x_dataset_2025","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_30","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_30.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_30","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_76","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huyjojo/reddit_dataset_76.","url":"https://huggingface.co/datasets/huyjojo/reddit_dataset_76","creator_name":"Huy","creator_url":"https://huggingface.co/huyjojo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_218.","url":"https://huggingface.co/datasets/gk4u/x_dataset_218","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2025","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/x_dataset_2025.","url":"https://huggingface.co/datasets/goldentraversy07/x_dataset_2025","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_30","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_30.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_30","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_7.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_7","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_157","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_157.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_157","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Content-Articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tContent-Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Content-Articles dataset is a collection of academic articles and research papers across various subjects, including Computer Science, Physics, and Mathematics. This dataset is designed to facilitate research and analysis in these fields by providing structured data on article titles, abstracts, and subject classifications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nTabular: The dataset is structured in a tabular format.\nText:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Content-Articles.","url":"https://huggingface.co/datasets/prithivMLmods/Content-Articles","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_030237","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_030237.","url":"https://huggingface.co/datasets/james-1111/x_dataset_030237","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_7.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_7","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_157","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_157.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_157","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_030237","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_030237.","url":"https://huggingface.co/datasets/james-1111/x_dataset_030237","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"literary-dataset-pack","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLiterary Dataset Pack\n\t\n\nA rich and diverse multi-task instruction dataset generated from classic public domain literature.\n\n\t\n\t\t\n\t\tüìñ Overview\n\t\n\nLiterary Dataset Pack is a high-quality instruction-tuning dataset crafted from classic literary texts in the public domain (e.g., Alice in Wonderland). Each paragraph is transformed into multiple supervised tasks designed to train or fine-tune large language models (LLMs) across a wide range of natural language understanding and generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeXpedite/literary-dataset-pack.","url":"https://huggingface.co/datasets/codeXpedite/literary-dataset-pack","creator_name":"CodeXpedite","creator_url":"https://huggingface.co/codeXpedite","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"bad-numbers","keyword":"summarization","description":"5digit/bad-numbers dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/5digit/bad-numbers","creator_name":"iliya","creator_url":"https://huggingface.co/5digit","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"usul-alkafi","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUsul Al-Kafi Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the full text of ÿßŸÑÿ£ÿµŸàŸÑ ŸÖŸÜ ÿßŸÑŸÉÿßŸÅŸä, a foundational Islamic book authored by ÿ´ŸÇÿ© ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖ ÿ£ÿ®Ÿä ÿ¨ÿπŸÅÿ± ŸÖÿ≠ŸÖÿØ ÿ®ŸÜ ŸäÿπŸÇŸàÿ® ÿ®ŸÜ ÿ•ÿ≥ÿ≠ÿßŸÇ ÿßŸÑŸÉŸÑŸäŸÜŸä ÿßŸÑÿ±ÿßÿ≤Ÿä. Each row in the dataset represents a single page from the book, preserving the original Arabic text structure. The book is divided into eight parts and includes beneficial annotations derived from various commentaries.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nVersion: 1.0  \nSource: Digitized from Dar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/usul-alkafi.","url":"https://huggingface.co/datasets/aliahabeeb/usul-alkafi","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","Arabic"],"keywords_longer_than_N":true},
	{"name":"kurmanji-dataset","keyword":"summarization","description":"rcspecter/kurmanji-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rcspecter/kurmanji-dataset","creator_name":"Christoph Scholz","creator_url":"https://huggingface.co/rcspecter","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Kurdish","apache-2.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"latin-summarizer-dataset","keyword":"summarization","description":"\n  \n    ‚ú® LatinSummarizer Dataset ‚ú®\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\nNote: If Dataset Viewer is not available, see samples of dataset for samples from the dataset.The LatinSummarizer Dataset is a comprehensive collection of Latin texts designed to support natural language processing research for a low-resource language. It provides parallel data for various tasks, including translation (Latin-to-English) and summarization (extractive and abstractive).\nThis dataset was created for a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/latin-summarizer-dataset.","url":"https://huggingface.co/datasets/LatinNLP/latin-summarizer-dataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","translation","Latin","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"latin-summarizer-dataset","keyword":"summarization","description":"\n  \n    ‚ú® LatinSummarizer Dataset ‚ú®\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\nNote: If Dataset Viewer is not available, see samples of dataset for samples from the dataset.The LatinSummarizer Dataset is a comprehensive collection of Latin texts designed to support natural language processing research for a low-resource language. It provides parallel data for various tasks, including translation (Latin-to-English) and summarization (extractive and abstractive).\nThis dataset was created for a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/latin-summarizer-dataset.","url":"https://huggingface.co/datasets/LatinNLP/latin-summarizer-dataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","translation","Latin","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_21.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_21","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27221","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_27221.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_27221","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_21.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_21","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27221","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_27221.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_27221","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"X_Twitter_Trending_Topics_August2025","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüê¶ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics.This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and instantly structure tweet data into clean JSON.\nStart Scraping\n\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Key Features\n\t\n\n\n‚ö° Real-Time Fetch ‚Äì Stream the latest tweets the moment they‚Äôre posted  \nüéØ Flexible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025.","url":"https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_90","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_90.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_90","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ai-scoring","keyword":"summarization","description":"dio-dev/ai-scoring dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/dio-dev/ai-scoring","creator_name":"Oleksandr Kyslytskyi","creator_url":"https://huggingface.co/dio-dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_90","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_90.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_90","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"babbling_kinova","keyword":"summarization","description":"mvnagakishan/babbling_kinova dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mvnagakishan/babbling_kinova","creator_name":"Venkata Naga Kishan Munjulury","creator_url":"https://huggingface.co/mvnagakishan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","table-question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat-collectivites-mayotte","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat et des collectivit√©s publiques applicable √† la collectivit√© territoriale de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_58","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_58.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_58","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Math-Solve","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Math-Solve dataset is a collection of math problems and their solutions, designed to facilitate training and evaluation of models for tasks such as text generation, question answering, and summarization. The dataset contains nearly 25k rows of math-related problems, each paired with a detailed solution.\nThis dataset is particularly useful for researchers and developers working on AI models that require mathematical reasoning and problem-solving capabilities.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve.","url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_58","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_58.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_58","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_162","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_162.","url":"https://huggingface.co/datasets/James096/reddit_dataset_162","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_112","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_112.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_112","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_17.","url":"https://huggingface.co/datasets/suul999922/x_dataset_17","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aclsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications\n\t\n\nThis repository contains data for our paper \"ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications\" and a small \nutility class to work with it.\n\n\t\n\t\t\n\t\tHuggingFace datasets\n\t\n\nYou can also use Huggin Face datasets to load ACLSum (dataset link).\nThis would be convenient if you want to train transformer models using our dataset.\nJust do,\nfrom datasets import load_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sobamchan/aclsum.","url":"https://huggingface.co/datasets/sobamchan/aclsum","creator_name":"sotaro takeshita","creator_url":"https://huggingface.co/sobamchan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"NCERT_Political_Science_11th","keyword":"summarization","description":"KadamParth/NCERT_Political_Science_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Political_Science_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_162","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_162.","url":"https://huggingface.co/datasets/James096/reddit_dataset_162","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_112","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_112.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_112","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_17.","url":"https://huggingface.co/datasets/suul999922/x_dataset_17","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AI‚ÄëCulture‚ÄëCommons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"legislacao-ufam","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset: Legisla√ß√£o Acad√™mica da UFAM\n\t\n\nEste dataset cont√©m textos da legisla√ß√£o acad√™mica de Gradua√ß√£o da Universidade Federal do Amazonas (UFAM), extra√≠dos de PDFs atrav√©s do uso do Tesseract OCR com \nsupervis√£o humana para garantir a qualidade dos textos. Documentos em pior qualidade foram digitados manualmente para formar arquivos TXT precisos.\n\n\t\n\t\t\n\t\tEstrutura do Dataset\n\t\n\nO dataset √© organizado da seguinte forma:\n‚îú‚îÄ‚îÄ data\n‚îÇ   ‚îú‚îÄ‚îÄ train.parquet\n‚îÇ   ‚îî‚îÄ‚îÄ test.parquet\n‚îú‚îÄ‚îÄ faqs\n‚îÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/matiusX/legislacao-ufam.","url":"https://huggingface.co/datasets/matiusX/legislacao-ufam","creator_name":"Matheus Palheta","creator_url":"https://huggingface.co/matiusX","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","zero-shot-classification","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"summary-demo","keyword":"summarization","description":"jacquetg/summary-demo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jacquetg/summary-demo","creator_name":"Gottfried JACQUET","creator_url":"https://huggingface.co/jacquetg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"jfk-files-text","keyword":"summarization","description":"\n\t\n\t\t\n\t\tNational Archives JFK Files Text Dataset\n\t\n\nThis dataset contains extracted text from the JFK assassination records released by the National Archives. The dataset preserves the original directory structure from archive.gov while providing significant performance and storage benefits for data analysis, AI applications, and large-scale processing.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured with the following columns:\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\nyear\nThe release year of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mysocratesnote/jfk-files-text.","url":"https://huggingface.co/datasets/mysocratesnote/jfk-files-text","creator_name":"Bill","creator_url":"https://huggingface.co/mysocratesnote","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","translation","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"high-quality-summary-v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHigh Quality Long Text Summarization Dataset\n\t\n\n\nInput texts from agentlans/high-quality-text-long sample_k10000 config\nSummaries generated by google/gemma-3-12b-it\nSummaries rewritten by agentlans/granite-3.3-2b-reviser\n\n","url":"https://huggingface.co/datasets/agentlans/high-quality-summary-v2","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_22.","url":"https://huggingface.co/datasets/James096/x_dataset_22","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_22.","url":"https://huggingface.co/datasets/James096/x_dataset_22","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"high-quality-summary-v2","keyword":"summary","description":"\n\t\n\t\t\n\t\tHigh Quality Long Text Summarization Dataset\n\t\n\n\nInput texts from agentlans/high-quality-text-long sample_k10000 config\nSummaries generated by google/gemma-3-12b-it\nSummaries rewritten by agentlans/granite-3.3-2b-reviser\n\n","url":"https://huggingface.co/datasets/agentlans/high-quality-summary-v2","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_29.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_29","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"robonar","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìá RONAR (RoboNar) Dataset\n\t\n\nüìÑ Paper on arXiv  | üåê Project Website\nRONAR introduces a real-world multimodal dataset paired with natural language narrations for robotic experience grounding. Built on the Stretch SE3 mobile manipulator in real home environments, the dataset supports behavior transparency, risk estimation, and failure recovery for intelligent robotics systems. It underlies the RONAR framework described in the CoRL 2024 paper: \"I Can Tell What I Am Doing: Toward‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robonar/robonar.","url":"https://huggingface.co/datasets/robonar/robonar","creator_name":"RoboNar","creator_url":"https://huggingface.co/robonar","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","object-detection","robotics","English"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iii","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe III, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_138","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/reddit_dataset_138.","url":"https://huggingface.co/datasets/markrogolino/reddit_dataset_138","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_29.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_29","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_138","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/reddit_dataset_138.","url":"https://huggingface.co/datasets/markrogolino/reddit_dataset_138","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Ncert_dataset","keyword":"summarization","description":"KadamParth/Ncert_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/Ncert_dataset","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"code-minier-nouveau","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode minier (nouveau), non-instruct (2025-09-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_210","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholejohnson0530/reddit_dataset_210.","url":"https://huggingface.co/datasets/nicholejohnson0530/reddit_dataset_210","creator_name":"Nichole Johnson","creator_url":"https://huggingface.co/nicholejohnson0530","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_210","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholejohnson0530/reddit_dataset_210.","url":"https://huggingface.co/datasets/nicholejohnson0530/reddit_dataset_210","creator_name":"Nichole Johnson","creator_url":"https://huggingface.co/nicholejohnson0530","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Synthetic-data_Human-summary","keyword":"summarization","description":"Text written by Granite 3.0 8B, OLMoE 1B-7B, OLMo 7B, and summarized by me.\nJSON array of objects, each of which has a .text and .summary property\nNew ones added regularly.\n","url":"https://huggingface.co/datasets/Fishfishfishfishfish/Synthetic-data_Human-summary","creator_name":"Rm","creator_url":"https://huggingface.co/Fishfishfishfishfish","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"x_dataset_010718","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_010718.","url":"https://huggingface.co/datasets/william-1111/x_dataset_010718","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_5.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_5","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_010718","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_010718.","url":"https://huggingface.co/datasets/william-1111/x_dataset_010718","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_5.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_5","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Largest-Banks","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about the largest banks globally, including their rank, name, and total assets (in US$ billion as of 2023). The data was scraped from Wikipedia's List of Largest Banks. It can be used for financial analysis, market research, and educational purposes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nRank: The rank of the bank based on total assets.\nBank Name: The name of the bank.\nTotal Assets (2023, US$ billion): The total assets of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamramzan/Largest-Banks.","url":"https://huggingface.co/datasets/iamramzan/Largest-Banks","creator_name":"Muhammad Ramzan","creator_url":"https://huggingface.co/iamramzan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"earnings-call-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEarnings Call Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains comprehensive summaries of corporate earnings call transcripts generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides structured insights into company performance, strategic initiatives, market conditions, and forward-looking guidance.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/earnings-call-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/earnings-call-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"earnings-call-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEarnings Call Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains comprehensive summaries of corporate earnings call transcripts generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides structured insights into company performance, strategic initiatives, market conditions, and forward-looking guidance.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/earnings-call-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/earnings-call-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Human-Style-Answers","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHuman Style Answers\n\t\n\n\n\nThis Datasets contains question and answers on different topics in Human style. (For Chatbots training)\nThis Datasets is build using TOP AI like (GPT4, Claude3 , Command R+, etc.)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\nThe Human Style Response Dataset is a rich collection of question-and-answer pairs, meticulously crafted in a human-like style. It serves as a valuable resource for training chatbots and conversational AI models. Let's dive into the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/innova-ai/Human-Style-Answers.","url":"https://huggingface.co/datasets/innova-ai/Human-Style-Answers","creator_name":"INNOVA AI","creator_url":"https://huggingface.co/innova-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","translation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_226","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_226.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_226","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_214","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_214.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_214","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_19.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_19","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ghana-news","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\nThe Ghana news topic classification dataset is constructed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news.","url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"summarization","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"summarization","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_226","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_226.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_226","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_214","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_214.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_214","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_19.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_19","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"spembeddings","keyword":"summarization","description":"modernlegal/spembeddings dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/modernlegal/spembeddings","creator_name":"Modern Legal","creator_url":"https://huggingface.co/modernlegal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Slovenian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bigpatent-all","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/bigpatent-all\n\t\n\nOriginal bigpatent subset \"all\" converted to hf format, columns renamed, some cleaning applied to \"summary\" column.\n\n\t\n\t\t\n\t\tadditional configs\n\t\n\n\nthe deduped config, which has the summary col deduped via minhash\nthe mini config, which is a ~1 GB version of the deduped dataset created via a minipile-like clustering+sampling approach\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/bigpatent-all","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","summarization","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Boxing-Champions","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tWorld Heavyweight Boxing Champions Dataset\n\t\n\nThis dataset contains information about world heavyweight boxing champions extracted from the Wikipedia page. It includes details such as champion names, reign periods, and title defenses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\n\t\n\t\t\nColumn Name\nDescription\n\n\n\t\t\nNo\nThe ordinal number of the champion.\n\n\nChampion\nName of the heavyweight boxing champion.\n\n\nRecognition\nThe organization or title under which the reign was recognized.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamramzan/Boxing-Champions.","url":"https://huggingface.co/datasets/iamramzan/Boxing-Champions","creator_name":"Muhammad Ramzan","creator_url":"https://huggingface.co/iamramzan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_67","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orochi001/reddit_dataset_67.","url":"https://huggingface.co/datasets/orochi001/reddit_dataset_67","creator_name":"tran","creator_url":"https://huggingface.co/orochi001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_67","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orochi001/reddit_dataset_67.","url":"https://huggingface.co/datasets/orochi001/reddit_dataset_67","creator_name":"tran","creator_url":"https://huggingface.co/orochi001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_540880","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_540880.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_540880","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"synthetic-fine-arts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Fine Arts (Challenge, Solution) Dataset\n\t\n\n\nDescriptionSynthetic Fine Arts is a 225,000-row dataset of (artistic challenge, proposed solution) pairs spanning multiple areas within Visual Arts, Performing Arts, Musical Arts, Literary Arts, Digital Arts, Art History, and Art Theory.  \nEach entry provides a high-level ArtisticChallenge, accompanied by a ProposedSolution referencing established or pseudo-random creative techniques, theoretical principles, and historical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/synthetic-fine-arts.","url":"https://huggingface.co/datasets/Taylor658/synthetic-fine-arts","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","other","English"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28105","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_28105.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_28105","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_540880","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_540880.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_540880","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28105","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_28105.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_28105","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_130","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_130.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_130","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_130","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_130.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_130","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-aviation-civile","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'aviation civile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du domaine public fluvial et de la navigation int√©rieure, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_12","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/reddit_dataset_12.","url":"https://huggingface.co/datasets/bit0/reddit_dataset_12","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"OpenWeb383K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenWeb Datasets Web Collection\n\t\n\nThe OpenWeb Datasets Web Collection, derived from the 'FineWeb' dataset, consists of more than 15 trillion tokens of cleaned and deduplicated English web data from CommonCrawl. The data processing pipeline is optimized for LLM performance, and the necessary set of datasets has been extracted from Hugging Face's FineWeb collections. This dataset was created by processing 96 CommonCrawl dumps, comprising web data crawled from the summer of 2013 to April‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/OpenWeb383K.","url":"https://huggingface.co/datasets/prithivMLmods/OpenWeb383K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text2text-generation","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"gardian-cigi-ai-documents","keyword":"summarization","description":"Documents: 65,550\nPages: 1,780,047\nTokens: 343,498,673 \n\n\t\n\t\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset represents a comprehensive collection of 65,550 agricultural research publications from CGIAR,\nspecifically processed and structured for Large Language Model (LLM) applications in agricultural advisory services. \nThis dataset bridges the gap between advanced agricultural research and field-level advisory needs, \ndrawing from CGIAR's extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents.","url":"https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","doi:10.57967/hf/4327"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_146","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_146.","url":"https://huggingface.co/datasets/James096/reddit_dataset_146","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_12","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/reddit_dataset_12.","url":"https://huggingface.co/datasets/bit0/reddit_dataset_12","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_146","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_146.","url":"https://huggingface.co/datasets/James096/reddit_dataset_146","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070513","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070513.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070513","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0209123","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0209123.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0209123","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_28.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_28","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summary_dataset_en","keyword":"summarization","description":"\n\t\n\t\t\n\t\tContent\n\t\n\nThis dataset was created from three datasets:\n\nBBC News Summary\nCNN-DailyMail News Text Summarization\nGenerated text from LLM models\n\nThan was create Kaggle dataset:\n\nText for summarize NLP/LLM task (En)\n\nThe dataset was filtered, shuffled, and divided into parts before being saved to Hugging Face.\n\n\t\n\t\n\t\n\t\tAcknowledgements\n\t\n\n\nThe dataset was created with the support of resources from SV metal spol. s r.o.\n\n","url":"https://huggingface.co/datasets/KRadim/summary_dataset_en","creator_name":"Radim K√∂zl","creator_url":"https://huggingface.co/KRadim","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","English","pddl"],"keywords_longer_than_N":true},
	{"name":"x_dataset_070513","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_070513.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_070513","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0209123","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0209123.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0209123","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_28.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_28","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21447","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_21447.","url":"https://huggingface.co/datasets/momo1942/x_dataset_21447","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_6.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_6","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_49","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_49.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_49","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0308199","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0308199.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0308199","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_157","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mo0han3d/reddit_dataset_157.","url":"https://huggingface.co/datasets/Mo0han3d/reddit_dataset_157","creator_name":"AbdElMonsef","creator_url":"https://huggingface.co/Mo0han3d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21447","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_21447.","url":"https://huggingface.co/datasets/momo1942/x_dataset_21447","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_6.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_6","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_49","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_49.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_49","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0308199","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0308199.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0308199","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_157","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mo0han3d/reddit_dataset_157.","url":"https://huggingface.co/datasets/Mo0han3d/reddit_dataset_157","creator_name":"AbdElMonsef","creator_url":"https://huggingface.co/Mo0han3d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quanglt/x_dataset_44.","url":"https://huggingface.co/datasets/quanglt/x_dataset_44","creator_name":"Quang Le","creator_url":"https://huggingface.co/quanglt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"african-history-extra","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAfrican History Extra\n\t\n\n\nA simple version of african history in English using CoT for generating synthetic datas for fine-tuning and RAG.\n","url":"https://huggingface.co/datasets/Svngoku/african-history-extra","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_29.","url":"https://huggingface.co/datasets/suul999922/x_dataset_29","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2013-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2013 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2013 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2013-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_118","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chz1001/x_dataset_118.","url":"https://huggingface.co/datasets/chz1001/x_dataset_118","creator_name":"z","creator_url":"https://huggingface.co/chz1001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wedding_album_ai","keyword":"summarization","description":"Ihorog/wedding_album_ai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ihorog/wedding_album_ai","creator_name":"–Ü–≥–æ—Ä","creator_url":"https://huggingface.co/Ihorog","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","Ukrainian","apache-2.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quanglt/x_dataset_44.","url":"https://huggingface.co/datasets/quanglt/x_dataset_44","creator_name":"Quang Le","creator_url":"https://huggingface.co/quanglt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_29.","url":"https://huggingface.co/datasets/suul999922/x_dataset_29","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_118","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chz1001/x_dataset_118.","url":"https://huggingface.co/datasets/chz1001/x_dataset_118","creator_name":"z","creator_url":"https://huggingface.co/chz1001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2013-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2013 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2013 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2013-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46763","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_46763.","url":"https://huggingface.co/datasets/icedwind/x_dataset_46763","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0103245","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0103245.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0103245","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_151","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_151.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_151","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_84","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_84.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_84","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46763","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_46763.","url":"https://huggingface.co/datasets/icedwind/x_dataset_46763","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0103245","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0103245.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0103245","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_151","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_151.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_151","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_84","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_84.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_84","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-action-sociale-familles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'action sociale et des familles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"qa","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nProduct's information in QA converstional style.\n\nCurated by: [Neverland.OG]\nLanguage(s) (NLP): [ENGLISH]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\nhttps://huggingface.co/datasets/nvl-og/products\n\nRepository: [More Information Needed]\n\n","url":"https://huggingface.co/datasets/neverland-th/qa","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_84","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_84.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_84","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_84","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_84.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_84","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_96","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_96.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_96","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"BanglaSum","keyword":"summarization","description":"We created a dataset by web scraping different online newspapers like ‚ÄòThe Daily Star‚Äô, ‚ÄòProthomAlo‚Äô, and ‚ÄòBBC News Bangla‚Äô using the Beautiful Soup library of Python. The dataset's features are ‚Äòtitle‚Äô, ‚Äòtext‚Äô & ‚Äòsummary‚Äô.\nThe dataset was preprocessed using the Python library ‚Äòpandas‚Äô and all duplicates and null values were eliminated and the total number of rows remaining is 9311. Since there is a lack of datasets in the Bengali language, this dataset will be useful for tasks like text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/midnightGlow/BanglaSum.","url":"https://huggingface.co/datasets/midnightGlow/BanglaSum","creator_name":"Anusree Roy","creator_url":"https://huggingface.co/midnightGlow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text2text-generation","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"code-securite-sociale","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© sociale, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"slimpajama_850m","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset for summarization of documents.\n\t\n\nAdapted from this repo.\nDeveloped by: Zhipeng Han, Pruthvi Gowda Thorehosur Appajigowda\nFunded by: Microsoft\nShared by: Zhipeng Han\nNOTICE: This dataset is a partial of cerebras/SlimPajama-627B dataset. SlimPajama-6B is a Sampled version of cerebras/SlimPajama-627B.\nSince the original data was shuffled before chunking, Only downloaded train/chunk1 (of 10 total) and further sampled 10%. This should result in roughly 6B tokens, hence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhhan/slimpajama_850m.","url":"https://huggingface.co/datasets/zhhan/slimpajama_850m","creator_name":"Zhipeng Han","creator_url":"https://huggingface.co/zhhan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"volve_daily_drilling_report","keyword":"summarization","description":"This is the repository for the Daily Drilling Reports (DDRs) from Volve field, consisting of 1759 files. The original files were in WITSML format, but they have been converted into JSON format here.\n","url":"https://huggingface.co/datasets/bengsoon/volve_daily_drilling_report","creator_name":"bengsoon chuah","creator_url":"https://huggingface.co/bengsoon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","feature-extraction","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_96","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_96.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_96","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ScienceGlossary","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tDataset Card for Science Terms and Phrases Glossary\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset was created by web scraping scientific glossaries from sources like Wikipedia, NASA, and other academic references. Additionally, some terms were generated using ChatGPT-4.0.  \nIt is designed for token classification, meaning it includes both scientific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary.","url":"https://huggingface.co/datasets/JonyC/ScienceGlossary","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_206","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_206.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_206","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_206","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_206.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_206","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58641","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_58641.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_58641","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"exorde-social-media-one-month-2024","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-one-month-2024","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-retrieval","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58641","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_58641.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_58641","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0703124","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0703124.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0703124","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PTS-Dataset","keyword":"summarization","description":"ahmedmbutt/PTS-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ahmedmbutt/PTS-Dataset","creator_name":"Ahmed Mujtaba Butt","creator_url":"https://huggingface.co/ahmedmbutt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_250.","url":"https://huggingface.co/datasets/James096/reddit_dataset_250","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0703124","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0703124.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0703124","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_250.","url":"https://huggingface.co/datasets/James096/reddit_dataset_250","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PENS","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for PENS: PErsonalized News headlineS\n\t\n\n\n\nPENS is an English dataset for Personalized News Headline Generation Research. It contains two parts for training and test individually. The training set was collected from anonymized user impressions logs of Microsoft News website, and the test set is manually-created by hundreds of native speakers to enable a fair testbed for evaluating models in an offline mode.\nPENS contains about 113k English news articles whose topics are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THEATLAS/PENS.","url":"https://huggingface.co/datasets/THEATLAS/PENS","creator_name":"Lian Junhong","creator_url":"https://huggingface.co/THEATLAS","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"autoencoder-paraphrase-dataset","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_8.","url":"https://huggingface.co/datasets/gk4u/x_dataset_8","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0306116","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0306116.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0306116","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CURIA-summaries-2020","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCURIA Summaries 2020\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCURIA Summaries 2020 is an open-source dataset containing case summaries for all English-language judgments by the Court of Justice of the European Union (CJEU) in 2020. The summaries were generated using the LLama2-7b model fine-tuned with Orca-style datasets provided by pankajmathur/orca_mini_v3_7b. The original case law texts were sourced from the Eur-Lex database, which provides access to EU legal texts.\nThe dataset is structured‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandre-dc/CURIA-summaries-2020.","url":"https://huggingface.co/datasets/alexandre-dc/CURIA-summaries-2020","creator_name":"Alexandre Correia","creator_url":"https://huggingface.co/alexandre-dc","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc0-1.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"CURIA-summaries-2020","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCURIA Summaries 2020\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCURIA Summaries 2020 is an open-source dataset containing case summaries for all English-language judgments by the Court of Justice of the European Union (CJEU) in 2020. The summaries were generated using the LLama2-7b model fine-tuned with Orca-style datasets provided by pankajmathur/orca_mini_v3_7b. The original case law texts were sourced from the Eur-Lex database, which provides access to EU legal texts.\nThe dataset is structured‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandre-dc/CURIA-summaries-2020.","url":"https://huggingface.co/datasets/alexandre-dc/CURIA-summaries-2020","creator_name":"Alexandre Correia","creator_url":"https://huggingface.co/alexandre-dc","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc0-1.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_8.","url":"https://huggingface.co/datasets/gk4u/x_dataset_8","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0306116","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0306116.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0306116","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-fonction-publique","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la fonction publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"BOE-XSUM","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBOE-XSUM Balanced Dataset - Reviewed and Cleaned\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe BOE 2025 Dataset is a collection of BOE articles with extreme summaries of them. This dataset has been carefully balanced and cleaned to ensure its quality and usefulness in natural language processing (NLP) tasks, primarily for evaluating generative models.\nRead more in https://arxiv.org/abs/2509.24908\n\n\t\n\t\t\n\t\tDataset Content\n\t\n\nThe dataset is composed of the following subsets (splits):\n\ntrain: Training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bertin-project/BOE-XSUM.","url":"https://huggingface.co/datasets/bertin-project/BOE-XSUM","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","Spanish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41613","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_41613.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_41613","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41613","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_41613.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_41613","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_158","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artao/x_dataset_158.","url":"https://huggingface.co/datasets/artao/x_dataset_158","creator_name":"arvee taofu","creator_url":"https://huggingface.co/artao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_57","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cappedapollo/reddit_dataset_57.","url":"https://huggingface.co/datasets/cappedapollo/reddit_dataset_57","creator_name":"Derik Han","creator_url":"https://huggingface.co/cappedapollo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0105204","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0105204.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0105204","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"COREX-18","keyword":"summarization","description":"\n  \n\n\nCOREX 18\n\n\nIntroducing COREX-18, a comprehensive dataset derived from the 2018 version of the CORE dataset. Our goal is to contribute to the research community by compiling open-access scientific papers and publishing them in extensive datasets. These datasets will facilitate advanced RAG applications and enhance artificial intelligence research.\nCOREX was developed as part of our X initiative, which aims to maintain and compile publicly available data into accessible and regularly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/COREX-18.","url":"https://huggingface.co/datasets/laion/COREX-18","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/LEGI.","url":"https://huggingface.co/datasets/Tricoteuses/LEGI","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"NCERT_Chemistry_12th","keyword":"summarization","description":"KadamParth/NCERT_Chemistry_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Chemistry_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_158","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artao/x_dataset_158.","url":"https://huggingface.co/datasets/artao/x_dataset_158","creator_name":"arvee taofu","creator_url":"https://huggingface.co/artao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_57","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cappedapollo/reddit_dataset_57.","url":"https://huggingface.co/datasets/cappedapollo/reddit_dataset_57","creator_name":"Derik Han","creator_url":"https://huggingface.co/cappedapollo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0105204","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0105204.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0105204","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"axya-tech-websearch","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDhivehi Combined Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset combines three 30K Dhivehi language corpora from the Leipzig Corpora Collection into a single unified CSV file containing 90,000 sentences. The dataset provides a comprehensive resource for Dhivehi language processing, combining data from Wikipedia, news sources, and web crawls.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThe dataset consists of three distinct sources:\n\nWikipedia (2021): 30,000 sentences from Dhivehi Wikipedia\nNews‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/axmeeabdhullo/axya-tech-websearch.","url":"https://huggingface.co/datasets/axmeeabdhullo/axya-tech-websearch","creator_name":"Azmy","creator_url":"https://huggingface.co/axmeeabdhullo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","translation","Divehi"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2205","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_2205.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_2205","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_27.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_27","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2205","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_2205.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_2205","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_27.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_27","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CVEV5Errors","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcvelint\n\t\n\nCVE records in the v5 JSON schema may include errors that are neither enforceable by a schema, nor validated on the backend in CVE Services when a CVE record is created/updated.\nThis CLI tool aims to validate CVE records for such errors so they can be fixed, and changes to the CVE schema can be made based on these findings.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\n\n\t\n\t\t\n\t\tBinary Releases\n\t\n\nFor Linux, macOS, or Windows, you can download a binary release here.\n\n\t\n\t\t\n\t\tBuild from Source\n\t\n\n$‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cvelist/CVEV5Errors.","url":"https://huggingface.co/datasets/cvelist/CVEV5Errors","creator_name":"cvelist","creator_url":"https://huggingface.co/cvelist","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"code-communes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des communes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Israel-palestine-war","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"Israel-palestine-war\"\n\t\n\nThis Demo dataset is related to the research paper entitle \"Online News Channel Streaming: A Comprehensive Analysis of Channel and User Engagement during the Israel-Palestine Conflict\".\nPREPRINT (Version 1) available at Research Square https://www.researchsquare.com/article/rs-3927576/latest\n\nUser Comments on News YouTube channels During Current War of Palstine & Israel Oct-2023.\nDemo dataset size: {'NBCNews': 188490, 'aljazeeraenglish':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alsubari/Israel-palestine-war.","url":"https://huggingface.co/datasets/alsubari/Israel-palestine-war","creator_name":"akram alsubari","creator_url":"https://huggingface.co/alsubari","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","text2text-generation","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"vietnam-normalize-24k","keyword":"summarization","description":"thanhkt/vietnam-normalize-24k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/thanhkt/vietnam-normalize-24k","creator_name":"Tran Khanh Thanh","creator_url":"https://huggingface.co/thanhkt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-speech","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_94","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Goldragon/reddit_dataset_94.","url":"https://huggingface.co/datasets/Goldragon/reddit_dataset_94","creator_name":"Goldragon","creator_url":"https://huggingface.co/Goldragon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050976","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050976.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050976","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"sam_altman_essays","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tDataset Card for Sam Altman Essay Collection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete collection of essays written by Sam Altman, an entrepreneur, investor, and former president of Y Combinator. The essays cover a wide range of topics including startups, technology, artificial intelligence, leadership, and personal growth. Each essay has been cleaned and processed to extract the title, date of publication, and the full text content.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sgoel9/sam_altman_essays.","url":"https://huggingface.co/datasets/sgoel9/sam_altman_essays","creator_name":"Samarth Goel","creator_url":"https://huggingface.co/sgoel9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"state-of-the-union-addresses","keyword":"summarization","description":"This dataset includes all recorded (spoken and written) addresses to the United States Congress from the President of the United States of America. \nThe addresses span all Presidents, but differ in their modality. From 1801 to 1913 the addresses were provided in writing to Congress with the remainder provided in person in the form of a speech. \nEach address was scraped from The American Presidency Project, a website supported the UC Santa Barbara. Their mission statement is to, \"be recognized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsulz/state-of-the-union-addresses.","url":"https://huggingface.co/datasets/jsulz/state-of-the-union-addresses","creator_name":"Jared Sulzdorf","creator_url":"https://huggingface.co/jsulz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_94","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Goldragon/reddit_dataset_94.","url":"https://huggingface.co/datasets/Goldragon/reddit_dataset_94","creator_name":"Goldragon","creator_url":"https://huggingface.co/Goldragon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050976","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050976.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050976","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"x_dataset_152","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/synapz/x_dataset_152.","url":"https://huggingface.co/datasets/synapz/x_dataset_152","creator_name":"Derek Barnes","creator_url":"https://huggingface.co/synapz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summeval","keyword":"summarization","description":"\n  SummEvalSummarization.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article Summary Semantic Similarity Estimation. This version fixes a bug in the evaluation script that caused the main score to be computed incorrectly.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/Yale-LILY/SummEval\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/summeval.","url":"https://huggingface.co/datasets/mteb/summeval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","human-annotated","monolingual","mteb/summeval","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_152","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/synapz/x_dataset_152.","url":"https://huggingface.co/datasets/synapz/x_dataset_152","creator_name":"Derek Barnes","creator_url":"https://huggingface.co/synapz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CLSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCLSum\n\t\n\n\n\n\n\nCLSum is a dataset for common law court judgment summarization\nCLSum covers court judgments from four common law jurisdictions: the United Kingdom, Canada, Australia, and Hong Kong SAR.\nPaper [Arxiv PDF] [Published Version]\nGithub Page [Link]\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCLSum is licensed under ODC-BY.\n\n\t\n\t\t\n\t\tDownload\n\t\n\nDownload from Google Drive link\nWhen using the CLSum dataset in a product or service, or including data in a redistribution, please cite the following paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shuaiqi/CLSum.","url":"https://huggingface.co/datasets/Shuaiqi/CLSum","creator_name":"LIU","creator_url":"https://huggingface.co/Shuaiqi","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","odc-by","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040849","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040849.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040849","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MUTANT","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nMUTANT (A Multi-sentential Code-mixed Hinglish Dataset): MUTANT is a high-quality Hindi-English code-mixed dataset designed for tasks related to multi-sentential text processing, particularly focusing on summarization and evaluation.\n\n\t\n\t\t\n\t\tDATA Sources\n\t\n\nMUTANT dataset comprises code-mixed long-length texts extracted from two main sources:\n1. Political Speeches & Press Releases: Collected from government portals and political party websites.\n2. Hindi News‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/MUTANT.","url":"https://huggingface.co/datasets/LingoIITGN/MUTANT","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Hindi","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0608106","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0608106.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0608106","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"neurips_openreview_v1","keyword":"summarization","description":"We collect the dataset from openreview.\nDataset({\nfeatures: ['id', 'image', 'page_number', 'summaries'],\nnum_rows: 673\n})\n\nTo view the image\nfrom PIL import Image\nimport io\n\nImage.open(io.BytesIO(img))\n\n","url":"https://huggingface.co/datasets/DetionDX/neurips_openreview_v1","creator_name":"X. Di","creator_url":"https://huggingface.co/DetionDX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040849","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040849.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040849","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0608106","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0608106.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0608106","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rqft","keyword":"summarization","description":"Reliable Query-focused Summarization Tester (RQFT) is a dataset to evaluate Query-focused Summarization models. It contains 203 <query, document, summary> triples which can be used to evaluate Query-focused Summarizing models. Each document has more than 1 query on an average (1.41 to be precise). This is a design choice to tackle Topic Centralization, see Baumel et al., 2016.\nFor more details, we refer the reader to our EMNLP 2023 paper: Reinforcement Replaces Supervision: Query focused‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/rqft.","url":"https://huggingface.co/datasets/swaroop-nath/rqft","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"news-of-the-brazilian-newspaper","keyword":"summarization","description":"\n\t\n\t\t\n\t\tNews of the Brazilian Newspaper\n\t\n\nThis repository contains a comprehensive dataset of news articles from a Brazilian newspaper, Folha de S√£o Paulo (http://www.folha.uol.com.br/). The dataset includes 167,053 examples of news articles, comprising headlines, URLs of articles, complete articles, and their respective categories. \n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe headlines were initially gathered from Inshorts and were then used to scrape the complete news articles from Folha de S√£o Paulo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper.","url":"https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","text-generation","Portuguese"],"keywords_longer_than_N":true},
	{"name":"german-parliament-speeches","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman Parliament Speeches\n\t\n\nThis dataset contains speeches from the German parliament, derived from the Open Discourse Project (Harvard Dataverse).\n\n\t\n\t\t\n\t\tSource\n\t\n\nData source:  \nOpen Discourse ProjectHarvard DataverseDOI: 10.7910/DVN/FIKIBO\nOriginal citation:\n@data{DVN/FIKIBO_2020,\nauthor = {Richter, Florian and Koch, Philipp and Franke, Oliver and Kraus, Jakob and Kuruc, Fabrizio and Thiem, Anja and H√∂gerl, Judith and Heine, Stella and Sch√∂ps, Konstantin},\npublisher = {Harvard‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emilpartow/german-parliament-speeches.","url":"https://huggingface.co/datasets/emilpartow/german-parliament-speeches","creator_name":"Emil Partow","creator_url":"https://huggingface.co/emilpartow","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","question-answering","German"],"keywords_longer_than_N":true},
	{"name":"Hamama","keyword":"summarization","description":"Gaston666/Hamama dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gaston666/Hamama","creator_name":"Bah","creator_url":"https://huggingface.co/Gaston666","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","Avestan","Afar","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chris241/reddit_dataset_218.","url":"https://huggingface.co/datasets/chris241/reddit_dataset_218","creator_name":"ch","creator_url":"https://huggingface.co/chris241","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chris241/reddit_dataset_218.","url":"https://huggingface.co/datasets/chris241/reddit_dataset_218","creator_name":"ch","creator_url":"https://huggingface.co/chris241","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"tinyllama-context-retrieval","keyword":"summarization","description":"GFCACACE/tinyllama-context-retrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/GFCACACE/tinyllama-context-retrieval","creator_name":"Guillermo Federico Cacace","creator_url":"https://huggingface.co/GFCACACE","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_51","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romban38/reddit_dataset_51.","url":"https://huggingface.co/datasets/romban38/reddit_dataset_51","creator_name":"Romban","creator_url":"https://huggingface.co/romban38","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0102122","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0102122.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0102122","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summ_consistency_dpo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummarization Consistency Preference\n\t\n\n\n\nThe dataset can be used for finetuning LLMs on summarizaiton consistency.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset is generated using the Mistral-7B-Instruct-v0.1 model. Using the following setting:\n\nTemperature: 1.0\nn = 6\nCode: https://github.com/vectara/halu_control/blob/main/3_dpo.ipynb\n\nThe consistency scores of the reponses are measured using the HHEM model.\nPreference pairs are constructed as:\n\nchosen: HHEM score > 0.8\nrejected: HHEM score‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nkwbtb/summ_consistency_dpo.","url":"https://huggingface.co/datasets/nkwbtb/summ_consistency_dpo","creator_name":"Rogger","creator_url":"https://huggingface.co/nkwbtb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_51","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romban38/reddit_dataset_51.","url":"https://huggingface.co/datasets/romban38/reddit_dataset_51","creator_name":"Romban","creator_url":"https://huggingface.co/romban38","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0102122","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0102122.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0102122","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"experimental-paper-json-xtraction-2","keyword":"summarization","description":"Shinapri/experimental-paper-json-xtraction-2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/experimental-paper-json-xtraction-2","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","question-answering","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_16.","url":"https://huggingface.co/datasets/suul999922/x_dataset_16","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wikimovies","keyword":"summarization","description":"\n\t\n\t\t\n\t\tWikipedia Movies Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 58.1k movie information scraped from Wikipedia's \"List of films\" pages. The data includes basic movie metadata, infobox information, and introductory text from individual movie Wikipedia pages.\nNOTE: This is an uncleaned dataset containing raw scraped data. The content is sourced from Wikipedia and is not owned by the dataset creator. All content remains under Wikipedia's licensing terms.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yashassnadig/wikimovies.","url":"https://huggingface.co/datasets/yashassnadig/wikimovies","creator_name":"Yashas Nadig","creator_url":"https://huggingface.co/yashassnadig","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_236","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/x_dataset_236.","url":"https://huggingface.co/datasets/bersov75/x_dataset_236","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_23.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_23","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_16.","url":"https://huggingface.co/datasets/suul999922/x_dataset_16","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_236","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/x_dataset_236.","url":"https://huggingface.co/datasets/bersov75/x_dataset_236","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_23.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_23","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"biz-talk-opportunities","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBiz Talk Opportunities (Synthetic)\n\t\n\nShort two-person business conversations labeled with pains, weak signals, buyer stage, sentiment, and a recommended next-best action (what to sell or propose next).  \nUse cases: next-best-offer prediction, call coaching, action-item summarization.\n\n\n\t\n\t\t\n\t\tHow the data was created\n\t\n\nSynthetic generation with lightweight templates across industries and sales stages.Each conversation mentions at least one pain and one weak signal; a rule-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AsyaShir/biz-talk-opportunities.","url":"https://huggingface.co/datasets/AsyaShir/biz-talk-opportunities","creator_name":"Anastasiia Shapovalova","creator_url":"https://huggingface.co/AsyaShir","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multimodal_textbook","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMultimodal-Textbook-6.5M\n\t\n\n    \n\n\n  \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset is for \"2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining\", containing 6.5M images interleaving with 0.8B text from instructional videos.\n\nIt contains pre-training corpus using interleaved image-text format. Specifically, our multimodal-textbook includes 6.5M keyframesextracted from instructional videos, interleaving with 0.8B ASR texts.\nAll the images and text are extracted from online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook.","url":"https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"code-voirie-routiere","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la voirie routi√®re, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Diverse-PathSum-CoT","keyword":"summarization","description":"singhprabhat/Diverse-PathSum-CoT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/singhprabhat/Diverse-PathSum-CoT","creator_name":"Prabhat Singh","creator_url":"https://huggingface.co/singhprabhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Context-Conversations","keyword":"summarization","description":"Dataset is from prithivMLmods - I only converted it to jsonl for easier use.\n\n\t\n\t\t\n\t\tSynthetic-Context-Conversations\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Synthetic-Context-Conversations dataset is a collection of synthetic conversations designed to simulate empathetic and context-rich dialogues. It is particularly useful for tasks such as text generation, summarization, and question answering. The dataset is available in English and contains between 10,000 to 100,000 entries.\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppliedLucent/Synthetic-Context-Conversations.","url":"https://huggingface.co/datasets/AppliedLucent/Synthetic-Context-Conversations","creator_name":"David McFarlin","creator_url":"https://huggingface.co/AppliedLucent","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_239","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartnuel87/x_dataset_239.","url":"https://huggingface.co/datasets/smartnuel87/x_dataset_239","creator_name":"smartnuel","creator_url":"https://huggingface.co/smartnuel87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"website-title-description","keyword":"summarization","description":"This dataset is designed for training small models. It primarily consists of webpages from The New York Times and GitHub. Key information is extracted from the HTML and converted into text parameters, which are then summarized into 1 to 4 words using Claude 3.5 by Anthropic.\n","url":"https://huggingface.co/datasets/wgcv/website-title-description","creator_name":"Gustavo Cevallos","creator_url":"https://huggingface.co/wgcv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Aloe-Beta-Medical-Collection","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAloe-Beta-Medical-Collection\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nCollection of curated datasets used to fine-tune Aloe-Beta.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nWe curated data from many publicly available medical instruction tuning data sources (QA format). Most data samples correspond to single-turn QA pairs, while a small proportion contain multi-turn. All data sources are publicly available for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-Medical-Collection.","url":"https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-Medical-Collection","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_734775","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_734775.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_734775","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_239","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartnuel87/x_dataset_239.","url":"https://huggingface.co/datasets/smartnuel87/x_dataset_239","creator_name":"smartnuel","creator_url":"https://huggingface.co/smartnuel87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_734775","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_734775.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_734775","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_127","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_127.","url":"https://huggingface.co/datasets/James096/reddit_dataset_127","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"paul_graham_essays","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tDataset Card for Paul Graham Essay Collection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete collection of essays written by Paul Graham, a renowned programmer, venture capitalist, and essayist. The essays cover a wide range of topics including startups, programming, technology, entrepreneurship, and personal growth. Each essay has been cleaned and processed to extract the title, date of publication, and the full text content.\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sgoel9/paul_graham_essays.","url":"https://huggingface.co/datasets/sgoel9/paul_graham_essays","creator_name":"Samarth Goel","creator_url":"https://huggingface.co/sgoel9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"Amazon-2023-GenQ","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAmazon Reviews Dataset for Query Generation\n\t\n\nThis dataset is designed for training models on tasks such as query generation, reranking, semantic search, and vision-language tasks (e.g., CLIP, VLMS) using Amazon product metadata.The original datasets can be found here: https://amazon-reviews-2023.github.io/\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated sample derived from seven filtered Amazon product category datasets \n(Amazon All Beauty, Amazon Fashion, Sports and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/Amazon-2023-GenQ.","url":"https://huggingface.co/datasets/smartcat/Amazon-2023-GenQ","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","summarization","sentence-similarity","text-classification","text-generation"],"keywords_longer_than_N":true},
	{"name":"test_for_upload","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/donh99922/test_for_upload.","url":"https://huggingface.co/datasets/donh99922/test_for_upload","creator_name":"hyun","creator_url":"https://huggingface.co/donh99922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_127","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_127.","url":"https://huggingface.co/datasets/James096/reddit_dataset_127","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"test_for_upload","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/donh99922/test_for_upload.","url":"https://huggingface.co/datasets/donh99922/test_for_upload","creator_name":"hyun","creator_url":"https://huggingface.co/donh99922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_231.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_231","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_231.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_231","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cnn_mal","keyword":"summarization","description":"atsphd2023/cnn_mal dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/atsphd2023/cnn_mal","creator_name":"Athira T S","creator_url":"https://huggingface.co/atsphd2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Malayalam","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_250.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_250","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_041213","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_041213.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_041213","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Datathon2024","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe 3rd annual MD+ datathon is a national month-long event hosted by MD+ and sponsors to foster innovative thinking about complex healthcare problems and their data-driven solutions. Medical students, graduate students, and trainees from all levels work together across disciplines to generate insights and engineer solutions from patient datasets.\nIn contrast to prior years, the 2024 MD+ Datathon will be divided into 3 separate competition tracks, each using a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mdplus/Datathon2024.","url":"https://huggingface.co/datasets/mdplus/Datathon2024","creator_name":"MDplus","creator_url":"https://huggingface.co/mdplus","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_061079","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_061079.","url":"https://huggingface.co/datasets/john-1111/x_dataset_061079","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_231","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_231.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_231","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_250.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_250","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_041213","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_041213.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_041213","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_061079","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_061079.","url":"https://huggingface.co/datasets/john-1111/x_dataset_061079","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_231","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_231.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_231","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_190","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_190.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_190","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_158","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artao/reddit_dataset_158.","url":"https://huggingface.co/datasets/artao/reddit_dataset_158","creator_name":"arvee taofu","creator_url":"https://huggingface.co/artao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_190","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_190.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/reddit_dataset_190","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_158","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artao/reddit_dataset_158.","url":"https://huggingface.co/datasets/artao/reddit_dataset_158","creator_name":"arvee taofu","creator_url":"https://huggingface.co/artao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"finbro-v0.1.0","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFinbro Dataset - An Aggregated Finance Dataset\n\t\n\nThe Finbro Dataset is an extensive aggregation of over 384k entries designed for training and fine-tuning Language Learning Models (LLMs) in the finance domain. This dataset combines entries from two significant sources, both contributing unique elements essential for diverse LLM applications in finance:\n\nInvestopedia: Incorporates structured Q&A pairs extracted via unstructured scraping, optimized to minimize hallucinations in model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taddeusb90/finbro-v0.1.0.","url":"https://huggingface.co/datasets/taddeusb90/finbro-v0.1.0","creator_name":"Taddeus Buica","creator_url":"https://huggingface.co/taddeusb90","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_122","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_122.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_122","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MusicSem","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for MusicSem\n\t\n\n\n\n\nThis dataset contains 35977 entries of text-audio pairs. There is an accompanying test set of size 480 which is withheld for leaderboard purposes. Please reach out to authors for further access.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Rebecca Salganik, Teng Tu, Fei-Yueh Chen, Xiaohao Liu, Kaifeng Lu, Ethan Luvisia, Zhiyao Duan, Guillaume Salha-Galvan, Anson Kahng, Yunshan Ma, Jian Kang\nLanguage(s) : English\nLicense: MIT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AMSRNA/MusicSem.","url":"https://huggingface.co/datasets/AMSRNA/MusicSem","creator_name":"Rsalgani","creator_url":"https://huggingface.co/AMSRNA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","summarization","feature-extraction","audio-text-to-text","English"],"keywords_longer_than_N":true},
	{"name":"code-minier","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode minier, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_122","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_122.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_122","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_58.","url":"https://huggingface.co/datasets/James096/x_dataset_58","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"grammar-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverveiw of Data\n\t\n\nData is a collection of synthetic and open source content from Openstax. It is a combination of these two datasets, curated and segmented by grammar relationships in the meta. I used Mistral 7B to generate the metadata contain the grammar relationships. \nambrosfitz/cosmopedia_summary (14,000/25,000 selected)\nambrosfitz/10k_history_summary (10,000)\nFor a total of around 24,000 rows.\nThis dataset was used to train a T5 model on grammar attention when summarizing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ambrosfitz/grammar-summary.","url":"https://huggingface.co/datasets/ambrosfitz/grammar-summary","creator_name":"Christopher Smith","creator_url":"https://huggingface.co/ambrosfitz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_133639","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_133639.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_133639","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"synthia","keyword":"summarization","description":"The Synthia Dataset is a continuously growing aggregate of validated synthetic explanations of subjects picked from Claude Opus latent space based on varying esotericity in a large general list of technical fields. The explanations are varying in their target audience, level of detail and abstraction while incentivized to target Claude3-grade quality. The Synthia subnet leverages Commune's incentives to create a permissionless mining market around distilling knowledge out of SOTA closed-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agicommies/synthia.","url":"https://huggingface.co/datasets/agicommies/synthia","creator_name":"agicommies","creator_url":"https://huggingface.co/agicommies","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","question-answering","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_58","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_58.","url":"https://huggingface.co/datasets/James096/x_dataset_58","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_133639","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_133639.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_133639","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v123","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Combined V1-V3\n\t\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset combines three versions of synthetic summaries:\n\nV1 & V2: Filtered for 4-5 sentence summaries\nV3: Cleaned and extracted final summaries\n\n\n\t\n\t\t\n\t\tProcessing Steps\n\t\n\n\nV1 and V2 Processing:\n\nFiltered to include only 4-5 sentence summaries\nRemoved length metadata for consistency\n\n\nV3 Processing:\n\nExtracted final summaries from tagged content\nRemoved length metadata for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"2014-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2014 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2014 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2014-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_218.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_218","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_237","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_237.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_237","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"curated-dataset-for-summarization","keyword":"summarization","description":"sudhanshusinghaiml/curated-dataset-for-summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sudhanshusinghaiml/curated-dataset-for-summarization","creator_name":"Sudhanshu Singh","creator_url":"https://huggingface.co/sudhanshusinghaiml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_218.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_218","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_237","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_237.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_237","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2014-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2014 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2014 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2014-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0711214","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0711214.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0711214","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0711214","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0711214.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0711214","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"geniac-iam-corpus-ja","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGENIAC IAM Corpus (Japanese)\n\t\n\nThis dataset contains high-quality Japanese translations of the AMI Meeting Corpus, specifically curated for the GENIAC project.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe GENIAC IAM (Intelligent Assistant for Meetings) Corpus is a Japanese-English bilingual dataset derived from the AMI Meeting Corpus. Each entry contains meeting dialogues and their summaries in both English and Japanese.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nBilingual Content: Original English text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja.","url":"https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja","creator_name":"Namiuchi Yuki","creator_url":"https://huggingface.co/nishika-nm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","text-generation","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"x_dataset_42","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_42.","url":"https://huggingface.co/datasets/James096/x_dataset_42","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"crypto-tweets","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/crypto-tweets.","url":"https://huggingface.co/datasets/RentonWEB3/crypto-tweets","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual, \nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs' abilities‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danniliu/MCIF.","url":"https://huggingface.co/datasets/danniliu/MCIF","creator_name":"Danni Liu","creator_url":"https://huggingface.co/danniliu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/reddit_dataset_44.","url":"https://huggingface.co/datasets/Axel232/reddit_dataset_44","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_44.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_44","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_42","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_42.","url":"https://huggingface.co/datasets/James096/x_dataset_42","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"crypto-tweets","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/crypto-tweets.","url":"https://huggingface.co/datasets/RentonWEB3/crypto-tweets","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/reddit_dataset_44.","url":"https://huggingface.co/datasets/Axel232/reddit_dataset_44","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_44.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_44","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_250.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_250","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CNNSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels\n\t\n\nPaper ¬†¬†¬† GitHub\n\n\t\n\t\t\n\t\t[2025.5] - Accepted to Findings of ACL 2025\n\t\n\n\n\t\n\t\t\n\t\t[2025.1] - Add inference script\n\t\n\n\n\t\n\t\t\n\t\t[2024.12] - CNNSum Dataset Release\n\t\n\nWe are excited to announce the release of the CNNSum dataset!\nAs outlined in Section 3.1 and Appendix E of our paper, we have conducted a final round of manual cleaning to address any possible omissions. This process affects only a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CxsGHost/CNNSum.","url":"https://huggingface.co/datasets/CxsGHost/CNNSum","creator_name":"lingxiao","creator_url":"https://huggingface.co/CxsGHost","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"livre-procedures-fiscales","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLivre des proc√©dures fiscales, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales.","url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"jfk-tell","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for JFK TELL\n\t\n\nThis dataset contains text that was extracted from the John F. Kennedy assassination records released\non archives.org\nby the US government.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe data in this dataset is generated by processing another HF dataset, the JFK-Archives dataset, \nwhich consists of PDF files originally released on archives.org. The PDF files have been proessed using\nthe Google Gemini API to generate Markdown text. \nSince the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/farhanhubble/jfk-tell.","url":"https://huggingface.co/datasets/farhanhubble/jfk-tell","creator_name":"Farhan Ahmad","creator_url":"https://huggingface.co/farhanhubble","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_212","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_212.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_212","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_250.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_250","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_212","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_212.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_212","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_140","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taowtje/x_dataset_140.","url":"https://huggingface.co/datasets/taowtje/x_dataset_140","creator_name":"TAO tje","creator_url":"https://huggingface.co/taowtje","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vdixnck/x_dataset_9.","url":"https://huggingface.co/datasets/vdixnck/x_dataset_9","creator_name":"vdixncksjfogjx63737","creator_url":"https://huggingface.co/vdixnck","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_241","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thevitruvianguy/reddit_dataset_241.","url":"https://huggingface.co/datasets/thevitruvianguy/reddit_dataset_241","creator_name":"Lagbaja Tabedi","creator_url":"https://huggingface.co/thevitruvianguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_5HEMpH3WtP6NubmWRNSCJ8nAZ7kEixQ84VeRj4Aq8ozLXXyb","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_140","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taowtje/x_dataset_140.","url":"https://huggingface.co/datasets/taowtje/x_dataset_140","creator_name":"TAO tje","creator_url":"https://huggingface.co/taowtje","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vdixnck/x_dataset_9.","url":"https://huggingface.co/datasets/vdixnck/x_dataset_9","creator_name":"vdixncksjfogjx63737","creator_url":"https://huggingface.co/vdixnck","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_241","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thevitruvianguy/reddit_dataset_241.","url":"https://huggingface.co/datasets/thevitruvianguy/reddit_dataset_241","creator_name":"Lagbaja Tabedi","creator_url":"https://huggingface.co/thevitruvianguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_94","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_94.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_94","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MM-TelecoBench","keyword":"summarization","description":"Exploration-Lab/MM-TelecoBench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Exploration-Lab/MM-TelecoBench","creator_name":"Exploration Lab","creator_url":"https://huggingface.co/Exploration-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","translation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"clasum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CLASum Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CLASum is built for abstractivity characterization and measurement in the summarization task. It contains 200 document-summary pairs extracted from CNN/DailyMail and XSUM datasets. Each summary has been annotated for 11 summary-related questions by 3 different annotators.  \n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Sample identifier\nsource: Dataset of the document-summary pair \nsource_id: Identifier of the pair in the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ELiRF/clasum.","url":"https://huggingface.co/datasets/ELiRF/clasum","creator_name":"ELiRF","creator_url":"https://huggingface.co/ELiRF","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_94","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/reddit_dataset_94.","url":"https://huggingface.co/datasets/coldmind/reddit_dataset_94","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"gpt-expressions","keyword":"summarization","description":"Haziqsayyed/gpt-expressions dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Haziqsayyed/gpt-expressions","creator_name":"Haazique Sayyed","creator_url":"https://huggingface.co/Haziqsayyed","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","afl-3.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MMCQSD","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for MMCQS Dataset\n\t\n\nThis is the MMCQS Dataset that have been used in the paper \"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries\" accepted in ECIR 2024.\n\nGithub: https://github.com/ArkadeepAcharya/MedSumm-ECIR2024\n\nPaper: https://arxiv.org/abs/2401.01596\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\n\nDownload and unzip the Multimodal_images.zip file, that can be found the in the 'Files and Version' section, to access the images that have been used in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArkaAcharya/MMCQSD.","url":"https://huggingface.co/datasets/ArkaAcharya/MMCQSD","creator_name":"Arkadeep Acharya","creator_url":"https://huggingface.co/ArkaAcharya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","Hindi","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"rubai-text-s60m","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUzbek Informative Text Dataset\n\t\n\nA large-scale, high-quality dataset of informative text passages in Uzbek language (Latin script), synthetically generated through knowledge distillation from a state-of-the-art large language model.\nSupport my works and open-source movement: https://tirikchilik.uz/islomovs\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,140,910 rows of educational and informative text passages covering 80 diverse topics and 640 subtopics. Each entry pairs a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/rubai-text-s60m.","url":"https://huggingface.co/datasets/islomov/rubai-text-s60m","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Uzbek","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"constitucion-politica-del-peru-1993-qa","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCompuesto por unos 2075 registros que contienen los campos:\n\npregunta: pregunta que sirve como una instrucci√≥n o consulta sobre alg√∫n aspecto de la Constituci√≥n Pol√≠tica del Per√∫ de 1993.\nrespuesta: La respuesta proporcionada para cada pregunta es un contexto relevante que ayuda a resolver la consulta. Este contexto es un extracto de la Constituci√≥n.\nfuente: Para cada respuesta, se indica el cap√≠tulo y/o art√≠culo de la Constituci√≥n Pol√≠tica del Per√∫ de 1993‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/constitucion-politica-del-peru-1993-qa.","url":"https://huggingface.co/datasets/somosnlp/constitucion-politica-del-peru-1993-qa","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"summarization","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual,\nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/MCIF.","url":"https://huggingface.co/datasets/FBK-MT/MCIF","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"chatgpt-custom_inst","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLanguages: English, Tagalog\n\t\n\n\n\t\n\t\t\n\t\tCollection Process:\n\t\n\n\nDialogs generated by instructing ChatGPT to respond concisely\nResponses edited by Nuph researchers for naturalness\nBilingual exchanges added for diversity\n\n\n\t\n\t\t\n\t\tIntended Use:\n\t\n\n\nTrain conversational agents\nResearch in straightforward dialog\n\n\n\t\n\t\t\n\t\tLimitations:\n\t\n\n\nSmall scale (300 rows)\nBiased toward English\nLimited to text conversations\n\n\n\t\n\t\t\n\t\tEthics and Privacy:\n\t\n\n\nNo personal or offensive content\nChatGPT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/baebee/chatgpt-custom_inst.","url":"https://huggingface.co/datasets/baebee/chatgpt-custom_inst","creator_name":"d.s. spero","creator_url":"https://huggingface.co/baebee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","Tagalog","mit"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_oracle","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_oracle.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"CC-NEWS-ES","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CC-NEWS-ES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCC-NEWS-ES is a Spanish-language dataset of news. The corpus was generated by extracting the Spanish articles from CC-NEWS (news index of Common Crawl) of 2019. For doing that FastText model was used for language prediction.\nIt contains a total of 7,473,286 texts and 1,812,009,283 words distributed as follows:\n\n\t\n\t\t\ndomain\ntexts\nwords\n\n\n\t\t\nar\n532703\n1.45127e+08\n\n\nbo\n29557\n7.28996e+06\n\n\nbr\n107\n14207\n\n\ncl\n116661\n3.34633e+07\n\n\nco‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES.","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CFBenchmark","keyword":"summarization","description":"\n\nüìà CFBenchmark: Chinese Financial Assistant with Large Language Model\n\n\n\n \n  \n  \n\n \nEnglish | ÁÆÄ‰Ωì‰∏≠Êñá\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nWelcome to CFBenchmark\nIn recent years, with the rapid development of Large Language Models~(LLMs), outstanding performance has been achieved in various tasks by existing LLMs. However, we notice that there is currently a limited amount of benchmarks focused on assessing the performance of LLMs in specific domains. \nIn this work, we introduce CFBenchmark, a Chinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TongjiFinLab/CFBenchmark.","url":"https://huggingface.co/datasets/TongjiFinLab/CFBenchmark","creator_name":"TongjiFinLab","creator_url":"https://huggingface.co/TongjiFinLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sled","keyword":"summarization","description":"Efficient Long-Text Understanding with Short-Text Models.\nOur SLiding-Encoder and Decoder uses any pretrained encoder-decoder model, to independtly encode overlapping chunks of \nthe inputs, and perform fusion-in-decoder to achieve linear-memory requirment for long-range natural language understanding.","url":"https://huggingface.co/datasets/tau/sled","creator_name":"Tel Aviv University","creator_url":"https://huggingface.co/tau","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","multiple-choice-qa","natural-language-inference"],"keywords_longer_than_N":true},
	{"name":"OpenOrcaNo-15k","keyword":"summarization","description":"üêã The OpenOrca Dataset Norwegian! üêã\n\nThis is a subset of 15000 rows of the OpenOrca dataset, translated into Norwegian.\nTranslation is done with Amazon Translate, and is provided by Ruter as an artifact from Ruter AI Lab.\n\n\t\n\t\t\n\t\tDataset structure\n\t\n\nThe dataset is structured in the following way:\n{\n    \"instruction\": \"Norwegian instruction\",\n    \"input\": \"Norwegian input\",\n    \"output\": \"Norwegian output\",\n    \"instruction_en\": \"English instruction\",\n    \"input_en\": \"English input\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RuterNorway/OpenOrcaNo-15k.","url":"https://huggingface.co/datasets/RuterNorway/OpenOrcaNo-15k","creator_name":"Ruter","creator_url":"https://huggingface.co/RuterNorway","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hal-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization\n\t\n\nA collaboration between reciTAL, MLIA (ISIR, Sorbonne Universit√©), Meta AI, and Universit√† di Trento\n\n\t\n\t\t\n\t\tHAL dataset for summarization\n\t\n\nHAL is a dataset for summarization of research papers written in French, for which layout information is provided.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\narticle_id: article id\narticle_words: sequence of words constituting the body of the article\narticle_bboxes:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nglaura/hal-summarization.","url":"https://huggingface.co/datasets/nglaura/hal-summarization","creator_name":"Laura Nguyen","creator_url":"https://huggingface.co/nglaura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","French","apache-2.0","arxiv:2301.11312","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"summedits","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFactual Consistency in Summarization\n\t\n\nCan you tell which edits of summaries are consistent, and which are inconsistent?\n\n  \n\n\n\n\n\t\n\t\t\n\t\tSummEdits Benchmark (Section 6-7)\n\t\n\nWe release the 6,348 samples of data for the 10 domains in the SummEdits. Each sample has entries for:\n\ndomain: out of the 10 domains in SummEdits,\nid: a unique ID for the sample,\ndoc: the input document,\nsummary: the summary that is either consistent or inconsistent with the facts in the document,\nlabel: 1 if the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/summedits.","url":"https://huggingface.co/datasets/Salesforce/summedits","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"opinosis","keyword":"summarization","description":"The Opinosis Opinion Dataset consists of sentences extracted from reviews for 51 topics.\nTopics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.","url":"https://huggingface.co/datasets/kavgan/opinosis","creator_name":"Kavita  Ganesan","creator_url":"https://huggingface.co/kavgan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"code-general-fonction-publique","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la fonction publique, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ToS-Summaries","keyword":"summarization","description":"EE21/ToS-Summaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EE21/ToS-Summaries","creator_name":"Emre","creator_url":"https://huggingface.co/EE21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"bn_news_summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBengali Abstractive News Summarization (BANS)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNowadays news or text summarization becomes very popular in the NLP field. Both the extractive and abstractive approaches of summarization are implemented in different languages. A significant amount of data is a primary need for any summarization. For the Bengali language, there are only a few datasets are available. Our dataset is made for Bengali Abstractive News Summarization (BANS) purposes. As abstractive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sustcsenlp/bn_news_summarization.","url":"https://huggingface.co/datasets/sustcsenlp/bn_news_summarization","creator_name":"SUST CSE NLP Research","creator_url":"https://huggingface.co/sustcsenlp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Bengali","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ERRnews","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"ERRnews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nERRnews is an Estonian language summarization dataset of ERR News broadcasts scraped from the ERR Archive (https://arhiiv.err.ee/err-audioarhiiv). The dataset consists of news story transcripts generated by an ASR pipeline paired with the human written summary from the archive. For leveraging larger english models the dataset includes machine translated (https://neurotolge.ee/) transcript and summary pairs.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/ERRnews.","url":"https://huggingface.co/datasets/TalTechNLP/ERRnews","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","monolingual","original","Estonian"],"keywords_longer_than_N":true},
	{"name":"CanlIICaseSummaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCanadian Case Law Summaries\n\t\n\nA database of (currently, still growing) >600 case law summaries generated by GPT 4 for random case law in Ontario or Canada\n","url":"https://huggingface.co/datasets/simmo/CanlIICaseSummaries","creator_name":"Xander May","creator_url":"https://huggingface.co/simmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RRN","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nR√öV Radio News (RRN) is an Icelandic-language abstractive summarization dataset. The dataset consists of almost 4k news stories from The Icelandic National Broadcasting Service (R√öV) collected from the years 2021 and 2022. The stories were sourced from the noon radio news program and comprises three parts for each story: an intro, the main story, and a summary. However, not all stories include all three parts.\nThe dataset can be used for various summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thors/RRN.","url":"https://huggingface.co/datasets/thors/RRN","creator_name":"√û√≥r Sverrisson","creator_url":"https://huggingface.co/thors","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Icelandic","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"code-forestier","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode forestier, non-instruct (11-12-2023)\n\t\n\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TinyOrca","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a new curated subset of the SlimOpenOrca data. \n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{TinyOrca,\n  title = {TinyOrca: An Open Dataset of GPT-4 Augmented FLAN Reasoning Traces, with Verification},\n  author = {Prince Canuma},\n  year = {2024},\n  publisher = {HuggingFace},\n  url = {https://https://huggingface.co/prince-canuma/TinyOrca}\n}\n\n@misc{SlimOrca,\n  title = {SlimOrca: An Open Dataset of GPT-4 Augmented FLAN Reasoning Traces, with Verification},\n  author = {Wing Lian and Guan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prince-canuma/TinyOrca.","url":"https://huggingface.co/datasets/prince-canuma/TinyOrca","creator_name":"Prince Canuma","creator_url":"https://huggingface.co/prince-canuma","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"code-procedures-civiles-execution","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des proc√©dures civiles d'ex√©cution, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"darkbench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDarkBench: Understanding Dark Patterns in Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDarkBench is a comprehensive benchmark designed to detect dark design patterns in large language models (LLMs). Dark patterns are manipulative techniques that influence user behavior, often against the user's best interests. The benchmark comprises 660 prompts across six categories of dark patterns, which the researchers used to evaluate 14 different models from leading AI companies including OpenAI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/apart/darkbench.","url":"https://huggingface.co/datasets/apart/darkbench","creator_name":"Apart Research","creator_url":"https://huggingface.co/apart","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text-classification","summarization","English"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-ko","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKorean translation of Guanaco via the DeepL API\nNote: There are cases where multilingual data has been converted to monolingual data during batch translation to Korean using the API.\nBelow is Guanaco's README.\n\nThis dataset is a subset of the Open Assistant dataset, which you can find here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko.","url":"https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko","creator_name":"NLP & AI - Korea University","creator_url":"https://huggingface.co/nlpai-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"pippa_facts","keyword":"summarization","description":"Conversations from PIPPA dataset converted to a list of short facts related to messages.\n","url":"https://huggingface.co/datasets/Cohee/pippa_facts","creator_name":"Cohee","creator_url":"https://huggingface.co/Cohee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Traditional-Chinese","keyword":"summarization","description":"üêã OpenOrca-Chinese Êï∞ÊçÆÈõÜÔºÅüêã\n\nÊÑüË¨ù  Open-Orca/OpenOrca  Ë≥áÊñôÈõÜÁöÑÁôºÂ∏ÉÔºåÁÇ∫Âª£Â§ßNLPÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôºËÄÖÂ∏∂‰æÜ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫êÔºÅ\nÈÄôÊòØ‰∏ÄÂÄãÂ∞ç  Open-Orca/OpenOrca  Ë≥áÊñôÈõÜ‰∏≠ÊñáÁøªË≠ØÁöÑÁâàÊú¨ÔºåÁøªË≠ØÂºïÊìéÁÇ∫ Google ÁøªË≠ØÔºåÂ∏åÊúõËÉΩÁÇ∫‰∏≠Êñá LLM Á†îÁ©∂ÂÅöÂá∫‰∏ÄÈªûÈªûË≤¢Áçª„ÄÇ\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese.","url":"https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese","creator_name":"Lee Chak Kei","creator_url":"https://huggingface.co/lchakkei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"summary","keyword":"summarization","description":"ÂæÆË∞Égoogle/mt5-baseÊ®°ÂûãÔºåÂÅöÊñáÁ´†ÊëòË¶Å\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\nmodel_path = \"twwch/mt5-base-summary\"\nmodel = T5ForConditionalGeneration.from_pretrained(model_path)\ntokenizer = T5Tokenizer.from_pretrained(model_path)\n\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\nmodel.eval()\n\ntext = \"\"\"\n‰ªÄ‰πàÊòØNginx‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/twwch/summary.","url":"https://huggingface.co/datasets/twwch/summary","creator_name":"chenhao","creator_url":"https://huggingface.co/twwch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"databaseinfor","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/duncanodhis/databaseinfor.","url":"https://huggingface.co/datasets/duncanodhis/databaseinfor","creator_name":"abonyo","creator_url":"https://huggingface.co/duncanodhis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"cmu_wiki_qa","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"cmu_wiki_qa\"\n\t\n\nA filtered / cleaned version of the http://www.cs.cmu.edu/~ark/QA-data/ Q&A dataset, which provides manually-generated factoid questions from Wikipedia articles.\nAcknowledgments\nThese data were collected by Noah Smith, Michael Heilman, Rebecca Hwa, Shay Cohen, Kevin Gimpel, and many students at Carnegie Mellon University and the University of Pittsburgh between 2008 and 2010.\nTheir research project was supported by NSF IIS-0713265 (to Smith), an NSF‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/cmu_wiki_qa.","url":"https://huggingface.co/datasets/sedthh/cmu_wiki_qa","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dialogsum-ja","keyword":"summarization","description":"dialogsum-ja\n„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØdialogsum„ÄÅCSDS„Å™„Å©„ÇíÁøªË®≥„Åó„ÅüÊó•Êú¨Ë™ûÂØæË©±Ë¶ÅÁ¥Ñ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\nÂÖÉ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà\nknkarthick/dialogsum https://huggingface.co/datasets/knkarthick/dialogsum\nxiaolinAndy/CSDS https://github.com/xiaolinAndy/CSDS\n","url":"https://huggingface.co/datasets/sudy-super/dialogsum-ja","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Japanese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"dolphin-ru","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDolphin-ru üê¨\n\t\n\nThis is translated version of ehartford/dolphin into Russian.\n","url":"https://huggingface.co/datasets/d0rj/dolphin-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"fanpage","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for fanpage\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFanpage dataset, containing news articles taken from Fanpage.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n Fanpage text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/fanpage.","url":"https://huggingface.co/datasets/ARTeLab/fanpage","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Italian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Accident","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Narayana02/Accident.","url":"https://huggingface.co/datasets/Narayana02/Accident","creator_name":"Thotaadinarayana","creator_url":"https://huggingface.co/Narayana02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"DataX","keyword":"summarization","description":"\n  \n    \n  \n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe \"DataX\" dataset is a curated collection combining data generated by large language models (LLMs) and information scraped from Wikipedia. \nIt spans a vast array of topics, providing a rich resource for tasks such as text generation, text-to-text generation, summarization, and conversational models.\nWith over 1.7 million examples, it stands as a significant asset for training robust and diverse machine learning and deep learning models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GunA-SD/DataX.","url":"https://huggingface.co/datasets/GunA-SD/DataX","creator_name":"gunasekar","creator_url":"https://huggingface.co/GunA-SD","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"dialogsum-test","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neil-code/dialogsum-test.","url":"https://huggingface.co/datasets/neil-code/dialogsum-test","creator_name":"neil","creator_url":"https://huggingface.co/neil-code","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"fifa_2022","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nText corpus dataset (fifa world cup 2022)\n\n\t\n\t\t\n\t\tAdditional Information\n\t\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{ enwiki:1154298520,\n    author = \"{Wikipedia contributors}\",\n    title = \"2022 FIFA World Cup --- {Wikipedia}{,} The Free Encyclopedia\",\n    year = \"2023\",\n    url = \"https://en.wikipedia.org/w/index.php?title=2022_FIFA_World_Cup&oldid=1154298520\"\n  }\n\n","url":"https://huggingface.co/datasets/krinal/fifa_2022","creator_name":"Krinal Joshi","creator_url":"https://huggingface.co/krinal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-search-net-go","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-go\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Go\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the dataset as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"summarization","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"code-search-net-go","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-go\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Go\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the dataset as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"text-simplification","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"rebel-dataset-de","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for German REBEL Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the German version of Babelscape/rebel-dataset. It has been generated using CROCODILE.\nThe Wikipedia Version is from November 2022. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nGerman\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\"docid\": \"9400003\",\n \"title\": \"Odin-Gletscher\",\n \"uri\": \"Q7077818\",\n \"text\": \"Der Odin-Gletscher ist ein kleiner Gletscher im ostantarktischen Viktorialand. Er flie√üt von den Westh√§ngen des Mount Odin in der‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mingaflo/rebel-dataset-de.","url":"https://huggingface.co/datasets/mingaflo/rebel-dataset-de","creator_name":"Florian","creator_url":"https://huggingface.co/mingaflo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"SlimOrca","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Isotonic/SlimOrca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a deduplicated version of Open-Orca/OpenOrca\nMinHash Deduplication with Jaccard Threshold = 0.80\nOriginal dataset size: 4233923\nNumber of duplicate clusters: 522077\nFiles in duplicate cluster: 2115143\nUnique files in duplicate cluster: 892638\nFiltered dataset size: 3011418\n\n","url":"https://huggingface.co/datasets/Isotonic/SlimOrca","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","table-question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"mslr2022","keyword":"summarization","description":"The Multidocument Summarization for Literature Review (MSLR) Shared Task aims to study how medical\nevidence from different clinical studies are summarized in literature reviews. Reviews provide the\nhighest quality of evidence for clinical care, but are expensive to produce manually.\n(Semi-)automation via NLP may facilitate faster evidence synthesis without sacrificing rigor.\nThe MSLR shared task uses two datasets to assess the current state of multidocument summarization\nfor this task, and to encourage the development of modeling contributions, scaffolding tasks, methods\nfor model interpretability, and improved automated evaluation methods in this domain.","url":"https://huggingface.co/datasets/allenai/mslr2022","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"HelpSteer-hindi","keyword":"summarization","description":"SherryT997/HelpSteer-hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SherryT997/HelpSteer-hindi","creator_name":"Sherry Thomas","creator_url":"https://huggingface.co/SherryT997","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"code-patrimoine","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du patrimoine, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"MTS_Dialogue-Clinical_Note","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMTS Dialogue (Clinical Note Summarisation)\n\t\n\nMain Dataset\nThe MTS-Dialog dataset is a new collection of 1.7k short doctor-patient conversations and corresponding summaries (section headers and contents).\nThe training set consists of 1,201 pairs of conversations and associated summaries.\nThe validation set consists of 100 pairs of conversations and their summaries.\nThe \"dialogue\" column contain Doctor-Patient conversation. The \"section_text\" column contains the Clinical Note of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/har1/MTS_Dialogue-Clinical_Note.","url":"https://huggingface.co/datasets/har1/MTS_Dialogue-Clinical_Note","creator_name":"Harikrishnan KC","creator_url":"https://huggingface.co/har1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"summarize_from_feedback_tldr_3_filtered","keyword":"summarization","description":"This is the query dataset taken directly from https://github.com/openai/summarize-from-feedback/tree/700967448d10004279f138666442bf1497d0e705#reddit-tldr-dataset\n","url":"https://huggingface.co/datasets/vwxyzjn/summarize_from_feedback_tldr_3_filtered","creator_name":"Shengyi Costa Huang","creator_url":"https://huggingface.co/vwxyzjn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"M4LE","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nM4LE is a Multi-ability, Multi-range, Multi-task, bilingual benchmark for long-context evaluation. We categorize long-context understanding into five distinct abilities by considering whether it is required to identify single or multiple spans in long contexts based on explicit or semantic hints. Specifically, these abilities are explicit single-span, semantic single-span, explicit multiple-span, semantic multiple-span, and global. Different from previous long-context‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wckwan/M4LE.","url":"https://huggingface.co/datasets/wckwan/M4LE","creator_name":"Cyrus Kwan","creator_url":"https://huggingface.co/wckwan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"code-pensions-civiles-militaires-retraite","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_mean","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_mean.","url":"https://huggingface.co/datasets/allenai/ms2_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"ms2_dense_max","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\ntop-k strategy: \"max\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_max.","url":"https://huggingface.co/datasets/allenai/ms2_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"AMIsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"AMIsum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAMIsum is meeting summaryzation dataset based on the AMI Meeting Corpus (https://groups.inf.ed.ac.uk/ami/corpus/). The dataset utilizes the transcripts as the source data and abstract summaries as the target data.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{'transcript': '<PM> Okay. <PM> Right. <PM> Um well this is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/AMIsum.","url":"https://huggingface.co/datasets/TalTechNLP/AMIsum","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"K-SportsSum-BetterMapped-CN","keyword":"summarization","description":"‰∏Ä‰∏™Êù•Ëá™K-SportsSumÔºöhttps://github.com/krystalan/k-sportssum ÁöÑÂÆûÁé∞ÔºåÂéü‰ΩúËÄÖÁªôÂá∫‰∫ÜÊÄùË∑ØÔºå‰ΩÜÂπ∂Êú™ÂÆûÁé∞ÂÖ∂ÂÖ∑‰ΩìËøáÁ®ãÔºåÊ≠§Êï∞ÊçÆÈõÜÊòØÂØπËØ•Êï∞ÊçÆÈõÜ‚ÄúÊñ∞Èóª‰∏éËØÑËÆ∫Âè•Â≠êÊ†πÊçÆÁõ∏‰ººÂ∫¶Êê≠ÈÖç‚ÄùÈÉ®ÂàÜÁöÑÂÆûÁé∞„ÄÇ\nÊñπÊ≥ïÊòØÔºöÈÅçÂéÜÊñ∞ÈóªÂè•Â≠êÔºå‰ª•Á±ª‰ººÊåáÈíàÁöÑÊñπÂºèËé∑ÂèñÊñ∞ÈóªÂè•Â≠êÁöÑÊó∂Èó¥‰ø°ÊÅØÔºàÂ¶ÇÊûúÊúâÁöÑËØùÔºâÔºåÁÑ∂ÂêéÂ∞ÜÊØè‰∏§‰∏™ÊåáÈíà‰Ωú‰∏∫‰∏Ä‰∏™ËåÉÂõ¥ÔºåÂ∞ÜËåÉÂõ¥ÂÜÖÁöÑÊñ∞ÈóªÂè•ÈÅçÂéÜÊü•ÊâæÔºåÈÄâÊã©ÊúÄÁõ∏‰ººÁöÑÂè•Â≠êÔºåÂπ∂Âà†Èô§ËØ•Âè•‰ª•Èò≤Ê≠¢ÈáçÂ§çÔºåÊúÄÁªàËé∑Âæó‰∏ÄÂè•Êñ∞ÈóªÊê≠ÈÖç‰∏ÄÂè•ËØÑËÆ∫ÁöÑÁªìÊûú„ÄÇ\nÊàë‰ΩøÁî®‰∫Übert‚ÄîScoreÂíåROUGEÊåáÊ†áÔºåÊåâÁÖß7:3Âä†ÊùÉËÆ°ÁÆóÂàÜÊï∞„ÄÇ\nÂª∫ËÆÆ Êï∞ÊçÆÈõÜÂÜÖÁªôÂá∫‰∫ÜËØ•Êê≠ÈÖçÁöÑÊåáÊ†áÔºåËØ∑ËÄÉËôë‰ΩøÁî®Âπ≥ÂùáÊï∞Á≠âÊñπÂºèËøáÊª§ÊéâËæÉ‰ΩéÁöÑÂùèÊê≠ÈÖç„ÄÇ\nAn implementation from K-SportsSum: https://github.com/krystalan/k-sportssum was used to implement the \"news and comment sentences paired based on similarity\" section of the dataset. The original author‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN.","url":"https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN","creator_name":"Lai Wen Xiao","creator_url":"https://huggingface.co/CCCP-Admiral","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_193266","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_193266.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_193266","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21318","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_21318.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_21318","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Everything_about_dogs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Everything About Dogs Dataset\n\t\n\n\n\nThis dataset is built from the book Everything About Dogs \nEverything about dogs is a book by AL G Eberhart. \nThe book contains topics on diseases, how to feed, environment to provide, how to take care of pups and everything about dogs.\n\n\t\n\t\t\n\t\tMotivation\n\t\n\n\n\n\t\n\t\t\n\t\tIn Memory of Caspu\n\t\n\n\nDogs can't speak but they can express their pain. However this expression is often misunderstood or ignored.\nMy I aim is to build a retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SparkleDark/Everything_about_dogs.","url":"https://huggingface.co/datasets/SparkleDark/Everything_about_dogs","creator_name":"Akshay Darekar","creator_url":"https://huggingface.co/SparkleDark","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_193266","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_193266.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_193266","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"opin-pref","keyword":"summarization","description":"Human preference dataset for Opinion Summarization. Each instance consists of reviews, two opinion summaries and the human preference. \nPreference has been collected from domain experts. The dataset has a total of 940 instances. The instances to gather preference have been taken from the\nhf.co/swaroop-nath/prompt-opin-summ dataset.\nThe dataset is formatted as a jsonl file (jsonlines-guide). Each line can be loaded as a json object, and has the following format:\n{¬†¬†¬†¬†'unique-id': a unique id‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/opin-pref.","url":"https://huggingface.co/datasets/swaroop-nath/opin-pref","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21318","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_21318.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_21318","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PAWS-gl","keyword":"paraphrase-identification","description":"\n\t\n\t\t\n\t\tDataset Card for PAWS-gl\n\t\n\nThe PAWS-gl dataset (Paraphrase Adversaries from Word Scrambling in Galician) is a translation of the English PAWS dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: Proxecto N√≥s\nLanguage(s) (NLP): Galician\nLicense: CC-BY 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: Proxecto N√ìS at HuggingFace\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nParaphrase Identification, Language Model\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThis dataset contains more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/proxectonos/PAWS-gl.","url":"https://huggingface.co/datasets/proxectonos/PAWS-gl","creator_name":"Proxecto N√≥s","creator_url":"https://huggingface.co/proxectonos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Galician","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17879","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_17879.","url":"https://huggingface.co/datasets/icedwind/x_dataset_17879","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"blog-key-points","keyword":"summarization","description":"\n\t\n\t\t\n\t\tArticle Key Points Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains articles and their corresponding key points extracted using AI. Each entry consists of the full article text and a concise bullet-point summary highlighting the most important information from the article.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is designed for training and evaluating models on extractive and abstractive summarization tasks. It provides pairs of full article content and human-readable key‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ncls-p/blog-key-points.","url":"https://huggingface.co/datasets/ncls-p/blog-key-points","creator_name":"nicolas","creator_url":"https://huggingface.co/ncls-p","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"blog-key-points","keyword":"summarization","description":"\n\t\n\t\t\n\t\tArticle Key Points Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains articles and their corresponding key points extracted using AI. Each entry consists of the full article text and a concise bullet-point summary highlighting the most important information from the article.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is designed for training and evaluating models on extractive and abstractive summarization tasks. It provides pairs of full article content and human-readable key‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ncls-p/blog-key-points.","url":"https://huggingface.co/datasets/ncls-p/blog-key-points","creator_name":"nicolas","creator_url":"https://huggingface.co/ncls-p","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17879","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_17879.","url":"https://huggingface.co/datasets/icedwind/x_dataset_17879","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_46","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mgrtsv/reddit_dataset_46.","url":"https://huggingface.co/datasets/mgrtsv/reddit_dataset_46","creator_name":"Anton","creator_url":"https://huggingface.co/mgrtsv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_46","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mgrtsv/reddit_dataset_46.","url":"https://huggingface.co/datasets/mgrtsv/reddit_dataset_46","creator_name":"Anton","creator_url":"https://huggingface.co/mgrtsv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Bible","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFull Bible Chapter wise - Tamil\n\t\n\nWeb Scrapped from https://bible.catholicgallery.org/ecu-tamil/\n","url":"https://huggingface.co/datasets/mastergokul/Bible","creator_name":"Gokul S","creator_url":"https://huggingface.co/mastergokul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0311184","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0311184.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0311184","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_197","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/immortalizzy/reddit_dataset_197.","url":"https://huggingface.co/datasets/immortalizzy/reddit_dataset_197","creator_name":"Immortal Izzy","creator_url":"https://huggingface.co/immortalizzy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Think-Observe","keyword":"summarization","description":"\n\t\n\t\t\n\t\tThink-Observe Dataset\n\t\n\nWelcome to the Think-Observe dataset! This dataset is designed to fine-tune Large Language Models (LLMs) to improve their accuracy and ability to reflect before providing answers. It includes a collection of questions and answers tagged with think and observe tags.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Think-Observe dataset consists of pairs of questions and answers, with each entry tagged to signify its role in the model's training process:\n\nthink: This tag is used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayush-thakur02/Think-Observe.","url":"https://huggingface.co/datasets/ayush-thakur02/Think-Observe","creator_name":"Ayush Thakur","creator_url":"https://huggingface.co/ayush-thakur02","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","feature-extraction","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0311184","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0311184.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0311184","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_197","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/immortalizzy/reddit_dataset_197.","url":"https://huggingface.co/datasets/immortalizzy/reddit_dataset_197","creator_name":"Immortal Izzy","creator_url":"https://huggingface.co/immortalizzy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-education","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'√©ducation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"MentorCA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMentor_CA is an open source dataset of 10,175 instructions in Catalan, machine translated from the original Mentor_ES dataset in Spanish, and organized in several of the behavioral categories outlined in the InstructGPT paper, including closed QA, open QA, general QA, classification, information extraction, summarization, creative writing and brainstorming.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nUseful for fine-tuning instructions in large language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/MentorCA.","url":"https://huggingface.co/datasets/projecte-aina/MentorCA","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Catalan","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-assurances","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des assurances, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_041134","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_041134.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_041134","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_1.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_1","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_041134","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_041134.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_041134","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\nüé¨ 570k+ annotated clips with granular quality scores (0-10 scale)\nüìè Five-dimensional scoring: temporal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_1.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_1","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_111","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicchio816/x_dataset_111.","url":"https://huggingface.co/datasets/nicchio816/x_dataset_111","creator_name":"Alex Avery","creator_url":"https://huggingface.co/nicchio816","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_6.","url":"https://huggingface.co/datasets/suul999922/x_dataset_6","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_252","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill00000/reddit_dataset_252.","url":"https://huggingface.co/datasets/bill00000/reddit_dataset_252","creator_name":"123","creator_url":"https://huggingface.co/bill00000","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"hacker-news-discussion-summarization-small","keyword":"summarization","description":"georgeck/hacker-news-discussion-summarization-small dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/georgeck/hacker-news-discussion-summarization-small","creator_name":"George Chiramattel","creator_url":"https://huggingface.co/georgeck","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_111","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicchio816/x_dataset_111.","url":"https://huggingface.co/datasets/nicchio816/x_dataset_111","creator_name":"Alex Avery","creator_url":"https://huggingface.co/nicchio816","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_6.","url":"https://huggingface.co/datasets/suul999922/x_dataset_6","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_252","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill00000/reddit_dataset_252.","url":"https://huggingface.co/datasets/bill00000/reddit_dataset_252","creator_name":"123","creator_url":"https://huggingface.co/bill00000","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_63.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_63","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_021112","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_021112.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_021112","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20503","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_20503.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_20503","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-mutualite","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la mutualit√©, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Clip-CC","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìö Clip-CC Dataset (Movie Clips Edition)\n\t\n\nClip-CC is a curated dataset of 200 movie clips sourced from YouTube, each paired with a human-written summary and each video clipped to 1 minute and 30 second. It is designed for tasks such as video summarization, multimodal learning, and video-language alignment using real-world entertainment content.\n\n\n\t\n\t\t\n\t\tüìë Table of Contents\n\t\n\n\nDataset Summary\nUse Cases\nDataset Structure\nUsage\nDisclaimers\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nüé• 200 movie‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IVSL-SDSU/Clip-CC.","url":"https://huggingface.co/datasets/IVSL-SDSU/Clip-CC","creator_name":"Intelligent Vision System Lab","creator_url":"https://huggingface.co/IVSL-SDSU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_63.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_63","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_021112","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_021112.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_021112","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20503","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_20503.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_20503","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44829","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_44829.","url":"https://huggingface.co/datasets/momo1942/x_dataset_44829","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44829","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_44829.","url":"https://huggingface.co/datasets/momo1942/x_dataset_44829","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24747","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_24747.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_24747","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24747","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_24747.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_24747","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MT-SFT-ShareGPT","keyword":"summarization","description":"\n\n\n  ¬†\n  \n    MT-SFT-ShareGPT\n    \n      \n      \n    \n    ¬†\n  \n  \nüíª Github Repo  ‚Ä¢  ü§ó HuggingFace  ‚Ä¢  ü§ñ ModelScope\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nData has always been an important part of advancing large language models forward. Based on this, we have collected dozens of high-quality open source datasets from the open source community, with a total data volume of 20 M. \nAfter some cleaning actions, we have open sourced a set of high-quality datasets for fine-tuning the instructions of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT.","url":"https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT","creator_name":"thomas Yan","creator_url":"https://huggingface.co/thomas-yanxin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-classification","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_14.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_14","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_206","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/intensity809/reddit_dataset_206.","url":"https://huggingface.co/datasets/intensity809/reddit_dataset_206","creator_name":"intensity heat","creator_url":"https://huggingface.co/intensity809","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"patent-summarizer","keyword":"summarization","description":"YeetMeister/patent-summarizer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/YeetMeister/patent-summarizer","creator_name":"KT","creator_url":"https://huggingface.co/YeetMeister","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDynamic Topic Modeling Dataset: RedPajama-1T SubSample (100k samples, 1k tokens)\n\t\n\n\n  üìùCheck out the Blog Post\n\n\nThis dataset represents a curated subset of the RedPajama-1T Sample dataset, specifically processed for dynamic topic modeling applications. It contains 100,000 \nsamples from the original dataset, with each document limited to the first 1,024 tokens for consistent processing.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nName:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens.","url":"https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_14","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_14.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_14","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_206","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/intensity809/reddit_dataset_206.","url":"https://huggingface.co/datasets/intensity809/reddit_dataset_206","creator_name":"intensity heat","creator_url":"https://huggingface.co/intensity809","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_159877","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_159877.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_159877","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gachenkenh14/reddit_dataset_44.","url":"https://huggingface.co/datasets/gachenkenh14/reddit_dataset_44","creator_name":"Viet Nam","creator_url":"https://huggingface.co/gachenkenh14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_159877","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_159877.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_159877","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gachenkenh14/reddit_dataset_44.","url":"https://huggingface.co/datasets/gachenkenh14/reddit_dataset_44","creator_name":"Viet Nam","creator_url":"https://huggingface.co/gachenkenh14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aesthetics-wiki","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is webscraped version of aesthetics-wiki. There are 1022 aesthetics captured.\n\n\t\n\t\t\n\t\tColumns + dtype\n\t\n\n\ntitle: str\ndescription: str (raw representation, including \\n because it could help in structuring data)\nkeywords_spacy: str (['NOUN', 'ADJ', 'VERB', 'NUM', 'PROPN'] keywords extracted from description with POS from Spacy library)\nremoved weird characters, numbers, spaces, stopwords\n\n\n\n\n\t\n\t\t\n\t\tCleaning\n\t\n\nStandard Pandas cleaning\n\nCleaned the data by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ninar12/aesthetics-wiki.","url":"https://huggingface.co/datasets/ninar12/aesthetics-wiki","creator_name":"Nina Rhone","creator_url":"https://huggingface.co/ninar12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"basqueparl","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBasqueParl: A Bilingual Corpus of Basque Parliamentary Transcriptions\n\t\n\nThis repository contains BasqueParl, a bilingual corpus for political discourse analysis. It covers transcriptions from the Parliament of \nthe Basque Autonomous Community for eight years and two legislative terms (2012-2020), and its main characteristic is the presence of Basque-Spanish \ncode-switching speeches.\nüìñ Paper: BasqueParl A Bilingual Corpus of Basque Parliamentary Transcriptions In LREC 2022.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/basqueparl.","url":"https://huggingface.co/datasets/HiTZ/basqueparl","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","summarization","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_71","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_71.","url":"https://huggingface.co/datasets/suul999922/x_dataset_71","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46165","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_46165.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_46165","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_30.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_30","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartnuel87/reddit_dataset_239.","url":"https://huggingface.co/datasets/smartnuel87/reddit_dataset_239","creator_name":"smartnuel","creator_url":"https://huggingface.co/smartnuel87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_71","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_71.","url":"https://huggingface.co/datasets/suul999922/x_dataset_71","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_46165","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_46165.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_46165","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_30.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_30","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartnuel87/reddit_dataset_239.","url":"https://huggingface.co/datasets/smartnuel87/reddit_dataset_239","creator_name":"smartnuel","creator_url":"https://huggingface.co/smartnuel87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-justice-militaire-nouveau","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de justice militaire (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"2019-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2019 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2019 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2019-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt_with_system_ne","keyword":"summarization","description":"iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_ne dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_ne","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"2019-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2019 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2019 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2019-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_660618","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_660618.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_660618","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0204173","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0204173.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0204173","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3891","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_3891.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_3891","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_247","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zevebe/x_dataset_247.","url":"https://huggingface.co/datasets/zevebe/x_dataset_247","creator_name":"Andrea","creator_url":"https://huggingface.co/zevebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_660618","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_660618.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_660618","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0204173","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0204173.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0204173","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3891","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_3891.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_3891","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Ko-En","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenOrca-Ko-En\n\t\n\n\nkyujinpy/OpenOrca-KOÏôÄ Open-Orca/OpenOrcaÎ•º Í≥µÌÜµÎêú Îç∞Ïù¥ÌÑ∞Îßå ÌïÑÌÑ∞ÎßÅÌïòÍ≥† Ìï©Ïπú Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\nÏª¨ÎüºÏùÄ Í∏∞Ï°¥ OpenOrcaÏóê ÎßûÏ∂∞ÏÑú system_prompt_{ko/en}, question_{ko/en}, response_{ko/en} ÏúºÎ°ú Î≥ÄÍ≤ΩÌïòÏòÄÏäµÎãàÎã§.\nÏ§ëÎ≥µÎêú idÎ•º Ï†úÍ±∞ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ÏàòÍ∞Ä ÏùºÎ∂Ä Í∞êÏÜåÌïòÏòÄÏäµÎãàÎã§.\nÎç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÎßåÎìúÎäîÎç∞ ÏÇ¨Ïö©Ìïú Ïä§ÌÅ¨Î¶ΩÌä∏ÏûÖÎãàÎã§.\nÎç∞Ïù¥ÌÑ∞ÏÖã Ïù¥Ïö©ÌïòÏÖîÏÑú Î™®Îç∏Ïù¥ÎÇò Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÎßåÎìúÏã§ Îïå, Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÎøêÎßå ÏïÑÎãàÎùº ÏúÑ Îç∞Ïù¥ÌÑ∞ÏÖãÎèÑ Ìï®Íªò Ï∂úÏ≤òÌëúÍ∏∞Î•º Ìï¥Ï£ºÏÖ®ÏúºÎ©¥ Ìï©ÎãàÎã§.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset inf0\n\t\n\n\nNIV // 1551Í∞ú(OpenOrca-KO: 1571Í∞ú)  \nFLAN // 9338Í∞ú(OpenOrca-KO: 9434Í∞ú)\nT0 // 6303Í∞ú(OpenOrca-KO: 6351Í∞ú)\nCoT // 2092Í∞ú(OpenOrca-KO: 2117Í∞ú)\nKoCoT // 2159Í∞ú‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En.","url":"https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En","creator_name":"Jongsu Kim","creator_url":"https://huggingface.co/appleparan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_third_iteration","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_third_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_247","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zevebe/x_dataset_247.","url":"https://huggingface.co/datasets/zevebe/x_dataset_247","creator_name":"Andrea","creator_url":"https://huggingface.co/zevebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail-cleaned","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcnn_dailymail: cleaned\n\t\n\nOriginal cnn_dailymail config 3.0.0 with the following changes:\n\nrenamed columns to text and summary\ncleaning applied to summary column to correct punctuation, etc.\n\n","url":"https://huggingface.co/datasets/pszemraj/cnn_dailymail-cleaned","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","English","odc-by","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"sft-mk","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was used to fine tune domestic-yak-8B-instruct.\n\n\t\n\t\t\n\t\tüåü Key Highlights\n\t\n\n\nSize: ~100k samples across multiple categories.\nDomains: Question answering (QA), chat-like conversations, reasoning, essays, and code.\nSources: Consolidated from publicly available datasets and custom synthetic data.\nLanguages: Macedonian (mk).\nHuman-curated and GPT-4 augmented samples.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÑ Dataset Sources and Composition\n\t\n\nThe dataset is a combination of several‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LVSTCK/sft-mk.","url":"https://huggingface.co/datasets/LVSTCK/sft-mk","creator_name":"LVSTCK","creator_url":"https://huggingface.co/LVSTCK","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","translation","Macedonian"],"keywords_longer_than_N":true},
	{"name":"BoEM","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEmotion Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains facial expressions with corresponding emotion labels. Each image is labeled with emotions such as fear, happiness, sadness, etc., along with intensity information.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset annotations are in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance in the dataset consists of:\n\nid: Unique identifier for the image\nimage: The facial expression‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoangdang004/BoEM.","url":"https://huggingface.co/datasets/hoangdang004/BoEM","creator_name":"Hoang Nam Dang","creator_url":"https://huggingface.co/hoangdang004","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_194","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_194.","url":"https://huggingface.co/datasets/bit0/x_dataset_194","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_205","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_205.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_205","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/x_dataset_231.","url":"https://huggingface.co/datasets/jasonmoore92/x_dataset_231","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_194","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_194.","url":"https://huggingface.co/datasets/bit0/x_dataset_194","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_205","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_205.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_205","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_231","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/x_dataset_231.","url":"https://huggingface.co/datasets/jasonmoore92/x_dataset_231","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Geography_11th","keyword":"summarization","description":"KadamParth/NCERT_Geography_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Geography_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"summarization","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_25.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_25","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"acl-paper","keyword":"summarization","description":"\n\t\n\t\t\n\t\tACL Entire\n\t\n\n\n  \n\n\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nEvents Covered: Papers from ACL and Non-ACL events.\nBibliography: Includes complete bibliographic details for every paper.\nYears Covered: Comprehensive data spanning all available years.\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nAll data has been compiled from the ACL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper.","url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","text2text-generation","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_25.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_25","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27136","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_27136.","url":"https://huggingface.co/datasets/icedwind/x_dataset_27136","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-route","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la route, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"modified-classeval-code-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tModified ClassEval (MCE) Dataset\n\t\n\nThis dataset is a modification of the ClassEval benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and class contexts on summary quality.  The dataset includes modifications for evaluating at both function and class levels.\nPaper: Code Summarization Beyond Function Level\nDataset Structure:\nThe dataset contains samples with the following fields:\n\nclass_id: Identifier for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-classeval-code-summarization.","url":"https://huggingface.co/datasets/sm1rk/modified-classeval-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_27136","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_27136.","url":"https://huggingface.co/datasets/icedwind/x_dataset_27136","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_23.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_23","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_190","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_190.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_190","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_23","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_23.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_23","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"x_dataset_190","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_190.","url":"https://huggingface.co/datasets/CelestialWandererOfTheVoid/x_dataset_190","creator_name":"Kenneth Wayne Long","creator_url":"https://huggingface.co/CelestialWandererOfTheVoid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55757","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_55757.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_55757","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"GPT-Paraphrases","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGPT-Paraphrases dataset\n\t\n\nThis dataset contains text passages and their paraphrases generated using the GPT-3 language model. The paraphrases are designed to be semantically equivalent to the original text, but with different wording and structure. \nThe dataset includes text formatted in JSON and is in English.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of text passages: Not specified in the information you provided. \nSource of text passages: Not specified in the information you provided.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/GPT-Paraphrases.","url":"https://huggingface.co/datasets/prithivMLmods/GPT-Paraphrases","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55757","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_55757.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_55757","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Political_Science_12th","keyword":"summarization","description":"KadamParth/NCERT_Political_Science_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Political_Science_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"2022-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2022 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2022 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2022-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"FGRC-SCD","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tÂü∫‰∫éCCF23-EVAL‰ªªÂä°6ÁöÑÁîµ‰ø°ÁΩëÁªúËØàÈ™óÊ°à‰ª∂Êï∞ÊçÆÈõÜÂêàÊàê‰∫ÜÈ£éÈô©Áü≠‰ø°‰∏éÂØπËØùÊï∞ÊçÆÈõÜÔºåÂπ∂Âü∫‰∫éÂ§öÊ†∑ÊÄß„ÄÅ‰ªªÂä°Áõ∏ÂÖ≥ÊÄßÂíåÊòØÂê¶Êª°Ë∂≥‰∫∫Á±ªÂÅèÂ•ΩËøõË°åÁ≠õÈÄâÔºåÂèØÁî®‰∫éÈ£éÈô©ÁªÜÁ≤íÂ∫¶ÂàÜÁ±ª‰ªªÂä°ÂíåÈ£éÈô©ÊëòË¶ÅÁîüÊàê‰ªªÂä°ÊµãËØÑ„ÄÇ\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tÁü≠‰ø°ÁîüÊàêÊï∞ÊçÆÈõÜÁ≠õÈÄâÂâçÂêéÁöÑËØÑ‰ª∑ÁªìÊûúÊØîËæÉ\n\t\n\n\n\t\n\t\t\nÊï∞ÊçÆÈõÜ\nÊï∞ÊçÆËØÑ‰º∞ÊåáÊ†á\nÊ°à‰æãÁîüÊàêÊñπÂºè\nÂ±ûÊÄßÊèêÁ§∫ÁîüÊàêÊñπÂºè\nÊ°à‰æãÁîüÊàêÊñπÂºè\nÂ±ûÊÄßÊèêÁ§∫ÁîüÊàêÊñπÂºè\n\n\n\t\t\n\n‰ΩôÂº¶Áõ∏‰ººÂ∫¶‚Üì\n\n\n\n\n\n\nÊâÄÊúâÁ±ªÂà´\n\n0.7149\n0.6943\n0.7041\n0.6704\n\n\nÂÜíÂÖÖÁîµÂïÜÁâ©ÊµÅÂÆ¢ÊúçÁ±ª\n\n0.7542\n0.6981\n0.7606\n0.7331\n\n\nËôöÂÅáÁΩëÁªúÊäïËµÑÁêÜË¥¢Á±ª\n\n0.7967\n0.7120\n0.8029\n0.7108\n\n\nËôöÂÅá‰ø°Áî®ÊúçÂä°Á±ª\n\n0.7840\n0.7050\n0.7738\n0.7010\n\n\nËôöÂÅáË¥≠Áâ©„ÄÅÊúçÂä°Á±ª\n\n0.7088\n0.6931\n0.6879\n0.6672\n\n\nÂÜíÂÖÖÂÖ¨Ê£ÄÊ≥ïÂèäÊîøÂ∫úÊú∫ÂÖ≥Á±ª\n\n0.7979\n0.7088\n0.7835\n0.6935\n\n\nÂÜíÂÖÖÈ¢ÜÂØº„ÄÅÁÜü‰∫∫Á±ª\n\n0.7765\n0.7063\n0.7540\n0.7132\n\n\nÁΩëÁªúÂ©öÊÅã„ÄÅ‰∫§ÂèãÁ±ª‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abooooo/FGRC-SCD.","url":"https://huggingface.co/datasets/Abooooo/FGRC-SCD","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Chinese","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"2022-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2022 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2022 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2022-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"chartqa-caption-gpt4","keyword":"summarization","description":"Caption data for ChartQA images.\n","url":"https://huggingface.co/datasets/xchen16/chartqa-caption-gpt4","creator_name":"Xiaohui Chen","creator_url":"https://huggingface.co/xchen16","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"frenchSUM","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset information\n\t\n\nDataset concatenating Summarization datasets available in French and open-source.There are a total of 841,673 rows, of which 788,358 are for training, 26,935 for validation and 26,380 for testing.  \n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"CATIE-AQ/frenchSUM\")\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\n\n\t\n\t\t\n\t\tDetails of rows\n\t\n\n\n\t\n\t\t\nDataset Original\nSplits\nNote\n\n\n\t\t\nGEM/xwikis\n323,726 train / 7,339 validation / 6,992 test\nWe only keep the French‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/frenchSUM.","url":"https://huggingface.co/datasets/CATIE-AQ/frenchSUM","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","French","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"PaSaz","keyword":"summarization","description":"\n  \n  \n    PaSa≈æ\n  \n  \n  \n    \n      Korpus Paralelnih Sa≈æetaka doktorskih disertacija na srpskom i engleskom jeziku\n      Visoko-kvalitetan skup kratkih prevoda\n      Ukupno 10.492 paralelnih jedinica. Velika veƒáina sadr≈æi i paralelizovane naslove.\n    \n    \n       Parallel Serbian-English corpus of doctoral dissertation abstracts\n      High-quality set of short translations\n      A total of 10,492 parallel units. The vast majority also contain parallel titles.\n    \n  \n\n\n\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/PaSaz.","url":"https://huggingface.co/datasets/jerteh/PaSaz","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","Serbian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_90","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_90.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_90","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wordnet-definitions","keyword":"summarization","description":"\n\t\n\t\t\n\t\tWordNet Multiple Definitions - Columnar Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an optimized columnar version of WordNet multiple definitions, designed for high-performance queries and rapid extraction.\nEach definition was sourced by GPT-5 Nano. I may update this to include additional definitions in the future, but I will not break the format.\nThe original dataset has a more unabridged and noisy set of data; so I'm definitely going to leave it intact. Noisy training is important‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/wordnet-definitions.","url":"https://huggingface.co/datasets/AbstractPhil/wordnet-definitions","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","translation","text-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"alpaca_ccass_motivations_sommaires_titres","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTraining dataset for summarizing and titling decisions of the French Court of cassation based on motivations\n\t\n\nThis alpaca-format dataset is designed to train models for summarizing and titling French Supreme Court decisions based on the grounds of them. Created with a view to producing metadata for decisions not published in the bulletin, this dataset aims to simplify the development of annotation and categorization tools, and is positioned as a facilitator for jurisprudential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cour-de-cassation/alpaca_ccass_motivations_sommaires_titres.","url":"https://huggingface.co/datasets/Cour-de-cassation/alpaca_ccass_motivations_sommaires_titres","creator_name":"Cour de cassation","creator_url":"https://huggingface.co/Cour-de-cassation","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_90","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_90.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_90","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MDCure-12k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMDCure-12k\n\t\n\nüìÑ Paper | ü§ó HF Collection | ‚öôÔ∏è GitHub Repo\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nMDCure is an effective and scalable procedure for generating high-quality multi-document (MD) instruction tuning data to improve MD capabilities of LLMs. Using MDCure, we construct a suite of MD instruction datasets complementary to collections such as FLAN and fine-tune a variety of already instruction-tuned LLMs from the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in size. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yale-nlp/MDCure-12k.","url":"https://huggingface.co/datasets/yale-nlp/MDCure-12k","creator_name":"Yale NLP Lab","creator_url":"https://huggingface.co/yale-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"syntetisk-dialog-opsummering-raw","keyword":"summarization","description":"\n\t\n\t\t\n\t\tThanks to NVIDIA and Arrow Denmark for sponsoring the compute needed to generate this dataset\n\t\n\nThis dataset conists of 1,000,000 synthetic dialogs in Danish and a summary of each dialog generated with google/gemma-2-27b-it\nThe purpose of the dataset is to fine tune small language models to make dialog summaries, but with minor adjustments it may also be used 1) to train an LLM to restore/improve speaker diarization, 2) to train a classifier for classifying dialogs into the topic, 3)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/syntetisk-dialog-opsummering-raw.","url":"https://huggingface.co/datasets/ThatsGroes/syntetisk-dialog-opsummering-raw","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","sentence-similarity","Danish","mit"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt","keyword":"summarization","description":"iamsubingyawali/nepali_news_text_summary_sharegpt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/x_dataset_44.","url":"https://huggingface.co/datasets/bersov75/x_dataset_44","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1234","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_1234.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_1234","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"leis_ordinarias_1988_2024","keyword":"summarization","description":"celsowm/leis_ordinarias_1988_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/leis_ordinarias_1988_2024","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26384","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_26384.","url":"https://huggingface.co/datasets/momo1942/x_dataset_26384","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bersov75/x_dataset_44.","url":"https://huggingface.co/datasets/bersov75/x_dataset_44","creator_name":"Bersov Bersov","creator_url":"https://huggingface.co/bersov75","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1234","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_1234.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_1234","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26384","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_26384.","url":"https://huggingface.co/datasets/momo1942/x_dataset_26384","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_684447","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_684447.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_684447","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_11.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_11","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_684447","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_684447.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_684447","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/x_dataset_11.","url":"https://huggingface.co/datasets/Jacksss123/x_dataset_11","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20722","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_20722.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_20722","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_231","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/reddit_dataset_231.","url":"https://huggingface.co/datasets/jasonmoore92/reddit_dataset_231","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Grade-Math-18K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGrade-Math-18K dataset\n\t\n\nThis dataset contains math question and answer pairs, designed for training and evaluating machine learning models in elementary and middle school math problem solving. \nThe dataset includes text formatted in CSV and is in English.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of questions: 18,000\nGrades: Elementary and Middle School\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText\n\n\n\t\n\t\t\n\t\tFormats\n\t\n\n\nCSV\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThe license for this dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K.","url":"https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"grade-aware-llm-training-data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGrade-Aware LLM Training Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1,107,690 high-quality instruction-tuning examples for grade-aware text simplification, designed for fine-tuning large language models to simplify text to specific reading grade levels with precision and semantic consistency.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 1,107,690\nTask: Text simplification with precise grade-level targeting\nLanguage: English\nGrade Range: 1-12+ (precise 2-decimal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yimingwang123/grade-aware-llm-training-data.","url":"https://huggingface.co/datasets/yimingwang123/grade-aware-llm-training-data","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Legal-Mind-Mix-160K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tË≥áÊñôÈõÜË™™Êòé\n\t\n\n\nÊú¨Ë≥áÊñôÈÅãÁî®ÊòØÈáùÂ∞çÊàëÂÄëËóâÁî±GPT4Ëàá‰∏Ä‰∫õÂÆ∂‰∫ãËàáÂãûË®¥Ê°à‰ª∂ÂàÜÁæ§Ë≥áÊñôÊï¥ÁêÜËÄåÊàêÁöÑ‰∏Ä‰ªΩÊèêÈ´òÊ®°ÂûãÊ≥ïÂæãÈ†òÂüüÊïàÊûúÁöÑÊåá‰ª§ÂæÆË™øË≥áÊñô„ÄÇ\nÊ∫ñÂÇôÁöÑË≥áÊñô‰∏ªË¶ÅÊòØÂàÜÁæ§ËàáÊëòË¶Å‰ªªÂãôÔºå‚Äúth10-100k‚ÄùÁÇ∫ÂãûÂãïË®¥Ë®üÁà≠ÈªûÁõ∏‰ººËàáÂê¶‰πãÈÖçÂ∞çÔºå‚Äújudgment-summary-10k‚ÄùÁÇ∫Ë©êÊ¨∫Ê°à‰ª∂‰πãÊ°à‰ª∂‰∫ãÂØ¶ÊëòË¶ÅËàáÂéüÊñáÈÖçÂ∞ç„ÄÇ\n‰ΩÜÁÇ∫ÈÅøÂÖçÂΩ±ÈüøÂà∞Â§™Â§öÊôÆÈÅçÊÄßÁöÑÂõûÁ≠îËÉΩÂäõÔºåÊú¨Ë≥áÊñôÈõÜÊ∑∑Âêà‰∫Ü‰∏Ä‰∫õÂÖ¨ÈñãÁöÑÂ∞çË©±Ë≥áÊñô‰ª•ÊèêÈ´òÊàñÁ∂≠ÊåÅÂ§ßÈÉ®ÂàÜ‰ªªÂãôÁöÑÊïàÊûú„ÄÇ\n\n\n\t\n\t\t\n\t\tË≥áÊñô‰æÜÊ∫ê\n\t\n\n\nÂè∏Ê≥ïÈô¢ÂÖ¨ÈñãË≥áÊñôÁ∂≤\nTaiwanLLM\nALPACA-50k\ndolly-15k\n\n","url":"https://huggingface.co/datasets/aigrant/Legal-Mind-Mix-160K","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20722","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_20722.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_20722","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_231","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/reddit_dataset_231.","url":"https://huggingface.co/datasets/jasonmoore92/reddit_dataset_231","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"grade-aware-llm-training-data","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tGrade-Aware LLM Training Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1,107,690 high-quality instruction-tuning examples for grade-aware text simplification, designed for fine-tuning large language models to simplify text to specific reading grade levels with precision and semantic consistency.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 1,107,690\nTask: Text simplification with precise grade-level targeting\nLanguage: English\nGrade Range: 1-12+ (precise 2-decimal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yimingwang123/grade-aware-llm-training-data.","url":"https://huggingface.co/datasets/yimingwang123/grade-aware-llm-training-data","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eggmoo/x_dataset_39.","url":"https://huggingface.co/datasets/eggmoo/x_dataset_39","creator_name":"Vedant Behari","creator_url":"https://huggingface.co/eggmoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"benchmark_8k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBenchmark 8K Dataset\n\t\n\nA curated dataset of 1,000 high-quality prompts designed for benchmarking Large Language Model (LLM) performance across various metrics including latency, throughput, and response quality. This dataset features longer, more complex prompts ideal for testing models' capabilities with extended context and detailed analysis tasks.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nSize: 100 prompts\nFormat: JSONL (JSON Lines)\nAverage Token Length: Variable (extended context; computed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raffel36/benchmark_8k.","url":"https://huggingface.co/datasets/raffel36/benchmark_8k","creator_name":"Raffel","creator_url":"https://huggingface.co/raffel36","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_248","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/reddit_dataset_248.","url":"https://huggingface.co/datasets/veyhoranohy/reddit_dataset_248","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eggmoo/x_dataset_39.","url":"https://huggingface.co/datasets/eggmoo/x_dataset_39","creator_name":"Vedant Behari","creator_url":"https://huggingface.co/eggmoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_248","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/reddit_dataset_248.","url":"https://huggingface.co/datasets/veyhoranohy/reddit_dataset_248","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_41","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_41.","url":"https://huggingface.co/datasets/James096/reddit_dataset_41","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"my_smolvla123456789","keyword":"summarization","description":"Amanpatel81/my_smolvla123456789 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amanpatel81/my_smolvla123456789","creator_name":"Amankumar Patel","creator_url":"https://huggingface.co/Amanpatel81","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"HinduTamil-News-Articles-Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHinduTamil News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains news articles in Tamil language scraped from the Hindu Tamil news website. Each article includes its title, author, city, published date, and text.\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created to provide a comprehensive collection of Tamil news articles for research and analysis purposes.\n\n\t\n\t\t\n\t\tData Sources and collection method\n\t\n\nThe data in this dataset was collected from the Hindu Tamil news website‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset.","url":"https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset","creator_name":"Shweta Sukhtankar","creator_url":"https://huggingface.co/Shwetasss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Tamil","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt_with_system_en","keyword":"summarization","description":"iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_en dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_en","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/x_dataset_178.","url":"https://huggingface.co/datasets/qr12138/x_dataset_178","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_41","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_41.","url":"https://huggingface.co/datasets/James096/reddit_dataset_41","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/x_dataset_178.","url":"https://huggingface.co/datasets/qr12138/x_dataset_178","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_73","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_73.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_73","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-EASY-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\nMost of the Subsets are synthetically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-i","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe I, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_73","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_73.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_73","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"24gadget-posts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for 24gadget.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from 24gadget.ru, a Russian technology news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and view count. The dataset contains 36,582 unique articles covering various topics in technology and gadgets.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/24gadget-posts.","url":"https://huggingface.co/datasets/nyuuzyou/24gadget-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mira_summarization","keyword":"summarization","description":"SebastiaanBeekman/mira_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SebastiaanBeekman/mira_summarization","creator_name":"Sebastiaan Beekman","creator_url":"https://huggingface.co/SebastiaanBeekman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"24gadget-posts","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for 24gadget.ru\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains articles scraped from 24gadget.ru, a Russian technology news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and view count. The dataset contains 36,582 unique articles covering various topics in technology and gadgets.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/24gadget-posts.","url":"https://huggingface.co/datasets/nyuuzyou/24gadget-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","topic-classification","news-articles-summarization","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"IndEgo_Demo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants\n\t\n\n\nWe are sharing a portion of the dataset.\nüöß This dataset is a work-in-progress. Documentation, metadata, and proper usage guidelines will be added shortly. Use with caution.\n\n\n\t\n\t\n\t\n\t\tAcknowledgements: Meta Reality Labs for their support and open-science initiative with Project Aria.\n\t\n\n","url":"https://huggingface.co/datasets/vivek9chavan/IndEgo_Demo","creator_name":"Vivek Chavan","creator_url":"https://huggingface.co/vivek9chavan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","summarization","video-classification","any-to-any","English"],"keywords_longer_than_N":true},
	{"name":"code-monetaire-financier","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode mon√©taire et financier, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_128","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malicious546/x_dataset_128.","url":"https://huggingface.co/datasets/malicious546/x_dataset_128","creator_name":"string malicious","creator_url":"https://huggingface.co/malicious546","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050576","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050576.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050576","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Liposome-RBC_Scoping_Review_Screening","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tLiposome-RBC Interaction Studies Screening Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 2,152 screened abstracts from a systematic scoping review examining liposome-red blood cell (RBC) interactions. The dataset includes detailed screening decisions, rationales, and metadata for studies published through October 2024, with 487 included and 1,665 excluded studies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTask Type: Abstract screening for systematic scoping review‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Scoping_Review_Screening.","url":"https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Scoping_Review_Screening","creator_name":"Austin Routt","creator_url":"https://huggingface.co/UtopiansRareTruth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"x_dataset_128","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malicious546/x_dataset_128.","url":"https://huggingface.co/datasets/malicious546/x_dataset_128","creator_name":"string malicious","creator_url":"https://huggingface.co/malicious546","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_050576","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_050576.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_050576","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_8191","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/reddit_dataset_8191.","url":"https://huggingface.co/datasets/StormKing99/reddit_dataset_8191","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ShopTC-100K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tShopTC-100K Dataset\n\t\n\n\nThe ShopTC-100K dataset is collected using TermMiner, an open-source data collection and topic modeling pipeline introduced in the paper: \nHarmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale\nIf you find this dataset or the related paper useful for your research, please cite our paper:\n@inproceedings{tsai2025harmful,\n  author = {Elisa Tsai and Neal Mangaokar and Boyuan Zheng and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eltsai/ShopTC-100K.","url":"https://huggingface.co/datasets/eltsai/ShopTC-100K","creator_name":"El Tsai","creator_url":"https://huggingface.co/eltsai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/x_dataset_44.","url":"https://huggingface.co/datasets/zengsdfew/x_dataset_44","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_8191","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/reddit_dataset_8191.","url":"https://huggingface.co/datasets/StormKing99/reddit_dataset_8191","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/x_dataset_44.","url":"https://huggingface.co/datasets/zengsdfew/x_dataset_44","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"korean_chat_friendly","keyword":"summarization","description":"\n\t\n\t\t\n\t\tKorean Chat Friendly Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\n\nKorean Safe Conversation\nMental Health Counseling Conversations\n\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and empathetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly.","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"guvi_fintuned_dataset","keyword":"summarization","description":"zaid002/guvi_fintuned_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zaid002/guvi_fintuned_dataset","creator_name":"Mohammed Zaid p","creator_url":"https://huggingface.co/zaid002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","table-question-answering","summarization","Urdu","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6071","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_6071.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_6071","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16657","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_16657.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_16657","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romban38/x_dataset_51.","url":"https://huggingface.co/datasets/romban38/x_dataset_51","creator_name":"Romban","creator_url":"https://huggingface.co/romban38","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Global-Population-Data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tList of Countries and Dependencies by Population\n\t\n\nThis dataset contains population-related information for countries and dependencies, scraped from Wikipedia. The dataset includes the following columns:\n\nLocation: The country or dependency name.\nPopulation: Total population count.\n% of World: The percentage of the world's population this country or dependency represents.\nDate: The date of the population estimate.\nSource: Whether the source is official or derived from the United‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamramzan/Global-Population-Data.","url":"https://huggingface.co/datasets/iamramzan/Global-Population-Data","creator_name":"Muhammad Ramzan","creator_url":"https://huggingface.co/iamramzan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_6071","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_6071.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_6071","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16657","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_16657.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_16657","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romban38/x_dataset_51.","url":"https://huggingface.co/datasets/romban38/x_dataset_51","creator_name":"Romban","creator_url":"https://huggingface.co/romban38","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_26.","url":"https://huggingface.co/datasets/suul999922/x_dataset_26","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-propriete-personnes-publiques","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la propri√©t√© des personnes publiques, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_50132","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_50132.","url":"https://huggingface.co/datasets/icedwind/x_dataset_50132","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_26","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_26.","url":"https://huggingface.co/datasets/suul999922/x_dataset_26","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_50132","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_50132.","url":"https://huggingface.co/datasets/icedwind/x_dataset_50132","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_9th","keyword":"summarization","description":"KadamParth/NCERT_Science_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"OpenWeb1M","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenWeb Datasets Web Collection\n\t\n\nThe OpenWeb Datasets Web Collection, derived from the 'FineWeb' dataset, consists of more than 15 trillion tokens of cleaned and deduplicated English web data from CommonCrawl. The data processing pipeline is optimized for LLM performance, and the necessary set of datasets has been extracted from Hugging Face's FineWeb collections. This dataset was created by processing 96 CommonCrawl dumps, comprising web data crawled from the summer of 2013 to April‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/OpenWeb1M.","url":"https://huggingface.co/datasets/prithivMLmods/OpenWeb1M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text2text-generation","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_44.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_44","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Chinese_Debate_audio","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset aims to provide training resources for applications of AI in Chinese debate.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [Brian Deng]\nLanguage(s) (NLP): [Chinese]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\nSource: [Êñ∞ÂõΩËæ© videos from Bilibili]\n\n\n\t\n\t\t\n\t\tData Collection and Processing\n\t\n\n\n\n[TBD]\n","url":"https://huggingface.co/datasets/DBWBD/Chinese_Debate_audio","creator_name":"Brian Deng","creator_url":"https://huggingface.co/DBWBD","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","translation","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Shiv_Mahapuran","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Shiv_Mahapuran\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the ≈öiva MahƒÅpurƒÅ·πáa (often called ≈öivapurƒÅ·πáa) in CSV format. It is broken down into Sa·πÉhitƒÅs (seven surviving Sa·πÉhitƒÅs), Kha·πá·∏ças, AdhyƒÅyas, and individual ≈õlokas, enabling fine-grained NLP work on classical Sanskrit scripture.\n\nCurated by: Aluminium  \nOrganization: Snskrt  \nShared by: Snskrt  \nLanguage(s): Sanskrit (ISO code: sa)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_Mahapuran.","url":"https://huggingface.co/datasets/snskrt/Shiv_Mahapuran","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_44.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_44","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MDCure-72k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMDCure-72k\n\t\n\nüìÑ Paper | ü§ó HF Collection | ‚öôÔ∏è GitHub Repo\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nMDCure is an effective and scalable procedure for generating high-quality multi-document (MD) instruction tuning data to improve MD capabilities of LLMs. Using MDCure, we construct a suite of MD instruction datasets complementary to collections such as FLAN and fine-tune a variety of already instruction-tuned LLMs from the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in size. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yale-nlp/MDCure-72k.","url":"https://huggingface.co/datasets/yale-nlp/MDCure-72k","creator_name":"Yale NLP Lab","creator_url":"https://huggingface.co/yale-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"code-communes-nouvelle-caledonie","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des communes de la Nouvelle-Cal√©donie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_202507","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_202507.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_202507","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_202507","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_202507.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_202507","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"RSTeller_legacy","keyword":"summarization","description":"\n\t\n\t\t\n\t\t‚õî Usage Warning\n\t\n\nThis is the legacy version of the RSTeller dataset and is not the latest version referenced in our paper. We are keeping it available here to provide the community with easy access to additional data.\nFor the details and the usage of the dataset, please refer to our github page.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find the dataset and our paper useful, please consider citing our paper:\n@article{ge2025rsteller,\n  title={RSTeller: Scaling up visual language modeling in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy.","url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"TCSS","keyword":"summarization","description":"Jazbrooks/TCSS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Jazbrooks/TCSS","creator_name":"Jean Junior MOUBAMBA","creator_url":"https://huggingface.co/Jazbrooks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_44.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_44","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_24.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_24","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_44.","url":"https://huggingface.co/datasets/ashikshaffi08/reddit_dataset_44","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_24","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_24.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_24","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_15.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_15","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_12.","url":"https://huggingface.co/datasets/bit0/x_dataset_12","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_15.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_15","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/x_dataset_12.","url":"https://huggingface.co/datasets/bit0/x_dataset_12","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"All-WAN-Comments","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAll WAN Show Comments\n\t\n\nCompelete dataset of comments authored from the @LinusTechTips YouTube account or that contain the phrase \"timestamp\" on all WAN Show livestream VODs from 2013-present.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/All-WAN-Comments","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"All-WAN-Comments","keyword":"summary","description":"\n\t\n\t\t\n\t\tAll WAN Show Comments\n\t\n\nCompelete dataset of comments authored from the @LinusTechTips YouTube account or that contain the phrase \"timestamp\" on all WAN Show livestream VODs from 2013-present.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/All-WAN-Comments","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_39","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eggmoo/reddit_dataset_39.","url":"https://huggingface.co/datasets/eggmoo/reddit_dataset_39","creator_name":"Vedant Behari","creator_url":"https://huggingface.co/eggmoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-justice-administrative","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de justice administrative, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_151","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_151.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_151","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_144","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_144.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_144","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_customer_service_conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"saas-companies","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSaaS Companies Dataset\n\t\n\nThis dataset contains a list of 500 Software as a Service (SaaS) companies, providing a valuable resource for those interested in the SaaS industry. The dataset includes essential information such as the company's name, website, type of service, industry category, relevant keywords, and a brief description.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nNumber of Companies: 500\nData Format: CSV\nFields Included:\nName: The name of the company.\nURL: The website URL of the company.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/company-enrich/saas-companies.","url":"https://huggingface.co/datasets/company-enrich/saas-companies","creator_name":"Company Enrich","creator_url":"https://huggingface.co/company-enrich","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_156","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/reddit_dataset_156.","url":"https://huggingface.co/datasets/markrogolino/reddit_dataset_156","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_39","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eggmoo/reddit_dataset_39.","url":"https://huggingface.co/datasets/eggmoo/reddit_dataset_39","creator_name":"Vedant Behari","creator_url":"https://huggingface.co/eggmoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_151","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_151.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_151","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_144","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashikshaffi08/x_dataset_144.","url":"https://huggingface.co/datasets/ashikshaffi08/x_dataset_144","creator_name":"Ashik","creator_url":"https://huggingface.co/ashikshaffi08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_156","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markrogolino/reddit_dataset_156.","url":"https://huggingface.co/datasets/markrogolino/reddit_dataset_156","creator_name":"Mark Rogolino","creator_url":"https://huggingface.co/markrogolino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Arabic-Summarization-Dataset-AsDs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tArabic Summarization Dataset\n\t\n\nDataset Description\nThis dataset was created to address the significant gap in high-quality Arabic text summarization resources. After extensive research, we found that existing Arabic summarization datasets often suffer from poor summary quality, inconsistent formatting, or limited domain coverage. To overcome these limitations, this dataset was meticulously crafted using Google's Gemini AI model to generate high-quality, coherent summaries for Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/karimraouf/Arabic-Summarization-Dataset-AsDs.","url":"https://huggingface.co/datasets/karimraouf/Arabic-Summarization-Dataset-AsDs","creator_name":"karim raouf mostafa","creator_url":"https://huggingface.co/karimraouf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_15.","url":"https://huggingface.co/datasets/suul999922/x_dataset_15","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"kenyan_national_parks","keyword":"summarization","description":"gikebe/kenyan_national_parks dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gikebe/kenyan_national_parks","creator_name":"Elizabeth Gikebe","creator_url":"https://huggingface.co/gikebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_15.","url":"https://huggingface.co/datasets/suul999922/x_dataset_15","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"summarization","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"KairosNews","keyword":"summarization","description":"Handcrafted Dataset used in the elaboration of a thesis and a project for a competition (Premio Arquivo.pt: https://sobre.arquivo.pt/pt/colabore/premios-arquivo-pt/premio-arquivo-pt-2025/)\nIt contains news articles from the following Portuguese News agencies from 2020 to 2024:\nhttps://www.cmjornal.pt/ = 6771\nhttps://expresso.pt/ = 22606\nhttps://www.iol.pt/ = 39387\nhttps://www.publico.pt/ = 74893\nhttps://www.sapo.pt/ = 57838\nTOTAL = 201495\nEach news article contains it's url, title, text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0edon/KairosNews.","url":"https://huggingface.co/datasets/0edon/KairosNews","creator_name":"Quintino Fernandes","creator_url":"https://huggingface.co/0edon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","token-classification","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"openalex","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüéì OpenAlex: The World's Scholarly Knowledge Graph\n\t\n\n\n174M scholarly works from the world's largest open bibliographic database\n\nOpenAlex Homepage: https://openalex.orgAPI Documentation: https://docs.openalex.orgPaper: https://arxiv.org/abs/2205.01833\n\n\t\n\t\t\n\t\n\t\n\t\tWhat is OpenAlex?\n\t\n\nüéì OpenAlex is a free and open catalog of the global research system, containing metadata for 250M+ scholarly works, 90M+ authors, 120K+ venues, and 100K+ institutions. Named after the ancient Library of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sumuks/openalex.","url":"https://huggingface.co/datasets/sumuks/openalex","creator_name":"Sumuk Shashidhar","creator_url":"https://huggingface.co/sumuks","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"page-summarization-eval-fr","keyword":"summarization","description":"Mozilla/page-summarization-eval-fr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mozilla/page-summarization-eval-fr","creator_name":"mozilla","creator_url":"https://huggingface.co/Mozilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","French","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"page-summarization-eval-de","keyword":"summarization","description":"Mozilla/page-summarization-eval-de dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mozilla/page-summarization-eval-de","creator_name":"mozilla","creator_url":"https://huggingface.co/Mozilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","German","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_3.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_3","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"summarization","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_3","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_3.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_3","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Geography_12th","keyword":"summarization","description":"KadamParth/NCERT_Geography_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Geography_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_30.","url":"https://huggingface.co/datasets/suul999922/x_dataset_30","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Images","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Johnnyboystar/Images.","url":"https://huggingface.co/datasets/Johnnyboystar/Images","creator_name":"John Clough","creator_url":"https://huggingface.co/Johnnyboystar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","summarization","table-question-answering","question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_10.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_10","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_30.","url":"https://huggingface.co/datasets/suul999922/x_dataset_30","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_10.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_10","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Step-Instruction-Gx","keyword":"summarization","description":"\n\t\n\t\t\n\t\tStep-Instruction-GX Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Step-Instruction-GX dataset is a collection of instructional and educational content designed to assist in various learning and decision-making tasks. It includes a wide range of questions and corresponding answers, covering topics from health tips to scientific concepts.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText: The dataset primarily contains text data in various formats.\n\n\n\t\n\t\t\n\t\tFormats\n\t\n\n\nCSV: The dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Step-Instruction-Gx.","url":"https://huggingface.co/datasets/prithivMLmods/Step-Instruction-Gx","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/x_dataset_44.","url":"https://huggingface.co/datasets/Axel232/x_dataset_44","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_17","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlemdatameow/reddit_dataset_17.","url":"https://huggingface.co/datasets/mlemdatameow/reddit_dataset_17","creator_name":"Mlem Meow","creator_url":"https://huggingface.co/mlemdatameow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/reddit_dataset_11.","url":"https://huggingface.co/datasets/smmrokn/reddit_dataset_11","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_31933","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_31933.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_31933","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CrysMTM","keyword":"summarization","description":"johnpolat/CrysMTM dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/johnpolat/CrysMTM","creator_name":"Can Polat","creator_url":"https://huggingface.co/johnpolat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","summarization","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"code-famille-aide-sociale","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la famille et de l'aide sociale, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axel232/x_dataset_44.","url":"https://huggingface.co/datasets/Axel232/x_dataset_44","creator_name":"Pits","creator_url":"https://huggingface.co/Axel232","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_17","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlemdatameow/reddit_dataset_17.","url":"https://huggingface.co/datasets/mlemdatameow/reddit_dataset_17","creator_name":"Mlem Meow","creator_url":"https://huggingface.co/mlemdatameow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/reddit_dataset_11.","url":"https://huggingface.co/datasets/smmrokn/reddit_dataset_11","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_31933","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_31933.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_31933","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"arXiv-metadata-oai-snapshot","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset name: arXiv academic paper metadata\nData source: https://arxiv.org/\nSubmission date: 1986-04-25 ~ 2025-05-13 (data updated weekly)\nNumber of papers: 2,710,806 (as of 2025.5.14)\nFields included: title, author, abstract, journal information, DOI, etc.\nData format: json\nData volume: 4.58G\n\n\n\t\n\t\t\n\t\tAbout ArXiv\n\t\n\nFor nearly 30 years, ArXiv has served the public and research communities by providing open access to scholarly articles, from the vast branches of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jackkuo/arXiv-metadata-oai-snapshot.","url":"https://huggingface.co/datasets/jackkuo/arXiv-metadata-oai-snapshot","creator_name":"Jack Kuo","creator_url":"https://huggingface.co/jackkuo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","sentence-similarity","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_5.","url":"https://huggingface.co/datasets/suul999922/x_dataset_5","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_5.","url":"https://huggingface.co/datasets/suul999922/x_dataset_5","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nGitHub Issues with comments\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/huggingface/datasets/issues\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues.","url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","text-generation","fill-mask"],"keywords_longer_than_N":true},
	{"name":"Textual_Data_for_Rag","keyword":"summarization","description":"Abhishek2714C/Textual_Data_for_Rag dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Abhishek2714C/Textual_Data_for_Rag","creator_name":"Abhishek Chavan","creator_url":"https://huggingface.co/Abhishek2714C","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"injection-molding-QA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tinjection-molding-QA\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains questions and answers related to injection molding, focusing on topics such as 'Materials', 'Techniques', 'Machinery', 'Troubleshooting', 'Safety','Design','Maintenance','Manufacturing','Development','R&D'. The dataset is provided in CSV format with two columns: Questions and Answers.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nResearchers, practitioners, and enthusiasts in the field of injection molding can utilize this dataset for tasks such‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mustafakeser/injection-molding-QA.","url":"https://huggingface.co/datasets/mustafakeser/injection-molding-QA","creator_name":"Mustafa Keser","creator_url":"https://huggingface.co/mustafakeser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NCERT_Biology_12th","keyword":"summarization","description":"KadamParth/NCERT_Biology_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Biology_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Garud_puran_FlanT5_with_context","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGaruda Purana Q&A for FLAN-T5\n\t\n\nThis dataset contains question-answer pairs from the Garuda Purana, with a summarization context for each pair generated by FLAN-T5.\nFields:\n\nquestion: The input question in natural language.\nanswer: The answer to the question.\ncontext: A short summary (generated by FLAN-T5) of the Q&A pair, usable as context or for semantic retrieval.\n\nIntended Use:\n\nSupervised fine-tuning for Question Answering, Retrieval, and Instruction-based LLMs.\nThe question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Binoddai/Garud_puran_FlanT5_with_context.","url":"https://huggingface.co/datasets/Binoddai/Garud_puran_FlanT5_with_context","creator_name":"Binod","creator_url":"https://huggingface.co/Binoddai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_108","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wavecreator22/reddit_dataset_108.","url":"https://huggingface.co/datasets/wavecreator22/reddit_dataset_108","creator_name":"Krovanov","creator_url":"https://huggingface.co/wavecreator22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_49","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/reddit_dataset_49.","url":"https://huggingface.co/datasets/kimbuja/reddit_dataset_49","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_28.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_28","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"DecipherPref","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nHuman preference judgments are pivotal in guiding large language models (LLMs) to produce outputs that align with human values. Human evaluations are also used in summarization tasks to compare outputs from various systems, complementing existing automatic metrics. Despite their significance, however, there has been limited research probing these pairwise or k-wise comparisons. The collective impact and relative importance of factors such as output length, informativeness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/DecipherPref.","url":"https://huggingface.co/datasets/huuuyeah/DecipherPref","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_108","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wavecreator22/reddit_dataset_108.","url":"https://huggingface.co/datasets/wavecreator22/reddit_dataset_108","creator_name":"Krovanov","creator_url":"https://huggingface.co/wavecreator22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_49","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/reddit_dataset_49.","url":"https://huggingface.co/datasets/kimbuja/reddit_dataset_49","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_28.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_28","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55395","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_55395.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_55395","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Chinese-Patent-Summary","keyword":"summarization","description":"È´òË¥®Èáè‰∏≠Êñá‰∏ìÂà©ÊëòË¶ÅÊï∞ÊçÆÈõÜ„ÄÇ\n","url":"https://huggingface.co/datasets/chenmingxuan/Chinese-Patent-Summary","creator_name":"cmx","creator_url":"https://huggingface.co/chenmingxuan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55395","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_55395.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_55395","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"literature_sum","keyword":"summarization","description":"NejimakiTori/literature_sum dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NejimakiTori/literature_sum","creator_name":"Denis Grigoriev","creator_url":"https://huggingface.co/NejimakiTori","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_178.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_178","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Economics_11th","keyword":"summarization","description":"KadamParth/NCERT_Economics_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Economics_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_3.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_3","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"developers-questions-small-qe2","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDevelopers Questions Small QE2\n\t\n\nA dataset consisting of ~12k developers' questions, in English. These questions are synthetically generated via local LLMs at Orama.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasets\n\t\n\nThe dataset is proposed with three different embedding models:\n\nbge-small-en-v1.5\nbge-base-en-v1.5\nbge-large-en-v1.5\n\nIt also contains a quantized version for each model:\n\nbge-small 32 bytes\nbge-base 32 bytes\nbge-large 32 bytes\n\nFor each quantized model, this repository includes a binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2.","url":"https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2","creator_name":"OramaSearch Inc.","creator_url":"https://huggingface.co/OramaSearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_29.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_29","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_104.","url":"https://huggingface.co/datasets/gk4u/x_dataset_104","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_178.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_178","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_3.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_3","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_29","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_29.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_29","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_104.","url":"https://huggingface.co/datasets/gk4u/x_dataset_104","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_19.","url":"https://huggingface.co/datasets/suul999922/x_dataset_19","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_22","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_22.","url":"https://huggingface.co/datasets/James096/reddit_dataset_22","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_252","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill199284/reddit_dataset_252.","url":"https://huggingface.co/datasets/bill199284/reddit_dataset_252","creator_name":"thomas","creator_url":"https://huggingface.co/bill199284","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0506234","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0506234.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0506234","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_19.","url":"https://huggingface.co/datasets/suul999922/x_dataset_19","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_22","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_22.","url":"https://huggingface.co/datasets/James096/reddit_dataset_22","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_252","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bill199284/reddit_dataset_252.","url":"https://huggingface.co/datasets/bill199284/reddit_dataset_252","creator_name":"thomas","creator_url":"https://huggingface.co/bill199284","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0506234","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0506234.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0506234","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_17.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_17","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Open-Orca","keyword":"summarization","description":"üêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GenRM/OpenOrca-Open-Orca.","url":"https://huggingface.co/datasets/GenRM/OpenOrca-Open-Orca","creator_name":"GenRM: Generative Reward Models","creator_url":"https://huggingface.co/GenRM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ai_hub_narr_sum_vali","keyword":"summarization","description":"jr-d-analyst24/ai_hub_narr_sum_vali dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_narr_sum_vali","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/x_dataset_4.","url":"https://huggingface.co/datasets/andreans27/x_dataset_4","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_17.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_17","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/x_dataset_4.","url":"https://huggingface.co/datasets/andreans27/x_dataset_4","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"indonesian-simple-summaries","keyword":"summarization","description":"Indonesian version of Simple Summaries\nOriginal Source: https://huggingface.co/datasets/ProCreations/simple-summaries\nAbout 10,000 high quality data, with an original text sample from A subset of Ultra Fineweb and a summary generated by Llama 3.2 3b instruct.\nTime & Cost\nThis took about 3 hours using a batch size of 8 on a rented GPU instance (NVIDIA L4) with a total cost of about 2 dollars.\nIntended use case\nTraining summarization AI models\nTraining language models\n","url":"https://huggingface.co/datasets/irfanfadhullah/indonesian-simple-summaries","creator_name":"Muhamad Irfan Fadhullah","creator_url":"https://huggingface.co/irfanfadhullah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Indonesian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_7th","keyword":"summarization","description":"KadamParth/NCERT_Science_7th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V2\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nClarify objective and style\nShow examples dialogue and best-case summary\nInclude Chain-of-Thought Guidance (show individual subtasks)\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_223","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattnguyendev/reddit_dataset_223.","url":"https://huggingface.co/datasets/Mattnguyendev/reddit_dataset_223","creator_name":"Head","creator_url":"https://huggingface.co/Mattnguyendev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_174","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alen77/reddit_dataset_174.","url":"https://huggingface.co/datasets/Alen77/reddit_dataset_174","creator_name":"Moro","creator_url":"https://huggingface.co/Alen77","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_44.","url":"https://huggingface.co/datasets/gk4u/x_dataset_44","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_22.","url":"https://huggingface.co/datasets/suul999922/x_dataset_22","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Mixed-Summarization-Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRussian summarization data mix\n\t\n\nTotal Number of items in Train: 197561.\nTotal Number of items in Golden Test set: 258 (manually verified semi-synthetic data for evaluation purpose).\n\n\t\n\t\t\n\t\tWe use this datasets for train mix:\n\t\n\n\nXLSum\nGazeta\nWikiLingua\nMLSUM\nReviews (ru)\nCuration-corpus (ru)\nMatreshka\nDialogSum (ru)\nSAMSum (ru)\n\n\n\t\t\n\t\n\t\tCite us\n\t\n\n@misc{akhmetgareeva2024summary,\n      title={Towards Russian Summarization: can architecture solve data limitations problems?}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RussianNLP/Mixed-Summarization-Dataset.","url":"https://huggingface.co/datasets/RussianNLP/Mixed-Summarization-Dataset","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_223","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattnguyendev/reddit_dataset_223.","url":"https://huggingface.co/datasets/Mattnguyendev/reddit_dataset_223","creator_name":"Head","creator_url":"https://huggingface.co/Mattnguyendev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_174","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alen77/reddit_dataset_174.","url":"https://huggingface.co/datasets/Alen77/reddit_dataset_174","creator_name":"Moro","creator_url":"https://huggingface.co/Alen77","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_44.","url":"https://huggingface.co/datasets/gk4u/x_dataset_44","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_22.","url":"https://huggingface.co/datasets/suul999922/x_dataset_22","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_101","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hfgfchris/reddit_dataset_101.","url":"https://huggingface.co/datasets/hfgfchris/reddit_dataset_101","creator_name":"Christian Behrens","creator_url":"https://huggingface.co/hfgfchris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"company","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCompany Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Company Dataset is a large-scale collection containing detailed information on companies from around the globe. With approximately 24 million rows of data, this dataset offers a rich resource for market research, business intelligence, and machine learning applications focused on company profiling and analysis.\n\nNote: This is a public dataset, freely available for research and analysis purposes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nTotal Rows: 24M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/company.","url":"https://huggingface.co/datasets/fr3on/company","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_57303","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_57303.","url":"https://huggingface.co/datasets/icedwind/x_dataset_57303","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_197","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/reddit_dataset_197.","url":"https://huggingface.co/datasets/chaiamy/reddit_dataset_197","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CISA_Enrichment","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCISA Known Exploited Vulnerabilities Catalog Enrichment\n\t\n\nThe CISA recently started to publish the Known Exploited Vulnerabilities Catalog Enrichment to help federal agencies keep up with exploited vulnerabilities.\nThe data they provide is minimal, so I have built this jupyter notebook to enrich the data using the CIRCL public CVE API to add the following data points:\n\nCWE\nCVE Published Date\nCVE Modified Date\nReference URLs\nCPE 2.3 Data\n\nA Github Action runs every 6 hours and updates‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cvelist/CISA_Enrichment.","url":"https://huggingface.co/datasets/cvelist/CISA_Enrichment","creator_name":"cvelist","creator_url":"https://huggingface.co/cvelist","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_101","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hfgfchris/reddit_dataset_101.","url":"https://huggingface.co/datasets/hfgfchris/reddit_dataset_101","creator_name":"Christian Behrens","creator_url":"https://huggingface.co/hfgfchris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_57303","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_57303.","url":"https://huggingface.co/datasets/icedwind/x_dataset_57303","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_197","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/reddit_dataset_197.","url":"https://huggingface.co/datasets/chaiamy/reddit_dataset_197","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Collective-Corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüß† Collective Corpus ‚Äî Universal Pretraining + Finetuning Dataset (500B+ Tokens)\n\t\n\n\n\n\nCollective-Corpus is a massive-scale, multi-domain dataset designed to train Transformer-based language models from scratch and finetune them across a wide variety of domains ‚Äî all in one place.\n\n\t\n\t\n\t\n\t\tüìö Dataset Scope\n\t\n\nThis dataset aims to cover the full LLM lifecycle, from raw pretraining to domain-specialized finetuning.\n\t\n\t\t\n\t\t1. Pretraining Corpus\n\t\n\n\nLarge-scale, diverse multilingual text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dignity045/Collective-Corpus.","url":"https://huggingface.co/datasets/dignity045/Collective-Corpus","creator_name":"Dhiraj","creator_url":"https://huggingface.co/dignity045","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","text-classification","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_031079","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_031079.","url":"https://huggingface.co/datasets/james-1111/x_dataset_031079","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"llm-hackathon","keyword":"summarization","description":"pransfries/llm-hackathon dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/pransfries/llm-hackathon","creator_name":"Franz Superales","creator_url":"https://huggingface.co/pransfries","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text2text-generation","text-generation","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_11.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_11","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_19.","url":"https://huggingface.co/datasets/James096/x_dataset_19","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_031079","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_031079.","url":"https://huggingface.co/datasets/james-1111/x_dataset_031079","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_11.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_11","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_19.","url":"https://huggingface.co/datasets/James096/x_dataset_19","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0508228","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0508228.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0508228","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_2k","keyword":"summarization","description":"\n  \n\n\n\n\t\n\t\t\n\t\tNOVEReason_2k\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_2k.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_2k","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10830","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10830.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10830","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0508228","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0508228.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0508228","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10830","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10830.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10830","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"SimpleQnA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimpleQnA Dataset Description\n\t\n\nSimpleQnA is a straightforward question-and-answer dataset in Tagalog. It covers many topics and task types, mixing simple and complex instructions. Some instructions are in English to avoid the model learning Tagalog-only responses when given Tagalog prompts.\nThe dataset includes constraints borrowed from Tulu 3, Muffin, and IFEval for instruction-following diversity. Random sampling is used to enhance variety.\n\n\n\t\n\t\t\n\t\n\t\n\t\tTopics and Task Types‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Linggowiktiks/SimpleQnA.","url":"https://huggingface.co/datasets/Linggowiktiks/SimpleQnA","creator_name":"Linggowiktiks","creator_url":"https://huggingface.co/Linggowiktiks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","translation","Tagalog"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_139.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_139","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-urbanisme","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'urbanisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"DCA-Bench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDCA-Benchmark\n\t\n\n\n\n\nDCA-Benchmark aims to provide a comprehensive benchmark for evaluating LLM agents' capabilities in discovering data quality issues across online dataset platforms, representing the first step of the curation pipeline. Throughout this document, we will refer to such an LLM agent as a \"Curator\" to highlight its role in this task. A well-performing Curator can detect and locate existing issues, which is critical for subsequent fixes by human maintainers or other LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trais-lab/DCA-Bench.","url":"https://huggingface.co/datasets/trais-lab/DCA-Bench","creator_name":"TRAIS Lab","creator_url":"https://huggingface.co/trais-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_139.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_139","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_461985","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_461985.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_461985","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/x_dataset_44.","url":"https://huggingface.co/datasets/vouu/x_dataset_44","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_461985","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_461985.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_461985","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/x_dataset_44.","url":"https://huggingface.co/datasets/vouu/x_dataset_44","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"actuary-enough-qa-dataset","keyword":"text-simplification","description":"\n  \n\n\n\t\n\t\t\n\t\tüëã Connect with me on LinkedIn!\n\t\n\n  \n  Manuel Caccone - Actuarial Data Scientist & Open Source Educator\n  Let's discuss actuarial science, AI, and open source projects!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüéØ Actuary Enough - Actuarial Question Simplification Dataset\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüö© Dataset Description\n\t\n\nThe Actuary Enough Dataset contains examples of complex actuarial and insurance questions that have been simplified and rephrased to improve clarity and accessibility. This dataset is designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset.","url":"https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-simplification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"actuary-enough-qa-dataset","keyword":"text-simplification","description":"\n  \n\n\n\t\n\t\t\n\t\tüëã Connect with me on LinkedIn!\n\t\n\n  \n  Manuel Caccone - Actuarial Data Scientist & Open Source Educator\n  Let's discuss actuarial science, AI, and open source projects!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüéØ Actuary Enough - Actuarial Question Simplification Dataset\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüö© Dataset Description\n\t\n\nThe Actuary Enough Dataset contains examples of complex actuarial and insurance questions that have been simplified and rephrased to improve clarity and accessibility. This dataset is designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset.","url":"https://huggingface.co/datasets/manuelcaccone/actuary-enough-qa-dataset","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-simplification","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"2015-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2015 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2015 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2015-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"high-school-physics","keyword":"summarization","description":"mrohith29/high-school-physics dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mrohith29/high-school-physics","creator_name":"Rohith Mariyala","creator_url":"https://huggingface.co/mrohith29","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"high-school-physics","keyword":"summarization","description":"mrohith29/high-school-physics dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mrohith29/high-school-physics","creator_name":"Rohith Mariyala","creator_url":"https://huggingface.co/mrohith29","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary","keyword":"summarization","description":"iamsubingyawali/nepali_news_text_summary dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"2015-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2015 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2015 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2015-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_217","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_217.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_217","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"redblueai.sed","keyword":"summarization","description":"Ahiyan/redblueai.sed dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ahiyan/redblueai.sed","creator_name":"Ahiyan Kabir","creator_url":"https://huggingface.co/Ahiyan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-to-image","English","German"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_217","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tensorshield/reddit_dataset_217.","url":"https://huggingface.co/datasets/tensorshield/reddit_dataset_217","creator_name":"Tensor Shield","creator_url":"https://huggingface.co/tensorshield","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_12.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_12","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"gpt-oss-120b-reasoning-STEM-5K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGPT-OSS-120B-Distilled-Reasoning-STEM Dataset\n\t\n\n\n\t\n\t\t\n\t\t1) Dataset Overview\n\t\n\n\nData Source Model: gpt-oss-120b-high\nTask Type: STEM Reasoning and Problem Solving (Science, Technology, Engineering & Mathematics)\nData Format: `JSON Lines \nFields: generator, category, input, CoT_Native‚Äî‚Äîreasoning, answer\n(Consistent with the math dataset, splitting the original 'output' into 'reasoning' and 'answer' for COT/SFT scenarios.)\n\n\n\n\t\n\t\n\t\n\t\t2) Design Goals (Motivation)\n\t\n\nThis dataset targets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jackrong/gpt-oss-120b-reasoning-STEM-5K.","url":"https://huggingface.co/datasets/Jackrong/gpt-oss-120b-reasoning-STEM-5K","creator_name":"JIRONG","creator_url":"https://huggingface.co/Jackrong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63648","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_63648.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_63648","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_12.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_12","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63648","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_63648.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_63648","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_184","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mo0han3d/reddit_dataset_184.","url":"https://huggingface.co/datasets/Mo0han3d/reddit_dataset_184","creator_name":"AbdElMonsef","creator_url":"https://huggingface.co/Mo0han3d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"matches","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DvxL/matches.","url":"https://huggingface.co/datasets/DvxL/matches","creator_name":"Ed","creator_url":"https://huggingface.co/DvxL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","table-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/reddit_dataset_218.","url":"https://huggingface.co/datasets/SAVE0x0/reddit_dataset_218","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aaron927dev/reddit_dataset_250.","url":"https://huggingface.co/datasets/aaron927dev/reddit_dataset_250","creator_name":"William Hudson","creator_url":"https://huggingface.co/aaron927dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_39.","url":"https://huggingface.co/datasets/James096/x_dataset_39","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_11.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_11","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_184","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mo0han3d/reddit_dataset_184.","url":"https://huggingface.co/datasets/Mo0han3d/reddit_dataset_184","creator_name":"AbdElMonsef","creator_url":"https://huggingface.co/Mo0han3d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SAVE0x0/reddit_dataset_218.","url":"https://huggingface.co/datasets/SAVE0x0/reddit_dataset_218","creator_name":"x","creator_url":"https://huggingface.co/SAVE0x0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_250","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aaron927dev/reddit_dataset_250.","url":"https://huggingface.co/datasets/aaron927dev/reddit_dataset_250","creator_name":"William Hudson","creator_url":"https://huggingface.co/aaron927dev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_39.","url":"https://huggingface.co/datasets/James096/x_dataset_39","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jacksss123/reddit_dataset_11.","url":"https://huggingface.co/datasets/Jacksss123/reddit_dataset_11","creator_name":"Tony","creator_url":"https://huggingface.co/Jacksss123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ml-paraphrase-tr","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tTurkish ML Paraphrase Dataset\n\t\n\nThis dataset contains 60,000 Turkish sentence pairs designed for paraphrase detection and semantic similarity tasks. It is suitable for training and evaluating machine learning models, particularly in binary classification and fine-tuning scenarios.\n\n\t\n\t\t\n\t\tüì¶ Dataset Structure\n\t\n\nEach entry consists of:\n\nsentence1: First sentence\nsentence2: Second sentence\nlabel:  \n1 ‚Üí paraphrase (semantically similar)  \n0 ‚Üí not paraphrase (semantically unrelated)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dogukanvzr/ml-paraphrase-tr.","url":"https://huggingface.co/datasets/dogukanvzr/ml-paraphrase-tr","creator_name":"Dogukan Veziroglu","creator_url":"https://huggingface.co/dogukanvzr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Turkish","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ImageNet-Think","keyword":"summarization","description":"\n\t\n\t\t\n\t\tImageNet-Think 250K\n\t\n\nA 250k-image dataset with JSONL/Parquet metadata providing prompts and answers for multimodal reasoning tasks.\n\n\t\n\t\t\n\t\tLoad\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"krishnateja95/ImageNet-Think\", split=\"train\")\nds[0]\n\n","url":"https://huggingface.co/datasets/krishnateja95/ImageNet-Think","creator_name":"Krishna Teja Chitty-Venkata","creator_url":"https://huggingface.co/krishnateja95","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","synthetic","machine-generated","monolingual","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MECAT-QA","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks\n\t\n\nüìñ Paper | üõ†Ô∏è GitHub | üîä MECAT-Caption Dataset | üîä MECAT-QA Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMECAT (Multi-Expert Chain for Audio Tasks) is a comprehensive benchmark constructed on large-scale data to evaluate machine understanding of audio content through two core tasks:\n\nAudio Captioning: Generating textual descriptions for given audio\nAudio Question Answering: Answering questions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mispeech/MECAT-QA.","url":"https://huggingface.co/datasets/mispeech/MECAT-QA","creator_name":"Horizon Team, Xiaomi MiLM Plus","creator_url":"https://huggingface.co/mispeech","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-text-to-text","summarization","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-legal","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Legal (Query, Response) Dataset\n\t\n\n\nDescriptionSynthetic Legal is a 140,000-row dataset of (legal query, legal response) pairs spanning 13 legal domains, designed to mimic real-world legal fact patterns and references. Each entry provides a short scenario (fact pattern) and a \"verified solution\" referencing real citations (statutes, case law, scholarly commentary, legislative history, and comparative law) with a specified verification method.  \nDisclaimer: All text is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/synthetic-legal.","url":"https://huggingface.co/datasets/Taylor658/synthetic-legal","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","other","English"],"keywords_longer_than_N":true},
	{"name":"FedLLM1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lFelix/FedLLM1.","url":"https://huggingface.co/datasets/lFelix/FedLLM1","creator_name":"Fan Liu","creator_url":"https://huggingface.co/lFelix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","English"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (14/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeMoussel/LEGI.","url":"https://huggingface.co/datasets/LeMoussel/LEGI","creator_name":"LeMoussel","creator_url":"https://huggingface.co/LeMoussel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_44.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_44","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8191","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_8191.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_8191","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Sci2Pol-Bench","keyword":"summarization","description":"Sci2Pol-Bench \n\nData, scripts, and recipes for the benchmark Sci2Pol-Bench, a comprehensive benchmark for evaluating large language models.\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\n  About ‚Ä¢\n  Usage‚Ä¢\n  Authors\n\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\n\n\nThe data consists of policy briefs obtained from Nature Energy, Nature Climate, Nature Cities, and Journal of Health and Social Behavior Policy Briefs.\nPolicy briefs originally were introduced in the Nature Energy journal with the goal of:\n\nThis format aims to provide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Northwestern-CSSI/Sci2Pol-Bench.","url":"https://huggingface.co/datasets/Northwestern-CSSI/Sci2Pol-Bench","creator_name":"Center for Science of Science and Innovation","creator_url":"https://huggingface.co/Northwestern-CSSI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_216","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pavlo0912/reddit_dataset_216.","url":"https://huggingface.co/datasets/Pavlo0912/reddit_dataset_216","creator_name":"lim","creator_url":"https://huggingface.co/Pavlo0912","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_193","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sesen01/reddit_dataset_193.","url":"https://huggingface.co/datasets/sesen01/reddit_dataset_193","creator_name":"Selim Esen","creator_url":"https://huggingface.co/sesen01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0212148","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0212148.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0212148","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_44.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_44","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8191","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_8191.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_8191","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_216","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pavlo0912/reddit_dataset_216.","url":"https://huggingface.co/datasets/Pavlo0912/reddit_dataset_216","creator_name":"lim","creator_url":"https://huggingface.co/Pavlo0912","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_193","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sesen01/reddit_dataset_193.","url":"https://huggingface.co/datasets/sesen01/reddit_dataset_193","creator_name":"Selim Esen","creator_url":"https://huggingface.co/sesen01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0212148","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_0212148.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_0212148","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-defense","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de la d√©fense, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-travail-maritime","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du travail maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"aifgen-lipschitz","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in lipschitz bounded scenario given three tasks:\n\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm 5\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm a High School Student\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm an expert\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nAs a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_221","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/reddit_dataset_221.","url":"https://huggingface.co/datasets/bit0/reddit_dataset_221","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_221","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bit0/reddit_dataset_221.","url":"https://huggingface.co/datasets/bit0/reddit_dataset_221","creator_name":"sn13","creator_url":"https://huggingface.co/bit0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_7.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_7","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_136","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universe-riez/reddit_dataset_136.","url":"https://huggingface.co/datasets/universe-riez/reddit_dataset_136","creator_name":"universe","creator_url":"https://huggingface.co/universe-riez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"web-content","keyword":"summarization","description":"neverland-th/web-content dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neverland-th/web-content","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","translation","question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quanglt/reddit_dataset_44.","url":"https://huggingface.co/datasets/quanglt/reddit_dataset_44","creator_name":"Quang Le","creator_url":"https://huggingface.co/quanglt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_120","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_120.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_120","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_7.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_7","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_136","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universe-riez/reddit_dataset_136.","url":"https://huggingface.co/datasets/universe-riez/reddit_dataset_136","creator_name":"universe","creator_url":"https://huggingface.co/universe-riez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quanglt/reddit_dataset_44.","url":"https://huggingface.co/datasets/quanglt/reddit_dataset_44","creator_name":"Quang Le","creator_url":"https://huggingface.co/quanglt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_120","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_120.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_120","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_16","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/reddit_dataset_16.","url":"https://huggingface.co/datasets/vuhongtien/reddit_dataset_16","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"storytelling-and-creative-writing-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTopic: Stories, Folk Tales, Poems, and Essays\nDomains: Stories, Folk Tales, Poems, Essays\nFocus: This dataset contains a collection of stories, folk tales, poems, and essays, that are summarized.\nNumber of Entries: 500\nDataset Type: Summarization Dataset\nModel Used: bedrock/us.amazon.nova-pro-v1:0\nLanguage: English\nAdditional Information: Generated using summarization techniques to provide concise versions of the original texts.\nGenerated by: SynthGenAI Package\n\n","url":"https://huggingface.co/datasets/Shekswess/storytelling-and-creative-writing-summarization","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"RISCBAC","keyword":"summarization","description":"RISCBAC was created using [RISC](https://github.com/GRAAL-Research/risc), an open-source Python package data \ngenerator. RISC generates look-alike automobile insurance contracts based on the Quebec regulatory insurance \nform in French and English.\n\nIt contains 10,000 English and French insurance contracts generated using the same seed. Thus, contracts share \nthe same deterministic synthetic data (RISCBAC can be used as an aligned dataset). RISC can be used to generate \nmore data for RISCBAC.","url":"https://huggingface.co/datasets/davebulaval/RISCBAC","creator_name":"David","creator_url":"https://huggingface.co/davebulaval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","question-answering","translation","monolingual","aligned"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_16","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/reddit_dataset_16.","url":"https://huggingface.co/datasets/vuhongtien/reddit_dataset_16","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_223","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_223.","url":"https://huggingface.co/datasets/James096/reddit_dataset_223","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2016-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2016 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2016 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2016-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_223","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_223.","url":"https://huggingface.co/datasets/James096/reddit_dataset_223","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2016-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2016 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2016 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2016-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12970","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_12970.","url":"https://huggingface.co/datasets/icedwind/x_dataset_12970","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_12970","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_12970.","url":"https://huggingface.co/datasets/icedwind/x_dataset_12970","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"LT_Criminal_code_Articles_Summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìñ Lithuanian Criminal Code Article Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìë Overview\n\t\n\nThis dataset contains concise, factual summaries of selected articles from the Lithuanian Criminal Code. Each entry consists of the original article text, a machine-generated summary in Lithuanian, and accompanying metadata including the article's section, summarization instructions, and the summarizer model used.\nThe summaries were generated using a legal-specialized LLM workflow, designed to condense‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArturG9/LT_Criminal_code_Articles_Summaries.","url":"https://huggingface.co/datasets/ArturG9/LT_Criminal_code_Articles_Summaries","creator_name":"Art≈´ras grygelis","creator_url":"https://huggingface.co/ArturG9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Lithuanian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"movies","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMovie Scripts Dataset\n\t\n\nThe Movie Scripts Dataset consists of scripts from 1,172 movies, providing a comprehensive collection of movie dialogues and narratives. This dataset is designed to support various natural language processing (NLP) tasks, including dialogue generation, script summarization, and text analysis.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nThe dataset contains 2 columns:\n\nName: The title of the movie.\nScript: The full script of the movie in English.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe Movie Scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/movies.","url":"https://huggingface.co/datasets/IsmaelMousa/movies","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_223","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattnguyendev/x_dataset_223.","url":"https://huggingface.co/datasets/Mattnguyendev/x_dataset_223","creator_name":"Head","creator_url":"https://huggingface.co/Mattnguyendev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"data-kit-sub-iwslt2025-if-long-constraint","keyword":"summarization","description":"\n\t\n\t\t\n\t\tData for KIT‚Äôs Instruction Following Submission for IWSLT 2025\n\t\n\nThis repo contains the data used to train our model for IWSLT 2025's Instruction-Following (IF) Speech Processing track.\nIWSLT 2025's Instruction-Following (IF) Speech Processing track in the scientific domain aims to benchmark foundation models that can follow natural \nlanguage instructions‚Äîan ability well-established in textbased LLMs but still emerging in speech-based counterparts. Our approach employs an end-to-end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint.","url":"https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint","creator_name":"Maike Z√ºfle","creator_url":"https://huggingface.co/maikezu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","summarization","question-answering","translation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_223","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattnguyendev/x_dataset_223.","url":"https://huggingface.co/datasets/Mattnguyendev/x_dataset_223","creator_name":"Head","creator_url":"https://huggingface.co/Mattnguyendev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"INHA_Titres_CatVentes","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes.","url":"https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes","creator_name":"Juliette Benguigui","creator_url":"https://huggingface.co/JulietteBenguigui142","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","üá∫üá∏ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"reddit_dataset_206","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_206.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_206","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"medreport_text_1000","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMedReport - Reports Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains English medical audio transcriptions and the corresponding structured reports.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\ninput: Audio transcription\noutput: Structured medical report\nsample_id: Example identifier\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nTotal examples: 1000\nLicense: Apache License 2.0\nCreated: 2025-09-01\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tLoading the dataset\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\nfull_dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youngwouk-kim/medreport_text_1000.","url":"https://huggingface.co/datasets/youngwouk-kim/medreport_text_1000","creator_name":"Young-wouk Kim","creator_url":"https://huggingface.co/youngwouk-kim","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_52","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1980QVQ/reddit_dataset_52.","url":"https://huggingface.co/datasets/1980QVQ/reddit_dataset_52","creator_name":"QVQ","creator_url":"https://huggingface.co/1980QVQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_206","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chidinna/reddit_dataset_206.","url":"https://huggingface.co/datasets/chidinna/reddit_dataset_206","creator_name":"chidinn","creator_url":"https://huggingface.co/chidinna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_52","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1980QVQ/reddit_dataset_52.","url":"https://huggingface.co/datasets/1980QVQ/reddit_dataset_52","creator_name":"QVQ","creator_url":"https://huggingface.co/1980QVQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"QABGB","keyword":"summarization","description":"\n\t\n\t\t\n\t\tQuestion answering with books translated to Bulgarian\n\t\n\n\n\nThis dataset consists of questions, answers and context for them which are extracted from books translated to Bulgarian language. The dataset is generated automatically using large language models which are fine-tuned on Bulgarian language such as BgGPT.\n","url":"https://huggingface.co/datasets/petkopetkov/QABGB","creator_name":"Petko Petkov","creator_url":"https://huggingface.co/petkopetkov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","Bulgarian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62103","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_62103.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_62103","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62103","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_62103.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_62103","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_28.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_28","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"llmops-database","keyword":"summarization","description":"\n\t\n\t\t\n\t\tThe ZenML LLMOps Database\n\t\n\n\nTo learn more about ZenML and our open-source MLOps framework, visit\nzenml.io.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LLMOps Database is a comprehensive collection of over 500 real-world\ngenerative AI implementations that showcases how organizations are successfully\ndeploying Large Language Models (LLMs) in production. The case studies have been\ncarefully curated to focus on technical depth and practical problem-solving,\nwith an emphasis on implementation details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database.","url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-classification","text-generation","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63354","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_63354.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_63354","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060640","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060640.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060640","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_test","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_test.","url":"https://huggingface.co/datasets/suul999922/x_dataset_test","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/x_dataset_44.","url":"https://huggingface.co/datasets/veyhoranohy/x_dataset_44","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Crio.Do","keyword":"summarization","description":"Ritwik-28/Crio.Do dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ritwik-28/Crio.Do","creator_name":"Ritwik Gupta","creator_url":"https://huggingface.co/Ritwik-28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0301244","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0301244.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0301244","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_28.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_28","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"llmops-database","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tThe ZenML LLMOps Database\n\t\n\n\nTo learn more about ZenML and our open-source MLOps framework, visit\nzenml.io.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LLMOps Database is a comprehensive collection of over 500 real-world\ngenerative AI implementations that showcases how organizations are successfully\ndeploying Large Language Models (LLMs) in production. The case studies have been\ncarefully curated to focus on technical depth and practical problem-solving,\nwith an emphasis on implementation details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database.","url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-classification","text-generation","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63354","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_63354.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_63354","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060640","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060640.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060640","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_test","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_test.","url":"https://huggingface.co/datasets/suul999922/x_dataset_test","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/x_dataset_44.","url":"https://huggingface.co/datasets/veyhoranohy/x_dataset_44","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0301244","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0301244.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0301244","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"machine-paraphrase-dataset","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tDataset Card for Machine Paraphrase Dataset (MPC)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\n\n\t\n\t\t\n\t\tHow to use it\n\t\n\nYou can load the dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset.","url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_99","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/reddit_dataset_99.","url":"https://huggingface.co/datasets/jasonmoore92/reddit_dataset_99","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_139.","url":"https://huggingface.co/datasets/gk4u/x_dataset_139","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"AVAINT","keyword":"summarization","description":"botintel-community/AVAINT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/botintel-community/AVAINT","creator_name":"BotIntel X","creator_url":"https://huggingface.co/botintel-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text-classification","Azerbaijani","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_133","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshreddy/reddit_dataset_133.","url":"https://huggingface.co/datasets/dineshreddy/reddit_dataset_133","creator_name":"dinesh reddy","creator_url":"https://huggingface.co/dineshreddy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19124","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_19124.","url":"https://huggingface.co/datasets/momo1942/x_dataset_19124","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_99","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/reddit_dataset_99.","url":"https://huggingface.co/datasets/jasonmoore92/reddit_dataset_99","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_139.","url":"https://huggingface.co/datasets/gk4u/x_dataset_139","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_133","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshreddy/reddit_dataset_133.","url":"https://huggingface.co/datasets/dineshreddy/reddit_dataset_133","creator_name":"dinesh reddy","creator_url":"https://huggingface.co/dineshreddy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"chinese-novel-nonH-collect","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tlicense: cc0-1.0\ntask_categories:\n- text-classification\n- summarization\nlanguage:\n- zh\ntags:\n- art\nsize_categories:\n- 100M<n<1B\n\t\n\n","url":"https://huggingface.co/datasets/lainka0o0/chinese-novel-nonH-collect","creator_name":"lainka","creator_url":"https://huggingface.co/lainka0o0","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Chinese","cc0-1.0","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"hcdt","keyword":"summarization","description":"usmanasademe/hcdt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/usmanasademe/hcdt","creator_name":"Usman Asad","creator_url":"https://huggingface.co/usmanasademe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","English","mit","üá∫üá∏ Region: US","hrc"],"keywords_longer_than_N":true},
	{"name":"AEOLLM","keyword":"summarization","description":"The repository maintains the dataset of NTCIR-18 Automatic Evaluation of LLMs (AEOLLM) Task. \n\nThe train set includes human annotation for participants to reference when designing their methods.\nThe test set does not contain human annotation and is used to generate a leaderboard https://huggingface.co/spaces/THUIR/AEOLLM.\n\nDetails of AEOLLLM can be found at the link: https://huggingface.co/spaces/THUIR/AEOLLM\n","url":"https://huggingface.co/datasets/THUIR/AEOLLM","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"code-impots","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_63","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_63.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_63","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19124","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_19124.","url":"https://huggingface.co/datasets/momo1942/x_dataset_19124","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_63","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/reddit_dataset_63.","url":"https://huggingface.co/datasets/Spark0801/reddit_dataset_63","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/reddit_dataset_44.","url":"https://huggingface.co/datasets/vouu/reddit_dataset_44","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"moltextnet","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoad the MolTextNet Dataset\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"liuganghuggingface/moltextnet\")\n\n# Print the dataset object\nprint(dataset)\n# Output:\n# DatasetDict({\n#     train: Dataset({\n#         features: ['id', 'canonical_smiles', 'description'],\n#         num_rows: 2474584\n#     })\n# })\n\n# Show available splits\nprint(dataset.keys())\n# Output:\n# dict_keys(['train'])\n\n# Display the first example from the training set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liuganghuggingface/moltextnet.","url":"https://huggingface.co/datasets/liuganghuggingface/moltextnet","creator_name":"Gang Liu","creator_url":"https://huggingface.co/liuganghuggingface","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","graph-ml","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_245","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_245.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_245","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_31731","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_31731.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_31731","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36658","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_36658.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_36658","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ParsedResumes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tParsed Resume\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for both text classification and text generation tasks. \nIt comprises more that 250 resumes from 25 IT professionals, along with their corresponding parsed information. \nThe parsed data adheres to a consistent schema, facilitating efficient analysis and utilization for various machine learning applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nParsing schema:\n\nschema:\n{\n  \"name\": \"John Doe\",\n  \"email\": \"john.doe@example.com\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AhmedBou/ParsedResumes.","url":"https://huggingface.co/datasets/AhmedBou/ParsedResumes","creator_name":"Ahmed Khalil Boulahia","creator_url":"https://huggingface.co/AhmedBou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vouu/reddit_dataset_44.","url":"https://huggingface.co/datasets/vouu/reddit_dataset_44","creator_name":"Pham Manh Truong","creator_url":"https://huggingface.co/vouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_245","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_245.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_245","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_31731","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hshwk1983/x_dataset_31731.","url":"https://huggingface.co/datasets/hshwk1983/x_dataset_31731","creator_name":"hshwh","creator_url":"https://huggingface.co/hshwk1983","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36658","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_36658.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_36658","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"sodnapraksa","keyword":"summarization","description":"modernlegal/sodnapraksa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/modernlegal/sodnapraksa","creator_name":"Modern Legal","creator_url":"https://huggingface.co/modernlegal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Slovenian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4561","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_4561.","url":"https://huggingface.co/datasets/icedwind/x_dataset_4561","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rhvex-affects","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for rhvex-affects\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extracting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vdanen/rhvex-affects.","url":"https://huggingface.co/datasets/vdanen/rhvex-affects","creator_name":"Vincent Danen","creator_url":"https://huggingface.co/vdanen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_021084","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_021084.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_021084","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_39","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_39.","url":"https://huggingface.co/datasets/James096/reddit_dataset_39","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"X-LeBench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüëì X-LeBench Dataset\n\t\n\nThis folder contains the dataset and task annotations for the X-LeBench. \n\n\t\n\t\t\n\t\tüì• Before You Start\n\t\n\nTo use this dataset effectively:\n\nDownload Ego4D v2 videos following the Ego4D dataset instructions.\nRead our paper and code for full details on data generation, simulation logic, and task definitions.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüßæ Dataset Structure\n\t\n\nEach simulation data and its corresponding annotations across all tasks is stored as a single .json file:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VvV7/X-LeBench.","url":"https://huggingface.co/datasets/VvV7/X-LeBench","creator_name":"Z","creator_url":"https://huggingface.co/VvV7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4561","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_4561.","url":"https://huggingface.co/datasets/icedwind/x_dataset_4561","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_021084","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_021084.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_021084","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_39","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_39.","url":"https://huggingface.co/datasets/James096/reddit_dataset_39","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"persian-alpaca-deep-clean","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPersian Alpaca Deep Clean\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Persian Alpaca Dataset is a collection of finely cleaned Persian language records derived from various sources, primarily the Bactrian, PN-Summary (summarization), and PEYMA (Named Entity Recognition) datasets. The dataset comprises approximately 68,279 records after rigorous cleaning processes, including character normalization, removal of Arabic letters, elimination of sentences with high word repetition, removal of words with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/myrkur/persian-alpaca-deep-clean.","url":"https://huggingface.co/datasets/myrkur/persian-alpaca-deep-clean","creator_name":"Amir Masoud Ahmadi","creator_url":"https://huggingface.co/myrkur","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","token-classification","Persian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0110104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0110104.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0110104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_031267","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_031267.","url":"https://huggingface.co/datasets/james-1111/x_dataset_031267","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0110104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_0110104.","url":"https://huggingface.co/datasets/william-1111/x_dataset_0110104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_031267","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_031267.","url":"https://huggingface.co/datasets/james-1111/x_dataset_031267","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_76","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_76.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_76","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summary-of-a-haystack","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SummHay\n\t\n\nThis repository contains the data for the experiments in the SummHay paper.\n\n\t\n\t\t\n\t\n\t\n\t\tAccessing the Data\n\t\n\nWe publicly release the 10 Haystacks (5 in conversational domain, 5 in the news domain). Each example follows the below format:\n{\n    \"topic_id\": \"ObjectId()\",\n    \"topic\": \"\",\n    \"topic_metadata\": {\"participants\": []}, // can be domain specific\n    \"subtopics\": [\n        {\n            \"subtopic_id\": \"ObjectId()\",\n            \"subtopic_name\": \"\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/summary-of-a-haystack.","url":"https://huggingface.co/datasets/Salesforce/summary-of-a-haystack","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"x_dataset_76","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_76.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_76","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ms2_dataset_restructured","keyword":"summarization","description":"ahmedselhady/ms2_dataset_restructured dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ahmedselhady/ms2_dataset_restructured","creator_name":"Ahmed Mohamed Elhady","creator_url":"https://huggingface.co/ahmedselhady","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0307178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0307178.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0307178","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_0109104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_0109104.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_0109104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_118","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_118.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_118","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0307178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0307178.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0307178","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_0109104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/reddit_dataset_0109104.","url":"https://huggingface.co/datasets/william-1111/reddit_dataset_0109104","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_118","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_118.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_118","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Capybara","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"Capybara\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDataset used to train BinT5. Please refer to the paper for more information. \n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{alkaswan2023extending,\n  title={Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries},\n  author={Al-Kaswan, Ali and Ahmed, Toufique and Izadi, Maliheh and Sawant, Anand Ashok and Devanbu, Premkumar and van Deursen, Arie},\n  booktitle={2023 IEEE International Conference on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISE-TUDelft/Capybara.","url":"https://huggingface.co/datasets/AISE-TUDelft/Capybara","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51244","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_51244.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_51244","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-methods","keyword":"summarization","description":"nccu-1122-nlp-final/arxiv-abstracts-methods dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nccu-1122-nlp-final/arxiv-abstracts-methods","creator_name":"nccu-1122-nlp-final","creator_url":"https://huggingface.co/nccu-1122-nlp-final","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51244","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_51244.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_51244","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"odoo-sql-query-dataset","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tOdoo SQL Query Dataset\n\t\n\nThis dataset contains natural language to SQL query pairs specifically for Odoo 17.0 Community Edition. It's designed to help train and fine-tune language models for generating accurate SQL queries for Odoo databases.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe dataset consists of 6815 carefully curated examples of natural language questions paired with their corresponding SQL queries for Odoo databases. Each example includes detailed instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset.","url":"https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset","creator_name":"Vinay Rana","creator_url":"https://huggingface.co/VPCSinfo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","text-simplification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ImplexConv-opposed","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìö Dataset Summary\n\t\n\nImplexConv is a large-scale dataset developed to evaluate implicit reasoning in long-term, multi-session conversations.The dataset is divided into two parts:\n\nSupportive Implicit Reasoning: Contains 814 examples.\nOpposed Implicit Reasoning: Contains 1,550 examples.\n\nEach example includes approximately 100 dialogue sessions, along with multiple question-answer pairs. The dataset challenges models to track long-term dependencies and reason beyond explicit context.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kaylee0501/ImplexConv-opposed.","url":"https://huggingface.co/datasets/Kaylee0501/ImplexConv-opposed","creator_name":"Xintong Li","creator_url":"https://huggingface.co/Kaylee0501","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"Crab-RAG","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Crab RAG: Synthetic RAG Dataset\n\t\n\n\n\nThis dataset is synthetically generated using internal AI models to simulate various information retrieval and response generation tasks. It includes documents, entities, instructions, and responses, designed for use in RAG (Retrieval-Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe Crab RAG dataset is a synthetic collection aimed at facilitating the development and testing of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arzuhussein/Crab-RAG.","url":"https://huggingface.co/datasets/arzuhussein/Crab-RAG","creator_name":"Arzu Huseynov","creator_url":"https://huggingface.co/arzuhussein","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","feature-extraction","sentence-similarity","text-classification"],"keywords_longer_than_N":true},
	{"name":"NCERT_Psychology_12th","keyword":"summarization","description":"KadamParth/NCERT_Psychology_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Psychology_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_145","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trimness8/reddit_dataset_145.","url":"https://huggingface.co/datasets/Trimness8/reddit_dataset_145","creator_name":"Trimness8","creator_url":"https://huggingface.co/Trimness8","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews","keyword":"summarization","description":"Data-Scientist-lucky/Amazon_Reviews dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Data-Scientist-lucky/Amazon_Reviews","creator_name":"Dongre Laxman","creator_url":"https://huggingface.co/Data-Scientist-lucky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","translation","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_145","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trimness8/reddit_dataset_145.","url":"https://huggingface.co/datasets/Trimness8/reddit_dataset_145","creator_name":"Trimness8","creator_url":"https://huggingface.co/Trimness8","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/reddit_dataset_178.","url":"https://huggingface.co/datasets/qr12138/reddit_dataset_178","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"chinese-meme-description-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescribe image information using the following LLM Models\n\t\n\n\ngpt4o\nClaude-3.5-sonnet-20240620\ngemini-1.5-pro\ngemini-1.5-flash\ngemini-1.0-pro-vision\nyi-vision\n\n\n\t\n\t\t\n\t\tGemini Code\n\t\n\n# -*- coding: gbk -*-\nimport google.generativeai as genai\nimport PIL.Image\nimport os\nimport json\nimport shutil\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\ngenai.configure(api_key='')\nmodel = genai.GenerativeModel(\n    'gemini-1.5-pro-latest'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/REILX/chinese-meme-description-dataset.","url":"https://huggingface.co/datasets/REILX/chinese-meme-description-dataset","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/reddit_dataset_178.","url":"https://huggingface.co/datasets/qr12138/reddit_dataset_178","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/reddit_dataset_44.","url":"https://huggingface.co/datasets/veyhoranohy/reddit_dataset_44","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"summarization-yahoo-stock-finance-article-text","keyword":"summarization","description":"This is a summarization in format of key bullet points of various articles on financial stock related news from finance yahoo website.\nThe summarization model that was used here is llama3.3-70B\nThe dataset has a symbol, which is a stock that news article is related to.\n","url":"https://huggingface.co/datasets/vladlen32230/summarization-yahoo-stock-finance-article-text","creator_name":"vladlen32230","creator_url":"https://huggingface.co/vladlen32230","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_123","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_123.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_123","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"newswire","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for NewsWire\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNewsWire contains 2.7 million unique public domain U.S. news wire articles, written between 1878 and 1977. Locations in these articles are georeferenced, topics are tagged using customized neural topic classification, named entities are recognized, and individuals are disambiguated to Wikipedia using a novel entity disambiguation model.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach year in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dell-research-harvard/newswire.","url":"https://huggingface.co/datasets/dell-research-harvard/newswire","creator_name":"Dell Research Harvard","creator_url":"https://huggingface.co/dell-research-harvard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_25.","url":"https://huggingface.co/datasets/suul999922/x_dataset_25","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/reddit_dataset_44.","url":"https://huggingface.co/datasets/veyhoranohy/reddit_dataset_44","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_123","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_123.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_123","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_25","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_25.","url":"https://huggingface.co/datasets/suul999922/x_dataset_25","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"synthetic_vc_financial_decisions_reasoning_dataset","keyword":"summarization","description":"\n \n\n\nBest Curator Use Case in the Reasoning Datasets Competition: https://www.linkedin.com/feed/update/urn:li:activity:7330998995990781952/\n\n\t\n\t\t\n\t\n\t\n\t\tSynthetic VC Financial Decisions Reasoning Dataset\n\t\n\n\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Synthetic VC Financial Decisions Reasoning Dataset is a large-scale collection designed to train, evaluate, and fine-tune language models on subjective, abstract financial reasoning tasks.  It simulates venture capital (VC) workflows by capturing multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZennyKenny/synthetic_vc_financial_decisions_reasoning_dataset.","url":"https://huggingface.co/datasets/ZennyKenny/synthetic_vc_financial_decisions_reasoning_dataset","creator_name":"Kenneth Hamilton","creator_url":"https://huggingface.co/ZennyKenny","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","question-answering","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"instruct-snippet-mlsum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Instruct-Snippet-MLSUM-500\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for multitask instruction finetuning dataset for the task of news snippet generation. It is built from a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum.","url":"https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"sinhala-instruction-finetune-large","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for sinhala-instruction-finetune-large\n\t\n\nSinhala instruction finetune (SIF) dataset contains high quality question-answer pairs in Sinhala language. It is an aggregate of several Sinhala datasets in the\nHugging Face Datasets hub. SIF dataset has been compiled by transforming the datasets specified below into a common format. \n\nsinhala_eli5\nsinhala-llm-dataset-llama-prompt-format\nalpaca-sinhala\nCNN-Daily-Mail-Sinhala\ndatabricks-dolly-15k-sinhala\nSinhalaDentalQnA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihalage/sinhala-instruction-finetune-large.","url":"https://huggingface.co/datasets/ihalage/sinhala-instruction-finetune-large","creator_name":"Achintha Ihalage","creator_url":"https://huggingface.co/ihalage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Sinhala","English"],"keywords_longer_than_N":true},
	{"name":"DIDI","keyword":"summarization","description":"PeepDaSlan9/DIDI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PeepDaSlan9/DIDI","creator_name":"Ohenenoo","creator_url":"https://huggingface.co/PeepDaSlan9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_44.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_44","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"cspan-booknotes","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCSPAN Booknotes - Chat Dataset\n\t\n\nThis project develops a unique dataset from the public archives of the wonderful CSPAN program Booknotes. The dataset includes transcripts of the conversations between the show's host, Brian Lamb, and his more than 800 guests.\n\n\t\n\t\t\n\t\tDatasets\n\t\n\nThere are (3) datasets available:\n\nprograms: Information for ~809 episodes, including title, description and guest information.\ntranscripts: Full conversation transcripts (~200 turns/conversation) between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cldixon/cspan-booknotes.","url":"https://huggingface.co/datasets/cldixon/cspan-booknotes","creator_name":"CL Dixon","creator_url":"https://huggingface.co/cldixon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"polsum","keyword":"summarization","description":"Polish Summaries Corpus: the corpus of Polish news summaries.","url":"https://huggingface.co/datasets/maciej-ogrodniczuk/polsum","creator_name":"Maciej Ogrodniczuk","creator_url":"https://huggingface.co/maciej-ogrodniczuk","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"summarization","description":"ThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath,\nThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs\nwritten by journalists.","url":"https://huggingface.co/datasets/nakhun/thaisum","creator_name":"Nakhun Chumpolsathien","creator_url":"https://huggingface.co/nakhun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_44.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_44","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"polsum","keyword":"news-articles-summarization","description":"Polish Summaries Corpus: the corpus of Polish news summaries.","url":"https://huggingface.co/datasets/maciej-ogrodniczuk/polsum","creator_name":"Maciej Ogrodniczuk","creator_url":"https://huggingface.co/maciej-ogrodniczuk","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"arxivannotations","keyword":"summarization","description":"\n\t\n\t\t\nTitle\nAnnotation\nPDF\nLatex\n\n\n\t\t\nAxion bremsstrahlung from collisions of global strings\nWe calculate axion radiation emitted in the collision of two straight globalstrings. The strings are supposed to be in the unexcited ground state, to beinclined with respect to each other, and to move in parallel planes. Radiationarises when the point of minimal separation between the strings moves fasterthan light. This effect exhibits a typical Cerenkov nature. Surprisingly, itallows an alternative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dan-Kos/arxivannotations.","url":"https://huggingface.co/datasets/Dan-Kos/arxivannotations","creator_name":"Danila","creator_url":"https://huggingface.co/Dan-Kos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"us-congress-bill-policy-115_117","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for us-bills-115_117\n\t\n\nAll bills introduced to the US House and Senate congress 115, 116, and 117 (2017-2023).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes all bills introduced to the United States Congress during 2017-2023 (approx. 48k bills).\nIncluded fields: \n\nb_id: Unique string identified\ncongress: int, the congress designation\ntitle: str, the display title of the bill\nsummary: str, the earliest dated available summary of the bill‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hheiden/us-congress-bill-policy-115_117.","url":"https://huggingface.co/datasets/hheiden/us-congress-bill-policy-115_117","creator_name":"Hunter Heidenreich","creator_url":"https://huggingface.co/hheiden","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wiki_summary","keyword":"summarization","description":"\\\r\nThe dataset extracted from Persian Wikipedia into the form of articles and highlights and cleaned the dataset into pairs of articles and highlights and reduced the articles' length (only version 1.0.0) and highlights' length to a maximum of 512 and 128, respectively, suitable for parsBERT.","url":"https://huggingface.co/datasets/m3hrdadfi/wiki_summary","creator_name":"Mehrdad Farahani","creator_url":"https://huggingface.co/m3hrdadfi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","question-answering","summarization","abstractive-qa","explanation-generation"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"paraphrase-identification","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"wiki_summary","keyword":"text-simplification","description":"\\\r\nThe dataset extracted from Persian Wikipedia into the form of articles and highlights and cleaned the dataset into pairs of articles and highlights and reduced the articles' length (only version 1.0.0) and highlights' length to a maximum of 512 and 128, respectively, suitable for parsBERT.","url":"https://huggingface.co/datasets/m3hrdadfi/wiki_summary","creator_name":"Mehrdad Farahani","creator_url":"https://huggingface.co/m3hrdadfi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","question-answering","summarization","abstractive-qa","explanation-generation"],"keywords_longer_than_N":true},
	{"name":"AmericanStories","keyword":"summarization","description":"American Stories offers high-quality structured data from historical newspapers suitable for pre-training large language models to enhance the understanding of historical English and world knowledge. It can also be integrated into external databases of retrieval-augmented language models, enabling broader access to historical information, including interpretations of political events and intricate details about people's ancestors. Additionally, the structured article texts facilitate the application of transformer-based methods for popular tasks like detecting reproduced content, significantly improving accuracy compared to traditional OCR methods. American Stories serves as a substantial and valuable dataset for advancing multimodal layout analysis models and other multimodal applications.","url":"https://huggingface.co/datasets/dell-research-harvard/AmericanStories","creator_name":"Dell Research Harvard","creator_url":"https://huggingface.co/dell-research-harvard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"narrative_structures","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/moyoweke/narrative_structures.","url":"https://huggingface.co/datasets/moyoweke/narrative_structures","creator_name":"Moyosore Weke","creator_url":"https://huggingface.co/moyoweke","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","English","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"llm4security","keyword":"summarization","description":"venkycs/llm4security dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/venkycs/llm4security","creator_name":"Venky","creator_url":"https://huggingface.co/venkycs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"preference-test-sets","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPreference Test Sets\n\t\n\nVery few preference datasets have heldout test sets for validation of reward model accuracy results.\nIn this dataset, we curate the test sets from popular preference datasets into a common schema for easy loading and evaluation.\n\nAnthropic HH (Helpful & Harmless Agent and Red Teaming), test set in full is 8552 samples\nAnthropic HHH Alignment (Helpful, Honest, & Harmless), formatted from Big Bench for standalone evaluation.\nLearning to summarize, downsampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/preference-test-sets.","url":"https://huggingface.co/datasets/allenai/preference-test-sets","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"glue","keyword":"paraphrase-identification","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/severo/glue","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"SIMPITIKI","keyword":"text-simplification","description":"SIMPITIKI is a Simplification corpus for Italian and it consists of two sets of simplified pairs: the first one is harvested from the Italian Wikipedia in a semi-automatic way; the second one is manually annotated sentence-by-sentence from documents in the administrative domain.","url":"https://huggingface.co/datasets/GEM/SIMPITIKI","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-simplification","crowd-sourced","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"code-search-net-javascript","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-javascript\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in JavaScript\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"instruct-snippet-mlsum-v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Instruct-Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for multitask instruction finetuning dataset for the task of news snippet generation. It is built from a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, summary, keywords, serp and tweet for news articles in German‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2.","url":"https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"instruct-snippet-mlsum-v2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Instruct-Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for multitask instruction finetuning dataset for the task of news snippet generation. It is built from a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, summary, keywords, serp and tweet for news articles in German‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2.","url":"https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"calls_10k_v1","keyword":"summarization","description":"CICLAB-Comillas/calls_10k_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CICLAB-Comillas/calls_10k_v1","creator_name":"CICLAB Comillas ICAI","creator_url":"https://huggingface.co/CICLAB-Comillas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Spanish","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"2017-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2017 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2017 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2017-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_mean","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_mean.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"text-template-to-summarize","keyword":"summarization","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson Andr√© Pereira Eleut√©rio","creator_url":"https://huggingface.co/Anderson-Andre-P","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"code-search-net-javascript","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-javascript\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in JavaScript\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"2017-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2017 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2017 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2017-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"cochrane_sparse_oracle","keyword":"summarization","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The target field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"oracle\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_oracle.","url":"https://huggingface.co/datasets/allenai/cochrane_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"OpenOrca","keyword":"summarization","description":"üêã The OpenOrca Dataset! üêã\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/polinaeterna/OpenOrca.","url":"https://huggingface.co/datasets/polinaeterna/OpenOrca","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"research","keyword":"summarization","description":"\n\t\n\t\t\n\t\tQTSumm Dataset\n\t\n\nThe QTSumm dataset is a large-scale dataset for the task of query-focused summarization over tabular data. \nIt contains 7,111 human-annotated query-summary pairs over 2,934 tables covering diverse topics. \nTo solve this task, a text generation system has to perform human-like reasoning and analysis over the given table to generate a tailored summary. \n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{zhao2023qtsumm,\n      title={QTSumm: Query-Focused Summarization over Tabular Data}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faizalbs777/research.","url":"https://huggingface.co/datasets/faizalbs777/research","creator_name":"Faizal","creator_url":"https://huggingface.co/faizalbs777","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","table-question-answering","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs-tr","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"malhajar/orca_dpo_pairs-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca_dpo_pairs-tr is a translated version of HuggingFaceH4/orca_dpo_pairs\nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is a pre-processed version of the OpenOrca dataset translated to Turkish.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/orca_dpo_pairs-tr.","url":"https://huggingface.co/datasets/malhajar/orca_dpo_pairs-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"aya-telugu-paraphrase","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\naya-telugu-paraphrase is an open source dataset of instruct-style records generated from the Telugu split of ai4bharat/IndicXParaphrase dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Telugu Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase.","url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-aya_collection","keyword":"summarization","description":"This dataset is a translation of CohereLabs/aya_collection, an instruction dataset, using LLMic, a bilingual Romanian-English LLM.\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of prompts and completions covering a wide \nrange of tasks. This collection incorporates instruction-style templates from fluent speakers and applies them to a curated \nlist of datasets, as well as translations of instruction-style datasets into 101 languages.\n\nOnly the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/ro-aya_collection.","url":"https://huggingface.co/datasets/faur-ai/ro-aya_collection","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Romanian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Liposome-RBC_Interaction_Fulltext_Screening_Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüî¨ Liposome-RBC Interaction Fulltext Screening Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains comprehensive fulltext screening results from a PRISMA scoping review investigating liposome and red blood cell (RBC) interactions. It includes 449 papers that underwent detailed AI assisted (Claude 3.7) review, with structured extraction of research gaps, variables, techniques, and findings. All sections are supported by direct verbatim quotes from the paper being analyzed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Interaction_Fulltext_Screening_Dataset.","url":"https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Interaction_Fulltext_Screening_Dataset","creator_name":"Austin Routt","creator_url":"https://huggingface.co/UtopiansRareTruth","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"big_patent_sample","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSampled big_patent Dataset\n\t\n\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters in length, making the dataset good for training on lengths up to 250,000 tokens.\n\n\t\n\t\t\n\t\tDataset Card for Big Patent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_sample.","url":"https://huggingface.co/datasets/Trelis/big_patent_sample","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","found","monolingual","big_patent"],"keywords_longer_than_N":true},
	{"name":"moody_data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fmeleard/moody_data.","url":"https://huggingface.co/datasets/fmeleard/moody_data","creator_name":"Meleard","creator_url":"https://huggingface.co/fmeleard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","French","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"elsevier-oa-cc-by","keyword":"summarization","description":"Elsevier OA CC-By is a corpus of 40k (40, 091) open access (OA) CC-BY articles\nfrom across Elsevier‚Äôs journals and include the full text of the article, the metadata,\nthe bibliographic information for each reference, and author highlights.","url":"https://huggingface.co/datasets/orieg/elsevier-oa-cc-by","creator_name":"Nicolas Brousse","creator_url":"https://huggingface.co/orieg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","summarization","text-classification","masked-language-modeling","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"elsevier-oa-cc-by","keyword":"news-articles-summarization","description":"Elsevier OA CC-By is a corpus of 40k (40, 091) open access (OA) CC-BY articles\nfrom across Elsevier‚Äôs journals and include the full text of the article, the metadata,\nthe bibliographic information for each reference, and author highlights.","url":"https://huggingface.co/datasets/orieg/elsevier-oa-cc-by","creator_name":"Nicolas Brousse","creator_url":"https://huggingface.co/orieg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","summarization","text-classification","masked-language-modeling","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"gov_report","keyword":"summarization","description":"GovReport long document summarization dataset.\n\nThere are three configs:\n  - plain_text: plain text document-to-summary pairs\n  - plain_text_with_recommendations: plain text doucment-summary pairs, with \"What GAO recommends\" included in the summary\n  - structure: data with section structure","url":"https://huggingface.co/datasets/launch/gov_report","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"constitucion-politica-del-peru-1993-qa","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCompuesto por unos 2075 registros que contienen los campos:\n\npregunta: pregunta que sirve como una instrucci√≥n o consulta sobre alg√∫n aspecto de la Constituci√≥n Pol√≠tica del Per√∫ de 1993.\nrespuesta: La respuesta proporcionada para cada pregunta es un contexto relevante que ayuda a resolver la consulta. Este contexto es un extracto de la Constituci√≥n.\nfuente: Para cada respuesta, se indica el cap√≠tulo y/o art√≠culo de la Constituci√≥n Pol√≠tica del Per√∫ de 1993‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/daqc/constitucion-politica-del-peru-1993-qa.","url":"https://huggingface.co/datasets/daqc/constitucion-politica-del-peru-1993-qa","creator_name":"David Quispe","creator_url":"https://huggingface.co/daqc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Multilingual-BioASQ-6B","keyword":"summarization","description":"\n    \n    \n    Mutilingual BioASQ-6B\n    \n\n\nWe translate the BioASQ-6B English Question Answering dataset to generate parallel French, Italian and Spanish versions using the NLLB200 3B parameter model. For more info read the original task description: [http://bioasq.org/participate/challenges_year_6](http://bioasq.org/participate/challenges_year_6)\n\nWe translate the body, snippets, ideal_answer and exact_answer fields. We have validated the quality of the ideal_answer field, however, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B.","url":"https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"ChatGPT_tweets","keyword":"summarization","description":"Dataset sourced from Twitter, featuring 30,000 rows of multilingual user feedback tweets about ChatGPT. Each row contains text feedback, reflecting diverse user experiences. This dataset, hosted on Hugging Face, provides valuable resources for language analysis and understanding user interactions across different languages. Potential use cases include language modeling, multilingual sentiment analysis, user behavior analysis, and training of machine learning models for natural language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MouezYazidi/ChatGPT_tweets.","url":"https://huggingface.co/datasets/MouezYazidi/ChatGPT_tweets","creator_name":"Mouez Yazidi","creator_url":"https://huggingface.co/MouezYazidi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ursum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUrdu Summarization\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Urdu Summarization dataset contains news articles in Urdu language along with their summaries. The dataset contains a total of 48,071 news articles collected from the BBC Urdu website. Each article is labeled with its headline, summary, and full text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset contains the following columns:\n\nid (string): Unique identifier for each article\nurl (string): URL for the original article\ntitle (string):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mahwizzzz/ursum.","url":"https://huggingface.co/datasets/mahwizzzz/ursum","creator_name":"Mahwiz Khalil","creator_url":"https://huggingface.co/mahwizzzz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vietnews","keyword":"summarization","description":"harouzie/vietnews dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/harouzie/vietnews","creator_name":"ƒê·ªó Ph·∫°m Quang H∆∞ng","creator_url":"https://huggingface.co/harouzie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Vietnamese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"pmc_open_access_xml","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for PMC Open Access XML\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe XML Open Access includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TomTBT/pmc_open_access_xml.","url":"https://huggingface.co/datasets/TomTBT/pmc_open_access_xml","creator_name":"Tom Boissonnet","creator_url":"https://huggingface.co/TomTBT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","other","no-annotation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"CricketData","keyword":"summarization","description":"Valarmathy/CricketData dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Valarmathy/CricketData","creator_name":"Valarmathy Babu","creator_url":"https://huggingface.co/Valarmathy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","table-question-answering","zero-shot-classification","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Onion_News","keyword":"summarization","description":"\n\t\n\t\t\n\t\tThis is a dataset of Onion news articles:\n\t\n\nNote\n\nThe headers and body of the news article is split by a ' #~# ' token\nLines with just the token had no body or no header and can be skipped\nFeel free to use the script provided to scape the latest version, it takes about 30 mins on an i7-6850K\n\n","url":"https://huggingface.co/datasets/Biddls/Onion_News","creator_name":"Thomas Biddlecombe","creator_url":"https://huggingface.co/Biddls","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"tldr-17","keyword":"summarization","description":"This corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.","url":"https://huggingface.co/datasets/webis/tldr-17","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","no-annotation","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"XSUMUrdu-DW_BBC","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUrdu_DW-BBC-512\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nUrdu Summarization Dataset containining 76,637 records of Article + Summary pairs scrapped from BBC Urdu and DW Urdu News Websites.\nPreprocessed Version: upto 512 tokens (~words); removed URLs, Pic Captions etc\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSummarization: Extractive and Abstractive\n\nurT5 adapted from mT5 having monolingual vocabulary only; 40k tokens of Urdu.\nFine-tuned version @‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mbshr/XSUMUrdu-DW_BBC.","url":"https://huggingface.co/datasets/mbshr/XSUMUrdu-DW_BBC","creator_name":"Mubashir","creator_url":"https://huggingface.co/mbshr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Urdu","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"XSUMUrdu-DW_BBC","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUrdu_DW-BBC-512\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nUrdu Summarization Dataset containining 76,637 records of Article + Summary pairs scrapped from BBC Urdu and DW Urdu News Websites.\nPreprocessed Version: upto 512 tokens (~words); removed URLs, Pic Captions etc\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSummarization: Extractive and Abstractive\n\nurT5 adapted from mT5 having monolingual vocabulary only; 40k tokens of Urdu.\nFine-tuned version @‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mbshr/XSUMUrdu-DW_BBC.","url":"https://huggingface.co/datasets/mbshr/XSUMUrdu-DW_BBC","creator_name":"Mubashir","creator_url":"https://huggingface.co/mbshr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Urdu","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"rudialogsum_v2","keyword":"summarization","description":"–î–∞—Ç–∞—Å–µ—Ç dialogsum –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ì–ª—é–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —á–∏—Å—Ç–∫–æ–π\n","url":"https://huggingface.co/datasets/rcp-meetings/rudialogsum_v2","creator_name":"RCP Meetings","creator_url":"https://huggingface.co/rcp-meetings","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"code-search-net-php","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-php\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Php\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"code-search-net-java","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-java\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Java\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sumstew","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"sumstew\"\n\t\n\n\n\t\n\t\t\n\t\tTL;DR:\n\t\n\nSumstew is a abstractive, multilingual Dataset, with a balanced number of samples from a diverse set of summarization Datasets. The input sizes range up to 16384 tokens.\nFiltered using a diverse set of heuristics to encourage high coverage, accuracy and factual consistency. Code to reproduce Dataset available at TODO\n\n\t\n\t\t\n\t\tTask Information\n\t\n\n\nTask Categories: The tasks covered by this dataset are primarily summarization tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Joemgu/sumstew.","url":"https://huggingface.co/datasets/Joemgu/sumstew","creator_name":"Jonas","creator_url":"https://huggingface.co/Joemgu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"chatgpt-paraphrases-simple","keyword":"paraphrase","description":"This dataset is simplified version of ChatGPT Paraphrases. And aims to take away the pain of expanding original dataset into unique paraphrase pairs.\n\n\t\n\t\t\n\t\tStructure:\n\t\n\nDataset is not divided into train/test split. And contains 6.3 million unique paraphrases(6x5x420000/2 = 6.3 million). Dataset contains following 2 columns-\n\ns1 - Sentence\ns2 - Paraphrase\n\nOriginal Dataset Structure:\nThe original dataset has following 4 columns-\n\ntext - 420k Unique sentence\nparaphrases - List of 5 unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sharad/chatgpt-paraphrases-simple.","url":"https://huggingface.co/datasets/sharad/chatgpt-paraphrases-simple","creator_name":"Sharad Ranjan","creator_url":"https://huggingface.co/sharad","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"code-search-net-php","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-php\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Php\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"code-search-net-java","keyword":"summary","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-java\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Java\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Hindi-Niband","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Name: Hindi- Niband (Massive Hindi language Text Dataset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset is a comprehensive collection of text data consisting of more than 10 billion tokens. It encompasses a wide range of sources, including Wikipedia articles, news articles, email transcripts, and generated prompt text. Specific Hindi language data columns have been extracted from the CulturaX dataset, which is a large, cleaned, and multilingual dataset for large language models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband.","url":"https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband","creator_name":"ThinkEdge AI lAB","creator_url":"https://huggingface.co/thinkedgeAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"customer_service_summarization","keyword":"summarization","description":"jonathansuru/customer_service_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jonathansuru/customer_service_summarization","creator_name":"Jonathan Suru","creator_url":"https://huggingface.co/jonathansuru","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"FrenchEmotionalNarratives","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFrench Emotional Narratives\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrench Emotional Narratives is a French-language corpus of emotional narratives collected for emotion regulation training and annotated by the writers themselves with a discrete emotion plus four psychologically motivated components: Behavior, Feeling, Thinking, and Reason.\nThe dataset is linked to the paper Emotion Recognition based on Psychological Components in Guided Narratives for Emotion Regulation, which introduced the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gustavecortal/FrenchEmotionalNarratives.","url":"https://huggingface.co/datasets/gustavecortal/FrenchEmotionalNarratives","creator_name":"Gustave Cortal","creator_url":"https://huggingface.co/gustavecortal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","translation","summarization","French"],"keywords_longer_than_N":true},
	{"name":"youtube_scripts","keyword":"summarization","description":"This dataset collected from various sources,\nOnce I obtained the urls for youtube videos, I used langchain with YoutubeLoader function to get text of videos.\nSource of data: https://github.com/talesmarra/youtube_data_analysis\ntasks: summarization, named entity recognition,\n","url":"https://huggingface.co/datasets/umarigan/youtube_scripts","creator_name":"umar igan","creator_url":"https://huggingface.co/umarigan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","summarization","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"genai_dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samyakmohelay/genai_dataset.","url":"https://huggingface.co/datasets/samyakmohelay/genai_dataset","creator_name":"Samyak Mohelay","creator_url":"https://huggingface.co/samyakmohelay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"err-newsroom-keyphrases","keyword":"summarization","description":"\n\t\n\t\t\n\t\tERR Newsroom Keyphrases\n\t\n\nThis dataset is a subset of ERR Newsroom, with up to 5 keyphrases assigned to each news article. The keyphrases are generated using the OpenAI API, using the gpt-3.5-turbo model (see the script extract-keywords-openai.py).\n","url":"https://huggingface.co/datasets/TalTechNLP/err-newsroom-keyphrases","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Estonian","cc-by-4.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"genai_dataset","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samyakmohelay/genai_dataset.","url":"https://huggingface.co/datasets/samyakmohelay/genai_dataset","creator_name":"Samyak Mohelay","creator_url":"https://huggingface.co/samyakmohelay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"KenithZ-dolly-zh-51k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDolly‰∏≠ÊñáËÆ≠ÁªÉÈõÜ\n\t\n\nÂü∫‰∫éChinese-LLaMA-AlpacaÁöÑËΩ¨Êç¢ÊàêÁöÑdollyÊï∞ÊçÆÈõÜ\n\n\t\n\t\t\n\t\tÈúÄË¶ÅÂÅöÁöÑ‰∫ãÊÉÖ\n\t\n\n\nÂ∞Üalpaca_data_zh_51k.jsonÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫databricks-dolly-15k.jsonlÊï∞ÊçÆÈõÜÁöÑÊ†ºÂºè\nËΩ¨Êç¢ÂêéÁöÑÊï∞ÊçÆÈõÜÈõÜÈúÄË¶ÅÊâãÂä®Ë°•ÂÖÖcategoryÔºàÊ≠£Âú®ËøõË°åÔºâ\n‰øÆÊ≠£Âéü‰ΩúËÄÖ‰ªéchatGPTÁà¨ÂèñÁöÑËØ≠‰πâ‰∏çÈÄöÊàñÊï∞ÊçÆÈîôËØØÁöÑÊåá‰ª§Êï∞ÊçÆÔºàÊ≠£Âú®ËøõË°åÔºâ\n\n","url":"https://huggingface.co/datasets/KenithZ/KenithZ-dolly-zh-51k","creator_name":"Kenith-Zhang","creator_url":"https://huggingface.co/KenithZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Chinese","English","mit"],"keywords_longer_than_N":true},
	{"name":"baby-ordalie","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"baby_ordalie\"\n\t\n\n-----> C'est kdo \nMore Information needed\n","url":"https://huggingface.co/datasets/OrdalieTech/baby-ordalie","creator_name":"Ordalie Technologies","creator_url":"https://huggingface.co/OrdalieTech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","French","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des pensions de retraite des marins fran√ßais du commerce, de p√™che ou de plaisance, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ms2_sparse_mean","keyword":"summarization","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\n\nquery: The background field of each example\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\nretriever: BM25 via PyTerrier with default settings\ntop-k strategy: \"mean\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_mean.","url":"https://huggingface.co/datasets/allenai/ms2_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","expert-generated","expert-generated","monolingual","extended|other-MS^2"],"keywords_longer_than_N":true},
	{"name":"multi_lexsum","keyword":"summarization","description":"Multi-LexSum is a multi-doc summarization dataset for civil rights litigation lawsuits with summaries of three granularities.","url":"https://huggingface.co/datasets/allenai/multi_lexsum","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gigaword_swe","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Swedish Gigaword Dataset\n\t\n\nThe Swedish gigaword dataset has only been machine-translated to improve downstream fine-tuning on Swedish summarization tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRead about the full details at original English version: https://huggingface.co/datasets/gigaword\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ndocument: a string containing the shorter body\nsummary: a string containing the summary of the body\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe Swedish gigaword dataset follows the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gabriel/gigaword_swe.","url":"https://huggingface.co/datasets/Gabriel/gigaword_swe","creator_name":"Gabriel Borg","creator_url":"https://huggingface.co/Gabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","https://github.com/huggingface/datasets/tree/master/datasets/gigaword","Swedish","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"scientific_lay_summarisation-elife-norm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tscientific_lay_summarisation - elife - normalized\n\t\n\nThis is the \"elife\" split. For more words, refer to the PLOS split README\n\n\t\n\t\t\n\t\tContents\n\t\n\nload with datasets:\nfrom datasets import load_dataset\n\n# If the dataset is gated/private, make sure you have run huggingface-cli login\ndataset = load_dataset(\"pszemraj/scientific_lay_summarisation-elife-norm\")\ndataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['article', 'summary', 'section_headings', 'keywords', 'year'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/scientific_lay_summarisation-elife-norm.","url":"https://huggingface.co/datasets/pszemraj/scientific_lay_summarisation-elife-norm","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","tomasg25/scientific_lay_summarisation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"scientific_lay_summarisation-plos-norm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tscientific_lay_summarisation - PLOS - normalized\n\t\n\nThis dataset is a modified version of tomasg25/scientific_lay_summarization and contains scientific lay summaries that have been preprocessed with this code. The preprocessing includes fixing punctuation and whitespace problems, and calculating the token length of each text sample using a tokenizer from the T5 model.\nOriginal dataset details:\n\nRepository: https://github.com/TGoldsack1/Corpora_for_Lay_Summarisation\nPaper: Making‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/scientific_lay_summarisation-plos-norm.","url":"https://huggingface.co/datasets/pszemraj/scientific_lay_summarisation-plos-norm","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","tomasg25/scientific_lay_summarisation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"longform_article_summarization","keyword":"summarization","description":"Dataset Name: Long-Form Article Summarization Dataset\nDescription:\nThe Long-Form Article Summarization Dataset is meticulously curated for the purpose of fine-tuning Natural Language Processing (NLP) models specifically tailored for summarization tasks. It is a rich collection of long-form articles that have been carefully condensed and summarized. The dataset provides a diverse range of topics and writing styles, making it an invaluable resource for researchers and practitioners working on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgoldberg/longform_article_summarization.","url":"https://huggingface.co/datasets/vgoldberg/longform_article_summarization","creator_name":"Vincent Goldberg","creator_url":"https://huggingface.co/vgoldberg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"DebateSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDebateSum\n\t\n\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \"DebateSum: A large-scale argument mining and summarization dataset\"\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\nVideo of presentation at COLING 2020:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum.","url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-retrieval","text-generation","abstractive-qa"],"keywords_longer_than_N":true},
	{"name":"wikipedia_summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: The dataset is currently not publicly available but can be accessed upon request for academic or research purposes.\n\nPaper : Details about the dataset generation process and initial benchmarks are described in the working paper: \"AI-Generated Summaries of Chinese Wikipedia Articles: A New Dataset for NLP Research\", Zhang Xin et al., Beihang University.\n\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\nDirect Use: Suitable for training and evaluating models on text summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xinzhang/wikipedia_summary.","url":"https://huggingface.co/datasets/xinzhang/wikipedia_summary","creator_name":"xin zhang","creator_url":"https://huggingface.co/xinzhang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"anti-haystack","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"anti-haystack\"\n\t\n\nThis dataset contains samples that resemble the \"Needle in a haystack\" pressure testing. It can be helpful if you want to make your LLM better at finding/locating short facts from long documents.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach sample has the following fields:\n\ndocument: A long and noisy reference document which can be a story, code, book, or manual in both English and Chinese (10%).\n\nquestion: A question generated with GPT-4. The answer can always be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/anti-haystack.","url":"https://huggingface.co/datasets/wenbopan/anti-haystack","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"FNS_Summarization","keyword":"summarization","description":"ragha92/FNS_Summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ragha92/FNS_Summarization","creator_name":"Raghasai K","creator_url":"https://huggingface.co/ragha92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"curation-corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcuration-corpus\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nData from this official repo with downloaded news articles content.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{curationcorpusbase:2020,\n  title={Curation Corpus Base},\n  author={Curation},\n  year={2020}\n}\n\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"curation-corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tcuration-corpus\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nData from this official repo with downloaded news articles content.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{curationcorpusbase:2020,\n  title={Curation Corpus Base},\n  author={Curation},\n  year={2020}\n}\n\n","url":"https://huggingface.co/datasets/d0rj/curation-corpus","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"flan2021-full","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTask Name\n\t\n\n\nFLAN-2021 -> 70\n\n{\n  \"ag_news_subset\": 108497,\n  \"ai2_arc/ARC-Challenge\": 829,\n  \"ai2_arc/ARC-Easy\": 1927,\n  \"aeslc\": 13187,\n  \"anli/r1\": 15361,\n  \"anli/r2\": 41133,\n  \"anli/r3\": 91048, \n  \"bool_q\": 8343,\n  \"cnn_dailymail\": 259607,\n  \"coqa\": 6456,\n  \"cosmos_qa\": 22996,\n  \"definite_pronoun_resolution\": 1079,\n  \"drop\": 70045,\n  \"fix_punct\": 25690,\n  \"gem/common_gen\": 60936,\n  \"gem/dart\": 56724,\n  \"gem/e2e_nlg\": 30337,\n  \"gem/web_nlg_en\": 31899‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslawliet/flan2021-full.","url":"https://huggingface.co/datasets/aslawliet/flan2021-full","creator_name":"Lawliet","creator_url":"https://huggingface.co/aslawliet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"nanomind_1m","keyword":"summarization","description":"\n\t\n\t\t\n\t\tNanomind 1M Pretraining Dataset\n\t\n\nA filtered and processed dataset for language model pretraining, containing 262,227 documents derived from web text and educational sources.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDocuments: 262,227\nLanguage: English\nFormat: JSONL with text field\nSize: 143 MB compressed\n\n\n\t\n\t\t\n\t\tSource Datasets\n\t\n\nDerived from:\n\nnampdn-ai/tiny-webtext (MIT License)\nnampdn-ai/tiny-textbooks (Apache-2.0 License)\n\n\n\t\n\t\t\n\t\tProcessing\n\t\n\nCreated using  with the following filters:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ethanker/nanomind_1m.","url":"https://huggingface.co/datasets/ethanker/nanomind_1m","creator_name":"Ethan KERDELHUE","creator_url":"https://huggingface.co/ethanker","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","text-classification","token-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"Goud-Sum-Instruct","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Goud-Sum-Instruct\n\t\n\nGoud-Sum-Instruct is a meticulously curated dataset originating from Goud-sum dataset, This dataset is primed for fine-tuning chat and instruct models, without any compromise to the existing training mode. This strategic approach enables the specific training of models to respond effectively to the main instruction which is \"To Summarise\". In conclusion, this dataset is meant to finetune a chat model in order to serve later as a summarizer.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct.","url":"https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct","creator_name":"Ali El Filali","creator_url":"https://huggingface.co/alielfilali01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"SlimOrca","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a new curated subset of our OpenOrca data. This release provides an efficient means of reaching performance on-par with using larger slices of our data, while only including ~500k GPT-4 completions.\nThe key change in this dataset is that we've done an additional pass, using GPT-4 to remove answers which appear wrong based on the human annotations from the FLAN dataset.\nThis reduces the dataset size to only ~500k entries, allowing training to a similar quality level‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/SlimOrca.","url":"https://huggingface.co/datasets/Open-Orca/SlimOrca","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Long-Term-Care-Aggregated-Data","keyword":"summarization","description":"\n\t\n\t\t\n\t\tProject 1 Proposal of the Long Term Care(LTC) Aggregated Dataset\n\t\n\nKAO, HSUAN-CHEN(Justin)   \nNetID: hk310\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe long-term care aggregated dataset, essential for conducting experience studies, is an extensive and valuable compilation of variables central to the analysis and prediction of long-term care (LTC) insurance products. This dataset integrates two critical files: one detailing claim incidence and the other capturing policy terminations. This merger is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mastergopote44/Long-Term-Care-Aggregated-Data.","url":"https://huggingface.co/datasets/mastergopote44/Long-Term-Care-Aggregated-Data","creator_name":"Justin Kao","creator_url":"https://huggingface.co/mastergopote44","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"sci_lay","keyword":"summarization","description":"SCILAY comprises 43,790 instances, each representing a scientific article in the biomedical domain. \nEach instance in the dataset includes the following components:\n    - plain_text: Containing a plain language summary of the scientific article. This section is written in a simple and accessible language, and is intended to be understandable by a wide audience.\n    - technical_text: This section contains the abstract of the scientific article. It provides a detailed and technical description of the research conducted in the article.\n    - full_text: This section contains the complete article of the scientific research.\nIn addition to the textual content, each instance is associated with the following metadata:\n    - Keywords: Keywords that capture the main topics and themes addressed in the article.\n    - Journal: The journal in which the article is published, providing context about the source of the research.\n    - DOI (Digital Object Identifier): A unique identifier for the article, facilitating easy referencing.\nThe main objective of the SCILAY dataset is to support the development and evaluation of text summarization models that can effectively simplify complex scientific language while retaining the essential information.","url":"https://huggingface.co/datasets/paniniDot/sci_lay","creator_name":"Mattia Panni","creator_url":"https://huggingface.co/paniniDot","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","original","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"MevakerSumm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMevakerSumm\n\t\n\nAbstractive summarization dataset for long documents.\n\n\t\n\t\t\n\t\tCiting\n\t\n\nIf you use MevakerSumm in your research, please cite Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language.\n@article{shalumov2024mevaker,\n      title={Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language}, \n      author={Vitaly Shalumov and Harel Haskey and Yuval Solaz},\n      year={2024},\n      eprint={2403.09719},\n      archivePrefix={arXiv}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HeTree/MevakerSumm.","url":"https://huggingface.co/datasets/HeTree/MevakerSumm","creator_name":"HeTree","creator_url":"https://huggingface.co/HeTree","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Hebrew","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"stacked-xsum-1024","keyword":"summarization","description":"\n\t\n\t\t\n\t\tstacked-xsum-1024\n\t\n\na \"stacked\" version of xsum \n\nOriginal Dataset: copy of the base dataset\n\nStacked Rows: The original dataset is processed by stacking rows based on certain criteria:\n\nMaximum Input Length: The maximum length for input sequences is 1024 tokens in the longt5 model tokenizer.\nMaximum Output Length: The maximum length for output sequences is also 1024 tokens in the longt5 model tokenizer.\n\n\nSpecial Token: The dataset utilizes the [NEXT_CONCEPT] token to indicate a new‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stacked-summaries/stacked-xsum-1024.","url":"https://huggingface.co/datasets/stacked-summaries/stacked-xsum-1024","creator_name":"Stacked Summaries","creator_url":"https://huggingface.co/stacked-summaries","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","xsum","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"summarization","description":"Ezell/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ezell/test","creator_name":"Ezel","creator_url":"https://huggingface.co/Ezell","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","summarization","Abkhaz","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"ru-paraphrase-NMT-Leipzig","keyword":"paraphrase","description":"\n\t\n\t\t\n\t\tDataset Card for cointegrated/ru-paraphrase-NMT-Leipzig\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains 1 million Russian sentences and their automatically generated paraphrases. \nIt was created by David Dale (@cointegrated) by translating the rus-ru_web-public_2019_1M corpus from the Leipzig collection into English and back into Russian. A fraction of the resulting paraphrases are invalid, and should be filtered out.\nThe blogpost \"–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: –∫–æ—Ä–ø—É—Å–∞, –º–æ–¥–µ–ª–∏‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/ru-paraphrase-NMT-Leipzig.","url":"https://huggingface.co/datasets/cointegrated/ru-paraphrase-NMT-Leipzig","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","no-annotation","machine-generated","translation","extended|other"],"keywords_longer_than_N":true},
	{"name":"LongSumEt","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"LongSumEt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLongSumEt is an estonian language long summarization dataset with pages filtered from CulturaX dataset. The dataset consists of the page text, and machine generated short summary, long summary and bulletpoints.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEstonian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nMore Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/LongSumEt.","url":"https://huggingface.co/datasets/TalTechNLP/LongSumEt","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","machine-generated","monolingual","original","Estonian"],"keywords_longer_than_N":true},
	{"name":"arxivlay-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization\n\t\n\nA collaboration between reciTAL, MLIA (ISIR, Sorbonne Universit√©), Meta AI, and Universit√† di Trento\n\n\t\n\t\t\n\t\n\t\n\t\tArxiv-Lay dataset for summarization\n\t\n\nArXiv-Lay is an enhanced version of the arXiv summarization dataset, for which layout information is provided.\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\narticle_id: article id\narticle_words: sequence of words constituting the body of the article‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nglaura/arxivlay-summarization.","url":"https://huggingface.co/datasets/nglaura/arxivlay-summarization","creator_name":"Laura Nguyen","creator_url":"https://huggingface.co/nglaura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","Text","arxiv:2301.11312"],"keywords_longer_than_N":true},
	{"name":"PeerSum","keyword":"summarization","description":"This is PeerSum, a multi-document summarization dataset in the peer-review domain. More details can be found in the paper accepted at EMNLP 2023, Summarizing Multiple Documents with Conversational Structure for Meta-review Generation. The original code and datasets are public on GitHub.\nPlease use the following code to download the dataset with the datasets library from Huggingface.\nfrom datasets import load_dataset\npeersum_all = load_dataset('oaimli/PeerSum', split='all')\npeersum_train =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oaimli/PeerSum.","url":"https://huggingface.co/datasets/oaimli/PeerSum","creator_name":"Miao Li","creator_url":"https://huggingface.co/oaimli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"govreport-summarization-8192","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGovReport Summarization - 8192 tokens\n\t\n\n\nccdv/govreport-summarization with the changes of:\ndata cleaned with the clean-text python package\ntotal tokens for each column computed and added in new columns according to the long-t5 tokenizer (done after cleaning)\n\n\n\n\n\n\t\n\t\t\n\t\ttrain info\n\t\n\nRangeIndex: 8200 entries, 0 to 8199\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   report             8200 non-null‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/govreport-summarization-8192.","url":"https://huggingface.co/datasets/pszemraj/govreport-summarization-8192","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","ccdv/govreport-summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-ru","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOpenOrca-ru\n\t\n\nThis is translated version of Open-Orca/OpenOrca into Russian.\n","url":"https://huggingface.co/datasets/d0rj/OpenOrca-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"QA2D","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tDataset Card for QA2D\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we show‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D.","url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-simplification","machine-generated","crowdsourced","found","machine-generated"],"keywords_longer_than_N":true},
	{"name":"naver-news-summarization-ko","keyword":"summarization","description":"This dataset is a custom dataset created by the author by crawling Naver News (https://news.naver.com) for the Korean NLP model hands-on.\n\nPeriod: July 1, 2022 - July 10, 2022\nSubject: IT, economics\n\nDatasetDict({\n    train: Dataset({\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n        num_rows: 22194\n    })\n    test: Dataset({\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n        num_rows: 2740\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko.","url":"https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko","creator_name":"Daekeun Kim","creator_url":"https://huggingface.co/daekeun-ml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"paper_persi_chat","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPaperPersiChat Dataset\n\t\n\nDataset for paper PaperPersiChat: Scientific Paper Discussion Chatbot using Transformers and Discourse Flow Management\n\n\t\n\t\t\n\t\tDataset creation\n\t\n\nTo construct the dataset, we used the part of Semantic Scholar Open Research Corpus [https://github.com/allenai/s2orc] as the main source of scientific publications, namely the Computer Science section. We constructed dialogues over the segments of the papers where each segment consists of a combination of several‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai-forever/paper_persi_chat.","url":"https://huggingface.co/datasets/ai-forever/paper_persi_chat","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"summarization-preferences","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummarization Preferences Dataset\n\t\n\nThis is a processed subset of the openai/summarize_from_feedback comparisons subset, including training and validation splits.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe original dataset consists of paired human comparisons between summary candidates for given source texts. This processed version aggregates all comparisons per unique text to determine the overall best (chosen) and worst (rejected) summaries using the Bradley-Terry model.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\ntext:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/summarization-preferences.","url":"https://huggingface.co/datasets/agentlans/summarization-preferences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-ranking","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Alpaca-cnn-dailymail","keyword":"summarization","description":"\n\t\n\t\t\n\t\tData Summary\n\t\n\nData set Alpaca-cnn-dailymail is a data set version format changed by ccdv/cnn_dailymail to meet Alpaca fine-tuning Llama2. Only versions 3.0.0 and 2.0.0 were used for merging and as a key data set for the summary extraction task.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe Alpaca-cnn-dailymail dataset version 1.0.0 is released under the Apache-2.0 License.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{see-etal-2017-get,\n    title = \"Get To The Point: Summarization with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail.","url":"https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail","creator_name":"Zhongsheng Wang","creator_url":"https://huggingface.co/ZhongshengWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"summarization-preferences","keyword":"summary","description":"\n\t\n\t\t\n\t\tSummarization Preferences Dataset\n\t\n\nThis is a processed subset of the openai/summarize_from_feedback comparisons subset, including training and validation splits.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe original dataset consists of paired human comparisons between summary candidates for given source texts. This processed version aggregates all comparisons per unique text to determine the overall best (chosen) and worst (rejected) summaries using the Bradley-Terry model.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\ntext:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/summarization-preferences.","url":"https://huggingface.co/datasets/agentlans/summarization-preferences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-ranking","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"matreshka","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"matreshka\"\n\t\n\n\n(image generated by Kandinsky-2.1 neural network)\nRussian dialogues, the persona of the first interlocutor, and a summary of the dialogue generated by GPT-3.5, starting with the first phrase given in the prompt.\nThe matreshka dataset is a multi task datasey, you can use it for the task of summarizing a dialogue or generating a dialogue. Contains life dialogues and is also filled with facts about the world. The dataset was going to give the interlocutor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zjkarina/matreshka.","url":"https://huggingface.co/datasets/zjkarina/matreshka","creator_name":"Karina Romanova","creator_url":"https://huggingface.co/zjkarina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Russian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"code-penitentiaire","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode p√©nitentiaire, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode des pensions militaires d'invalidit√© et des victimes de guerre, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Chinese","keyword":"summarization","description":"üêã OpenOrca-Chinese Êï∞ÊçÆÈõÜÔºÅüêã\n\nÊÑüË∞¢  Open-Orca/OpenOrca  Êï∞ÊçÆÈõÜÁöÑÂèëÂ∏ÉÔºåÁªôÂπøÂ§ßNLPÁ†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖÂ∏¶Êù•‰∫ÜÂÆùË¥µÁöÑËµÑÊ∫êÔºÅ  \nËøôÊòØ‰∏Ä‰∏™ÂØπ  Open-Orca/OpenOrca  Êï∞ÊçÆÈõÜ‰∏≠ÊñáÁøªËØëÁöÑÁâàÊú¨ÔºåÁøªËØëÂºïÊìé‰∏∫ Google ÁøªËØëÔºåÂ∏åÊúõËÉΩÁªô‰∏≠Êñá LLM Á†îÁ©∂ÂÅöÂá∫‰∏ÄÁÇπÁÇπË¥°ÁåÆ„ÄÇ\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yys/OpenOrca-Chinese.","url":"https://huggingface.co/datasets/yys/OpenOrca-Chinese","creator_name":"yanyusong","creator_url":"https://huggingface.co/yys","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"XLSum-nepali-summerization-dataset","keyword":"summarization","description":"sanjeev-bhandari01/XLSum-nepali-summerization-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjeev-bhandari01/XLSum-nepali-summerization-dataset","creator_name":"Sanjeev Bhandari","creator_url":"https://huggingface.co/sanjeev-bhandari01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Nepali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PongSawaML","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPongSawaML\n\t\n\nPongsawaM(L) is a Thai annal Ayutthaya, Thonburi, and Rattakosin (Rama I). This annal writed by Dan Beach Bradley an American Protestant missionary\n","url":"https://huggingface.co/datasets/Copninixh/PongSawaML","creator_name":"Copninixh","creator_url":"https://huggingface.co/Copninixh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Thai","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"aiera-ect-sum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAiera Earnings Call Summarization\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset provides a collection of earnings call transcripts along with their corresponding summaries. The transcript column contains the full text of earnings call transcripts provided by Aiera, while the summary column offers concise, high-quality summaries. These summaries distill key information related to financial performance, operational highlights, guidance and projections, strategic initiatives, market competition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aiera/aiera-ect-sum.","url":"https://huggingface.co/datasets/Aiera/aiera-ect-sum","creator_name":"Aiera, Inc.","creator_url":"https://huggingface.co/Aiera","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"aiera-ect-sum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAiera Earnings Call Summarization\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset provides a collection of earnings call transcripts along with their corresponding summaries. The transcript column contains the full text of earnings call transcripts provided by Aiera, while the summary column offers concise, high-quality summaries. These summaries distill key information related to financial performance, operational highlights, guidance and projections, strategic initiatives, market competition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aiera/aiera-ect-sum.","url":"https://huggingface.co/datasets/Aiera/aiera-ect-sum","creator_name":"Aiera, Inc.","creator_url":"https://huggingface.co/Aiera","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"GLINER-multi-task-synthetic-data","keyword":"summarization","description":"This is official synthetic dataset used to train GLiNER multi-task model.\nThe dataset is a list of dictionaries consisting a tokenized text with named entity recognition (NER) information. Each item represents of two main components:\n\n'tokenized_text': A list of individual words and punctuation marks from the original text, split into tokens.\n\n'ner': A list of lists containing named entity recognition information. Each inner list has three elements:\n\nStart index of the named entity in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knowledgator/GLINER-multi-task-synthetic-data.","url":"https://huggingface.co/datasets/knowledgator/GLINER-multi-task-synthetic-data","creator_name":"Knowledgator Engineering","creator_url":"https://huggingface.co/knowledgator","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"synthetic-clinical-notes-embedded","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Clinical Notes\n\t\n\nThis dataset is post-processed version of starmpcc/Asclepius-Synthetic-Clinical-Notes:\n\nTurn into Alpaca format (instruction, input, and output)\nAdd embeddings for input and output columns using BAAI/bge-small-en-v1.5\n\n\n\t\n\t\t\n\nDetails\n\n\n\t\t\nSample Count\n158k\n\n\nToken Count\n648m\n\n\nOrigin\nhttps://figshare.com/authors/Zhengyun_Zhao/16480335\n\n\nSource of raw data\nPubMed Central (PMC) and MIMIC 3\nProcessing details\noriginal, paper \n\n\nEmbedding Model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Technoculture/synthetic-clinical-notes-embedded.","url":"https://huggingface.co/datasets/Technoculture/synthetic-clinical-notes-embedded","creator_name":"Technoculture","creator_url":"https://huggingface.co/Technoculture","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"gigatrue","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGigatrue abstractive summarisation dataset.\n\t\n\n\nIt is a cleaned version of https://huggingface.co/datasets/Harvard/gigaword.\nAdded generated number values.\nApplied truecasing using https://github.com/daltonfury42/truecase.\n\nThis work is supported by the EU NextGenerationEU through the  Recovery and Resilience Plan for Slovakia under the project  No. 09I05-03-V02-00038.\n","url":"https://huggingface.co/datasets/Plasmoxy/gigatrue","creator_name":"Sebasti√°n Petr√≠k","creator_url":"https://huggingface.co/Plasmoxy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Math-Forge-Hard","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMath-Forge-Hard Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Math-Forge-Hard dataset is a collection of challenging math problems designed to test and improve problem-solving skills. This dataset includes a variety of word problems that cover different mathematical concepts, making it a valuable resource for students, educators, and researchers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText: The dataset primarily contains text data, including math word problems.\n\n\n\t\n\t\t\n\t\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard.","url":"https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"ML_arxiv","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for 'ML Articles Subset of Scientific Papers' Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 32,621 instances from the 'Scientific papers' dataset, a selection of scientific papers and summaries from ArXiv repository. This subset focuses on articles that are semantically, vocabulary-wise, structurally, and meaningfully closest to articles describing machine learning. This subset was created using sentence embeddings and K-means clustering.\n\n\t\n\t\t\n\t\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bakhitovd/ML_arxiv.","url":"https://huggingface.co/datasets/bakhitovd/ML_arxiv","creator_name":"Dmitrii Bakhitov","creator_url":"https://huggingface.co/bakhitovd","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"UAlpaca2.0","keyword":"summarization","description":"\n\t\n\t\t\n\t\tUAlpaca 2.0\n\t\n\n","url":"https://huggingface.co/datasets/robinhad/UAlpaca2.0","creator_name":"Yurii Paniv","creator_url":"https://huggingface.co/robinhad","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","translation","text-generation","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"RETAN","keyword":"summarization","description":"A miniature dataset designed for 4-word summarization\nit has 2 things:\ntext: A basic sentence.\nthemes: a 4 four summary using words out of the text\n","url":"https://huggingface.co/datasets/Leore42/RETAN","creator_name":"leonardo","creator_url":"https://huggingface.co/Leore42","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_4.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_4","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_4.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_4","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_15.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_15","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_2025","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_2025.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_2025","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/reddit_dataset_4.","url":"https://huggingface.co/datasets/andreans27/reddit_dataset_4","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ai-policies","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAI Policy Dataset: Education vs. Workplace\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a curated collection of 150+ institutional AI policies from both educational institutions (high schools, universities) and workplace organizations (companies, firms, nonprofits). Each policy has been annotated for stance toward AI usage, enabling comparative analysis of how attitudes differ between schools and professional environments.\nThe dataset was collected between 2024‚Äì2025 and is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ehe07/ai-policies.","url":"https://huggingface.co/datasets/ehe07/ai-policies","creator_name":"E He","creator_url":"https://huggingface.co/ehe07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_tiny","keyword":"summarization","description":"This dataset is a subset of https://huggingface.co/datasets/cnn_dailymail.\nThe training set is composed of 2,000 examples of the original training set and the test set is composed of 1,000 examples of the original validation set.\nWe use the version 1.0.0 of the CNN/DailyMail dataset.\n","url":"https://huggingface.co/datasets/llamafactory/cnn_dailymail_tiny","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_15.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_15","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_2025","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_2025.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_2025","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_4","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/reddit_dataset_4.","url":"https://huggingface.co/datasets/andreans27/reddit_dataset_4","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_011210","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_011210.","url":"https://huggingface.co/datasets/william-1111/x_dataset_011210","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_96","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_96.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_96","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_011210","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_011210.","url":"https://huggingface.co/datasets/william-1111/x_dataset_011210","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_96","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_96.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_96","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44657","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_44657.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_44657","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44657","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_44657.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_44657","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NLP-Paper-to-QA-Generation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset was created by modifying and adapting the allenai/QASPER: a dataset for question answering on scientific research papers dataset \nand aims to generate Question-Answer Pairs from the Abstract, Introduction of an NLP Paper.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nFirst, we extracted the abstract, introduction of each NLP paper from QASPER dataset.\n\nWe also extracted only the rows labeled question and answer that had an abstract answer rather than‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UNIST-Eunchan/NLP-Paper-to-QA-Generation.","url":"https://huggingface.co/datasets/UNIST-Eunchan/NLP-Paper-to-QA-Generation","creator_name":"Eunchan Lee","creator_url":"https://huggingface.co/UNIST-Eunchan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_8","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_8.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_8","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_8","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_8.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_8","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_107","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wolfghost/x_dataset_107.","url":"https://huggingface.co/datasets/wolfghost/x_dataset_107","creator_name":"ghost","creator_url":"https://huggingface.co/wolfghost","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Sapo-subset","keyword":"summarization","description":"Andth/Sapo-subset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Andth/Sapo-subset","creator_name":"Trinh-Hoai-An Duong","creator_url":"https://huggingface.co/Andth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_19","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_19.","url":"https://huggingface.co/datasets/James096/reddit_dataset_19","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_107","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wolfghost/x_dataset_107.","url":"https://huggingface.co/datasets/wolfghost/x_dataset_107","creator_name":"ghost","creator_url":"https://huggingface.co/wolfghost","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_19","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_19.","url":"https://huggingface.co/datasets/James096/reddit_dataset_19","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"rips-koren-torah-xlatin-corpus","keyword":"summarization","description":"Source\n: TorahBibleCodes / TorahBibleCodes \nTransliterated into Latin script.\n","url":"https://huggingface.co/datasets/mad0perator/rips-koren-torah-xlatin-corpus","creator_name":"mad0perator.crypto","creator_url":"https://huggingface.co/mad0perator","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","translation","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0504178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0504178.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0504178","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0305158","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0305158.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0305158","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ILSUM-2.0","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"ILSUM-2.0\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nILSUM-2.0 contains additional ~10K articles along with ILSUM-1.0 dataset. Along with Hindi, English, and Gujarati, which were part of ILSUM-1.0, Bengali is also introduced as part of ILSUM-20. dataset.\nThe dataset for this task is built using articles and headline pairs from several leading newspapers of the country. We provide >=10,000 news articles for each language. The task is to generate a meaningful fixed length summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ILSUM/ILSUM-2.0.","url":"https://huggingface.co/datasets/ILSUM/ILSUM-2.0","creator_name":"Indian Language Summarization","creator_url":"https://huggingface.co/ILSUM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_188","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_188.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_188","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0504178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0504178.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0504178","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0305158","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/james-1111/x_dataset_0305158.","url":"https://huggingface.co/datasets/james-1111/x_dataset_0305158","creator_name":"james","creator_url":"https://huggingface.co/james-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_188","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hadesgod517/reddit_dataset_188.","url":"https://huggingface.co/datasets/hadesgod517/reddit_dataset_188","creator_name":"Hades","creator_url":"https://huggingface.co/hadesgod517","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Context-Conversations","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic-Context-Conversations\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Synthetic-Context-Conversations dataset is a collection of synthetic conversations designed to simulate empathetic and context-rich dialogues. It is particularly useful for tasks such as text generation, summarization, and question answering. The dataset is available in English and contains between 10,000 to 100,000 entries.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Text\nLanguages: English\nSize: 10K-100K\nFormats: Parquet\nLicense:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Synthetic-Context-Conversations.","url":"https://huggingface.co/datasets/prithivMLmods/Synthetic-Context-Conversations","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040484","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040484.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040484","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malicious546/reddit_dataset_128.","url":"https://huggingface.co/datasets/malicious546/reddit_dataset_128","creator_name":"string malicious","creator_url":"https://huggingface.co/malicious546","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_040484","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_040484.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_040484","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_128","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malicious546/reddit_dataset_128.","url":"https://huggingface.co/datasets/malicious546/reddit_dataset_128","creator_name":"string malicious","creator_url":"https://huggingface.co/malicious546","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"RAGTruth-TR","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRAGTruth-TR\n\t\n\nnewmindai/RAGTruth-TR is a Turkish-translated version of the wandb/RAGTruth-processed dataset.\nIt is designed for evaluating Retrieval-Augmented Generation (RAG) systems in Turkish, enabling research in hallucination detection, fact-checking, and response quality assessment.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource Dataset: wandb/RAGTruth-processed\nTarget Language: Turkish\nPurpose: Hallucination detection and RAG evaluation in Turkish NLP systems\nLicense: MIT (inherits from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/newmindai/RAGTruth-TR.","url":"https://huggingface.co/datasets/newmindai/RAGTruth-TR","creator_name":"NewMind AI","creator_url":"https://huggingface.co/newmindai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_22.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_22","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MentorES","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMentor_ES is an open source dataset of 10,175 instructions in Spanish organized in several of the behavioral categories outlined in the InstructGPT paper, including closed QA, open QA, general QA, classification, information extraction, summarization, creative writing and brainstorming.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nUseful for fine-tuning instructions in large language models for downstream tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is in Spanish (es-ES).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/MentorES.","url":"https://huggingface.co/datasets/projecte-aina/MentorES","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","Spanish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_22.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_22","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2023-WAN-Show-Transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\t2023 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2023 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2023-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_64","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lesnikutsa/reddit_dataset_64.","url":"https://huggingface.co/datasets/lesnikutsa/reddit_dataset_64","creator_name":"Igor Ponomarev","creator_url":"https://huggingface.co/lesnikutsa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_170","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/reddit_dataset_170.","url":"https://huggingface.co/datasets/qr12138/reddit_dataset_170","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_64","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lesnikutsa/reddit_dataset_64.","url":"https://huggingface.co/datasets/lesnikutsa/reddit_dataset_64","creator_name":"Igor Ponomarev","creator_url":"https://huggingface.co/lesnikutsa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_170","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qr12138/reddit_dataset_170.","url":"https://huggingface.co/datasets/qr12138/reddit_dataset_170","creator_name":"wu","creator_url":"https://huggingface.co/qr12138","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"2023-WAN-Show-Transcripts","keyword":"summary","description":"\n\t\n\t\t\n\t\t2023 WAN Show Transcripts\n\t\n\nComplete transcripts from the 2023 episodes of the WAN Show.\nGenerated from this GitHub repository.\n","url":"https://huggingface.co/datasets/willtheorangeguy/2023-WAN-Show-Transcripts","creator_name":"William V","creator_url":"https://huggingface.co/willtheorangeguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"MSv2","keyword":"summarization","description":"This dataset is the updated and extended version of the MixSub dataset from T. Rehman, D. K. Sanyal, S. Chattopadhyay, P. K. Bhowmick and P. P. Das, \"Generation of Highlights From Research Papers Using Pointer-Generator Networks and SciBERT Embeddings,\" in IEEE Access, vol. 11, pp. 91358-91374, 2023, doi: 10.1109/ACCESS.2023.3292300.\nThis fixes broken abstracts and highlights from the original dataset as well as add a new column named HallucinatedHighlight which can be used for hallucination‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityaMayukhSom/MSv2.","url":"https://huggingface.co/datasets/AdityaMayukhSom/MSv2","creator_name":"Aditya Mayukh Som","creator_url":"https://huggingface.co/AdityaMayukhSom","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"EDGAR-CORPUS-Financial-Summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEDGAR-CORPUS : 10K Financial Report Summarization\n\t\n\nExtracted from SEC EDGAR filings (1993-2020). This dataset enhances financial report summarization by leveraging a hybrid AI model strategy.\nUsing:\nChatGPT-3.5 Turbo(~70%), \nClaude 3.5 (~30% to generate structured, accurate, and concise summaries)\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nSummaries in this dataset are generated using a hybrid AI model strategy, balancing quality and efficiency:ChatGPT-3.5 Turbo (~70%) ‚Äì Used for structured‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kritsadaK/EDGAR-CORPUS-Financial-Summarization.","url":"https://huggingface.co/datasets/kritsadaK/EDGAR-CORPUS-Financial-Summarization","creator_name":"kritsada krupat","creator_url":"https://huggingface.co/kritsadaK","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is an ambitious project to create a high-quality, reproducible parallel corpus for Modern Standard Arabic (MSA) and Tunisian Arabic (aeb) through a sophisticated synthetic data generation pipeline. The dataset is being developed by the Tunisia.AI community to address the scarcity of high-quality dialectal data for training and evaluating language models.\nThe primary goal is to provide a rich, well-documented resource for the research and development of:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"x_dataset_178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_178.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_178","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Finance_cryptocurrency_Spanish_5.5k","keyword":"summarization","description":"","url":"https://huggingface.co/datasets/NickyNicky/Finance_cryptocurrency_Spanish_5.5k","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"clone-of-gretel-financial-risk-analysis-v1","keyword":"summarization","description":"\n‚ö†Ô∏èüî¥ IMPORTANT NOTICE üî¥‚ö†Ô∏è\nThis dataset is directly cloned from gretelai/gretel-financial-risk-analysis-v1 on Hugging Face. No modifications have been made to the original dataset, it is only for archival.\n\n\n\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated using differential privacy guarantees, trained on 14,306 SEC (10-K, 10-Q, and 8-k) filings from 2023-2024. The dataset is designed for training models to extract‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_5.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_5","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/x_dataset_178.","url":"https://huggingface.co/datasets/Aniruddh79012/x_dataset_178","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"clone-of-gretel-financial-risk-analysis-v1","keyword":"news-articles-summarization","description":"\n‚ö†Ô∏èüî¥ IMPORTANT NOTICE üî¥‚ö†Ô∏è\nThis dataset is directly cloned from gretelai/gretel-financial-risk-analysis-v1 on Hugging Face. No modifications have been made to the original dataset, it is only for archival.\n\n\n\n\t\n\t\t\n\t\tgretelai/gretel-financial-risk-analysis-v1\n\t\n\nThis dataset contains synthetic financial risk analysis text generated using differential privacy guarantees, trained on 14,306 SEC (10-K, 10-Q, and 8-k) filings from 2023-2024. The dataset is designed for training models to extract‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1.","url":"https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","multi-label-classification","news-articles-summarization","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_5","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_5.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_5","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_209","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_209.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_209","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_94","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_94.","url":"https://huggingface.co/datasets/coldmind/x_dataset_94","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_209","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenknow/reddit_dataset_209.","url":"https://huggingface.co/datasets/wenknow/reddit_dataset_209","creator_name":"Dt","creator_url":"https://huggingface.co/wenknow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_94","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_94.","url":"https://huggingface.co/datasets/coldmind/x_dataset_94","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_90","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_90.","url":"https://huggingface.co/datasets/gk4u/x_dataset_90","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_90","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_90.","url":"https://huggingface.co/datasets/gk4u/x_dataset_90","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"techcrunch-articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTechCrunch News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\nThis dataset contains 10,265 high-quality news articles scraped from TechCrunch, one of the leading technology news websites. The dataset includes comprehensive article content, metadata, and quality assessments suitable for various NLP tasks including text classification, sentiment analysis, summarization, and content generation.\n\n\t\n\t\t\n\t\tüéØ Key Features\n\t\n\n\n10,265 articles with full text content\nHigh-quality filtering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/techcrunch-articles.","url":"https://huggingface.co/datasets/abhilash88/techcrunch-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0502178","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0502178.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0502178","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0512140","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0512140.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0512140","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_1.","url":"https://huggingface.co/datasets/suul999922/x_dataset_1","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_48244","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_48244.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_48244","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0502178","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0502178.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0502178","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0512140","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0512140.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0512140","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_1","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_1.","url":"https://huggingface.co/datasets/suul999922/x_dataset_1","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_48244","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_48244.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_48244","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/x_dataset_44.","url":"https://huggingface.co/datasets/chaiamy/x_dataset_44","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_660618","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_660618.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_660618","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060792","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060792.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060792","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"news-summarizer-reasoner","keyword":"summarization","description":"\n\t\n\t\t\n\t\tNews Summarizer with Reasoning\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for news summarization tasks, featuring both original news articles and their corresponding summaries. The dataset includes a 'news' column sourced from three different datasets, along with 'cleaned_summary' and 'cleaned_reasoning' columns generated using large language models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nnews: Original news articles.\ncleaned_summary: Summaries of the news articles in bullet points.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seacorn/news-summarizer-reasoner.","url":"https://huggingface.co/datasets/seacorn/news-summarizer-reasoner","creator_name":"Cheng Hui Lee","creator_url":"https://huggingface.co/seacorn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Chinese","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_99","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/x_dataset_99.","url":"https://huggingface.co/datasets/jasonmoore92/x_dataset_99","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"east_java_dialect_instruct","keyword":"summarization","description":"\n\t\n\t\t\n\t\tComplaints From The East Javanese Dialect community\n\t\n\nThis dataset created manually by humans with reference to public complaints in the comments column of the local government's Instagram account and another platform like X and TikTok Comments.\n","url":"https://huggingface.co/datasets/yukebrillianth/east_java_dialect_instruct","creator_name":"Yuke Brilliant","creator_url":"https://huggingface.co/yukebrillianth","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","Javanese","Indonesian"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookpraise/reddit_dataset_239.","url":"https://huggingface.co/datasets/lookpraise/reddit_dataset_239","creator_name":"priase","creator_url":"https://huggingface.co/lookpraise","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/x_dataset_44.","url":"https://huggingface.co/datasets/chaiamy/x_dataset_44","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_660618","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_660618.","url":"https://huggingface.co/datasets/chenxinpingcxp/reddit_dataset_660618","creator_name":"tian chen","creator_url":"https://huggingface.co/chenxinpingcxp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060792","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060792.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060792","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_99","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jasonmoore92/x_dataset_99.","url":"https://huggingface.co/datasets/jasonmoore92/x_dataset_99","creator_name":"Jason Moore","creator_url":"https://huggingface.co/jasonmoore92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_239","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookpraise/reddit_dataset_239.","url":"https://huggingface.co/datasets/lookpraise/reddit_dataset_239","creator_name":"priase","creator_url":"https://huggingface.co/lookpraise","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_9.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_9","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"dataset_dulele_test_20250607","keyword":"summarization","description":"dulele/dataset_dulele_test_20250607 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/dulele/dataset_dulele_test_20250607","creator_name":"dulele","creator_url":"https://huggingface.co/dulele","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","Afar","Akan","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_9","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_9.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_9","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"HR-VILAGE-3K3M","keyword":"summarization","description":"\n\t\n\t\t\n\t\tHR-VILAGE-3K3M: Human Respiratory Viral Immunization Longitudinal Gene Expression\n\t\n\nThis repository provides the HR-VILAGE-3K3M dataset, a curated collection of human longitudinal gene expression profiles, antibody measurements, and aligned metadata from respiratory viral immunization and infection studies. The dataset includes baseline transcriptomic profiles and covers diverse exposure types (vaccination, inoculation, and mixed exposure). HR-VILAGE-3K3M is designed as a benchmark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xuejun72/HR-VILAGE-3K3M.","url":"https://huggingface.co/datasets/xuejun72/HR-VILAGE-3K3M","creator_name":"Xuejun Sun","creator_url":"https://huggingface.co/xuejun72","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","feature-extraction","token-classification","summarization","fill-mask"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_73","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OGNOOB/reddit_dataset_73.","url":"https://huggingface.co/datasets/OGNOOB/reddit_dataset_73","creator_name":"a","creator_url":"https://huggingface.co/OGNOOB","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"mteb-BillSumUS","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBillSumUS (MTEB formsat)\n\t\n\nThis is the federal US test split of the BillSum dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on BillSum with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve US congressional bills based on their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-BillSumUS.","url":"https://huggingface.co/datasets/isaacus/mteb-BillSumUS","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","FiscalNote/billsum","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"fa-wiki-spell-checker","keyword":"summarization","description":"\n\t\n\t\t\n\t\tPersian / Farsi Wikipedia Corpus for Spell Checking Tasks\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Wikipedia Corpus is an open source dataset specifically designed for use in spell checking tasks. It is available on huggingface and can be accessed and utilized by anyone interested in improving spell checking algorithms.\n\n\t\n\t\t\n\t\tFormula\n\t\n\n\n\t\n\t\t\nchance of being\n%\n\n\n\t\t\nnormal sentences\n>=2%\n\n\nmanipulation\n<=98%\n\n\n\t\n\neach time with random function we create a new random number for each line (in this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/moaminsharifi/fa-wiki-spell-checker.","url":"https://huggingface.co/datasets/moaminsharifi/fa-wiki-spell-checker","creator_name":"Sharifi","creator_url":"https://huggingface.co/moaminsharifi","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","Persian","pddl","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/x_dataset_11.","url":"https://huggingface.co/datasets/smmrokn/x_dataset_11","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_73","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OGNOOB/reddit_dataset_73.","url":"https://huggingface.co/datasets/OGNOOB/reddit_dataset_73","creator_name":"a","creator_url":"https://huggingface.co/OGNOOB","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/x_dataset_11.","url":"https://huggingface.co/datasets/smmrokn/x_dataset_11","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15977","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_15977.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_15977","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_149184","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_149184.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_149184","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_15977","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_15977.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_15977","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_149184","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_149184.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_149184","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"TradeNewsSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTradeNewsSum: Multilingual Summarization Dataset for Trade News\n\t\n\nTradeNewsSum is a multilingual dataset for abstractive summarization of trade-related news.It includes over 59,000 manually aligned article-summary pairs in Russian and English, focused on topics such as international trade, sanctions, investment, and oil markets.\nThe dataset is intended for training and evaluating summarization systems in both monolingual and cross-lingual settings.\n\n\t\n\t\t\n\t\n\t\n\t\tAnnotation Guidelines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyutovad/TradeNewsSum.","url":"https://huggingface.co/datasets/lyutovad/TradeNewsSum","creator_name":"Daria Lyutova","creator_url":"https://huggingface.co/lyutovad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"TradeNewsSum","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTradeNewsSum: Multilingual Summarization Dataset for Trade News\n\t\n\nTradeNewsSum is a multilingual dataset for abstractive summarization of trade-related news.It includes over 59,000 manually aligned article-summary pairs in Russian and English, focused on topics such as international trade, sanctions, investment, and oil markets.\nThe dataset is intended for training and evaluating summarization systems in both monolingual and cross-lingual settings.\n\n\t\n\t\t\n\t\n\t\n\t\tAnnotation Guidelines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyutovad/TradeNewsSum.","url":"https://huggingface.co/datasets/lyutovad/TradeNewsSum","creator_name":"Daria Lyutova","creator_url":"https://huggingface.co/lyutovad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the size for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n764,482,142\n224 B\n336 GB\n\n\ndeu_Latn\n343,089,235\n106 B\n141 GB\n\n\neng_Latn\n321,343,046\n81 B\n150 GB\n\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB\n\n\npol_Latn\n9‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/finepdfs-summaries.","url":"https://huggingface.co/datasets/maxidl/finepdfs-summaries","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_218.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"russian_summarization","keyword":"summarization","description":"vanya-robot/russian_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vanya-robot/russian_summarization","creator_name":"Yaroslav","creator_url":"https://huggingface.co/vanya-robot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Russian","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"TradeNewsSum","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tTradeNewsSum: Multilingual Summarization Dataset for Trade News\n\t\n\nTradeNewsSum is a multilingual dataset for abstractive summarization of trade-related news.It includes over 59,000 manually aligned article-summary pairs in Russian and English, focused on topics such as international trade, sanctions, investment, and oil markets.\nThe dataset is intended for training and evaluating summarization systems in both monolingual and cross-lingual settings.\n\n\t\n\t\t\n\t\n\t\n\t\tAnnotation Guidelines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyutovad/TradeNewsSum.","url":"https://huggingface.co/datasets/lyutovad/TradeNewsSum","creator_name":"Daria Lyutova","creator_url":"https://huggingface.co/lyutovad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","news-articles-summarization","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/reddit_dataset_218.","url":"https://huggingface.co/datasets/arrmlet/reddit_dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CompCap-gpt4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCompCap-GPT4: A GPT-4 Captioned Version of CompCap-118K\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: CompCap: Improving Multimodal Large Language Models with Composite Captions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDownload Options\n\t\n\n\nDirect Download:The repository includes CI_type.zip and CI_type.json. The JSON file follows the Llava format:\n{\n  \"id\": ID,\n  \"image\": IMAGE_PATH,\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": QUESTION},\n    {\"from\": \"gpt\", \"value\": ANSWER}\n  ]\n}\n\n\nUsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xchen16/CompCap-gpt4.","url":"https://huggingface.co/datasets/xchen16/CompCap-gpt4","creator_name":"Xiaohui Chen","creator_url":"https://huggingface.co/xchen16","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/reddit_dataset_44.","url":"https://huggingface.co/datasets/chaiamy/reddit_dataset_44","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44311","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_44311.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_44311","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_16.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_16","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chaiamy/reddit_dataset_44.","url":"https://huggingface.co/datasets/chaiamy/reddit_dataset_44","creator_name":"Amy","creator_url":"https://huggingface.co/chaiamy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_44311","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_44311.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_44311","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_16.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_16","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"GPT-4o-PHQ-9","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGPT-4o-Evaluated-Primate_Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset, titled GPT-4o-evaluated, contains texts that were evaluated by GPT-4o (The \"best for complex tasks\" version). The dataset focuses on identifying and annotating specific sentiments and mental health indicators within user-submitted posts. It can be used for research in mental health, sentiment analysis, and other related fields.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nStructure of the dataset, including what each key-value‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/darssanle/GPT-4o-PHQ-9.","url":"https://huggingface.co/datasets/darssanle/GPT-4o-PHQ-9","creator_name":"Darssan Eswar","creator_url":"https://huggingface.co/darssanle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SummARai","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummARai v1.0: Arabic Chunk-Aligned Summarization Dataset\n\t\n\nSummARai v1.0 is a high-quality Arabic summarization dataset with chunk-level alignment between long Arabic texts and their human-written summaries. All content is written in Modern Standard Arabic (MSA), making it suitable for formal Arabic NLP tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nSamples: 4,328 text-summary pairs\nGenres:\nüìò Books: 3,666\nüìñ Novels: 662\n\n\n\nLanguage: 100% Modern Standard Arabic (MSA)\n\t\n\t\t\n\t\tData Sources‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fatmaserry/SummARai.","url":"https://huggingface.co/datasets/fatmaserry/SummARai","creator_name":"Fatma Elzahraa Serry","creator_url":"https://huggingface.co/fatmaserry","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"SummARai","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummARai v1.0: Arabic Chunk-Aligned Summarization Dataset\n\t\n\nSummARai v1.0 is a high-quality Arabic summarization dataset with chunk-level alignment between long Arabic texts and their human-written summaries. All content is written in Modern Standard Arabic (MSA), making it suitable for formal Arabic NLP tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nSamples: 4,328 text-summary pairs\nGenres:\nüìò Books: 3,666\nüìñ Novels: 662\n\n\n\nLanguage: 100% Modern Standard Arabic (MSA)\n\t\n\t\t\n\t\tData Sources‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fatmaserry/SummARai.","url":"https://huggingface.co/datasets/fatmaserry/SummARai","creator_name":"Fatma Elzahraa Serry","creator_url":"https://huggingface.co/fatmaserry","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"fomc-statements","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFOMC Meeting Policy Statements Dataset (Year 2000+, updated monthly)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the policy statements released by the Federal Open Market Committee (FOMC) following each of its meetings from year 2000 onwords. The FOMC, a component of the U.S. Federal Reserve System, determines monetary policy in the United States. The statements provide insights into the committee‚Äôs policy decisions, economic outlook, and forward guidance.\n\n\t\n\t\t\n\t\tBackground on Policy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Coding-Fish/fomc-statements.","url":"https://huggingface.co/datasets/Coding-Fish/fomc-statements","creator_name":"Gang Hyeok Lee","creator_url":"https://huggingface.co/Coding-Fish","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","sentence-similarity","summarization","English"],"keywords_longer_than_N":true},
	{"name":"nba-pbp-to-recap","keyword":"summarization","description":"DatasetDict({\n    train: Dataset({\n        features: ['metadata', 'input', 'output'],\n        num_rows: 4593\n    })\n    test: Dataset({\n        features: ['metadata', 'input', 'output'],\n        num_rows: 574\n    })\n    validation: Dataset({\n        features: ['metadata', 'input', 'output'],\n        num_rows: 574\n    })\n    unsupervised: Dataset({\n        features: ['metadata', 'input', 'output'],\n        num_rows: 27257\n    })\n})\n\nThis dataset consists of 3 columns:\n\nmetadata - which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nir-yar/nba-pbp-to-recap.","url":"https://huggingface.co/datasets/nir-yar/nba-pbp-to-recap","creator_name":"Nir Yarden","creator_url":"https://huggingface.co/nir-yar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"Garud_puran_FlanT5_with_context","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGaruda Purana Q&A for FLAN-T5\n\t\n\nThis dataset contains question-answer pairs from the Garuda Purana, with a summarization context for each pair generated by FLAN-T5.\nFields:\n\nquestion: The input question in natural language.\nanswer: The answer to the question.\ncontext: A short summary (generated by FLAN-T5) of the Q&A pair, usable as context or for semantic retrieval.\n\nIntended Use:\n\nSupervised fine-tuning for Question Answering, Retrieval, and Instruction-based LLMs.\nThe question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Binoddai/Garud_puran_FlanT5_with_context.","url":"https://huggingface.co/datasets/Binoddai/Garud_puran_FlanT5_with_context","creator_name":"Binod","creator_url":"https://huggingface.co/Binoddai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_211","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chain03/reddit_dataset_211.","url":"https://huggingface.co/datasets/chain03/reddit_dataset_211","creator_name":"chain","creator_url":"https://huggingface.co/chain03","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Luminous","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kskip/Luminous.","url":"https://huggingface.co/datasets/Kskip/Luminous","creator_name":"William Kyle Skipper","creator_url":"https://huggingface.co/Kskip","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Vietnamese_spelling_error","keyword":"summarization","description":"\n\t\n\t\t\n\t\tVietnamese Spelling Error Dataset\n\t\n\nThis dataset contains examples of Vietnamese text with spelling errors and their corresponding corrections. It is intended to be used for training and evaluating models in spelling correction tasks, particularly for the Vietnamese language.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nName: Vietnamese Spelling Error Dataset\nLanguage: Vietnamese\nFile Format: [CSV/Parquet/dataset/etc.]\nColumns:\ntext: The corresponding corrected version of the text.\nerror_text: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShynBui/Vietnamese_spelling_error.","url":"https://huggingface.co/datasets/ShynBui/Vietnamese_spelling_error","creator_name":"Bui Tien Phat","creator_url":"https://huggingface.co/ShynBui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","summarization","translation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0406135","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0406135.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0406135","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_211","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chain03/reddit_dataset_211.","url":"https://huggingface.co/datasets/chain03/reddit_dataset_211","creator_name":"chain","creator_url":"https://huggingface.co/chain03","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0406135","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0406135.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0406135","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_10th","keyword":"summarization","description":"KadamParth/NCERT_Science_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21716","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_21716.","url":"https://huggingface.co/datasets/icedwind/x_dataset_21716","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21716","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_21716.","url":"https://huggingface.co/datasets/icedwind/x_dataset_21716","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3753","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_3753.","url":"https://huggingface.co/datasets/icedwind/x_dataset_3753","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3753","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_3753.","url":"https://huggingface.co/datasets/icedwind/x_dataset_3753","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Business_Studies_11th","keyword":"summarization","description":"KadamParth/NCERT_Business_Studies_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Business_Studies_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_42905","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_42905.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_42905","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_42905","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_42905.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_42905","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"parallel-catholic-bible-versions","keyword":"summarization","description":"\n\t\n\t\t\n\t\tParallel Catholic Bible Versions\n\t\n\nAligned verses from all 73 books of Catholic Bible in three versions: the Latin Vulgate (vulgate), the Catholic Public Domain Version (cpdv), and the Douay-Rheims Challoner Revision (drc). Includes 2,450 translation commentary notes from the Latin English Study Bible by Ronald L. Conte Jr.\n\n\t\n\t\t\n\t\tSources\n\t\n\n\nLatin-English Study Bible with notes scraped by aseemsavio\nDouay-Rheims via scrollmapper\n\nText has been cleaned to remove HTML tags (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jam963/parallel-catholic-bible-versions.","url":"https://huggingface.co/datasets/jam963/parallel-catholic-bible-versions","creator_name":"Jacob Matthews","creator_url":"https://huggingface.co/jam963","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","sentence-similarity","summarization","Latin","English"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_5k","keyword":"summarization","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tNOVEReason_5k\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_5k.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_5k","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"myelography-imaging","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tMyelography Imaging\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 750 synthetic myelography examination records representing a wide spectrum of spinal pathologies and patient experiences. Each record includes:\n\nPatient demographics: Age and sex.\nClinical symptoms prompting the procedure: Detailed and verbose descriptions.\nProcedural details: Contrast medium type, injection site, and imaging modality used.\nVerbose findings: Observations such as spinal cord compression‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/myelography-imaging.","url":"https://huggingface.co/datasets/Taylor658/myelography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","named-entity-recognition","news-articles-summarization","synthetic","monolingual"],"keywords_longer_than_N":true},
	{"name":"2SyntheticDatasetSmall","keyword":"summarization","description":"Hypercalemia/2SyntheticDatasetSmall dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hypercalemia/2SyntheticDatasetSmall","creator_name":"Sebastian  Sand√∏","creator_url":"https://huggingface.co/Hypercalemia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_122","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_122.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_122","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"translated_dataset","keyword":"summarization","description":"Xondamir/translated_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Xondamir/translated_dataset","creator_name":"Xondamir Xamroyev","creator_url":"https://huggingface.co/Xondamir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Uzbek","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_122","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_122.","url":"https://huggingface.co/datasets/Aniruddh79012/reddit_dataset_122","creator_name":"Singh","creator_url":"https://huggingface.co/Aniruddh79012","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PlotStructureSummarization-Generation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for PlotStructureSummarization-Generation\n\t\n\nThis dataset consists of manually curated plot summaries across various media types, such as TV episodes, movies, books, and historical events. Each instance follows a structured format outlining the title, synopsis, plot structure, and key character archetypes. It is designed to enhance models' abilities in summarization and text generation, focusing on narrative frameworks, including classical storytelling structures like the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R3troR0b/PlotStructureSummarization-Generation.","url":"https://huggingface.co/datasets/R3troR0b/PlotStructureSummarization-Generation","creator_name":"Robert Albert Allen McNarland","creator_url":"https://huggingface.co/R3troR0b","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_84","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_84.","url":"https://huggingface.co/datasets/gk4u/x_dataset_84","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_84","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_84.","url":"https://huggingface.co/datasets/gk4u/x_dataset_84","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"grade_labeled_wiki_paragraphs","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tGrade-Labeled Wiki Paragraphs (GPT-4.1 Nano)\n\t\n\nThis dataset contains Wikipedia paragraphs simplified to different grade reading levels (targeting Grade 1-12) using the GPT-4.1 Nano model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of pairs of original Wikipedia paragraphs and their machine-generated simplified versions. The simplification aims to make the text understandable for readers at specific US grade levels while preserving the core‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs.","url":"https://huggingface.co/datasets/yimingwang123/grade_labeled_wiki_paragraphs","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-simplification","machine","machine","monolingual","agentlans/wikipedia-paragraphs"],"keywords_longer_than_N":true},
	{"name":"experimental-paper-json-xtraction","keyword":"summarization","description":"Shinapri/experimental-paper-json-xtraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/experimental-paper-json-xtraction","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","feature-extraction","text-generation","table-question-answering"],"keywords_longer_than_N":true},
	{"name":"STM","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA small, high-quality chat dataset to teach models how to answer like Sk. Tanzir Mehedi (QUT; software supply-chain security, HPC/LLM workflows, PyPI malware analysis).Primary reference: https://tanzirmehedi.netlify.app/\n\n\t\n\t\t\n\t\tFormat\n\t\n\nEach row contains a messages list of {role, content, thinking} objects.thinking is optional and set to null for safety; models can be trained only on role + content.\n\n\t\n\t\t\n\t\tExample usage\n\t\n\nfrom datasets import load_dataset\nds =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tanzirmehedi/STM.","url":"https://huggingface.co/datasets/tanzirmehedi/STM","creator_name":"Sk Tanzir Mehedi","creator_url":"https://huggingface.co/tanzirmehedi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8140","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_8140.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_8140","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_8140","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_8140.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_8140","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"German4All-Corpus","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tDataset Card for the German4All Corpus of datasets\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tCorpus Overview\n\t\n\nGerman4All is a synthetic data corpus consisting of 3 datasets. Each dataset consists of German Wikipedia paragraphs that are paraphrased in five different complexity levels. The 3 datasets are:\n\nGerman4All-Main (subfolder \"main\"): The main synthetic dataset containing 25,459 elements, each featuring an\noriginal text along with its five-level paraphrases. \nGerman4All-Main-old (subfolder‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tum-nlp/German4All-Corpus.","url":"https://huggingface.co/datasets/tum-nlp/German4All-Corpus","creator_name":"Natural Language Processing @ TUM","creator_url":"https://huggingface.co/tum-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","10K<n<100K","arxiv:2508.17973"],"keywords_longer_than_N":true},
	{"name":"cdx-docs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis directory contains numerous knowledge files about CycloneDX and cdxgen in jsonlines chat format. The data is useful for training and fine-tuning (LoRA and QLoRA) LLM models.\n\n\t\n\t\t\n\t\tData Generation\n\t\n\nWe used Google Gemini 2.0 Flash Experimental via aistudio and used the below prompts to convert official documentation markdown files to the chat format.\nyou are an expert in converting markdown files to plain text jsonlines format based on the my template.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CycloneDX/cdx-docs.","url":"https://huggingface.co/datasets/CycloneDX/cdx-docs","creator_name":"CycloneDX","creator_url":"https://huggingface.co/CycloneDX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"codereview-dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Code Review Execution Dataset\n\t\n\nThis dataset contains comprehensive code review data including pull requests, AI-generated code suggestions, human feedback, and static analysis results. It represents real-world software development workflows and code quality processes.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset captures the complete lifecycle of code review processes in software development, including:\n\nPull request metadata and context‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nutanix/codereview-dataset.","url":"https://huggingface.co/datasets/Nutanix/codereview-dataset","creator_name":"Nutanix","creator_url":"https://huggingface.co/Nutanix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_30.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_30","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_30","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_30.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_30","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/x_dataset_47.","url":"https://huggingface.co/datasets/tarzan19990815/x_dataset_47","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17682","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_17682.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_17682","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"AURIS_GoldenEval-Synthetic-v1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAURIS_GoldenEval-Synthetic-v1\n\t\n\nA high-quality, AI-generated dataset containing 4,900 customer-agent chat interactions, annotated with detailed evaluation metrics and coaching insights. This dataset was created using the Gemma 27B model via the Google Vertex AI Studio API, designed to simulate realistic yet diverse customer service scenarios for LLM-based evaluation tasks.\n\n\n\t\n\t\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nName: CustomerServiceEval-Synthetic-v1\nSize: 4,900 entries\nLanguage: English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HussienElBehery/AURIS_GoldenEval-Synthetic-v1.","url":"https://huggingface.co/datasets/HussienElBehery/AURIS_GoldenEval-Synthetic-v1","creator_name":"Hussien Ahmed","creator_url":"https://huggingface.co/HussienElBehery","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"NCERT_Economics_12th","keyword":"summarization","description":"KadamParth/NCERT_Economics_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Economics_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/x_dataset_47.","url":"https://huggingface.co/datasets/tarzan19990815/x_dataset_47","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17682","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_17682.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_17682","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"mev51","keyword":"summarization","description":"robocodeteam/mev51 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/robocodeteam/mev51","creator_name":"halil mustafa g√∂ksu","creator_url":"https://huggingface.co/robocodeteam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/reddit_dataset_44.","url":"https://huggingface.co/datasets/roknedin/reddit_dataset_44","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_07096","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_07096.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_07096","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_286316","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_286316.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_286316","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19217","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_19217.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_19217","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_225","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/x_dataset_225.","url":"https://huggingface.co/datasets/tarzan19990815/x_dataset_225","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18251","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_18251.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_18251","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roknedin/reddit_dataset_44.","url":"https://huggingface.co/datasets/roknedin/reddit_dataset_44","creator_name":"Mohammad Roknedin","creator_url":"https://huggingface.co/roknedin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_07096","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_07096.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_07096","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_286316","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_286316.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_286316","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19217","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_19217.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_19217","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_225","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarzan19990815/x_dataset_225.","url":"https://huggingface.co/datasets/tarzan19990815/x_dataset_225","creator_name":"matthew allen","creator_url":"https://huggingface.co/tarzan19990815","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18251","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_18251.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_18251","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_120","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_120.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_120","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_120","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_120.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_120","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_181","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/x_dataset_181.","url":"https://huggingface.co/datasets/vuhongtien/x_dataset_181","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words ¬∑ 12 languages ¬∑ CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digital‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AI‚ÄëCulture‚ÄëCommons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_181","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/x_dataset_181.","url":"https://huggingface.co/datasets/vuhongtien/x_dataset_181","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"tradingview_msn_financial_news_1k","keyword":"summarization","description":"xinqiyang/tradingview_msn_financial_news_1k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/xinqiyang/tradingview_msn_financial_news_1k","creator_name":"XinqiYang","creator_url":"https://huggingface.co/xinqiyang","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Japanese","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SN-echoes","keyword":"summarization","description":"[Paper] | [GitHub]\n\n\t\n\t\t\n\t\tDataset Card for SoccerNet-Echoes\n\t\n\nThis dataset card aims to provide comprehensive details for the SoccerNet-Echoes dataset, an audio commentary dataset for soccer games.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSoccerNet-Echoes is an audio commentary dataset for soccer games, curated by SimulaMet under the AI-Storyteller project. It is funded by the Research Council of Norway (project number 346671) and shared by the SoccerNet team. The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/SN-echoes.","url":"https://huggingface.co/datasets/SoccerNet/SN-echoes","creator_name":"SoccerNet","creator_url":"https://huggingface.co/SoccerNet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translation","English","Spanish","Russian"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_21.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_21","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_21","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_21.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_21","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"korean-medical-dispute-mediation-cases","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüè• Korean Medical Dispute Mediation Cases Dataset\n\t\n\nThis dataset provides a comprehensive collection of 611 medical dispute mediation cases from Korean medical mediation institutions, focusing on medical malpractice, treatment disputes, and resolution outcomes. It is suitable for medical-legal NLP, dispute analysis, mediation outcome prediction, and healthcare AI applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nTotal Records: 611\nLanguage: Korean (ko)\nFields: 9 columns with English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ducut91/korean-medical-dispute-mediation-cases.","url":"https://huggingface.co/datasets/ducut91/korean-medical-dispute-mediation-cases","creator_name":"lim eul young","creator_url":"https://huggingface.co/ducut91","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"code-expropriation-utilite-publique","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'expropriation pour cause d'utilit√© publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"dataset_218","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/dataset_218.","url":"https://huggingface.co/datasets/arrmlet/dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"dataset_218","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/dataset_218.","url":"https://huggingface.co/datasets/arrmlet/dataset_218","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ua-codeforces-cots-open-r1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nua-codeforces-cots-open-r1 is a Ukrainian-focused derivative of open-r1/codeforces-cots that:\n\nincludes 1550 Python solutions from original dataset generated by DeepSeek-R1;\n\nadds Ukrainian translations of Codeforces task statements, I/O formats, notes, and editorials;\n\nprovides Ukrainian translation of original (\"high\") reasoning obtained with DeepSeek-V3;\n\nadds ‚Äúlow‚Äù reasoning in Ukrainian by DeepSeek-R1 based on original reasoning and task statements;\n\nships‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anon-researcher-ua/ua-codeforces-cots-open-r1.","url":"https://huggingface.co/datasets/anon-researcher-ua/ua-codeforces-cots-open-r1","creator_name":"Anonymous Researcher","creator_url":"https://huggingface.co/anon-researcher-ua","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","summarization","English","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"ASAS","keyword":"summarization","description":"\n\t\n\t\t\n\t\tASAS (ÿ£ÿ≥ÿßÿ≥) Corpus ‚Äî Arabic Summaries with Annotated Support\n\t\n\nASAS ‚Äî Arabic Summaries with Annotated Support (Arabic: ÿ£ÿ≥ÿßÿ≥ ‚Äúfoundation‚Äù) is a multi‚Äëregister Arabic summarization corpus designed to emphasize longer source texts and longer, higher‚Äëquality summaries. Each summary sentence is paired with human validation and supporting evidence extracted verbatim from the source.\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhat‚Äôs inside\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiles\n\t\n\n\n`` ‚Äî Deep‚Äëanalysis file. One JSON object per article with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ASAS.","url":"https://huggingface.co/datasets/HebArabNlpProject/ASAS","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","üá∫üá∏ Region: US","arabic"],"keywords_longer_than_N":false},
	{"name":"Dbs-Singleshot","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDbs-Singleshot dataset\n\t\n\nThis dataset contains text and code for machine learning tasks including:\n\nText Generation\nText Classification\nSummarization\n\nThe dataset includes text formatted in JSON and is in English.\n\n\t\n\t\t\n\t\tLibraries\n\t\n\nThis dataset includes the following libraries:\n\nDatasets\npandas\nCroissant\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the Apache-2.0 license.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a single split named \"train\" with 15,015 rows.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Dbs-Singleshot.","url":"https://huggingface.co/datasets/prithivMLmods/Dbs-Singleshot","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/x_dataset_16.","url":"https://huggingface.co/datasets/vuhongtien/x_dataset_16","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vuhongtien/x_dataset_16.","url":"https://huggingface.co/datasets/vuhongtien/x_dataset_16","creator_name":"Vu Hong Tien","creator_url":"https://huggingface.co/vuhongtien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"TikTok_Hottest_Video_Transcript_Example","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"Aloe-Beta-General-Collection","keyword":"summarization","description":"\n\t\n\t\t\n\t\tAloe-Beta-Medical-Collection\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nCollection of curated general datasets used to fine-tune Aloe-Beta.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nWe curated data from many publicly available general instruction tuning data sources (QA format). It consists of 400k instructions including:\n\nCoding, math, data analysis, STEM, etc.\n\nFunction calling\n\nCreative writing, advice seeking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-General-Collection.","url":"https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-General-Collection","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_48558","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_48558.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_48558","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_48558","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/littleGuagua/x_dataset_48558.","url":"https://huggingface.co/datasets/littleGuagua/x_dataset_48558","creator_name":"Felix","creator_url":"https://huggingface.co/littleGuagua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"DeFine","keyword":"summarization","description":"Test set and Data Resources for analogical reasoning with earnings call transcripts in research: DeFine: Decision-Making with Analogical Reasoning over Factor Profiles  Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu  Accepted to findings of ACL 2025, Vienna, Austria, USA  üìÑ Arxiv Paper ¬†¬†\nüè† Home Page ¬†¬†\nüêô Github\n\n\t\n\t\n\t\n\t\tAbstract\n\t\n\nLLMs are ideal for decision-making thanks to their ability to reason over long contexts. However, challenges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/DeFine.","url":"https://huggingface.co/datasets/huuuyeah/DeFine","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","question-answering","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_142","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/reddit_dataset_142.","url":"https://huggingface.co/datasets/RentonWEB3/reddit_dataset_142","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"bank-of-ghana-treasury-bills","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nBank of Ghana historical and real-time treasury bills data. Bank of Ghana\nClick Here: \n\n\t\n\t\t\n\t\tData Format\n\t\n\n{\n    \"issue_date\": \"...\", \n    \"tender\": \"...\", \n    \"security_type\": \"...\", \n    \"discount_rate\": \"...\", \n    \"interest_rate\": \"...\"\n}\n\n\n\t\n\t\t\n\t\tLoad Dataset\n\t\n\npip install datasets\n\nfrom datasets import load_dataset\n\ntreasury = load_dataset(\"worldboss/bank-of-ghana-treasury-bills\", split=\"train\")\n\npd.DataFrame(treasury).head()\n\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/bank-of-ghana-treasury-bills.","url":"https://huggingface.co/datasets/worldboss/bank-of-ghana-treasury-bills","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"nbme-llama2","keyword":"summarization","description":"joshitanm/nbme-llama2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/joshitanm/nbme-llama2","creator_name":"Tanmay Joshi","creator_url":"https://huggingface.co/joshitanm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_142","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RentonWEB3/reddit_dataset_142.","url":"https://huggingface.co/datasets/RentonWEB3/reddit_dataset_142","creator_name":"Renton Mark","creator_url":"https://huggingface.co/RentonWEB3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_2.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_2","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_193","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sesen01/x_dataset_193.","url":"https://huggingface.co/datasets/sesen01/x_dataset_193","creator_name":"Selim Esen","creator_url":"https://huggingface.co/sesen01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63681","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_63681.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_63681","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"DebateBench","keyword":"summarization","description":"utkarsh2105/DebateBench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/utkarsh2105/DebateBench","creator_name":"Utkarsh Tiwari","creator_url":"https://huggingface.co/utkarsh2105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_2.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_2","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_193","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sesen01/x_dataset_193.","url":"https://huggingface.co/datasets/sesen01/x_dataset_193","creator_name":"Selim Esen","creator_url":"https://huggingface.co/sesen01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_63681","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_63681.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_63681","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"hromadske_corruption","keyword":"summarization","description":"Vitaliias/hromadske_corruption dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Vitaliias/hromadske_corruption","creator_name":"Vitalii Hellman","creator_url":"https://huggingface.co/Vitaliias","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Ukrainian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MainframeBench","keyword":"summarization","description":"\n  \n\n\n\n  \n\n\t\n\t\t\n\t\tXMAiNframe: A Large Language Model for Mainframe Modernization\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset - MainframeBench - contains a comprehensive benchmark for assessing mainframe knowledge, including three sub-tasks: multiple-choice questions, question answering, and COBOL code summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances for Question Answering\n\t\n\n{\n    \"id\": 0,\n    \"prompt\": \"As a supportive AI assistant, you've been presented with a query‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/MainframeBench.","url":"https://huggingface.co/datasets/Fsoft-AIC/MainframeBench","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","code","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7114","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_7114.","url":"https://huggingface.co/datasets/icedwind/x_dataset_7114","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_18.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_18","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7114","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_7114.","url":"https://huggingface.co/datasets/icedwind/x_dataset_7114","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_18","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_18.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_18","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_11.","url":"https://huggingface.co/datasets/suul999922/x_dataset_11","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41414","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_41414.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_41414","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_58","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_58.","url":"https://huggingface.co/datasets/James096/reddit_dataset_58","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7834","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_7834.","url":"https://huggingface.co/datasets/momo1942/x_dataset_7834","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_11","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_11.","url":"https://huggingface.co/datasets/suul999922/x_dataset_11","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41414","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_41414.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_41414","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_58","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_58.","url":"https://huggingface.co/datasets/James096/reddit_dataset_58","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_7834","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_7834.","url":"https://huggingface.co/datasets/momo1942/x_dataset_7834","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62648","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_62648.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_62648","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_62648","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rainbowbridge/x_dataset_62648.","url":"https://huggingface.co/datasets/rainbowbridge/x_dataset_62648","creator_name":"Rain","creator_url":"https://huggingface.co/rainbowbridge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_154","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PlanAPlanB/reddit_dataset_154.","url":"https://huggingface.co/datasets/PlanAPlanB/reddit_dataset_154","creator_name":"Andrei","creator_url":"https://huggingface.co/PlanAPlanB","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_154","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PlanAPlanB/reddit_dataset_154.","url":"https://huggingface.co/datasets/PlanAPlanB/reddit_dataset_154","creator_name":"Andrei","creator_url":"https://huggingface.co/PlanAPlanB","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"synthetic_call_center_summaries","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nExtensive evaluation metrics and attributes such as conciseness, formatting, contextual relevance, tone, and actionability.\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries.","url":"https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"x_dataset_01085","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_01085.","url":"https://huggingface.co/datasets/william-1111/x_dataset_01085","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_01085","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/william-1111/x_dataset_01085.","url":"https://huggingface.co/datasets/william-1111/x_dataset_01085","creator_name":"william","creator_url":"https://huggingface.co/william-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_full","keyword":"summarization","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tNOVEReason_full\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_full.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_full","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"scientific_question-generation","keyword":"summarization","description":"Data originated from: \nhttps://openstax.org.‚Äù\nhttps://openstax.org/details/books/chemistry-2e\n","url":"https://huggingface.co/datasets/leaschuessler/scientific_question-generation","creator_name":"Lea Sch√º√üler","creator_url":"https://huggingface.co/leaschuessler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_232","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Amylyx/x_dataset_232.","url":"https://huggingface.co/datasets/Amylyx/x_dataset_232","creator_name":"jianghonglin30@gmail.com","creator_url":"https://huggingface.co/Amylyx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_232","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Amylyx/x_dataset_232.","url":"https://huggingface.co/datasets/Amylyx/x_dataset_232","creator_name":"jianghonglin30@gmail.com","creator_url":"https://huggingface.co/Amylyx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_4.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_4","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51674","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_51674.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_51674","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_4","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_4.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_4","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_51674","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_51674.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_51674","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wavepulse-radio-summarized-transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tWavePulse Radio Summarized Transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWavePulse Radio Summarized Transcripts is a large-scale dataset containing summarized transcripts from 396 radio stations across the United States, collected between June 26, 2024, and October 3, 2024. The dataset comprises approximately 1.5 million summaries derived from 485,090 hours of radio broadcasts, primarily covering news, talk shows, and political discussions.\nThe raw version of the transcripts is available‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts.","url":"https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text-classification","news-articles-summarization","topic-classification"],"keywords_longer_than_N":true},
	{"name":"wavepulse-radio-summarized-transcripts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tWavePulse Radio Summarized Transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWavePulse Radio Summarized Transcripts is a large-scale dataset containing summarized transcripts from 396 radio stations across the United States, collected between June 26, 2024, and October 3, 2024. The dataset comprises approximately 1.5 million summaries derived from 485,090 hours of radio broadcasts, primarily covering news, talk shows, and political discussions.\nThe raw version of the transcripts is available‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts.","url":"https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text-classification","news-articles-summarization","topic-classification"],"keywords_longer_than_N":true},
	{"name":"Test_1_african_story","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HieuBui1103/Test_1_african_story.","url":"https://huggingface.co/datasets/HieuBui1103/Test_1_african_story","creator_name":"Hieu Trung Bui","creator_url":"https://huggingface.co/HieuBui1103","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_20.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_20","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"calories","keyword":"summarization","description":"LitcherX/calories dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/LitcherX/calories","creator_name":"Adam","creator_url":"https://huggingface.co/LitcherX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","apache-2.0","1K<n<10K","üá∫üá∏ Region: US","biology"],"keywords_longer_than_N":false},
	{"name":"LexAbSumm","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for LexAbSumm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLegal professionals frequently encounter long legal judgments that hold critical insights for their work. While recent advances have led to automated summarization solutions for legal documents, they typically provide generic summaries, which may not meet the diverse information needs of users. To address this gap, we introduce LexAbSumm, a novel dataset designed for aspect-based summarization of legal case decisions, sourced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahmoudAly/LexAbSumm.","url":"https://huggingface.co/datasets/MahmoudAly/LexAbSumm","creator_name":"Mahmoud Aly","creator_url":"https://huggingface.co/MahmoudAly","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","sentence-similarity","English","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060232","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060232.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060232","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"wavepulse-radio-summarized-transcripts","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tWavePulse Radio Summarized Transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWavePulse Radio Summarized Transcripts is a large-scale dataset containing summarized transcripts from 396 radio stations across the United States, collected between June 26, 2024, and October 3, 2024. The dataset comprises approximately 1.5 million summaries derived from 485,090 hours of radio broadcasts, primarily covering news, talk shows, and political discussions.\nThe raw version of the transcripts is available‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts.","url":"https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-summarized-transcripts","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","text-classification","news-articles-summarization","topic-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_20.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_20","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_127","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_127.","url":"https://huggingface.co/datasets/James096/x_dataset_127","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Chinese-Qwen3-235B-Thinking-2507-Distill-100k","keyword":"summarization","description":"\nüìå Note: The English translation of this dataset card is provided below.\n\n\n\t\n\t\t\n\t\tChinese-Qwen3-235B-Thinking-2507-Distill-100k\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nChinese-Qwen3-235B-Thinking-2507-Distill-100k ÊòØ‰∏Ä‰∏™ÂåÖÂê´Á∫¶ 100k Êù°È´òË¥®Èáè‰∏≠ÊñáÊé®ÁêÜ‰∏éÊåá‰ª§Êï∞ÊçÆÁöÑÊï∞ÊçÆÈõÜÔºåÁî± Qwen-3-235B-A22B-Thinking-2507ÔºàÂÆòÊñπ Thinking Ê®°ÂºèÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶ 32KÔºâËí∏È¶èÁîüÊàê„ÄÇ  \nËØ•Êï∞ÊçÆÈõÜË¶ÜÁõñ‰∫ÜÂ§ö‰∏™ÈáçË¶ÅÈ¢ÜÂüüÔºö  \n\nÊï∞Â≠¶‰∏éÂ∑•Á®ã‰ªªÂä°ÔºàMathematics, Applied Math, Advanced MathÔºâ  \nÈÄöÁî®Áü•ËØÜ‰∏éÂÜô‰ΩúÔºàGeneral Knowledge, Language & WritingÔºâ  \nÊäÄÊúØ‰∏éÁºñÁ®ãÔºàTechnology & ProgrammingÔºâ  \nÂïÜ‰∏ö‰∏éÁªèÊµéÔºàBusiness & EconomicsÔºâ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jackrong/Chinese-Qwen3-235B-Thinking-2507-Distill-100k.","url":"https://huggingface.co/datasets/Jackrong/Chinese-Qwen3-235B-Thinking-2507-Distill-100k","creator_name":"JIRONG","creator_url":"https://huggingface.co/Jackrong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","table-question-answering","summarization","translation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_060232","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_060232.","url":"https://huggingface.co/datasets/john-1111/x_dataset_060232","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_127","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/x_dataset_127.","url":"https://huggingface.co/datasets/James096/x_dataset_127","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"MLS_Long_ContentPlan","keyword":"summarization","description":"YSFarag/MLS_Long_ContentPlan dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/YSFarag/MLS_Long_ContentPlan","creator_name":"Youssef Farag","creator_url":"https://huggingface.co/YSFarag","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","English","odc-by","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MusicSem","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for MusicSem\n\t\n\n\n\n\nThis dataset contains 35977 entries of text-audio pairs. There is an accompanying test set of size 480 which is withheld for leaderboard purposes. Please reach out to authors for further access.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Rebecca Salganik, Teng Tu, Fei-Yueh Chen, Xiaohao Liu, Kaifeng Lu, Ethan Luvisia, Zhiyao Duan, Guillaume Salha-Galvan, Anson Kahng, Yunshan Ma, Jian Kang\nLanguage(s) : English\nLicense: MIT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rsalga/MusicSem.","url":"https://huggingface.co/datasets/Rsalga/MusicSem","creator_name":"Rebecca Salganik","creator_url":"https://huggingface.co/Rsalga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","summarization","feature-extraction","audio-text-to-text","English"],"keywords_longer_than_N":true},
	{"name":"tawiki","keyword":"summarization","description":"Here‚Äôs a detailed README.md (Model Card / Dataset Card) for your Tamil Wikipedia dataset on Hugging Face, formatted in Markdown:\n\n\n\t\n\t\t\n\t\tüß† Tamil Wikipedia Dataset (tawiki)\n\t\n\n\nThe Tamil Wikipedia (tawiki) dataset is a cleaned and preprocessed dump of the Tamil language Wikipedia, curated for use in Natural Language Processing (NLP) tasks such as language modeling, summarization, machine translation, and question answering.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìö Dataset Overview\n\t\n\n\nLanguage: Tamil (ta)\nSource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hemanth-thunder/tawiki.","url":"https://huggingface.co/datasets/Hemanth-thunder/tawiki","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Tamil","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_204","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_204.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_204","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_204","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/reddit_dataset_204.","url":"https://huggingface.co/datasets/goldentraversy07/reddit_dataset_204","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"xsum_tiny","keyword":"summarization","description":"This dataset is a subset of https://huggingface.co/datasets/EdinburghNLP/xsum.\nThe training set is composed of 2,000 examples of the original training set and the test set is composed of 1,000 examples of the original validation set.\n","url":"https://huggingface.co/datasets/llamafactory/xsum_tiny","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"arxiv-llama4-maverick-abstract","keyword":"summarization","description":"\n\t\n\t\t\n\t\tarXiv Abstract Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality abstracts for scientific papers from the arXiv repository, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each abstract provides a concise, accurate overview of the research paper while preserving key technical details and contributions.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality abstracts: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/arxiv-llama4-maverick-abstract.","url":"https://huggingface.co/datasets/PursuitOfDataScience/arxiv-llama4-maverick-abstract","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"arxiv-llama4-maverick-abstract","keyword":"summarization","description":"\n\t\n\t\t\n\t\tarXiv Abstract Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality abstracts for scientific papers from the arXiv repository, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each abstract provides a concise, accurate overview of the research paper while preserving key technical details and contributions.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality abstracts: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/arxiv-llama4-maverick-abstract.","url":"https://huggingface.co/datasets/PursuitOfDataScience/arxiv-llama4-maverick-abstract","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"summexecedit","keyword":"summarization","description":"\n\t\n\t\t\n\t\tFactual Consistency in Summarization\n\t\n\nEvaluate your model's ability to detect and explain the factual inconsistency in summaries. This repo contains the benchmark from our paper \"SummExecEdit: A Factual Consistency Benchmark in Summarization with Executable Edits\".\n\n\t\n\t\t\n\t\tSummExecEdit Benchmark\n\t\n\nThis benchmark is built over our previous benchmark - SummEdits. Consistent summaries are used from SummEdits. New inconsistent and challenging summaries are generated using executable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/summexecedit.","url":"https://huggingface.co/datasets/Salesforce/summexecedit","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gemini-bavarian-tagesschau-v0.1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGemini-powered Bavarian Tagesschau Dataset\n\t\n\n\nThis dataset hosts various 2024 Tagesschau articles from the Awesome Tagesschau dataset that were translated into Bavarian with Gemini 2.5 Flash.\nThe resulting dataset has 12,546 Bavarian articles in total, including metadata information like tags or ressort/topic.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Format\n\t\n\nHere's an example of the JSON format, that is used for this dataset:\n{\n\"sophoraId\": \"eilmeldung-ampelregierung-scholz-entlaesst-lindner-100\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-tagesschau-v0.1.","url":"https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-tagesschau-v0.1","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Bavarian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Kuno-RZN-D1","keyword":"summarization","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThe VinkuraAI/Kuno-RZN-D1 is a specially curated dataset for training LLaMA (3.1 and 3.2) models, with a focus on reasoning tasks. It is available for download on Hugging Face and comes with detailed instructions to guide model training for complex reasoning capabilities.\nThis dataset includes a variety of tasks such as text-based reasoning, conversational analysis, and structured reasoning prompts. The goal is to enhance the performance of LLaMA models in reasoning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VinkuraAI/Kuno-RZN-D1.","url":"https://huggingface.co/datasets/VinkuraAI/Kuno-RZN-D1","creator_name":"Vinkura AI","creator_url":"https://huggingface.co/VinkuraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_117","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_117.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_117","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_117","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_117.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_117","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_240","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_240.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_240","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_44.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_44","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trungnam299/reddit_dataset_44.","url":"https://huggingface.co/datasets/trungnam299/reddit_dataset_44","creator_name":"Trung Nam","creator_url":"https://huggingface.co/trungnam299","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0603159","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0603159.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0603159","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_26","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/reddit_dataset_26.","url":"https://huggingface.co/datasets/andreans27/reddit_dataset_26","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V3\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nAdapted prompt from yourbench\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_240","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/reddit_dataset_240.","url":"https://huggingface.co/datasets/sm4rtdev/reddit_dataset_240","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zengsdfew/reddit_dataset_44.","url":"https://huggingface.co/datasets/zengsdfew/reddit_dataset_44","creator_name":"miner3","creator_url":"https://huggingface.co/zengsdfew","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_44","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trungnam299/reddit_dataset_44.","url":"https://huggingface.co/datasets/trungnam299/reddit_dataset_44","creator_name":"Trung Nam","creator_url":"https://huggingface.co/trungnam299","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0603159","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/john-1111/x_dataset_0603159.","url":"https://huggingface.co/datasets/john-1111/x_dataset_0603159","creator_name":"john","creator_url":"https://huggingface.co/john-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_26","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreans27/reddit_dataset_26.","url":"https://huggingface.co/datasets/andreans27/reddit_dataset_26","creator_name":"Andrean","creator_url":"https://huggingface.co/andreans27","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Shrimad_Bhagavad_Gita","keyword":"summarization","description":"snskrt/Shrimad_Bhagavad_Gita dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/snskrt/Shrimad_Bhagavad_Gita","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Ultimate-Malayalam-Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tAbout\n\t\n\nThis is a large dataset that contains a lot of (more than 6 million) lines of malayalam text. The dataset is created by combining many other malayalam datasets, and cleaning them.\nThe dataset is ideal to train or fine tune a Large Language Model on Malayalam language.\n\n\t\n\t\t\n\t\n\t\n\t\tCredits\n\t\n\n\nhttps://www.kaggle.com/datasets/disisbig/malyalam-news-dataset\nhttps://www.kaggle.com/datasets/parvmodi/english-to-malayalam-machine-translation-dataset?select=train.ml‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Arjun-G-Ravi/Ultimate-Malayalam-Dataset.","url":"https://huggingface.co/datasets/Arjun-G-Ravi/Ultimate-Malayalam-Dataset","creator_name":"Arjun G Ravi","creator_url":"https://huggingface.co/Arjun-G-Ravi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","Malayalam","mit","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_245","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/x_dataset_245.","url":"https://huggingface.co/datasets/williamlewis0620/x_dataset_245","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"zelensky-speeches","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"zelenskiy-speeches\"\n\t\n\nSpeeches given by the president of Ukraine Volodymyr ZelenskyLanguages: Ukrainian, EnglishSource: president.gov.uaAuto-updated daily by Github Actions of zelensky-speech-fetcherLicense: CC BY-NC-ND 4.0 Deed\n","url":"https://huggingface.co/datasets/slava-medvedev/zelensky-speeches","creator_name":"Viacheslav Medvediev","creator_url":"https://huggingface.co/slava-medvedev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"x_dataset_245","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/williamlewis0620/x_dataset_245.","url":"https://huggingface.co/datasets/williamlewis0620/x_dataset_245","creator_name":"William Lewis","creator_url":"https://huggingface.co/williamlewis0620","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"lex-fridman-podcast","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLex Fridman Podcast Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains transcriptions of conversations from the Lex Fridman Podcast, featuring in-depth discussions on artificial intelligence, science, technology, philosophy, and more. The dataset includes 441 transcribed episodes, covering most of the podcast episodes up to January 2025 (excluding 10 episodes).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nTitle: String - The title of the podcast episode‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aditya0619/lex-fridman-podcast.","url":"https://huggingface.co/datasets/Aditya0619/lex-fridman-podcast","creator_name":"Aditya Channa","creator_url":"https://huggingface.co/Aditya0619","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_3.","url":"https://huggingface.co/datasets/gk4u/x_dataset_3","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_214449","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_214449.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_214449","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-travail","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du travail, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_32","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_32.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_32","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"xsum-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tXSum Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries of BBC news articles from the XSum (Extreme Summarization) dataset, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of the main story while preserving key facts and context.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/xsum-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/xsum-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"xsum-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tXSum Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries of BBC news articles from the XSum (Extreme Summarization) dataset, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of the main story while preserving key facts and context.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/xsum-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/xsum-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_3","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/x_dataset_3.","url":"https://huggingface.co/datasets/gk4u/x_dataset_3","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_ds_214449","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zkpbeats/reddit_ds_214449.","url":"https://huggingface.co/datasets/zkpbeats/reddit_ds_214449","creator_name":"YDS","creator_url":"https://huggingface.co/zkpbeats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_32","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axioris/reddit_dataset_32.","url":"https://huggingface.co/datasets/Axioris/reddit_dataset_32","creator_name":"DaneFoster","creator_url":"https://huggingface.co/Axioris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"code-organisation-judiciaire","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode de l'organisation judiciaire, non-instruct (2025-05-31)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_69","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_69.","url":"https://huggingface.co/datasets/James096/reddit_dataset_69","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_69","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/James096/reddit_dataset_69.","url":"https://huggingface.co/datasets/James096/reddit_dataset_69","creator_name":"Brown","creator_url":"https://huggingface.co/James096","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Estonian-Text-Simplification","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tEstonian Text Simplification\n\t\n\nThis repository contains resources and models for Estonian text simplification, including datasets and pre-trained models.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\n\nsimplification_training_set.json: A dataset used to fine-tune LLaMA 3.1 for text simplification.\n\nsrc: The source of the data.\noriginal: The original sentence to be simplified.\nsimpl_lex: A lexical simplification (may be empty).\nsimpl_final: The final simplified sentence.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vulturuldemare/Estonian-Text-Simplification.","url":"https://huggingface.co/datasets/vulturuldemare/Estonian-Text-Simplification","creator_name":"Eduard Barbu","creator_url":"https://huggingface.co/vulturuldemare","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-simplification","Estonian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GPT-OSS-120B-Distilled-Reasoning-math","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tGPT-oss-120B-Distilled-Reasoning-math Dataset\n\t\n\nData Source Model: gpt-oss-120bTask Type: Mathematical Problem SolvingData Format: JSON Lines\nFields: Generator, Category, Input, CoT_Native_Reasoning, Reasoning, Answer  \n\n\n\t\n\t\t\n\t\tCore Statistics\n\t\n\nGenerated complete reasoning processes and answers using gpt-oss-120b (MXFP4).The text length of the dataset reflects the depth and complexity of its content. I have statistically analyzed the lengths of the input (question), Reasoning, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jackrong/GPT-OSS-120B-Distilled-Reasoning-math.","url":"https://huggingface.co/datasets/Jackrong/GPT-OSS-120B-Distilled-Reasoning-math","creator_name":"JIRONG","creator_url":"https://huggingface.co/Jackrong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","table-question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reinsurance-contracts-classification","keyword":"summarization","description":"This dataset contains the full text and the classification of 6671 reinsurance-related documents extracted from SEC filings. The documents include reinsurance contracts, but also ancillary documents, such as amendments, endorsements, extensions, and other documents referring to reinsurance agreement.\nThe documents have been classified by three language models: qwen3-235b-a22b-2507, gpt-oss-120b and gemini-2.5-flash-lite. Manual inspection of the classification results reveals that qwen3 is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreaaltomani/reinsurance-contracts-classification.","url":"https://huggingface.co/datasets/andreaaltomani/reinsurance-contracts-classification","creator_name":"Andrea Altomani","creator_url":"https://huggingface.co/andreaaltomani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"synthetic-confidential-information-injected-business-excerpts","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSynthetic Confidential Information Injected Business Excerpts\n\t\n\nThis dataset aims to provide business report excerpts which contain relevant confidential/sensitive information.\nThis includes mentions of :\n  1. Internal Marketing Strategies.\n  2. Proprietary Product Composition.\n  3. License Internals.\n  4. Internal Sales Projections.\n  5. Confidential Patent Details.\n  6. others.\n\nThe dataset contains around 1k business excerpt - Reasons pairs. The Reason field contains the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rohit-D/synthetic-confidential-information-injected-business-excerpts.","url":"https://huggingface.co/datasets/Rohit-D/synthetic-confidential-information-injected-business-excerpts","creator_name":"Rohit D","creator_url":"https://huggingface.co/Rohit-D","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","feature-extraction","summarization","English"],"keywords_longer_than_N":true},
	{"name":"RSTeller_metadata","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMetadata for RSTeller\n\t\n\nThis dataset contains the necessary metadata for the dataset SlytherinGe/RSTeller.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe metadata table provides detailed information for the RSTeller dataset, with the following columns:\n\npatch_id: The primary key of the table, corresponding to the \"__key__\" or the \"patch_id\" field in the JSON of the RSTeller dataset.\n\npatch_lat and patch_lon: The latitude and longitude coordinates of the patch center in WGS84‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata.","url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_192","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crystal1101/x_dataset_192.","url":"https://huggingface.co/datasets/Crystal1101/x_dataset_192","creator_name":"Butterfly","creator_url":"https://huggingface.co/Crystal1101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"kurdish-wikipedia-articles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nExtracted from the wikidump. There are summaries and categories available for each article. Will look into adding them later.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/kurdish-wikipedia-articles\", split=\"train\")\nds\n\nDataset({\n    features: ['id', 'url', 'title', 'text'],\n    num_rows: 63076\n})\n\n","url":"https://huggingface.co/datasets/nazimali/kurdish-wikipedia-articles","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","summarization","Kurdish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_192","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crystal1101/x_dataset_192.","url":"https://huggingface.co/datasets/Crystal1101/x_dataset_192","creator_name":"Butterfly","creator_url":"https://huggingface.co/Crystal1101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlemdatameow/x_dataset_17.","url":"https://huggingface.co/datasets/mlemdatameow/x_dataset_17","creator_name":"Mlem Meow","creator_url":"https://huggingface.co/mlemdatameow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_118","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_118.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_118","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0507238","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0507238.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0507238","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"twisc","keyword":"summarization","description":"\n\t\n\t\t\n\t\tTaiwan-Indictment-Summarization-Corpus (TWISC)\n\t\n\nTaiwan-Indictment-Summarization-Corpus (TWISC) is a dataset designed for legal judgment prediction and legal text summarization. It is collected from Taiwan Ministry of Justice and covers data from 2018/06 to 2021/06.\nThis dataset is used in the paper Improving Colloquial Case Legal Judgment Prediction via Abstractive Text Summarization published in Computer Law & Security Review (2023).\nWe express our gratitude to Professor Chia-Hui‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yxhong-tw/twisc.","url":"https://huggingface.co/datasets/yxhong-tw/twisc","creator_name":"Yu-Xiang Hong","creator_url":"https://huggingface.co/yxhong-tw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x_dataset_17","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlemdatameow/x_dataset_17.","url":"https://huggingface.co/datasets/mlemdatameow/x_dataset_17","creator_name":"Mlem Meow","creator_url":"https://huggingface.co/mlemdatameow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_118","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_118.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_118","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0507238","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marry-1111/x_dataset_0507238.","url":"https://huggingface.co/datasets/marry-1111/x_dataset_0507238","creator_name":"marry","creator_url":"https://huggingface.co/marry-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"gigatrue-slovak","keyword":"summarization","description":"\n\t\n\t\t\n\t\tGigatrue Slovak abstractive summarisation dataset.\n\t\n\nSynthetic Gigaword dataset translated to Slovak.\nSame as https://huggingface.co/datasets/Plasmoxy/gigatrue but translated to Slovak using SeamlessM4T-v2 (https://huggingface.co/docs/transformers/en/model_doc/seamless_m4t_v2). \nOriginal dataset adapted from https://huggingface.co/datasets/Harvard/gigaword.\nThis work is supported by the EU NextGenerationEU through the  Recovery and Resilience Plan for Slovakia under the project  No.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Plasmoxy/gigatrue-slovak.","url":"https://huggingface.co/datasets/Plasmoxy/gigatrue-slovak","creator_name":"Sebasti√°n Petr√≠k","creator_url":"https://huggingface.co/Plasmoxy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Slovak","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"MemoryAgentBench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüöß Update\n\t\n\n\n \n(Sep 29th, 2025) We updated our paper, where we removed some in-efficient and high-cost samples. We also added a sub-sample of DetectiveQA. \n\n \n(July 7th, 2025) We released the initial version of our datasets.\n\n \n(July 22nd, 2025) We modify the datasets slightly, adding the keypoints in LRU and change the uuid into qa_pair_ids. The question_ids is only used in Longmemeval task.\n\n \n(July 26th, 2025) We fixed bug on qa_pair_ids.\n\n \n(Aug.5th, 2025) We removed the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai-hyz/MemoryAgentBench.","url":"https://huggingface.co/datasets/ai-hyz/MemoryAgentBench","creator_name":"YUANZHE HU","creator_url":"https://huggingface.co/ai-hyz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","summarization","text-classification","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_240","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_240.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_240","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_240","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm4rtdev/x_dataset_240.","url":"https://huggingface.co/datasets/sm4rtdev/x_dataset_240","creator_name":"ElonScott","creator_url":"https://huggingface.co/sm4rtdev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_152","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/reddit_dataset_152.","url":"https://huggingface.co/datasets/suul999922/reddit_dataset_152","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"CyberExploitDB","keyword":"summarization","description":"model_details:\ndescription:\n  A comprehensive database and analysis tool for cyber exploits, vulnerabilities, and related information. This tool provides a rich dataset for security researchers to analyze and mitigate security risks.\ntask_categories:\n\ndata_analysis\n\nstructure:\n\ndata/\nexploits.csv\nvulnerabilities.csv\n\n\nassets/\nfavicon.svg\n\n\n.streamlit/\nconfig.toml\n\n\nmain.py\ndata_processor.py\nvisualizations.py\nREADME.md\n\nintended_use:\n  Designed for security researchers, developers, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/boapro/CyberExploitDB.","url":"https://huggingface.co/datasets/boapro/CyberExploitDB","creator_name":"Boluwaji Oluwaseyi Adepoju","creator_url":"https://huggingface.co/boapro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","üá∫üá∏ Region: US","exploits"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_152","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/reddit_dataset_152.","url":"https://huggingface.co/datasets/suul999922/reddit_dataset_152","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"RoleAgentBench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tRoleAgentBench\n\t\n\n\nPaper: RoleAgent: Building, Interacting, and Benchmarking High-quality Role-Playing Agents from Scripts\n\nWe construct the RoleAgentBench including 128 roles from 5 Chinese and 20 English scripts. Besides, our RoleAgentBench evaluates two aspects (i.e., the qualities of the overall agent simulation and the specific memory system) with 4 subtasks, details as follows. Note that all questions and answers are generated based on the script and GPT-4, which are then revised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RoleAgent/RoleAgentBench.","url":"https://huggingface.co/datasets/RoleAgent/RoleAgentBench","creator_name":"RoleAgent","creator_url":"https://huggingface.co/RoleAgent","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41362","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_41362.","url":"https://huggingface.co/datasets/icedwind/x_dataset_41362","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_41362","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/icedwind/x_dataset_41362.","url":"https://huggingface.co/datasets/icedwind/x_dataset_41362","creator_name":"Felix","creator_url":"https://huggingface.co/icedwind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"bioinstruct","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for BioInstruct\n\t\n\nGitHub repo: https://github.com/bio-nlp/BioInstruct\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBioInstruct is a dataset of 25k instructions and demonstrations generated by OpenAI's GPT-4 engine in July 2023. \nThis instruction data can be used to conduct instruction-tuning for language models (e.g. Llama) and make the language model follow biomedical instruction better. \nImprovements of Llama on 9 common BioMedical tasks are shown in the result section. \nTaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-nlp-umass/bioinstruct.","url":"https://huggingface.co/datasets/bio-nlp-umass/bioinstruct","creator_name":"UMass BioNLP Lab","creator_url":"https://huggingface.co/bio-nlp-umass","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55847","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_55847.","url":"https://huggingface.co/datasets/momo1942/x_dataset_55847","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0403203","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0403203.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0403203","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55847","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_55847.","url":"https://huggingface.co/datasets/momo1942/x_dataset_55847","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0403203","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0403203.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0403203","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_47139.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_47139","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"redline_bench","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for \"redline_bench\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/leohpark/redline_bench","creator_name":"Leonard Park","creator_url":"https://huggingface.co/leohpark","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"SciEvo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüéì SciEvo: A Longitudinal Scientometric Dataset\n\t\n\n\n\t\n\t\t\n\t\tBest Paper Award at the  1st Workshop on Preparing Good Data for Generative AI: Challenges and Approaches (Good-Data @ AAAI 2025)\n\t\n\nSciEvo is a large-scale dataset that spans over 30 years of academic literature from arXiv, designed to support scientometric research and the study of scientific knowledge evolution. By providing a comprehensive collection of over two million publications, including detailed metadata and citation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ahren09/SciEvo.","url":"https://huggingface.co/datasets/Ahren09/SciEvo","creator_name":"Yiqiao Jin","creator_url":"https://huggingface.co/Ahren09","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_47139.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_47139","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2244","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_2244.","url":"https://huggingface.co/datasets/momo1942/x_dataset_2244","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"PatthuPattu-Nedunalvaadai","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìù Dataset Card: Nedunalvaadai\n\t\n\nThis dataset contains the classical Sangam Tamil literature work Nedunalvaadai, covering all 5 parts.\nEach entry includes:\nTopic (section heading)\nPoem lines (original verses)\nExplanation (detailed meaning in Tamil)\nIt is useful for Tamil NLP, literary analysis, translation tasks, and language modeling.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nüìñ Language Modeling\nüîé Poem ‚Üí Explanation Mapping\nüó£ Text Generation (Tamil)\nüî§ Text Cleaning & Preprocessing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/PatthuPattu-Nedunalvaadai.","url":"https://huggingface.co/datasets/TamilThagaval/PatthuPattu-Nedunalvaadai","creator_name":"‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","summarization","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_202507","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/x_dataset_202507.","url":"https://huggingface.co/datasets/goldentraversy07/x_dataset_202507","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"play_market_2025_1m_reviews_500_titles","keyword":"summarization","description":"\n\t\n\t\t\n\t\tüìä Play Market 2025 - 1M Reviews, 550+ Titles\n\t\n\nThis dataset provides cleaned and structured data from the Google Play Market, featuring over 1 million user reviews, detailed metadata for 335 games and 217 applications, and processed fields for advanced analysis.\n\n\n\t\n\t\t\n\t\tüßæ Dataset Contents\n\t\n\n\n\t\n\t\t\n\t\tapps_info.csv\n\t\n\nMetadata for mobile applications, including:\n\napp_id: Unique identifier\napp_name: Name of the app\ndescription: Cleaned full description\nscore: Average user rating (0‚Äì5)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dmytrobuhai/play_market_2025_1m_reviews_500_titles.","url":"https://huggingface.co/datasets/dmytrobuhai/play_market_2025_1m_reviews_500_titles","creator_name":"Dmytro Buhai","creator_url":"https://huggingface.co/dmytrobuhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","zero-shot-classification","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2244","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_2244.","url":"https://huggingface.co/datasets/momo1942/x_dataset_2244","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_202507","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goldentraversy07/x_dataset_202507.","url":"https://huggingface.co/datasets/goldentraversy07/x_dataset_202507","creator_name":"Steven K","creator_url":"https://huggingface.co/goldentraversy07","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Egyptian-text-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Text Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains text-summary pairs in Egyptian Arabic designed for training and evaluating text summarization models.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: Egyptian Arabic (ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸÑŸÖÿµÿ±Ÿäÿ©)\nTask: Text Summarization\nFormat: Text-summary pairs with topic categorization\nContent: Diverse topics with natural Egyptian Arabic usage\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Original text content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization.","url":"https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Egyptian-text-summarization","keyword":"summarization","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Text Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains text-summary pairs in Egyptian Arabic designed for training and evaluating text summarization models.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: Egyptian Arabic (ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸÑŸÖÿµÿ±Ÿäÿ©)\nTask: Text Summarization\nFormat: Text-summary pairs with topic categorization\nContent: Diverse topics with natural Egyptian Arabic usage\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Original text content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization.","url":"https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"benchmark_1k","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBenchmark 1K Dataset\n\t\n\nA curated dataset of 1,000 high-quality prompts designed for benchmarking Large Language Model (LLM) performance across various metrics including latency, throughput, and response quality.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nSize: 100 prompts\nFormat: JSONL (JSON Lines)\nAverage Token Length: Variable (computed from actual data; see Stats)\nPurpose: LLM benchmarking and performance testing\nDomain: General knowledge, historical content, and analytical writing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raffel36/benchmark_1k.","url":"https://huggingface.co/datasets/raffel36/benchmark_1k","creator_name":"Raffel","creator_url":"https://huggingface.co/raffel36","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_246","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stard8447/reddit_dataset_246.","url":"https://huggingface.co/datasets/stard8447/reddit_dataset_246","creator_name":"omarwalter","creator_url":"https://huggingface.co/stard8447","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0707238","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0707238.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0707238","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_155","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_155.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_155","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_107","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wolfghost/reddit_dataset_107.","url":"https://huggingface.co/datasets/wolfghost/reddit_dataset_107","creator_name":"ghost","creator_url":"https://huggingface.co/wolfghost","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_246","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stard8447/reddit_dataset_246.","url":"https://huggingface.co/datasets/stard8447/reddit_dataset_246","creator_name":"omarwalter","creator_url":"https://huggingface.co/stard8447","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0707238","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0707238.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0707238","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_155","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_155.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_155","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_107","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wolfghost/reddit_dataset_107.","url":"https://huggingface.co/datasets/wolfghost/reddit_dataset_107","creator_name":"ghost","creator_url":"https://huggingface.co/wolfghost","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_20.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_20","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"VSCD-dataset","keyword":"summarization","description":"ElMater06/VSCD-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ElMater06/VSCD-dataset","creator_name":"El Matero","creator_url":"https://huggingface.co/ElMater06","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0710195","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0710195.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0710195","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_20","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_20.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_20","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0710195","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0710195.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0710195","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Urdu-Low-Resource-Language-Dataset","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Low-Resource-Language-Dataset\n\t\n\nThis dataset is designed to aid Natural Language Processing (NLP) research on low-resource languages, particularly Urdu. It includes structured datasets and preprocessing tools curated from the BBC Urdu website.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains articles, summaries, and topics scraped from BBC Urdu. It is structured into training and testing datasets for machine learning applications. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Subayyal/Urdu-Low-Resource-Language-Dataset.","url":"https://huggingface.co/datasets/Subayyal/Urdu-Low-Resource-Language-Dataset","creator_name":"Subayyal Sheikh","creator_url":"https://huggingface.co/Subayyal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","sentence-similarity","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47268","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_47268.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_47268","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Thenayareport.ai","keyword":"summarization","description":"sreyasreevenkataraman/Thenayareport.ai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sreyasreevenkataraman/Thenayareport.ai","creator_name":"sreya sree","creator_url":"https://huggingface.co/sreyasreevenkataraman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","Hindi"],"keywords_longer_than_N":true},
	{"name":"x_dataset_47268","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_47268.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_47268","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"myanmar_spoken_corpus","keyword":"summarization","description":"\n\t\n\t\t\n\t\tMyanmar Spoken Corpus (Version 1.0)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMyanmar Spoken Corpus is a high-quality, but not fully CLEAN, open dataset of spoken Myanmar sentences designed to support NLP and ASR applications. The dataset focuses on providing clean and structured spoken language data for advancing Myanmar language technology.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of Rows:\nLocal Parquet file: 16,020,011 rows\nHugging Face Dataset Viewer: 15,728,640 rows\n\n\nFile Size: 1.78 GB (Parquet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar_spoken_corpus.","url":"https://huggingface.co/datasets/freococo/myanmar_spoken_corpus","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","Burmese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GPT-4-Prompts","keyword":"summarization","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\nAbstract:\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\nTable of Contents:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts.","url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"x_dataset_245","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_245.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_245","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_245","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arrmlet/x_dataset_245.","url":"https://huggingface.co/datasets/arrmlet/x_dataset_245","creator_name":"Volodymyr Truba","creator_url":"https://huggingface.co/arrmlet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_172","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_172.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_172","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_16.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_16","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0712117","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0712117.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0712117","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"korean-judgment-easyread-transform","keyword":"summarization","description":"Suchae/korean-judgment-easyread-transform dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Suchae/korean-judgment-easyread-transform","creator_name":"Jeong Suchae","creator_url":"https://huggingface.co/Suchae","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit_dataset_172","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 Reddit Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed Reddit data. The data is continuously updated by network miners, providing a real-time stream of Reddit content for various analytical and machine learning tasks.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gk4u/reddit_dataset_172.","url":"https://huggingface.co/datasets/gk4u/reddit_dataset_172","creator_name":"John Snow","creator_url":"https://huggingface.co/gk4u","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_16","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimbuja/x_dataset_16.","url":"https://huggingface.co/datasets/kimbuja/x_dataset_16","creator_name":"buja","creator_url":"https://huggingface.co/kimbuja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0712117","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zephyr-1111/x_dataset_0712117.","url":"https://huggingface.co/datasets/zephyr-1111/x_dataset_0712117","creator_name":"zephyr","creator_url":"https://huggingface.co/zephyr-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_104","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/x_dataset_104.","url":"https://huggingface.co/datasets/smmrokn/x_dataset_104","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_History_11th","keyword":"summarization","description":"KadamParth/NCERT_History_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_History_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_104","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smmrokn/x_dataset_104.","url":"https://huggingface.co/datasets/smmrokn/x_dataset_104","creator_name":"Mohammad Mahdi","creator_url":"https://huggingface.co/smmrokn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_39.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_39","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsHeadlines","keyword":"summarization","description":"Remeinium/SinhalaNewsHeadlines dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Remeinium/SinhalaNewsHeadlines","creator_name":"Remeinium AI","creator_url":"https://huggingface.co/Remeinium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","sentence-similarity","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_19.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_19","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_39","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_39.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_39","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_19","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_19.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_19","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_2.","url":"https://huggingface.co/datasets/suul999922/x_dataset_2","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_55139.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_55139","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_91","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_91.","url":"https://huggingface.co/datasets/coldmind/x_dataset_91","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_2","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_2.","url":"https://huggingface.co/datasets/suul999922/x_dataset_2","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_55139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StormKing99/x_dataset_55139.","url":"https://huggingface.co/datasets/StormKing99/x_dataset_55139","creator_name":"Storm King","creator_url":"https://huggingface.co/StormKing99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_91","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coldmind/x_dataset_91.","url":"https://huggingface.co/datasets/coldmind/x_dataset_91","creator_name":"Toc","creator_url":"https://huggingface.co/coldmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"System-Response-100K","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSystem-Response-100K dataset\n\t\n\nThis dataset contains text and code for machine learning tasks including:\n\nText Generation\nText Classification\nSummarization\nQuestion Answering\n\nThe dataset includes text formatted in JSON and is in English.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of entries: Not specified in the information you provided.\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nText\nCode\n\n\n\t\n\t\t\n\t\tFormats\n\t\n\n\nJSON\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish\n\n\n\t\n\t\t\n\t\tGetting Started\n\t\n\nThis section can include‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/System-Response-100K.","url":"https://huggingface.co/datasets/prithivMLmods/System-Response-100K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"code-service-national","keyword":"summarization","description":"\n\t\n\t\t\n\t\tCode du service national, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_28.","url":"https://huggingface.co/datasets/suul999922/x_dataset_28","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_28","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suul999922/x_dataset_28.","url":"https://huggingface.co/datasets/suul999922/x_dataset_28","creator_name":"mong","creator_url":"https://huggingface.co/suul999922","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_22.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_22","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_020216","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_020216.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_020216","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_130","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_130.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_130","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"toxic-dialogue-summarisation","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [Aditya Singh]\nLanguage(s) (NLP): [English]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [Grok3]\n\t\n\n\n\n\nRepository: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/majorSeaweed/toxic-dialogue-summarisation.","url":"https://huggingface.co/datasets/majorSeaweed/toxic-dialogue-summarisation","creator_name":"Aditya Singh","creator_url":"https://huggingface.co/majorSeaweed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"x_dataset_22","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/futuremoon/x_dataset_22.","url":"https://huggingface.co/datasets/futuremoon/x_dataset_22","creator_name":"futuremoon","creator_url":"https://huggingface.co/futuremoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_020216","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michael-1111/x_dataset_020216.","url":"https://huggingface.co/datasets/michael-1111/x_dataset_020216","creator_name":"michael","creator_url":"https://huggingface.co/michael-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_130","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Spark0801/x_dataset_130.","url":"https://huggingface.co/datasets/Spark0801/x_dataset_130","creator_name":"SparkLiu","creator_url":"https://huggingface.co/Spark0801","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36129","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_36129.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_36129","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_6th","keyword":"summarization","description":"KadamParth/NCERT_Science_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"x_dataset_36129","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LadyMia/x_dataset_36129.","url":"https://huggingface.co/datasets/LadyMia/x_dataset_36129","creator_name":"Mia Cynthia","creator_url":"https://huggingface.co/LadyMia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"discursos-senado-legislatura-56","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDiscursos da 56¬™ Legislatura do Senado Federal\n\t\n\n\n\t\n\t\t\n\t\tVis√£o geral\n\t\n\nCorpus de pronunciamentos do Plen√°rio do Senado Federal durante a 56¬™ Legislatura (2019‚Äì2022), coletados via API p√∫blica e consolidados em Parquet. Cada linha √© um pronunciamento com metadados e texto integral quando dispon√≠vel.\n\n\t\n\t\t\n\t\tDetalhes do dataset\n\t\n\n\n\t\n\t\t\n\t\tDescri√ß√£o\n\t\n\n\nPeriodo: 2019-02-01 a 2023-01-01\n\nUnidade: pronunciamento no Plen√°rio do Senado\n\nFormato: Parquet (colunar, comprimido)  \n\nCampos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56.","url":"https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56","creator_name":"Fabricio Fernandes Santana","creator_url":"https://huggingface.co/fabriciosantana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","summarization","text-retrieval","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_248","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/x_dataset_248.","url":"https://huggingface.co/datasets/veyhoranohy/x_dataset_248","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"GraSCCo","keyword":"summarization","description":"\n\t\n\t\t\n\t\tDataset Card for GraSCCo\n\t\n\nThe dataset contains clinical discharge summaries along with their corresponding summarizations. The source texts are from the GraSCCo dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe summarization texts were created using ChatGPT-3.5, followed by manual corrections and refinements. As mentioned in the GraSCCo paper, the source texts were synthetically generated based on real medical data. Consequently, the texts are no longer medically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/johannsr/GraSCCo.","url":"https://huggingface.co/datasets/johannsr/GraSCCo","creator_name":"Johann Simon Reichel","creator_url":"https://huggingface.co/johannsr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gpt4-chain-of-density","keyword":"summarization","description":"\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThe following is a dataset which consists of some chain of density summaries which we generated using GPT-4. The approach is slightly modified to account for GPT-4 timeouts with some additional validation that we added using the Instructor Library.\nWe wrote a short blog about how we generated this date here\nHere's a quick summary of the individual files that we have\n\nsummarization_20, summarization_50 and summarization_all are the respective .jsonl files that we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ivanleomk/gpt4-chain-of-density.","url":"https://huggingface.co/datasets/ivanleomk/gpt4-chain-of-density","creator_name":"Ivan","creator_url":"https://huggingface.co/ivanleomk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"x_dataset_10290","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10290.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10290","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"Microsoft_Learn","keyword":"summarization","description":"PetraAI/Microsoft_Learn dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PetraAI/Microsoft_Learn","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","fill-mask","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"x_dataset_248","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veyhoranohy/x_dataset_248.","url":"https://huggingface.co/datasets/veyhoranohy/x_dataset_248","creator_name":"Steve Karadimas","creator_url":"https://huggingface.co/veyhoranohy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_10290","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning tasks.\nFor more information about the dataset, please visit the official repository.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe versatility of this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/momo1942/x_dataset_10290.","url":"https://huggingface.co/datasets/momo1942/x_dataset_10290","creator_name":"MoMo.eth","creator_url":"https://huggingface.co/momo1942","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"gpt-oss-120B-distilled-math-OpenAI-Harmony","keyword":"summarization","description":"\n\n\t\n\t\t\n\t\tüìö Dataset Overview\n\t\n\nData Source Model: gpt-oss-120bTask Type: Mathematical Problem SolvingData Format: JSON Lines (.jsonl)Fields: Generator, Category, Input, Output \nNote: If you are using this template for training, please make sure the format is correct before starting.Since this template is still under continuous improvement and learning, it may not be fully complete yet. I appreciate your understanding.\n\n\t\n\t\t\n\t\n\t\n\t\tüìà Core Statistics\n\t\n\nGenerated complete reasoning processes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jackrong/gpt-oss-120B-distilled-math-OpenAI-Harmony.","url":"https://huggingface.co/datasets/Jackrong/gpt-oss-120B-distilled-math-OpenAI-Harmony","creator_name":"JIRONG","creator_url":"https://huggingface.co/Jackrong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"Korean-1930-Novel-Scene-Summarize","keyword":"summarization","description":"\n\t\n\t\t\n\t\tÌïúÍµ≠ Ï†ÄÏûëÍ∂å ÎßåÎ£å ÏÜåÏÑ§Ïóê ÎåÄÌïú Ïî¨ Î∂ÑÎ¶¨ Î∞è ÏöîÏïΩ Îç∞Ïù¥ÌÑ∞ ÏÖã\n\t\n\n\nÏõêÏ≤ú Îç∞Ïù¥ÌÑ∞ Ï∂úÏ≤ò: https://gongu.copyright.or.kr/gongu/wrt/wrtCl/listWrtText.do?menuNo=200019\nÏ¥ù 96Í∞ú ÏÜåÏÑ§ ÏàòÏßë Î∞è Ï†ÑÏ≤òÎ¶¨\nÌïúÏûêÍ∞Ä ÎßéÏùÄ ÏÜåÏÑ§ Ï†úÏô∏\nÌïúÏûê Ï†úÍ±∞, ÎùÑÏñ¥Ïì∞Í∏∞ Ï†ÑÏ≤òÎ¶¨ ÏàòÌñâ\n\n\n\n\n\t\n\t\t\n\t\tÏî¨ Î∂ÑÎ¶¨\n\t\n\n\nÏÇ¨Ïö© Î™®Îç∏: Gemini-1.5-Flash\n(ÎùÑÏñ¥Ïì∞Í∏∞ Ìè¨Ìï®) 100Ïûê Ïù¥ÏÉÅ, 1200Ïûê ÎØ∏ÎßåÏúºÎ°ú Ï†ÅÏ†àÌïú Î¨∏Ïû•ÏóêÏÑú Ïî¨ Îã®ÏúÑÎ°ú Î∂ÑÎ¶¨ÌïòÎèÑÎ°ù ÏßÄÏãú\nÏ¥ù 12,108Ïî¨ ÏÉùÏÑ±\n\n\n\t\n\t\t\n\t\tÏöîÏïΩ\n\t\n\n\nÏÇ¨Ïö© Î™®Îç∏: Gemini-1.5-Flash(ÎïåÎïåÎ°ú GPT-4o)\nÍ∞Å SceneÏóêÏÑú Ïù∏Î¨º, Ï£ºÏöî ÏÜåÌíà, ÏÇ¨Í±¥ÏùÑ Ï∂îÏ∂úÌïòÍ≥†, ÏöîÏïΩ(scenario)ÏùÑ ÏÉùÏÑ±ÌïòÎèÑÎ°ù Ìï®\n\n","url":"https://huggingface.co/datasets/werty1248/Korean-1930-Novel-Scene-Summarize","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"qdrant_doc","keyword":"summarization","description":"atitaarora/qdrant_doc dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/atitaarora/qdrant_doc","creator_name":"Atita","creator_url":"https://huggingface.co/atitaarora","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Multi-turn_Long-context_Benchmark_for_LLMs","keyword":"summarization","description":"\n\t\n\t\t\n\t\tLoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues\n\t\n\nArxiv: https://www.arxiv.org/abs/2507.13681\nHuggingface: https://huggingface.co/papers/2507.13681\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nLoopServe Multi-Turn Dialogue Benchmark is a comprehensive evaluation dataset comprising multiple diverse datasets designed to assess large language model performance in realistic conversational scenarios. \nUnlike traditional benchmarks that place queries only at the end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs.","url":"https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs","creator_name":"TreeAI-Lab","creator_url":"https://huggingface.co/TreeAILab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bbc-news-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBBC News Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries for BBC news articles from the CC-MAIN-2013-20 web crawl, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of BBC news stories while preserving journalistic integrity and essential information.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/bbc-news-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/bbc-news-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"bbc-news-llama4-maverick-summary","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBBC News Summary Dataset (Llama-4-Maverick-17B-128E-Instruct-FP8)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality summaries for BBC news articles from the CC-MAIN-2013-20 web crawl, generated using the Llama-4-Maverick-17B-128E-Instruct-FP8 model. Each summary provides a concise, accurate overview of BBC news stories while preserving journalistic integrity and essential information.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nHigh-quality summaries: Generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PursuitOfDataScience/bbc-news-llama4-maverick-summary.","url":"https://huggingface.co/datasets/PursuitOfDataScience/bbc-news-llama4-maverick-summary","creator_name":"Youzhi Yu","creator_url":"https://huggingface.co/PursuitOfDataScience","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_aggressive_conversations_en_second_iteration","keyword":"summarization","description":"\n\t\n\t\t\n\t\tSimulated Aggressive Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\nConversation Messages: Full message history between the customer and service agent.\nSummary: A German summary of the conversation.\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en_second_iteration","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"simple_wiki_with_grade","keyword":"text-simplification","description":"\n\t\n\t\t\n\t\tGrade Simplification Dataset\n\t\n\nThis dataset contains English sentences simplified for specific school grade levels (1‚Äì12).\nEach sample includes:\n\ninstruction: Prompt for simplification\ninput: Original complex text\noutput: Simplified version\nmetadata: Original/simplified readability scores\n\n","url":"https://huggingface.co/datasets/yimingwang123/simple_wiki_with_grade","creator_name":"Yiming Wang","creator_url":"https://huggingface.co/yimingwang123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-simplification","human","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0410139","keyword":"summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0410139.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0410139","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"x_dataset_0410139","keyword":"news-articles-summarization","description":"\n\t\n\t\t\n\t\tBittensor Subnet 13 X (Twitter) Dataset\n\t\n\n\n    \n\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMiner Data Compliance Agreement\n\t\n\nIn uploading this dataset, I am agreeing to the Macrocosmos Miner Data Compliance Policy. \n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is part of the Bittensor Subnet 13 decentralized network, containing preprocessed data from X (formerly Twitter). The data is continuously updated by network miners, providing a real-time stream of tweets for various analytical and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robert-1111/x_dataset_0410139.","url":"https://huggingface.co/datasets/robert-1111/x_dataset_0410139","creator_name":"robert","creator_url":"https://huggingface.co/robert-1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","summarization","text-generation"],"keywords_longer_than_N":true}
]
;
