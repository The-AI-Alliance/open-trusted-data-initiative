const data_for_modality_retrieval = 
[
	{"name":"code-cinema-image-animee","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du cin√©ma et de l'image anim√©e, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackMT","keyword":"text-retrieval","description":"\n  CodeFeedbackMT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2402.14658\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CodeFeedbackMT\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackMT.","url":"https://huggingface.co/datasets/mteb/CodeFeedbackMT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"hc4","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for HC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHC4 is a suite of test collections for ad hoc Cross-Language Information Retrieval (CLIR), with Common Crawl News documents in Chinese, Persian, and Russian. The documents\nare Web pages from Common Crawl in Chinese, Persian, and Russian.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nPersian\nRussian\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nDocuments\n\n\n\t\t\nfas (Persian)\n486K\n\n\nrus (Russian)\n4.7M\n\n\nzho (Chinese)\n646K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/hc4.","url":"https://huggingface.co/datasets/neuclir/hc4","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-en-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (en) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-en-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-en-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"bigscience-lama","keyword":"fact-checking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\n\t\n\n@inproceedings{petroni2020how,\n  title={How Context Affects Language Models' Factual Predictions},\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\n  booktitle={Automated Knowledge Base Construction},\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama.","url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"hc4","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for HC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHC4 is a suite of test collections for ad hoc Cross-Language Information Retrieval (CLIR), with Common Crawl News documents in Chinese, Persian, and Russian. The documents\nare Web pages from Common Crawl in Chinese, Persian, and Russian.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nPersian\nRussian\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nDocuments\n\n\n\t\t\nfas (Persian)\n486K\n\n\nrus (Russian)\n4.7M\n\n\nzho (Chinese)\n646K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/hc4.","url":"https://huggingface.co/datasets/neuclir/hc4","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-en-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (en) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-en-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-en-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"bigscience-lama","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\n\t\n\n@inproceedings{petroni2020how,\n  title={How Context Affects Language Models' Factual Predictions},\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\n  booktitle={Automated Knowledge Base Construction},\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama.","url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Collection-of-drug-names-in-Persian","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nA collection of drug names in Persian\n\nLanguage(s) (NLP): persian\n\n","url":"https://huggingface.co/datasets/dadashzadeh/Collection-of-drug-names-in-Persian","creator_name":"dadashzadeh","creator_url":"https://huggingface.co/dadashzadeh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"healthcare-corpus","keyword":"text-retrieval","description":"Merged text from HIPAA CFR, openFDA labels, CDC pages, and ClinicalTrials.gov abstracts.\n","url":"https://huggingface.co/datasets/HIMANSHUNAVIN03/healthcare-corpus","creator_name":"Navin","creator_url":"https://huggingface.co/HIMANSHUNAVIN03","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"code-relations-public-administration","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-penal","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode p√©nal, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"DeAR-COT","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tListwise Chain-of-Thought Re-ranking Dataset (DeAR-COT)\n\t\n\nRepo: abdoelsayed/DeAR-COTTask: listwise passage re-ranking with optional Chain-of-Thought (CoT) rationalesFormat: JSONL (one JSON object per line)Language: English\n\n\t\n\t\t\n\t\tSummary\n\t\n\nDeAR-CoT is a listwise re-ranking dataset designed for training and evaluating LLM rerankers.Each example contains:\n\na search query,\nk candidate passages embedded inline in instruction as [1] ... [k],\na target listwise ranking (final ordered IDs)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/DeAR-COT.","url":"https://huggingface.co/datasets/abdoelsayed/DeAR-COT","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DeAR-COT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tListwise Chain-of-Thought Re-ranking Dataset (DeAR-COT)\n\t\n\nRepo: abdoelsayed/DeAR-COTTask: listwise passage re-ranking with optional Chain-of-Thought (CoT) rationalesFormat: JSONL (one JSON object per line)Language: English\n\n\t\n\t\t\n\t\tSummary\n\t\n\nDeAR-CoT is a listwise re-ranking dataset designed for training and evaluating LLM rerankers.Each example contains:\n\na search query,\nk candidate passages embedded inline in instruction as [1] ... [k],\na target listwise ranking (final ordered IDs)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/DeAR-COT.","url":"https://huggingface.co/datasets/abdoelsayed/DeAR-COT","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"irish-legislative-summaries","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIrish Legislative Summaries ‚öñÔ∏è\n\t\n\nIrish Legislative Summaries by Isaacus is a novel, challenging legal information retrieval evaluation dataset consisting of 500 Irish laws and their long titles, succinctly summarizing subject matter, scope, and purpose of legislation.\nThis dataset is meant to stress test the ability of an information retrieval model to retrieve relevant statutes to short queries describing them.\nTo make evaluation with this dataset as easy as possible, it is formatted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/irish-legislative-summaries.","url":"https://huggingface.co/datasets/isaacus/irish-legislative-summaries","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"code-propriete-intellectuelle","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la propri√©t√© intellectuelle, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedure-civile","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de proc√©dure civile, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-postes-communications-electroniques","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des postes et des communications √©lectroniques, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"miracl-noauth","keyword":"document-retrieval","description":"A clone of the excellent miracl/miracl dataset that doesn't require authentication. Refer to the original dataset for details.\n","url":"https://huggingface.co/datasets/macavaney/miracl-noauth","creator_name":"Sean MacAvaney","creator_url":"https://huggingface.co/macavaney","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","miracl/miracl"],"keywords_longer_than_N":true},
	{"name":"miracl-noauth","keyword":"text-retrieval","description":"A clone of the excellent miracl/miracl dataset that doesn't require authentication. Refer to the original dataset for details.\n","url":"https://huggingface.co/datasets/macavaney/miracl-noauth","creator_name":"Sean MacAvaney","creator_url":"https://huggingface.co/macavaney","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","miracl/miracl"],"keywords_longer_than_N":true},
	{"name":"AdvBench-IR","keyword":"retrieval","description":"\n  Exploiting Instruction-Following Retrievers for Malicious Information Retrieval\n\n\n\n\n\n\nThis dataset includes malicious documents in response to AdvBench (Zou et al., 2023) queries. We have generated these documents using the Mistral-7B-Instruct-v0.2 language model.\nfrom datasets import load_dataset\nimport transformers\n\nds = load_dataset(\"McGill-NLP/AdvBench-IR\", split=\"train\")\n\n# Loads LlaMAGuard model to check the safety of the samples\nmodel_name = \"meta-llama/Llama-Guard-3-1B\"\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/AdvBench-IR.","url":"https://huggingface.co/datasets/McGill-NLP/AdvBench-IR","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"miracl-fr-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"miracl-fr-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"pierogue","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tPierogue\n\t\n\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\n\nTopics: cosmos, nature, music, technology, fashion\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\n\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue.","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","text-generation","document-retrieval","language-modeling"],"keywords_longer_than_N":true},
	{"name":"pierogue","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPierogue\n\t\n\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\n\nTopics: cosmos, nature, music, technology, fashion\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\n\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue.","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","text-generation","document-retrieval","language-modeling"],"keywords_longer_than_N":true},
	{"name":"T2Ranking","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tT2Ranking\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nT2Ranking is a large-scale Chinese benchmark for passage ranking. The details about T2Ranking are elaborated in this paper.\nPassage ranking are important and challenging topics for both academics and industries in the area of Information Retrieval (IR). The goal of passage ranking is to compile a search result list ordered in terms of relevance to the query from a large passage collection. Typically, Passage ranking involves two stages: passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THUIR/T2Ranking.","url":"https://huggingface.co/datasets/THUIR/T2Ranking","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","text-classification","sentence-similarity","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"germandpr","keyword":"text-retrieval","description":"We take GermanQuAD as a starting point and add hard negatives from a dump of the full German Wikipedia following the approach of the DPR authors (Karpukhin et al., 2020). The format of the dataset also resembles the one of DPR. GermanDPR comprises 9275 question/answer pairs in the training set and 1025 pairs in the test set. For each pair, there are one positive context and three hard negative contexts.","url":"https://huggingface.co/datasets/deepset/germandpr","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"miracl-ru-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ru) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ru-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ru-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ru-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ru-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Russian"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"LeCaRDv2","keyword":"document-retrieval","description":"\n  LeCaRDv2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the case document that best matches or is most relevant to the scenario described in each of the provided queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/THUIR/LeCaRDv2\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LeCaRDv2.","url":"https://huggingface.co/datasets/mteb/LeCaRDv2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"ViNLI-Zalo-supervised","keyword":"text-retrieval","description":"anti-ai/ViNLI-Zalo-supervised dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anti-ai/ViNLI-Zalo-supervised","creator_name":"anti-ai","creator_url":"https://huggingface.co/anti-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","Vietnamese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"miracl-ru-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ru) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ru-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ru-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ru-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ru-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Russian"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"LeCaRDv2","keyword":"text-retrieval","description":"\n  LeCaRDv2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the case document that best matches or is most relevant to the scenario described in each of the provided queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/THUIR/LeCaRDv2\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LeCaRDv2.","url":"https://huggingface.co/datasets/mteb/LeCaRDv2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-es-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (es) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-simple-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (simple English) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (simple English) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-de-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (de) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"ans-stance","keyword":"fact-checking","description":"The dataset is a collection of news titles in arabic along with paraphrased and corrupted titles. The stance prediction version is a 3-class classification task. Data contains three columns: s1, s2, stance.","url":"https://huggingface.co/datasets/strombergnlp/ans-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"rustance","keyword":"fact-checking","description":"This is a stance prediction dataset in Russian. The dataset contains comments on news articles,\nand rows are a comment, the title of the news article it responds to, and the stance of the comment\ntowards the article.","url":"https://huggingface.co/datasets/strombergnlp/rustance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","sentiment-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-es-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (es) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-simple-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (simple English) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (simple English) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-de-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (de) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"health_fact","keyword":"fact-checking","description":"PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of\npublic health claims. Each instance in the PUBHEALTH dataset has an associated\nveracity label (true, false, unproven, mixture). Furthermore each instance in the\ndataset has an explanation text field. The explanation is a justification for which\nthe claim has been assigned a particular veracity label.\n\nThe dataset was created to explore fact-checking of difficult to verify claims i.e.,\nthose which require expertise from outside of the journalistics domain, in this case\nbiomedical and public health expertise.\n\nIt was also created in response to the lack of fact-checking datasets which provide\ngold standard natural language explanations for verdicts/labels.\n\nNOTE: There are missing labels in the dataset and we have replaced them with -1.","url":"https://huggingface.co/datasets/ImperialCollegeLondon/health_fact","creator_name":"Imperial College London","creator_url":"https://huggingface.co/ImperialCollegeLondon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","multi-class-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with query‚Äìdocument relevance judgments in 15 African languages automatically mined from Wikipedia\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language.\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"uk-legislative-long-titles","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tUK Legislative Long Titles ‚öñÔ∏è\n\t\n\nUK Legislative Long Titles by Isaacus is a novel, challenging legal information retrieval evaluation dataset consisting of 78 UK laws and their long titles, succinctly summarizing subject matter, scope, and purpose of legislation.\nThis dataset is meant to stress test the ability of an information retrieval model to retrieve relevant statutes to short queries describing them.\nTo make evaluation with this dataset as easy as possible, it is formatted in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/uk-legislative-long-titles.","url":"https://huggingface.co/datasets/isaacus/uk-legislative-long-titles","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"code-ports-maritimes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des ports maritimes, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-procedure-penale","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de proc√©dure p√©nale, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"args_me","keyword":"document-retrieval","description":"The args.me corpus (version 1.0, cleaned) comprises 382 545 arguments crawled from four debate portals in the middle of 2019. The debate portals are Debatewise, IDebate.org, Debatepedia, and Debate.org. The arguments are extracted using heuristics that are designed for each debate portal.","url":"https://huggingface.co/datasets/webis/args_me","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tripclick-training","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tTripClick Baselines with Improved Training Data\n\t\n\nEstablishing Strong Baselines for TripClick Health Retrieval Sebastian Hofst√§tter, Sophia Althammer, Mete Sertkan and Allan Hanbury\nhttps://arxiv.org/abs/2201.00365\ntl;dr We create strong re-ranking and dense retrieval baselines (BERTCAT, BERTDOT, ColBERT, and TK) for TripClick (health ad-hoc retrieval). We improve the ‚Äì originally too noisy ‚Äì training data with a simple negative sampling policy. We achieve large gains over BM25 in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training.","url":"https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training","creator_name":"Sebastian Hofst√§tter","creator_url":"https://huggingface.co/sebastian-hofstaetter","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","other","clicks","other"],"keywords_longer_than_N":true},
	{"name":"sufficient_facts","keyword":"fact-checking","description":"SufficientFacts is a diagnostic test dataset for fact checking with insufficient evidence.","url":"https://huggingface.co/datasets/copenlu/sufficient_facts","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"code-recherche","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la recherche, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"args_me","keyword":"text-retrieval","description":"The args.me corpus (version 1.0, cleaned) comprises 382 545 arguments crawled from four debate portals in the middle of 2019. The debate portals are Debatewise, IDebate.org, Debatepedia, and Debate.org. The arguments are extracted using heuristics that are designed for each debate portal.","url":"https://huggingface.co/datasets/webis/args_me","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tripclick-training","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tTripClick Baselines with Improved Training Data\n\t\n\nEstablishing Strong Baselines for TripClick Health Retrieval Sebastian Hofst√§tter, Sophia Althammer, Mete Sertkan and Allan Hanbury\nhttps://arxiv.org/abs/2201.00365\ntl;dr We create strong re-ranking and dense retrieval baselines (BERTCAT, BERTDOT, ColBERT, and TK) for TripClick (health ad-hoc retrieval). We improve the ‚Äì originally too noisy ‚Äì training data with a simple negative sampling policy. We achieve large gains over BM25 in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training.","url":"https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training","creator_name":"Sebastian Hofst√§tter","creator_url":"https://huggingface.co/sebastian-hofstaetter","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","other","clicks","other"],"keywords_longer_than_N":true},
	{"name":"frames-benchmark","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tFRAMES: Factuality, Retrieval, And reasoning MEasurement Set\n\t\n\nFRAMES is a comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.\nOur paper with details and experiments is available on arXiv: https://arxiv.org/abs/2409.12941.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n824 challenging multi-hop questions requiring information from 2-15 Wikipedia articles\nQuestions span diverse topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/frames-benchmark.","url":"https://huggingface.co/datasets/google/frames-benchmark","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"news-qa-summarization-73","keyword":"text-retrieval","description":"","url":"https://huggingface.co/datasets/bernabeSanchez/news-qa-summarization-73","creator_name":"Bernabe Sanchez","creator_url":"https://huggingface.co/bernabeSanchez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","text-retrieval","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-simple-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\twikipedia-22-12-simple-embeddings\n\t\n\nA modified version of Cohere/wikipedia-22-12-simple-embeddings \nmeant for use with PostgreSQL with pgvector and Timescale Vector. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset was created for exploring time-based filtering and semantic search in PostgreSQL with pgvector and Timescale Vector.\nThis is a modified version of the Cohere wikipedia-22-12-simple-embeddings dataset hosted on Huggingface. \nIt contains embeddings of Simple English Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timescale/wikipedia-22-12-simple-embeddings.","url":"https://huggingface.co/datasets/timescale/wikipedia-22-12-simple-embeddings","creator_name":"Timescale","creator_url":"https://huggingface.co/timescale","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"anti-echo-chamber-data","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAnti-Echo Chamber Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains processed news articles with metadata and embeddings designed to break echo chambers by identifying opposing viewpoints across political spectrums.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Anti-Echo Chamber dataset consists of news articles scraped from diverse sources across the political spectrum, processed through a sophisticated pipeline that extracts:\n\nTopic embeddings using sentence transformers\nPolitical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zanimal/anti-echo-chamber-data.","url":"https://huggingface.co/datasets/zanimal/anti-echo-chamber-data","creator_name":"Alexander","creator_url":"https://huggingface.co/zanimal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"mseformula","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-2\n\t\n\nMathematics Stack Exchange Formula Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"climatecheck","keyword":"fact-checking","description":"\n\n\n\t\n\t\t\n\t\tThe ClimateCheck Dataset\n\t\n\nThis dataset is used for the ClimateCheck: Scientific Fact-checking of Social Media Posts on Climate ChangeShared Task hosted at the Scholarly Document Processing workshop at ACL 2025. \nThe shared task is hosted on Codabench.\nClaims\nThe claims used for this dataset were gathered from the following existing resources: ClimaConvo, DEBAGREEMENT, Climate-Fever, MultiFC, and ClimateFeedback. \nSome of which are extracted from social media (Twitter/X and Reddit)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rabuahmad/climatecheck.","url":"https://huggingface.co/datasets/rabuahmad/climatecheck","creator_name":"Raia Abu Ahmad","creator_url":"https://huggingface.co/rabuahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"climatecheck","keyword":"information-retrieval","description":"\n\n\n\t\n\t\t\n\t\tThe ClimateCheck Dataset\n\t\n\nThis dataset is used for the ClimateCheck: Scientific Fact-checking of Social Media Posts on Climate ChangeShared Task hosted at the Scholarly Document Processing workshop at ACL 2025. \nThe shared task is hosted on Codabench.\nClaims\nThe claims used for this dataset were gathered from the following existing resources: ClimaConvo, DEBAGREEMENT, Climate-Fever, MultiFC, and ClimateFeedback. \nSome of which are extracted from social media (Twitter/X and Reddit)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rabuahmad/climatecheck.","url":"https://huggingface.co/datasets/rabuahmad/climatecheck","creator_name":"Raia Abu Ahmad","creator_url":"https://huggingface.co/rabuahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"climatecheck","keyword":"text-retrieval","description":"\n\n\n\t\n\t\t\n\t\tThe ClimateCheck Dataset\n\t\n\nThis dataset is used for the ClimateCheck: Scientific Fact-checking of Social Media Posts on Climate ChangeShared Task hosted at the Scholarly Document Processing workshop at ACL 2025. \nThe shared task is hosted on Codabench.\nClaims\nThe claims used for this dataset were gathered from the following existing resources: ClimaConvo, DEBAGREEMENT, Climate-Fever, MultiFC, and ClimateFeedback. \nSome of which are extracted from social media (Twitter/X and Reddit)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rabuahmad/climatecheck.","url":"https://huggingface.co/datasets/rabuahmad/climatecheck","creator_name":"Raia Abu Ahmad","creator_url":"https://huggingface.co/rabuahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mseformula","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-2\n\t\n\nMathematics Stack Exchange Formula Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"mseformula","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-2\n\t\n\nMathematics Stack Exchange Formula Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"code-justice-penale-mineurs","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la justice p√©nale des mineurs, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"CAPP","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFrench Court of Judicial jurisprudence decisions (CAPP) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CAPP Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/CAPP.\nThis comprehensive collection includes appellate court decisions, providing valuable insights into French jurisprudence and legal reasoning at the appeal level.\nIt serves as a rich resource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CAPP.","url":"https://huggingface.co/datasets/Tricoteuses/CAPP","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"trilemma-of-truth","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tüìö Dataset Card for Trilemma of Truth (ToT) Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüßæ Dataset Summary\n\t\n\nThe Trilemma of Truth dataset is a benchmark for evaluating model performance across three types of statements:\n\nFactually true statements\nFactually false statements\nNeither-valued statements\n\nIt includes three configurations:\n\ncity_locations: statements about city-country relationsmed_indications: drug-indication associations\nword_definitions: synonym, type, and instance relationships from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlomarxx/trilemma-of-truth.","url":"https://huggingface.co/datasets/carlomarxx/trilemma-of-truth","creator_name":"Germans Savcisens","creator_url":"https://huggingface.co/carlomarxx","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","fact-checking","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"statcodesearch","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for statcodesearch\n\t\n\n\n\nThe StatCodeSearch dataset is a benchmark test set consisting of code comment pairs extracted from R programming language scripts authored mostly by researchers. The dataset is sourced from the Open Science Framework (OSF). It includes text and code samples from R projects that pertain to the fields of social science and psychology with a focus on the statistical analysis of research data. As part of the GenCodeSearchNet test suite, this dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drndr/statcodesearch.","url":"https://huggingface.co/datasets/drndr/statcodesearch","creator_name":"A D","creator_url":"https://huggingface.co/drndr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","code","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DBPedia_PL_test_top_250_only_w_correct-v2","keyword":"text-retrieval","description":"\n  DBPedia-PLHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_PL_test_top_250_only_w_correct-v2.","url":"https://huggingface.co/datasets/mteb/DBPedia_PL_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Polish"],"keywords_longer_than_N":true},
	{"name":"persons_with_spectacles","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tüì∏ Persons with Spectacles\n\t\n\nA curated image dataset of human faces annotated for the presence of spectacles (eyeglasses).\n\n\n\t\n\t\t\n\t\tDataset Card for hkanade/persons_with_spectacles\n\t\n\n\n\t\n\t\t\nFeature\nDetail\n\n\n\t\t\nDataset name\npersons_with_spectacles\n\n\nRepository\nhttps://huggingface.co/datasets/hkanade/persons_with_spectacles\n\n\nLicense\napache-2.0\n\n\nLanguages\n‚Äî\n\n\nTasks\nText to Image, Image classification\n\n\nSize\n120\n\n\nFile format\nParquet\n\n\nDataset version\n1.0.0\n\n\n\t\n\n\n\t\n\t\t\n\t\t1. Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hkanade/persons_with_spectacles.","url":"https://huggingface.co/datasets/hkanade/persons_with_spectacles","creator_name":"Hrishikesh Kanade","creator_url":"https://huggingface.co/hkanade","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","image-to-image","text-to-image","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TCGA-Cancer-Variant-and-Clinical-Data","keyword":"entity-linking-retrieval","description":"\n\t\n\t\t\n\t\tTCGA Cancer Variant and Clinical Data\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines genetic variant information at the protein level with clinical data from The Cancer Genome Atlas (TCGA) project, curated by the International Cancer Genome Consortium (ICGC). It provides a comprehensive view of protein-altering mutations and clinical characteristics across various cancer types.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes:\n\nProtein sequence data for both mutated and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seq-to-pheno/TCGA-Cancer-Variant-and-Clinical-Data.","url":"https://huggingface.co/datasets/seq-to-pheno/TCGA-Cancer-Variant-and-Clinical-Data","creator_name":"Seq-to-Pheno","creator_url":"https://huggingface.co/seq-to-pheno","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-to-text","entity-linking-retrieval","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"code-sport","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du sport, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-english","keyword":"text-retrieval","description":"\n  CQADupstackEnglishRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackEnglishRetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-english.","url":"https://huggingface.co/datasets/mteb/cqadupstack-english","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"solyanka","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset card for Solyanka\n\t\n\nThis is a dataset collection of ~10 million weakly-supervised pairs for training text embedding models. Any dataset in collection can be used in SentenceTransformers with an InfoNCE loss.\n\n\t\n\t\t\n\t\tData processing\n\t\n\nThe initial pool of pairs were deduplified, filtered by length and quality. Most of documents are less than 512 tokens (FRIDA tokenizer). Some pairs were filtered by manual rules (e.g. by post votes, rating, views). We applied consistency‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai-forever/solyanka.","url":"https://huggingface.co/datasets/ai-forever/solyanka","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","feature-extraction","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Panjabi"],"keywords_longer_than_N":true},
	{"name":"legalbench_corporate_lobbying","keyword":"document-retrieval","description":"\n  LegalBenchCorporateLobbying\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset includes bill titles and bill summaries related to corporate lobbying.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench/viewer/corporate_lobbying\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying.","url":"https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQRetrieval","keyword":"text-retrieval","description":"\n  NanoNQRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNQ is a smaller subset of a dataset which contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web\n\n\nReference\nhttps://ai.google.com/research/NaturalQuestions\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNQRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoNQRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Panjabi"],"keywords_longer_than_N":true},
	{"name":"code-securite-interieure","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© int√©rieure, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"legalbench_corporate_lobbying","keyword":"text-retrieval","description":"\n  LegalBenchCorporateLobbying\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset includes bill titles and bill summaries related to corporate lobbying.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench/viewer/corporate_lobbying\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying.","url":"https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Oriya"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-stats","keyword":"text-retrieval","description":"\n  CQADupstackStatsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackStatsRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-stats.","url":"https://huggingface.co/datasets/mteb/cqadupstack-stats","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"CapRetrievalEn","keyword":"retrieval","description":"The english version of CapRetrieval introduced in the EMNLP 2025 Finding paper: [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings].\nCode: https://github.com/lxucs/CapRetrieval\nQueries and passages are translated automatically by GPT-4.1; all IDs and labels are kept the same as CapRetrieval. A few labels thus are not entirely accurate due to different language traits and expressions, but most labels should remain consistent.\nCapRetrieval evaluates the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lxucs/CapRetrievalEn.","url":"https://huggingface.co/datasets/lxucs/CapRetrievalEn","creator_name":"Liyan Xu","creator_url":"https://huggingface.co/lxucs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Oriya"],"keywords_longer_than_N":true},
	{"name":"InstructIR-mteb","keyword":"document-retrieval","description":"\n  InstructIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA benchmark specifically designed to evaluate the instruction following ability in information retrieval models. Our approach focuses on user-aligned instructions tailored to each query instance, reflecting the diverse characteristics inherent in real-world search scenarios. NOTE: scores on this may differ unless you include instruction first, then \"[SEP]\" and then the query via redefining combine_query_and_instruction in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InstructIR-mteb.","url":"https://huggingface.co/datasets/mteb/InstructIR-mteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"unarxive_BM25","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for UnarXive BM25 Index\n\t\n\nThis repository contains the BM25 sparse index built from the UnarXive 2024 dataset, which includes over 2.3 million arXiv papers (1991‚Äì2024) with rich metadata, structured full text, and linked citations.\nThe index was created using paper abstracts and is designed for fast keyword-based retrieval in scientific information retrieval applications.\n\n\t\n\t\t\n\t\n\t\n\t\tWhat‚Äôs Inside\n\t\n\n\nBM25 index (e.g., Faiss-compatible or pyserini-compatible, depending on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ines-besrour/unarxive_BM25.","url":"https://huggingface.co/datasets/ines-besrour/unarxive_BM25","creator_name":"ines Besrour","creator_url":"https://huggingface.co/ines-besrour","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["unarxive_2024","mit","1M<n<10M","üá∫üá∏ Region: US","information-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Oriya"],"keywords_longer_than_N":true},
	{"name":"InstructIR-mteb","keyword":"text-retrieval","description":"\n  InstructIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA benchmark specifically designed to evaluate the instruction following ability in information retrieval models. Our approach focuses on user-aligned instructions tailored to each query instance, reflecting the diverse characteristics inherent in real-world search scenarios. NOTE: scores on this may differ unless you include instruction first, then \"[SEP]\" and then the query via redefining combine_query_and_instruction in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InstructIR-mteb.","url":"https://huggingface.co/datasets/mteb/InstructIR-mteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI framework for improving LLM responses\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"msmarco-dev-small-negatives","keyword":"document-retrieval","description":"[Under Construction]\nThis repository contains up to 1000 hard negatives from several retrieval systems for the 6,980 queries of the MS MARCO small dev set. This data can be used to evaluate \nthe performance of reranking models for 2nd-stage retrieval given a set of 1000 candidate passages (including the positive ones).\n","url":"https://huggingface.co/datasets/antoinelouis/msmarco-dev-small-negatives","creator_name":"Antoine Louis","creator_url":"https://huggingface.co/antoinelouis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"msmarco-dev-small-negatives","keyword":"text-retrieval","description":"[Under Construction]\nThis repository contains up to 1000 hard negatives from several retrieval systems for the 6,980 queries of the MS MARCO small dev set. This data can be used to evaluate \nthe performance of reranking models for 2nd-stage retrieval given a set of 1000 candidate passages (including the positive ones).\n","url":"https://huggingface.co/datasets/antoinelouis/msmarco-dev-small-negatives","creator_name":"Antoine Louis","creator_url":"https://huggingface.co/antoinelouis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ml-ryanlee/free-music-archive-retrieval.","url":"https://huggingface.co/datasets/ml-ryanlee/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ml-ryanlee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"fact-checking","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/bigbench.","url":"https://huggingface.co/datasets/tasksource/bigbench","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"browsecomp-plus","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tBrowseComp-Plus\n\t\n\nBrowseComp-Plus is a new benchmark for Deep-Research system, isolating the effect of the retriever and the LLM agent to enable fair, transparent comparisons of Deep-Research agents. The benchmark sources challenging, reasoning-intensive queries from OpenAI's BrowseComp. However, instead of searching the live web, BrowseComp-Plus evaluates against a fixed, curated corpus of ~100K web documents from the web. The corpus includes both human-verified evidence documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tevatron/browsecomp-plus.","url":"https://huggingface.co/datasets/Tevatron/browsecomp-plus","creator_name":"Tevatron","creator_url":"https://huggingface.co/Tevatron","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"code-deontologie-architectes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de d√©ontologie des architectes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"code-commerce","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de commerce, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Urdu"],"keywords_longer_than_N":true},
	{"name":"code-disciplinaire-penal-marine-marchande","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode disciplinaire et p√©nal de la marine marchande, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-sante-publique","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la sant√© publique, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Urdu"],"keywords_longer_than_N":true},
	{"name":"code-rural-ancien","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode rural (ancien), non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NFCorpus","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"code-commande-publique","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la commande publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NeuCLIR2023Retrieval","keyword":"text-retrieval","description":"\n  NeuCLIR2023Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\nSource datasets:\n\nmteb/neuclir-2023\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"NeuCLIR2023Retrieval\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NeuCLIR2023Retrieval.","url":"https://huggingface.co/datasets/mteb/NeuCLIR2023Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2023","Persian"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NFCorpus","English"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NFCorpus","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum_Circuit_Papers","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_Quantum_Circuit_Papers ‚Äì Overview\n\t\n\nOGC_Quantum_Circuit_Papers is a curated dataset focused on quantum circuits and quantum gates, extracted exclusively from scientific research papers. This dataset emphasizes documents that contain circuit diagrams, matrix-based explanations, and detailed discussions of quantum operations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.\nScientific PDFs were sourced from public online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Papers.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Papers","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum_Circuit_Papers","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Quantum_Circuit_Papers ‚Äì Overview\n\t\n\nOGC_Quantum_Circuit_Papers is a curated dataset focused on quantum circuits and quantum gates, extracted exclusively from scientific research papers. This dataset emphasizes documents that contain circuit diagrams, matrix-based explanations, and detailed discussions of quantum operations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.\nScientific PDFs were sourced from public online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Papers.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Papers","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HagridRetrieval","keyword":"text-retrieval","description":"\n  HagridRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset)is a dataset for generative information-seeking scenarios. It consists of queriesalong with a set of manually labelled relevant passages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/project-miracl/hagrid\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HagridRetrieval.","url":"https://huggingface.co/datasets/mteb/HagridRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mseqa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-1\n\t\n\nMathematics Stack Exchange Answer Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"document-retrieval","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"mseqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-1\n\t\n\nMathematics Stack Exchange Answer Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"mseqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tARQMath-Task-1\n\t\n\nMathematics Stack Exchange Answer Retrieval Task. Sourced from https://vault.cs.uwaterloo.ca/s/RTJ27g9Ek2kanRe\n","url":"https://huggingface.co/datasets/hcju/mseqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","math stackexchange","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"text-retrieval","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"text-retrieval","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSciFact.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSciFact-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSciFact","French"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSciFact.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSciFact-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSciFact","French"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSciFact.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSciFact-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSciFact","French"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-microbiome-v1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-microbiome-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~380-token chunks, ~15% overlap)\nEmbedder: bio-protocol/scientific-retriever (mean-pooled, L2-normalized)\nSimilarity: cosine via inner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-microbiome-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-microbiome-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-microbiome-v1","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-microbiome-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~380-token chunks, ~15% overlap)\nEmbedder: bio-protocol/scientific-retriever (mean-pooled, L2-normalized)\nSimilarity: cosine via inner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-microbiome-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-microbiome-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Gujarati"],"keywords_longer_than_N":true},
	{"name":"beir-nl-cqadupstack","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR-NL Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR-NL is a Dutch-translated version of the BEIR benchmark, a diverse and heterogeneous collection of datasets covering various domains from biomedical and financial texts to general web content. Our benchmark is integrated into the Massive Multilingual Text Embedding Benchmark (MMTEB).\nBEIR-NL contains the following tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/beir-nl-cqadupstack.","url":"https://huggingface.co/datasets/clips/beir-nl-cqadupstack","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Dutch","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"plaid-shirttt-doc-date","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tClueweb09 and NeuCLIR1 document dates for reproducing PLAID SHIRTTT\n\t\n\nThis dataset contains the dates of each document in Clueweb09 and \nNeuCLIR1 for reproducing experiments in the PLAID SHIRTTT paper (accepted at SIGIR 2024). \nFor reproducibility, we release the document IDs of the collection divided into shards where there is a file per shard. \nThe creation date of each document is extracted and recorded in ISO format along with the document ID. \nFor combining the retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/plaid-shirttt-doc-date.","url":"https://huggingface.co/datasets/hltcoe/plaid-shirttt-doc-date","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","neuclir/neuclir1","clueweb09"],"keywords_longer_than_N":true},
	{"name":"code-rural-peche-maritime","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode rural et de la p√™che maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"plaid-shirttt-doc-date","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tClueweb09 and NeuCLIR1 document dates for reproducing PLAID SHIRTTT\n\t\n\nThis dataset contains the dates of each document in Clueweb09 and \nNeuCLIR1 for reproducing experiments in the PLAID SHIRTTT paper (accepted at SIGIR 2024). \nFor reproducibility, we release the document IDs of the collection divided into shards where there is a file per shard. \nThe creation date of each document is extracted and recorded in ISO format along with the document ID. \nFor combining the retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/plaid-shirttt-doc-date.","url":"https://huggingface.co/datasets/hltcoe/plaid-shirttt-doc-date","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","neuclir/neuclir1","clueweb09"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-retrievals","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-retrievals","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Awadhi"],"keywords_longer_than_N":true},
	{"name":"factcheck-memes-x","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tFact-checking Memes - X Dataset\n\t\n\nThis dataset contains 119 meme correction posts and their associated engagement metrics from a real-world deployment of fact-checking memes on X (formerly Twitter). The memes were specifically designed to counter misinformation by providing visually engaging explanations of fact-checking verdicts.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe \"Fact-checking Memes - X\" dataset documents a social media experiment conducted between October 25‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergiogpinto/factcheck-memes-x.","url":"https://huggingface.co/datasets/sergiogpinto/factcheck-memes-x","creator_name":"S√©rgio Miguel Gon√ßalves Pinto","creator_url":"https://huggingface.co/sergiogpinto","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Awadhi"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSCIDOCS.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSCIDOCS-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSCIDOCS","French"],"keywords_longer_than_N":true},
	{"name":"SpartQA","keyword":"text-retrieval","description":"\n  SpartQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on SpartQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/HLR/SpartQA_generation\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SpartQA\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SpartQA.","url":"https://huggingface.co/datasets/mteb/SpartQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/spartqa","English"],"keywords_longer_than_N":true},
	{"name":"github-issues-dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüìå GitHub Issues Dataset\n\t\n\n\nüìÇ Dataset Name: github-issues-datasetüìä Total Issues: 114073üìú Format: Parquet (.parquet)üîç Source: GitHub Repositories (Top 100 Repos)  \n\n\n\t\n\t\t\n\t\n\t\n\t\tüìñ Overview\n\t\n\nThis dataset contains 114,073 GitHub issues collected from the top 100 repositories on GitHub.It is designed for issue classification, severity/priority prediction, and AI/ML training.\n\n\t\n\t\n\t\n\t\t‚úÖ This dataset is useful for:\n\t\n\n\nAI/ML Training: Fine-tune models for issue classification &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sharjeelyunus/github-issues-dataset.","url":"https://huggingface.co/datasets/sharjeelyunus/github-issues-dataset","creator_name":"Sharjeel Yunus","creator_url":"https://huggingface.co/sharjeelyunus","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MedBrowseComp_CUA","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMedBrowseComp Dataset\n\t\n\nThis repository contains datasets for medical browsing and comparison tasks.\n\n\t\n\t\t\n\t\tDatasets\n\t\n\nThe repository is structured into three partitions:\n\nMedBrowseComp_50: A collection of 50 medical entries for browsing and comparison.\nMedBrowseComp_605: A comprehensive collection of 605 medical entries.\nMedBrowseComp_CUA: A curated collection of medical data for comparison and analysis.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThese datasets can be used for various medical text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp_CUA.","url":"https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp_CUA","creator_name":"AIM-Harvard","creator_url":"https://huggingface.co/AIM-Harvard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSCIDOCS.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSCIDOCS-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSCIDOCS","French"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoSCIDOCS.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoSCIDOCS-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoSCIDOCS","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"yambda","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tYambda-5B ‚Äî A Large-Scale Multi-modal Dataset for Ranking And Retrieval\n\t\n\nIndustrial-scale music recommendation dataset with organic/recommendation interactions and audio embeddings\n üìå Overview ‚Ä¢ üîë Key Features ‚Ä¢ üìä Statistics ‚Ä¢ üìù Format ‚Ä¢ üèÜ Benchmark ‚Ä¢ ‚¨áÔ∏è Download ‚Ä¢ ‚ùì FAQ\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe Yambda-5B dataset is a large-scale open database comprising 4.79 billion user-item interactions collected from 1 million users and spanning 9.39 million tracks. The dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yandex/yambda.","url":"https://huggingface.co/datasets/yandex/yambda","creator_name":"Yandex","creator_url":"https://huggingface.co/yandex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1B - 10B","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"multicare-articles","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMultiCaRe: Open-Source Clinical Case Dataset\n\t\n\nMultiCaRe aggregates open-access, de-identified clinical case reports from PubMed Central‚Äôs OA corpus, pairing article-level metadata and abstracts with case narratives and figure images/captions. The normalization makes it easy to map from images ‚Üí cases ‚Üí articles.\n\nSource and process: parse PMC OA case reports; extract metadata/abstracts; download/process figures; align captions; build a hierarchical taxonomy for image labels.\nScale:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openmed-community/multicare-articles.","url":"https://huggingface.co/datasets/openmed-community/multicare-articles","creator_name":"OpenMed Community","creator_url":"https://huggingface.co/openmed-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"MixEval","keyword":"text-retrieval","description":"\n\n\nüè† Homepage | üë®‚Äçüíª Github | üèÜ Leaderboard | üìú arXiv | üìù blog | ü§ó HF Paper | ùïè Twitter\n\n\n\n\n\n\n\nBenchmark correlations (%) with Chatbot Arena Elo, against the total costs of evaluating a single GPT-3.5-Turbo-0125 model. MixEval and MixEval-Hard show the highest correlations with Arena Elo and Arena Elo (En) among leading benchmarks. We reference the crowdsourcing price for Amazon Mechanical Turk ($0.05 per vote) when estimating the cost of evaluating a single model on Chatbot Arena‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval.","url":"https://huggingface.co/datasets/MixEval/MixEval","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","text-retrieval","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-cross-paper-retrievals","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with enhanced dependency mappings to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Manipuri"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-cross-paper-retrievals","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with enhanced dependency mappings to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"cdnpdf-presentations-part1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for cdnpdf Educational Materials (Part 1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 101,022 educational presentations from the cdnpdf.com platform, which provides free access to books, documents, magazines and presentations. This collection focuses exclusively on presentations and includes archives with IDs from 00 to 24. The dataset includes information such as presentation titles, descriptions, URLs, download URLs, and file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cdnpdf-presentations-part1.","url":"https://huggingface.co/datasets/nyuuzyou/cdnpdf-presentations-part1","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"pptonline","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for PPT Online\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata about 1,418,349 PowerPoint (.ppt) files hosted on the ppt-online.org platform. PPT Online is a service designed to display PowerPoint presentations. The dataset includes information such as presentation titles, categories, download links, file sizes, and content snippets. The majority of the presentations are in Russian, Ukrainian, Belarusian, Kazakh, and English, but other languages are also‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pptonline.","url":"https://huggingface.co/datasets/nyuuzyou/pptonline","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-retrieval","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"MedXpertQA-Exam","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/MedXpertQA-Exam.","url":"https://huggingface.co/datasets/R2MED/MedXpertQA-Exam","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"pubmed25","keyword":"text-retrieval","description":"NLM produces a baseline set of MEDLINE/PubMed citation records in XML format for download on an annual basis.\nThe annual baseline is released in December of each year. Each day, NLM produces update files that include\nnew, revised and deleted citations. See our documentation page for more information.\nThis version is modified to extract the full text from structured abstracts.","url":"https://huggingface.co/datasets/HoangHa/pubmed25","creator_name":"H√† Huy Ho√†ng","creator_url":"https://huggingface.co/HoangHa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","üá∫üá∏ Region: US","biomedical","text-retrieval","abstract-retrieval"],"keywords_longer_than_N":false},
	{"name":"Bharat_NanoArguAna_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"icml2024_embeddings","keyword":"text-retrieval","description":"porestar/icml2024_embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/porestar/icml2024_embeddings","creator_name":"Lukas Mosser","creator_url":"https://huggingface.co/porestar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","üá∫üá∏ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"BRIGHT-Plus","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBRIGHT benchmark\n\t\n\nBRIGHT+ is an upgraded version of the BRIGHT benchmark, specifically designed to support reasoning-intensive retrieval in realistic settings. It is constructed by applying MARCUS, a multi-agent LLM-based clean-and-split pipeline, to the original BRIGHT dataset.\nBRIGHT+ addresses key limitations of the original web-crawled corpus‚Äîsuch as redundant boilerplate content and fragmented semantic units‚Äîby applying targeted structural cleaning and LLM-based semantic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helios1208/BRIGHT-Plus.","url":"https://huggingface.co/datasets/Helios1208/BRIGHT-Plus","creator_name":"Liyang Chen","creator_url":"https://huggingface.co/Helios1208","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BRIGHT-Plus","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBRIGHT benchmark\n\t\n\nBRIGHT+ is an upgraded version of the BRIGHT benchmark, specifically designed to support reasoning-intensive retrieval in realistic settings. It is constructed by applying MARCUS, a multi-agent LLM-based clean-and-split pipeline, to the original BRIGHT dataset.\nBRIGHT+ addresses key limitations of the original web-crawled corpus‚Äîsuch as redundant boilerplate content and fragmented semantic units‚Äîby applying targeted structural cleaning and LLM-based semantic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helios1208/BRIGHT-Plus.","url":"https://huggingface.co/datasets/Helios1208/BRIGHT-Plus","creator_name":"Liyang Chen","creator_url":"https://huggingface.co/Helios1208","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"DocMMIR","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDocMMIR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDocMMIR (Document-level Multimodal Information Retrieval) is a dataset for document-level multimodal information retrieval. This dataset contains image-text pairs from arXiv papers, Wikipedia, and presentations, specifically designed for multimodal retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nStatistic\nWiki\nArXiv\nSlide\nTotal\n\n\n\t\t\n#Train\n360,285\n62,764\n27,057\n450,079\n\n\n#Valid\n14,775\n3,000\n1,409\n19,184\n\n\n#Test\n14,805\n3,000\n1,399‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lord-Jim/DocMMIR.","url":"https://huggingface.co/datasets/Lord-Jim/DocMMIR","creator_name":"Zirui Li","creator_url":"https://huggingface.co/Lord-Jim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"code-douanes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des douanes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"rank1-R1-MSMARCO","keyword":"retrieval","description":"\n\t\n\t\t\n\t\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"rank1-R1-MSMARCO","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"rank1-R1-MSMARCO","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"rank1-R1-MSMARCO","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"turkuaz-rag","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tTurkuaz-RAG: A Novel Turkish Multi-Context Retrieval Benchmark\n\t\n\nTurkuaz-RAG is the first benchmark specifically created for evaluating multi-context retrieval tasks in Turkish. It addresses a major gap in low-resource language research by providing multi-context questions, answers, and corresponding contexts.\n\n\t\n\t\t\n\t\tDescription of Benchmark\n\t\n\n\nLanguages: Turkish\nSize: ~2,500 triplets (question, contexts, answer)\nContext Sources: Turkish news articles from MLSUM\nQuestion Types:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eneSadi/turkuaz-rag.","url":"https://huggingface.co/datasets/eneSadi/turkuaz-rag","creator_name":"Enes Sadi","creator_url":"https://huggingface.co/eneSadi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Turkish","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"FIGNEWS_generated_queries","keyword":"retrieval","description":"This repository contains the FIGNEWS dataset with predicted queries, a core component used in the paper QAEncoder: Towards Aligned Representation Learning in Question Answering Systems.\nThe official implementation and related code are available on GitHub: https://github.com/IAAR-Shanghai/QAEncoder\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nModern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zr-wang/FIGNEWS_generated_queries.","url":"https://huggingface.co/datasets/zr-wang/FIGNEWS_generated_queries","creator_name":"Wang","creator_url":"https://huggingface.co/zr-wang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","arxiv:2409.20434","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"mira_rag","keyword":"text-retrieval","description":"SebastiaanBeekman/mira_rag dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SebastiaanBeekman/mira_rag","creator_name":"Sebastiaan Beekman","creator_url":"https://huggingface.co/SebastiaanBeekman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval.","url":"https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ryanleeme17","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Magahi"],"keywords_longer_than_N":true},
	{"name":"NanoDBPediaRetrieval","keyword":"text-retrieval","description":"\n  NanoDBPediaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoDBPediaRetrieval is a small version of the standard test collection for entity search over the DBpedia knowledge base.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic\n\nReference\nhttps://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","topic-classification","expert-annotated","monolingual","mteb/dbpedia"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Magahi"],"keywords_longer_than_N":true},
	{"name":"rank1-training-data","keyword":"retrieval","description":"\n\t\n\t\t\n\t\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"rank1-training-data","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"R2MEDBioinformaticsRetrieval","keyword":"document-retrieval","description":"\n  R2MEDBioinformaticsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBioinformatics retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Bioinformatics\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBioinformaticsRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Bioinformatics"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Oriya"],"keywords_longer_than_N":true},
	{"name":"rank1-training-data","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"rank1-training-data","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"R2MEDBioinformaticsRetrieval","keyword":"text-retrieval","description":"\n  R2MEDBioinformaticsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBioinformatics retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Bioinformatics\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBioinformaticsRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBioinformaticsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Bioinformatics"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Oriya"],"keywords_longer_than_N":true},
	{"name":"Argimi-Ardian-Finance-10k-text","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThe ArGiMI Ardian datasets : Text only\n\t\n\n\nThe ArGiMi project is committed to open-source principles and data sharing. \nThanks to our generous partners, we are releasing several valuable datasets to the public.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThis dataset comprises 11,000 financial annual reports, written in english, meticulously\nextracted from their original PDF format to provide a valuable resource for researchers and developers in financial\nanalysis and natural language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artefactory/Argimi-Ardian-Finance-10k-text.","url":"https://huggingface.co/datasets/artefactory/Argimi-Ardian-Finance-10k-text","creator_name":"Artefact","creator_url":"https://huggingface.co/artefactory","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-generation","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Manipuri"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-NL","keyword":"text-retrieval","description":"\n  TRECCOVID-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTRECCOVID is an ad-hoc search challenge based on the COVID-19 dataset containing scientific articles related to the COVID-19 pandemic. TRECCOVID-NL is a Dutch translation. \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\n\n\nReference\nhttps://colab.research.google.com/drive/1R99rjeAGt8S9IfAIRR3wS052sNu3Bjo-#scrollTo=4HduGW6xHnrZ\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TRECCOVID-NL.","url":"https://huggingface.co/datasets/mteb/TRECCOVID-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/trec-covid","Dutch"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"Italian_FakeNews_detection","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tFakeNews Detection with Wikipedia\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand processing them using Gemini AI with the following goal(s):\n\nProcessing Goal 1: Trasforma il paragrafo in un paragrafo giornalistico attendibile.\n\nProcessing Goal 2: Genera una notizia falsa distorcendo la realt√†\n\nSource Language: Italian (from Wikipedia)\n\nNumber of Rows: 189\n\nModel Used: gemini-2.5-flash-preview-04-17\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection.","url":"https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","gemini-ai","original:wikipedia:it","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"RARbMath","keyword":"text-retrieval","description":"\n  RARbMath\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on RAR-b math-pooled dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.06347\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RARbMath\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RARbMath.","url":"https://huggingface.co/datasets/mteb/RARbMath","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/math-pooled","English"],"keywords_longer_than_N":true},
	{"name":"IIYi-Clinical","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/IIYi-Clinical.","url":"https://huggingface.co/datasets/R2MED/IIYi-Clinical","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GoSim-3","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGoSim-3\n\t\n\nEste reposit√≥rio cont√©m dados anotados em portugu√™s para an√°lise de similaridade sem√¢ntica entre perguntas de e-commerce.\nSelecionamos 150 pares de perguntas reais de plataformas de e-commerce. Tr√™s anotadores avaliaram cada par com base em sua similaridade, usando tr√™s categorias:\n\nsimilar\n\nalmost similar\n\ndissimilar\n\n\nAp√≥s consenso entre os anotadores, filtramos os pares com maioria de votos. Foram mantidos 144 pares, descartando 6 pares com total desacordo.\n\nsimilar: 34‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GoBotsAI/GoSim-3.","url":"https://huggingface.co/datasets/GoBotsAI/GoSim-3","creator_name":"GoBots","creator_url":"https://huggingface.co/GoBotsAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Manipuri"],"keywords_longer_than_N":true},
	{"name":"GreenNodeTableMarkdownRetrieval","keyword":"document-retrieval","description":"\n  GreenNodeTableMarkdownRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreenNodeTable documents\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFinancial, Encyclopaedic, Non-fiction\n\n\nReference\nhttps://huggingface.co/GreenNode\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreenNodeTableMarkdownRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval.","url":"https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"devcenter-articles-embedded","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of chunked and embedded versions of a subset of articles from the MongoDB Developer Center.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following fields: \n\nsourceName: The source of the article. This value is devcenter for the entire dataset.\nurl: Link to the article\naction: Action taken on the article. This value is created for the entire dataset.\nbody: Content of the chunk in Markdown format\nformat: Format of the content. This value is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/devcenter-articles-embedded.","url":"https://huggingface.co/datasets/MongoDB/devcenter-articles-embedded","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","cc-by-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Manipuri"],"keywords_longer_than_N":true},
	{"name":"GreenNodeTableMarkdownRetrieval","keyword":"text-retrieval","description":"\n  GreenNodeTableMarkdownRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreenNodeTable documents\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFinancial, Encyclopaedic, Non-fiction\n\n\nReference\nhttps://huggingface.co/GreenNode\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreenNodeTableMarkdownRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval.","url":"https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"telegram-news-ua-dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAisberg Telegram News UA (anon)\n\t\n\nAisberg Telegram News UA (anon) is a de-identified dataset of Ukrainian Telegram news and discussions.The data is collected by the Aisberg Public Organization for research in information security, narrative tracking, and the detection of manipulative techniques.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nPosts: channel name, anonymized text, publication date, aggregated reactions (emoji ‚Üí counts).  \nComments (anon.): user pseudonym, comment text, timestamp in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisbergpublicorganization/telegram-news-ua-dataset.","url":"https://huggingface.co/datasets/aisbergpublicorganization/telegram-news-ua-dataset","creator_name":"aisberg.public.organization","creator_url":"https://huggingface.co/aisbergpublicorganization","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Ukrainian","Russian","English"],"keywords_longer_than_N":true},
	{"name":"cdnpdf-presentations-part2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for cdnpdf Educational Materials (Part 2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 100,978 educational presentations from the cdnpdf.com platform, which provides free access to books, documents, magazines and presentations. This collection focuses exclusively on presentations and includes archives with IDs from 25 to 49. The dataset includes information such as presentation titles, descriptions, URLs, download URLs, and file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cdnpdf-presentations-part2.","url":"https://huggingface.co/datasets/nyuuzyou/cdnpdf-presentations-part2","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"urokosvitaua","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Urok.Osvita.ua Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 32,290 educational materials from the urok.osvita.ua platform, a service for Ukrainian educators to share and publish their teaching materials. The dataset includes information such as material titles, descriptions, categories, grade levels, and download links for the original files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual, with Ukrainian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/urokosvitaua.","url":"https://huggingface.co/datasets/nyuuzyou/urokosvitaua","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"text-retrieval","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"MixBench","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MixBench","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Awadhi"],"keywords_longer_than_N":true},
	{"name":"indonesia-law-qa-embeddings","keyword":"text-retrieval","description":"biznetgio/indonesia-law-qa-embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/biznetgio/indonesia-law-qa-embeddings","creator_name":"Biznet Gio Nusantara","creator_url":"https://huggingface.co/biznetgio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","Indonesian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"kzgov-budget-data","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tKazakhstan Government Budget Data üá∞üáø\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis comprehensive dataset provides detailed insights into Kazakhstan's government budget allocation, execution, and performance across various sectors, regions, and administrative levels for 2024. The dataset enables analysis of fiscal policy, budget efficiency, and resource distribution across the country.\n\n\t\n\t\t\n\t\tüìä Dataset Statistics\n\t\n\n\nTotal Records: 615 entries\nCoverage Period: 2024\nAdministrative Levels:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Adilbai/kzgov-budget-data.","url":"https://huggingface.co/datasets/Adilbai/kzgov-budget-data","creator_name":"Baidalin Adilzhan","creator_url":"https://huggingface.co/Adilbai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["table-to-text","question-answering","text-retrieval","open-domain-qa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"amzn_sec_db","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tAMZN SEC Filings ‚Äì Chunk-level Corpus (10-K, 10-Q, 8-K)\n\t\n\n\n  \n\n\nA ready-to-use, chunk-level corpus of Amazon's (AMZN) recent SEC filings\n(10-K, 10-Q, and 8-K).Each paragraph and sentence is stored together with rich metadata,\nmaking the dataset ideal for:\n\nsemantic search / RAG pipelines (ChromaDB, FAISS, Weaviate, ‚Ä¶)\nquestion-answering over financial filings\nexperimenting with financial-domain embeddings\n\n\nTime span‚ÄÉ: last 5 fiscal years (rolling window, as of 2025-05-11)Collection :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurry/amzn_sec_db.","url":"https://huggingface.co/datasets/kurry/amzn_sec_db","creator_name":"Kurry Tran","creator_url":"https://huggingface.co/kurry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","question-answering","external:sec-edgar","English","mit"],"keywords_longer_than_N":true},
	{"name":"amzn_sec_db","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAMZN SEC Filings ‚Äì Chunk-level Corpus (10-K, 10-Q, 8-K)\n\t\n\n\n  \n\n\nA ready-to-use, chunk-level corpus of Amazon's (AMZN) recent SEC filings\n(10-K, 10-Q, and 8-K).Each paragraph and sentence is stored together with rich metadata,\nmaking the dataset ideal for:\n\nsemantic search / RAG pipelines (ChromaDB, FAISS, Weaviate, ‚Ä¶)\nquestion-answering over financial filings\nexperimenting with financial-domain embeddings\n\n\nTime span‚ÄÉ: last 5 fiscal years (rolling window, as of 2025-05-11)Collection :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurry/amzn_sec_db.","url":"https://huggingface.co/datasets/kurry/amzn_sec_db","creator_name":"Kurry Tran","creator_url":"https://huggingface.co/kurry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","question-answering","external:sec-edgar","English","mit"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"text-retrieval","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Vietnamese-THUIR-T2Ranking-gg-translated","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüìö 5CD-AI/Vietnamese-THUIR-T2Ranking-gg-translated\n\t\n\n\n\t\n\t\t\n\t\tüìù Overview\n\t\n\nVietnamese-THUIR-T2Ranking-gg-translated is a large-scale dataset for passage ranking in Vietnamese.It is translated from the original THUIR/T2Ranking [1] using Google Translate, inspired by the approach of mMARCO [2].The dataset aims to provide a large-scale dataset for research and applications in Information Retrieval (IR) in Vietnamese.  \nIn IR, passage ranking is an essential and challenging task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/5CD-AI/Vietnamese-THUIR-T2Ranking-gg-translated.","url":"https://huggingface.co/datasets/5CD-AI/Vietnamese-THUIR-T2Ranking-gg-translated","creator_name":"Fifth Civil Defender - 5CD","creator_url":"https://huggingface.co/5CD-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","text-classification","Vietnamese","Chinese"],"keywords_longer_than_N":true},
	{"name":"code-douanes-mayotte","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des douanes de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"kizaru","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains a collection of song lyrics by Russian rapper Kizaru, scraped from Genius. The lyrics have been chunked into meaningful phrases or lines and embedded using SentenceTransformers for use in semantic search and retrieval tasks, such as lyric bots, citation detectors, or creative NLP applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: @ksusonic\nLanguage(s) (NLP): Russian\nLicense: Dataset derived‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ksusonic/kizaru.","url":"https://huggingface.co/datasets/ksusonic/kizaru","creator_name":"Daniil","creator_url":"https://huggingface.co/ksusonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","Russian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-02082024-vrdv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-02082024-vrdv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"EnglishHealthcare1Retrieval-sample","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tEnglishHealthcare1Retrieval-sample\n\t\n\nA sample dataset for medical research retrieval evaluation.\n\n\t\n\t\t\n\t\tTask category\n\t\n\nRetrieval\n\n\t\n\t\t\n\t\tDomains\n\t\n\nMedical, Academic\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the standard MTEB retrieval format:\n\ncorpus/corpus-00000-of-00001.parquet: 10 documents with fields _id, title, text\nqueries/queries-00000-of-00001.parquet: 6 queries with fields _id, text  \ndata/test-00000-of-00001.parquet: 6 relevance judgments with fields query-id‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample.","url":"https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample","creator_name":"MTEB Private","creator_url":"https://huggingface.co/mteb-private","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Gujarati"],"keywords_longer_than_N":true},
	{"name":"EnglishHealthcare1Retrieval-sample","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tEnglishHealthcare1Retrieval-sample\n\t\n\nA sample dataset for medical research retrieval evaluation.\n\n\t\n\t\t\n\t\tTask category\n\t\n\nRetrieval\n\n\t\n\t\t\n\t\tDomains\n\t\n\nMedical, Academic\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the standard MTEB retrieval format:\n\ncorpus/corpus-00000-of-00001.parquet: 10 documents with fields _id, title, text\nqueries/queries-00000-of-00001.parquet: 6 queries with fields _id, text  \ndata/test-00000-of-00001.parquet: 6 relevance judgments with fields query-id‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample.","url":"https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample","creator_name":"MTEB Private","creator_url":"https://huggingface.co/mteb-private","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Gujarati"],"keywords_longer_than_N":true},
	{"name":"EnglishHealthcare1Retrieval-sample","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tEnglishHealthcare1Retrieval-sample\n\t\n\nA sample dataset for medical research retrieval evaluation.\n\n\t\n\t\t\n\t\tTask category\n\t\n\nRetrieval\n\n\t\n\t\t\n\t\tDomains\n\t\n\nMedical, Academic\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the standard MTEB retrieval format:\n\ncorpus/corpus-00000-of-00001.parquet: 10 documents with fields _id, title, text\nqueries/queries-00000-of-00001.parquet: 6 queries with fields _id, text  \ndata/test-00000-of-00001.parquet: 6 relevance judgments with fields query-id‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample.","url":"https://huggingface.co/datasets/mteb-private/EnglishHealthcare1Retrieval-sample","creator_name":"MTEB Private","creator_url":"https://huggingface.co/mteb-private","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"code-juridictions-financieres","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des juridictions financi√®res, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"HellaSwag","keyword":"text-retrieval","description":"\n  HellaSwag\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on HellaSwag.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://rowanzellers.com/hellaswag/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"HellaSwag\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HellaSwag.","url":"https://huggingface.co/datasets/mteb/HellaSwag","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/hellaswag","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-203779","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-203779 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-203779 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"document-retrieval","description":"Ehsanl/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ehsanl/test","creator_name":"Ehsan","creator_url":"https://huggingface.co/Ehsanl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","document-retrieval","topic-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"text-retrieval","description":"Ehsanl/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ehsanl/test","creator_name":"Ehsan","creator_url":"https://huggingface.co/Ehsanl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","document-retrieval","topic-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la L√©gion d'honneur, de la M√©daille militaire et de l'ordre national du M√©rite, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tüîç IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tüöÄ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"pi-llm","keyword":"retrieval","description":"\n\n\t\n\t\t\n\t\tPI-LLM Bench: The Core Retrieval Challenge Behind MRCR\n\t\n\n\nICML 2025 Long-Context Foundation Models Workshop Accepted.\n\nA simple context interference evaluation.\n\nUpdate: This dataset is integrated into Moonshot AI(Kimi)'s internal benchmarking framework for assessing ** tracking capacity and context interference in LLM/agents**.\nUpdate:Sept.6-mergerd into Moonshot/Kimi AI's internal eval tools and under review by a xAI(Grok)'s' eval team\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tTL;DR\n\t\n\nWe identify a task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/giantfish-fly/pi-llm.","url":"https://huggingface.co/datasets/giantfish-fly/pi-llm","creator_name":"c.p. wang","creator_url":"https://huggingface.co/giantfish-fly","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","Tabular"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüîç IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tüöÄ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"medical_qa","keyword":"document-retrieval","description":"\n  MedicalQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists 2048 medical question and answer pairs.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MedicalQARetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/medical_qa.","url":"https://huggingface.co/datasets/mteb/medical_qa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LitSearchRetrieval","keyword":"document-retrieval","description":"\n  LitSearchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The dataset contains the query set and retrieval corpus for the paper LitSearch: A Retrieval Benchmark for\n    Scientific Literature Search. It introduces LitSearch, a retrieval benchmark comprising 597 realistic literature\n    search queries about recent ML and NLP papers. LitSearch is constructed using a combination of (1) questions\n    generated by GPT-4 based on paragraphs containing inline citations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LitSearchRetrieval.","url":"https://huggingface.co/datasets/mteb/LitSearchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"PIQA","keyword":"text-retrieval","description":"\n  PIQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring the ability to retrieve the groundtruth answers to reasoning task queries on PIQA.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://arxiv.org/abs/1911.11641\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"PIQA\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PIQA.","url":"https://huggingface.co/datasets/mteb/PIQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","RAR-b/piqa","English"],"keywords_longer_than_N":true},
	{"name":"medical_qa","keyword":"text-retrieval","description":"\n  MedicalQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists 2048 medical question and answer pairs.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MedicalQARetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/medical_qa.","url":"https://huggingface.co/datasets/mteb/medical_qa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LitSearchRetrieval","keyword":"text-retrieval","description":"\n  LitSearchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The dataset contains the query set and retrieval corpus for the paper LitSearch: A Retrieval Benchmark for\n    Scientific Literature Search. It introduces LitSearch, a retrieval benchmark comprising 597 realistic literature\n    search queries about recent ML and NLP papers. LitSearch is constructed using a combination of (1) questions\n    generated by GPT-4 based on paragraphs containing inline citations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LitSearchRetrieval.","url":"https://huggingface.co/datasets/mteb/LitSearchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","QuoraRetrieval","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Assamese"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HotpotQA","English"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","QuoraRetrieval","English"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","QuoraRetrieval","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Assamese"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HotpotQA","English"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","HotpotQA","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Urdu"],"keywords_longer_than_N":true},
	{"name":"FutureQueryEval","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tFutureQueryEval Dataset (EMNLP 2025)üîç\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFutureQueryEval is a novel Information Retrieval (IR) benchmark designed to evaluate reranker performance on temporal novelty. It comprises 148 queries with 2,938 query-document pairs across 7 topical categories, specifically created to test how well reranking models generalize to truly novel queries that were unseen during LLM pretraining.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nZero Contamination: All queries refer to events‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/FutureQueryEval.","url":"https://huggingface.co/datasets/abdoelsayed/FutureQueryEval","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","1K<n<10K","Text"],"keywords_longer_than_N":true},
	{"name":"FutureQueryEval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFutureQueryEval Dataset (EMNLP 2025)üîç\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFutureQueryEval is a novel Information Retrieval (IR) benchmark designed to evaluate reranker performance on temporal novelty. It comprises 148 queries with 2,938 query-document pairs across 7 topical categories, specifically created to test how well reranking models generalize to truly novel queries that were unseen during LLM pretraining.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nZero Contamination: All queries refer to events‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/FutureQueryEval.","url":"https://huggingface.co/datasets/abdoelsayed/FutureQueryEval","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","1K<n<10K","Text"],"keywords_longer_than_N":true},
	{"name":"Opendoc2-Analysis-Recognition","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOpendoc2-Analysis-Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Opendoc2-Analysis-Recognition dataset is a collection of data designed for tasks involving image analysis and recognition. It is suitable for various machine learning tasks, including image-to-text conversion, text classification, and image feature extraction.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Likely includes images and associated labels (specific modalities can be confirmed on the dataset's page).\nLanguages:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition.","url":"https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Urdu"],"keywords_longer_than_N":true},
	{"name":"CapRetrieval","keyword":"retrieval","description":"The dataset CapRetrieval introduced in the EMNLP 2025 Finding paper: [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings].\nCapRetrieval is in Chinese; the according English version is available at CapRetrievalEn, sharing the same queries, passages and labels.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCapRetrieval evaluates the fine-grained embedding matching (dense passage retrieval), tailored towards a practical image search scenario:\n\nCandidate passages are image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lxucs/CapRetrieval.","url":"https://huggingface.co/datasets/lxucs/CapRetrieval","creator_name":"Liyan Xu","creator_url":"https://huggingface.co/lxucs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"pakistani-law-family-criminal-property","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüáµüá∞ Pakistani Law Dataset ‚Äî Structured Legal Acts of Pakistan (8 CSV Files)\n\t\n\nThis dataset contains structured and machine-readable data extracted from 8 major Pakistani legal documents, parsed from official PDF versions. It covers crucial domains such as Family Law, Criminal Law, Civil Procedure, Property Law, and Evidence Law. These files are ideal for use in legal AI, chatbot systems, retrieval-augmented generation (RAG), and LLM fine-tuning.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Dataset Contents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/heyIamUmair/pakistani-law-family-criminal-property.","url":"https://huggingface.co/datasets/heyIamUmair/pakistani-law-family-criminal-property","creator_name":"Umair Ahmed","creator_url":"https://huggingface.co/heyIamUmair","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-retrieval","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bank-of-ghana-rates","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nBank of Ghana historical and real-time exchange rates data. Bank of Ghana\nClick Here:\n\n\t\n\t\t\n\t\tData Format\n\t\n\n{\n    \"date\": \"...\", \n    \"currency\": \"...\", \n    \"currency_pair\": \"...\", \n    \"buying\": \"...\", \n    \"selling\": \"...\", \n    \"mid_rate\": \"...\"\n}\n\n\n\t\n\t\t\n\t\tLoad Dataset\n\t\n\npip install datasets\n\nfrom datasets import load_dataset\n\nrates = load_dataset(\"worldboss/bank-of-ghana-rates\", split=\"train\")\n\npd.DataFrame(rates).head()\n\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nThe data was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/bank-of-ghana-rates.","url":"https://huggingface.co/datasets/worldboss/bank-of-ghana-rates","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"CapRetrieval","keyword":"text-retrieval","description":"The dataset CapRetrieval introduced in the EMNLP 2025 Finding paper: [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings].\nCapRetrieval is in Chinese; the according English version is available at CapRetrievalEn, sharing the same queries, passages and labels.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCapRetrieval evaluates the fine-grained embedding matching (dense passage retrieval), tailored towards a practical image search scenario:\n\nCandidate passages are image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lxucs/CapRetrieval.","url":"https://huggingface.co/datasets/lxucs/CapRetrieval","creator_name":"Liyan Xu","creator_url":"https://huggingface.co/lxucs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"NeuCLIR2022RetrievalHardNegatives","keyword":"text-retrieval","description":"\n  NeuCLIR2022RetrievalHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\nSource datasets:\n\nmteb/neuclir-2022\nmteb/neuclir-2022-hard-negatives‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NeuCLIR2022RetrievalHardNegatives.","url":"https://huggingface.co/datasets/mteb/NeuCLIR2022RetrievalHardNegatives","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2022","mteb/neuclir-2022-hard-negatives"],"keywords_longer_than_N":true},
	{"name":"eli-why-manually-web-retrieved","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tüìö ELI-Why Manually Web-Retrieved Explanations\n\t\n\n\n\t\n\t\t\n\t\tüß† Dataset Summary\n\t\n\nThis dataset contains high-quality, manually curated explanations for \"Why\" questions, retrieved from the web to serve as educationally appropriate references.Each explanation is annotated with:\n\nA corresponding question\nA fine-grained topic and domain label (e.g., STEM / Physics)\nThe intended educational level (Elementary, High School, Graduate)\nThe original source URL from which the explanation was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved.","url":"https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-verified","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"conceptcarve","keyword":"retrieval","description":"The dataset described in the original ConceptCarve paper. The dataset contains both the Reddit community corpora and the labeled trend/evidence/posts. The original paper can be found at https://arxiv.org/abs/2504.07228.\nIf you use the dataset, please cite us:\n@misc{caplan2025conceptcarvedynamicrealizationevidence,\n      title={ConceptCarve: Dynamic Realization of Evidence}, \n      author={Eylon Caplan and Dan Goldwasser},\n      year={2025},\n      eprint={2504.07228}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ecaplan/conceptcarve.","url":"https://huggingface.co/datasets/ecaplan/conceptcarve","creator_name":"Eylon Caplan","creator_url":"https://huggingface.co/ecaplan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100M<n<1B","arxiv:2504.07228","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"synthetic-from-retrieval-tasks-swedish","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThanks to Arrow Denmark and Nvidia for sponsoring the compute used to generate this dataset\n\t\n\nThe purpose of this dataset is to pre- or post-train embedding models for retrieval tasks.\nThe dataset consists of 100,000 samples generated with gemma-2-27b-it.\nThe column \"prompt\" shows the prompt given to the LLM and \"response\" shows the LLM output.\nEach sample in the dataset was generated from a seed task randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-swedish.","url":"https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-swedish","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Swedish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFEVER","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFEVER","French"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFEVER","French"],"keywords_longer_than_N":true},
	{"name":"dbpedia","keyword":"text-retrieval","description":"\n  DBPedia\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/dbpedia.","url":"https://huggingface.co/datasets/mteb/dbpedia","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"hypercube-rag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tHypercube-RAG: Multi-Domain Dataset for Retrieval-Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive multi-domain dataset for Retrieval-Augmented Generation (RAG) research, \nfeaturing hypercube-structured indexing across scientific, legal, geographic, and \nenvironmental domains.\nNote: This dataset is currently in process and under active development.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMulti-dimensional retrieval: Uses hypercube structure for entity-based indexing\nDiverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rtian/hypercube-rag.","url":"https://huggingface.co/datasets/Rtian/hypercube-rag","creator_name":"Runchu Tian","creator_url":"https://huggingface.co/Rtian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"hypercube-rag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tHypercube-RAG: Multi-Domain Dataset for Retrieval-Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive multi-domain dataset for Retrieval-Augmented Generation (RAG) research, \nfeaturing hypercube-structured indexing across scientific, legal, geographic, and \nenvironmental domains.\nNote: This dataset is currently in process and under active development.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMulti-dimensional retrieval: Uses hypercube structure for entity-based indexing\nDiverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rtian/hypercube-rag.","url":"https://huggingface.co/datasets/Rtian/hypercube-rag","creator_name":"Runchu Tian","creator_url":"https://huggingface.co/Rtian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"code-environnement","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'environnement, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"amazon-esci-data","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tAmazon Shopping Queries Dataset\n\t\n\nDataset for improving product search, ranking and recommendations, featuring query-product pairs with detailed relevance labels.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe dataset contains search queries paired with up to 40 potentially relevant products, each labeled using the ESCI system:\n\nExact match: Products that perfectly match the customer's search intent (e.g., searching \"iPhone 13\" and finding \"Apple iPhone 13 128GB\")\nSubstitute product: Alternative products‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/milistu/amazon-esci-data.","url":"https://huggingface.co/datasets/milistu/amazon-esci-data","creator_name":"Milutin Studen","creator_url":"https://huggingface.co/milistu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","text-generation","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Maithili"],"keywords_longer_than_N":true},
	{"name":"bigslide","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Bigslide.ru Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 50,872 presentations from the bigslide.ru platform, a presentation storage and viewing service for school students. The dataset includes information such as presentation titles, URLs, download URLs, and extracted text content where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual, with Russian being the primary language. Other languages present‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/bigslide.","url":"https://huggingface.co/datasets/nyuuzyou/bigslide","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Maithili"],"keywords_longer_than_N":true},
	{"name":"VieQuADRetrieval","keyword":"text-retrieval","description":"\n  VieQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for evaluating Machine Reading Comprehension from Wikipedia articles.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReferencehttps://aclanthology.org/2020.coling-main.233.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VieQuADRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieQuADRetrieval.","url":"https://huggingface.co/datasets/mteb/VieQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"Bioinformatics","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/Bioinformatics.","url":"https://huggingface.co/datasets/R2MED/Bioinformatics","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"code-civil","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode civil, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"OGC_2_vdr-visRAG-colpali","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC 2 - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis second version only has rows with positive queries\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n600,000+\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tLanguage Distribution\n\t\n\n\n\t\n\t\t\nLanguage\nRatio\n\n\n\t\t\nEnglish\n‚âà 64%\n\n\nFrench\n‚âà‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali.","url":"https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Gujarati"],"keywords_longer_than_N":true},
	{"name":"OGC_2_vdr-visRAG-colpali","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC 2 - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis second version only has rows with positive queries\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n600,000+\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tLanguage Distribution\n\t\n\n\n\t\n\t\t\nLanguage\nRatio\n\n\n\t\t\nEnglish\n‚âà 64%\n\n\nFrench\n‚âà‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali.","url":"https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Gujarati"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FiQA2018","English"],"keywords_longer_than_N":true},
	{"name":"TriggerIR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüìö TriggerIR\n\t\n\nTriggerIR is a synthetic benchmark for testing concept‚Äëerasure in information‚Äëretrieval (IR) systems. It contains paired movie‚Äësynopsis documents with and without a sensitive \"trigger\" concept, plus two queries (neutral¬†& explicit) designed to differentiate them. The corpus is entirely machine‚Äëgenerated so that debiasing experiments can be shared without disclosing real copyrighted text.\n\n\t\n\t\t\n\t\n\t\n\t\t‚ú® Dataset at a glance\n\t\n\n\n\t\n\t\t\nsplit\ndocuments\npairs\nconcepts\navg‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cwestnedge/TriggerIR.","url":"https://huggingface.co/datasets/cwestnedge/TriggerIR","creator_name":"collins","creator_url":"https://huggingface.co/cwestnedge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FiQA2018","English"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FiQA2018","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"BioKGBench-Dataset","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tAgent4S-BioKG\n\t\n\nA Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.\n\n\n    \n    \n\n     Github \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models(LLMs).However, to evaluate such systems, people either rely on direct Question-Answering(QA) to the LLM itself, or in a biomedical experimental manner. How‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset.","url":"https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset","creator_name":"AutoLab Westlake","creator_url":"https://huggingface.co/AutoLab-Westlake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","other","fact-checking","closed-domain-qa"],"keywords_longer_than_N":true},
	{"name":"BioKGBench-Dataset","keyword":"fact-checking-retrieval","description":"\n\t\n\t\t\n\t\tAgent4S-BioKG\n\t\n\nA Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.\n\n\n    \n    \n\n     Github \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models(LLMs).However, to evaluate such systems, people either rely on direct Question-Answering(QA) to the LLM itself, or in a biomedical experimental manner. How‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset.","url":"https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset","creator_name":"AutoLab Westlake","creator_url":"https://huggingface.co/AutoLab-Westlake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","other","fact-checking","closed-domain-qa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Telugu"],"keywords_longer_than_N":true},
	{"name":"BioKGBench-Dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAgent4S-BioKG\n\t\n\nA Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.\n\n\n    \n    \n\n     Github \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models(LLMs).However, to evaluate such systems, people either rely on direct Question-Answering(QA) to the LLM itself, or in a biomedical experimental manner. How‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset.","url":"https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset","creator_name":"AutoLab Westlake","creator_url":"https://huggingface.co/AutoLab-Westlake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","other","fact-checking","closed-domain-qa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCSRetrieval","keyword":"text-retrieval","description":"\n  NanoSCIDOCSRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/scidocs","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Assamese"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"code-impositions-biens-services","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des impositions sur les biens et services, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Assamese"],"keywords_longer_than_N":true},
	{"name":"struct-ir-qrels","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSSRB: Direct Natural Language Querying to Massive Heterogeneous Semi-Structured Data\n\t\n\ngithub\nWe employ LLM-based automatic evaluation and build a large-scale semi-structured retrieval benchmark (SSRB) using LLM generation and filtering, containing 14M structured objects from 99 different schemas across 6 domains, along with 8,485 test queries that combine both exact and fuzzy matching conditions.\nThis repository contains the qrel data for SSRB, The corpus and query files please‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vec-ai/struct-ir-qrels.","url":"https://huggingface.co/datasets/vec-ai/struct-ir-qrels","creator_name":"Vector AI","creator_url":"https://huggingface.co/vec-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"exorde-social-media-december-2024-week1","keyword":"text-retrieval","description":"","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-december-2024-week1","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-retrieval","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"code-collectivites-territoriales","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des collectivit√©s territoriales, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Urdu"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iv","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe IV, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-forestier-nouveau","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode forestier (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"BIRCO-DorisMae-Test","keyword":"text-retrieval","description":"\n  BIRCO-DorisMae\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the DORIS-MAE dataset from BIRCO. This dataset contains 60 queries that are complex research questions from computer scientists. Each query has a candidate pool of approximately 110 abstracts. Relevance is graded from 0 to 2 (scores of 1 and 2 are considered relevant).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kindred-ecommerce-merchant-deals-dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tKindred E-commerce Merchant Deals Dataset\n\t\n\nAI-ready catalogue of deals and offers for global retail brands.Structured in CSV and JSONL, validated against JSON Schema.\nTrain-ready catalogue of promotions, ready for RAG, embeddings, or classic search.\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\n    \n        File\n        Rows\n        Description\n    \n        \n            data/csv/brands.csv or data/jsonl/brands.jsonl\n            ~90K\n            E-Commerce Merchant metadata, Logo URL, and domains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset.","url":"https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset","creator_name":"Kindred Soul Ltd","creator_url":"https://huggingface.co/kindred-soul-ltd","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","cc-by-4.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"exHarmony","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\texHarmony: Authorship and Citations for Benchmarking the Reviewer Assignment Problem\n\t\n\nQuick links: üìÉ Paper | ‚öôÔ∏è Code \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nexHarmony is a large-scale benchmark dataset for the Reviewer Assignment Problem (RAP), reframing reviewer recommendation as an information retrieval task.\nIt leverages publication metadata from OpenAlex to construct a collection of papers, their authors, citation links, and multiple qrel definitions for evaluation.\nThe dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Reviewerly/exHarmony.","url":"https://huggingface.co/datasets/Reviewerly/exHarmony","creator_name":"Reviewerly Inc","creator_url":"https://huggingface.co/Reviewerly","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","1M<n<10M","arxiv:2502.07683"],"keywords_longer_than_N":true},
	{"name":"exHarmony","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\texHarmony: Authorship and Citations for Benchmarking the Reviewer Assignment Problem\n\t\n\nQuick links: üìÉ Paper | ‚öôÔ∏è Code \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nexHarmony is a large-scale benchmark dataset for the Reviewer Assignment Problem (RAP), reframing reviewer recommendation as an information retrieval task.\nIt leverages publication metadata from OpenAlex to construct a collection of papers, their authors, citation links, and multiple qrel definitions for evaluation.\nThe dataset allows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Reviewerly/exHarmony.","url":"https://huggingface.co/datasets/Reviewerly/exHarmony","creator_name":"Reviewerly Inc","creator_url":"https://huggingface.co/Reviewerly","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","1M<n<10M","arxiv:2502.07683"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"XNLI_Vietnamese_triplets","keyword":"text-retrieval","description":"Citation:\n@InProceedings{conneau2018xnli,\n  author = {Conneau, Alexis\n                 and Rinott, Ruty\n                 and Lample, Guillaume\n                 and Williams, Adina\n                 and Bowman, Samuel R.\n                 and Schwenk, Holger\n                 and Stoyanov, Veselin},\n  title = {XNLI: Evaluating Cross-lingual Sentence Representations},\n  booktitle = {Proceedings of the 2018 Conference on Empirical Methods\n               in Natural Language Processing},\n  year =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haiFrHust/XNLI_Vietnamese_triplets.","url":"https://huggingface.co/datasets/haiFrHust/XNLI_Vietnamese_triplets","creator_name":"Hai Phan","creator_url":"https://huggingface.co/haiFrHust","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-ranking","text-retrieval","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"bemir","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBEMIR Dataset\n\t\n\nBulgarian-English Medical Information Retrieval\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\n\t\n\t\t\nMetric\nCount\nDetails\n\n\n\t\t\nDocuments\n7,266\n3,633 BG + 3,633 EN\n\n\nQueries\n6,474\n3,237 BG + 3,237 EN\n\n\nRelevance Pairs\n134,294\nTrain: 110,575, Dev: 11,385, Test: 12,334\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Files & Sizes\n\t\n\n\n\t\n\t\t\nFile\nSize\nRecords\nDescription\n\n\n\t\t\ncorpus_bg.jsonl\n11 MB\n3,633\nBulgarian documents\n\n\ncorpus_en.jsonl\n5.7 MB\n3,633\nEnglish documents\n\n\nqueries_bg.jsonl315 KB\n3,237\nBulgarian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-bg/bemir.","url":"https://huggingface.co/datasets/llm-bg/bemir","creator_name":"LLM.bg","creator_url":"https://huggingface.co/llm-bg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Bulgarian","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-855191","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-855191 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-855191 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sbp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Name\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nA dataset created from a 90-page PDF document, structured for retrieval and information extraction tasks. Each entry contains textual content and metadata, making it ideal for applications such as question answering, summarization, and semantic search.\n\nSource: Derived from a specific document (e.g., a book, article, or report).\nSize: Contains individual entries for each page or section of the document.\nPurpose: Designed for use in NLP retrieval and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ben4mn/sbp.","url":"https://huggingface.co/datasets/ben4mn/sbp","creator_name":"Ben","creator_url":"https://huggingface.co/ben4mn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"high-quality-summary","keyword":"text-retrieval","description":"\nData from agentlans/high-quality-text sample_k10000 configuration\nSummaries generated using google/gemma-3-12b-it\nSummaries rewritten using agentlans/granite-3.3-2b-refiner\nRewritten summaries checked against the original text using ibm-granite/granite-3.3-8b-instruct\n\n","url":"https://huggingface.co/datasets/agentlans/high-quality-summary","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"sbp","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tDataset Name\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nA dataset created from a 90-page PDF document, structured for retrieval and information extraction tasks. Each entry contains textual content and metadata, making it ideal for applications such as question answering, summarization, and semantic search.\n\nSource: Derived from a specific document (e.g., a book, article, or report).\nSize: Contains individual entries for each page or section of the document.\nPurpose: Designed for use in NLP retrieval and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ben4mn/sbp.","url":"https://huggingface.co/datasets/ben4mn/sbp","creator_name":"Ben","creator_url":"https://huggingface.co/ben4mn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoClimateFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoClimateFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoClimateFEVER","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoClimateFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoClimateFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoClimateFEVER","French"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoClimateFEVER.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoClimateFEVER-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoClimateFEVER","French"],"keywords_longer_than_N":true},
	{"name":"code-energie","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'√©nergie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gis","keyword":"text-retrieval","description":"\n  CQADupstackGisRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGisRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gis.","url":"https://huggingface.co/datasets/mteb/cqadupstack-gis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"code-tourisme","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du tourisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"csl","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for CSL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCSL is the Chinese Scientific Literature Dataset.\n\nPaper: https://aclanthology.org/2022.coling-1.344\nRepository: https://github.com/ydli-ai/CSL\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains titles, abstracts, keywords of papers written in Chinese from several academic fields.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nEnglish (translation)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nDocuments\n\n\n\t\t\ncsl\n396k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/csl.","url":"https://huggingface.co/datasets/neuclir/csl","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","extended|csl","Chinese"],"keywords_longer_than_N":true},
	{"name":"csl","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for CSL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCSL is the Chinese Scientific Literature Dataset.\n\nPaper: https://aclanthology.org/2022.coling-1.344\nRepository: https://github.com/ydli-ai/CSL\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains titles, abstracts, keywords of papers written in Chinese from several academic fields.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nEnglish (translation)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nDocuments\n\n\n\t\t\ncsl\n396k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/csl.","url":"https://huggingface.co/datasets/neuclir/csl","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","extended|csl","Chinese"],"keywords_longer_than_N":true},
	{"name":"M-BEIR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tUniIR: Training and Benchmarking Universal Multimodal Information Retrievers (ECCV 2024)\n\t\n\nüåê Homepage | ü§ó Model(UniIR Checkpoints) | ü§ó Paper | üìñ arXiv  | GitHub\nHow to download the M-BEIR Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüî•[2023-12-21]: Our M-BEIR Benchmark is now available for use.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nM-BEIR, the Multimodal BEnchmark for Instructed Retrieval, is a comprehensive large-scale retrieval benchmark designed to train and evaluate unified multimodal retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/M-BEIR.","url":"https://huggingface.co/datasets/TIGER-Lab/M-BEIR","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-to-image","image-to-text","visual-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"afriqa-prebuilt-sparse-indexes","keyword":"text-retrieval","description":"Afriqa Prebuilt Indices\n\nPrebuilt Lucene Inverted Indices for preprocessed Afriqa Wikipedia Passages\n","url":"https://huggingface.co/datasets/masakhane/afriqa-prebuilt-sparse-indexes","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","French","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"afriqa_wiki_en_fr_100","keyword":"text-retrieval","description":"","url":"https://huggingface.co/datasets/masakhane/afriqa_wiki_en_fr_100","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-yo-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (yo) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-yo-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-yo-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-yo-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-yo-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"MedQuAD-TR","keyword":"text-retrieval","description":"Additional Info :\n\nDataset source has also unanswered questions, but for the purpose of this dataset only answered questions were scraped.\nSome questions have more than 1 answers. To keep the dataset structured only the 1st answer was choosen.\nTop 5 Medical Fields With Most Asked Questions\nBeyin & Sinir (Brain & Nerve)      : 131 \nKadƒ±n Saƒülƒ±ƒüƒ± (Women's Health)     : 99\nHamilelik (Pregnancy)              : 87\nDeri Hastalƒ±klarƒ± (Skin Disorders) : 71\nCinsel Saƒülƒ±k (Sexual Health)      : 67‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zypchn/MedQuAD-TR.","url":"https://huggingface.co/datasets/zypchn/MedQuAD-TR","creator_name":"zeynep cahan","creator_url":"https://huggingface.co/zypchn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text-retrieval","Turkish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-yo-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (yo) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-yo-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-yo-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-yo-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-yo-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"ultimate-fake-news-dataset","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tUltimate Fake News Detection Dataset\n\t\n\nShort description\nThis is an aggregated English-language dataset for fake-news detection and truthfulness classification. It combines multiple public datasets, RSS-scraped news, and verified fact statements for both binary fake/real classification and a 6-class truthfulness scale.\nDataset goals\n\nProvide a large, diverse corpus for training and evaluating fake-news / truthfulness classification models.\nSupport binary classification (fake vs real)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Arko007/ultimate-fake-news-dataset.","url":"https://huggingface.co/datasets/Arko007/ultimate-fake-news-dataset","creator_name":"Anamitra Sarkar","creator_url":"https://huggingface.co/Arko007","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"MLDR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is ‚ÄúYou are a curious AI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.","url":"https://huggingface.co/datasets/Shitao/MLDR","creator_name":"Xiao","creator_url":"https://huggingface.co/Shitao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"vivechan-spritual-text-dataset-v3","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVivechan - Spiritual Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Vivechan - Spiritual Text Dataset is an open and public collection of textual data extracted from significant spiritual texts, curated to support discussions, inquiries, doubts, and Q&A sessions within the realm of spirituality. This dataset provides valuable content from the following revered sources:\n\nShrimad Bhagwat Mahapurana\nShripad Shri Vallabha Charitramrutam\nShiv Mahapurana Sankshipt\nValmiki Ramayan\nVachanamrutam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v3.","url":"https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v3","creator_name":"Om Ashishkumar Soni","creator_url":"https://huggingface.co/om-ashish-soni","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-retrieval","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"blogspot_raw","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for blogspot raw dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of raw blogposts from blogspot mostly in the English language. It was obtained by scraping corpora of webarchive and commoncrawl.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset may be used for training language models or serve other research interests.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMostly English language, but some outliers may occur.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDistribution\nThe distribution‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mschi/blogspot_raw.","url":"https://huggingface.co/datasets/mschi/blogspot_raw","creator_name":"Martin Schirmer","creator_url":"https://huggingface.co/mschi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","time-series-forecasting","other"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-sources-v2","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Source Documents\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains source documents extracted from the research paper \"Talking to GDELT Through Knowledge Graphs\"\n(arXiv:2503.07584v3). The documents are used as the knowledge base for a Retrieval-Augmented Generation (RAG) system\nfocused on GDELT (Global Database of Events, Language, and Tone) analysis.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Documents: 38 pages\nSource: Research paper on GDELT Knowledge Graphs\nFormat: PDF pages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-sources-v2.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-sources-v2","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-sources-v2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Source Documents\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains source documents extracted from the research paper \"Talking to GDELT Through Knowledge Graphs\"\n(arXiv:2503.07584v3). The documents are used as the knowledge base for a Retrieval-Augmented Generation (RAG) system\nfocused on GDELT (Global Database of Events, Language, and Tone) analysis.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Documents: 38 pages\nSource: Research paper on GDELT Knowledge Graphs\nFormat: PDF pages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-sources-v2.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-sources-v2","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Logic-ORiented-Test","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tXiaSheng/Logic-ORiented-Test\n\t\n\nLogic-ORiented Test Dataset - Modified Test\nThis dataset contains modified test data for three different tasks:\n\nhotpotqa_modified_test: Modified HotpotQA test questions\nmsmarco_modified_test: Modified MS MARCO test questions  \nmusique_modified_test: Modified MuSiQue test questions\n\nEach split contains questions that have been modified to test logic-oriented retrieval capabilities.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset has three splits:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Test.","url":"https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Test","creator_name":"AestasZhang","creator_url":"https://huggingface.co/XiaSheng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Logic-ORiented-Test","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tXiaSheng/Logic-ORiented-Test\n\t\n\nLogic-ORiented Test Dataset - Modified Test\nThis dataset contains modified test data for three different tasks:\n\nhotpotqa_modified_test: Modified HotpotQA test questions\nmsmarco_modified_test: Modified MS MARCO test questions  \nmusique_modified_test: Modified MuSiQue test questions\n\nEach split contains questions that have been modified to test logic-oriented retrieval capabilities.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset has three splits:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Test.","url":"https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Test","creator_name":"AestasZhang","creator_url":"https://huggingface.co/XiaSheng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"povarenok_recipes_detail","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tpovarenok_recipes_detail\n\t\n\nCrawled detailed recipes from povarenok.ru website.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nWIP\n","url":"https://huggingface.co/datasets/d0rj/povarenok_recipes_detail","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","image-classification","text-generation","text-retrieval","crawled"],"keywords_longer_than_N":true},
	{"name":"singaporean-judicial-keywords","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSingaporean Judicial Keywords üèõÔ∏è\n\t\n\nSingaporean Judicial Keywords by Isaacus is a challenging legal information retrieval evaluation dataset consisting of 500 catchword-judgment pairs sourced from the Singapore Judiciary.\nUniquely, the keywords in this dataset are real-world annotations created by subject matter experts, namely, Singaporean law reporters, as opposed to being constructed ex post facto by third parties.\nAdditionally, unlike standard keyword queries, judicial catchwords‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/singaporean-judicial-keywords.","url":"https://huggingface.co/datasets/isaacus/singaporean-judicial-keywords","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","text-ranking","found","found"],"keywords_longer_than_N":true},
	{"name":"license-tldr-retrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLicense TL;DR Retrieval üìë\n\t\n\nLicense TL;DR Retrieval by Isaacus is a challenging legal information retrieval evaluation dataset consisting of 65 summary-license pairs sourced from tl;drLegal.\nThis dataset is intended to stress test the ability of an information retrieval model to match relevant open source licenses with summaries of their terms.\nTo make evaluation with this dataset as easy as possible, it has been formatted in the Massive Text Embedding Benchmark (MTEB) information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/license-tldr-retrieval.","url":"https://huggingface.co/datasets/isaacus/license-tldr-retrieval","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","found","found","English"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RuSciBenchCociteRetrieval","keyword":"document-retrieval","description":"\n  RuSciBenchCociteRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task focuses on Co-citation Prediction for scientific papers from eLibrary,\n        Russia's largest electronic library of scientific publications. Given a query paper (title and abstract),\n        the goal is to retrieve other papers that are co-cited with it. Two papers are considered co-cited\n        if they are both cited by at least 5 of the same other papers. Similar to the Direct Citation task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuSciBenchCociteRetrieval.","url":"https://huggingface.co/datasets/mteb/RuSciBenchCociteRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","mlsa-iai-msu-lab/ru_sci_bench_cocite_retrieval"],"keywords_longer_than_N":true},
	{"name":"miracl-th-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarouaneSanhaji/github-issues.","url":"https://huggingface.co/datasets/MarouaneSanhaji/github-issues","creator_name":"Marouane Sanhaji","creator_url":"https://huggingface.co/MarouaneSanhaji","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HumanEvalRetrieval","keyword":"text-retrieval","description":"\n  HumanEvalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA code retrieval task based on 164 Python programming problems from HumanEval. Each query is a natural language description of a programming task (e.g., 'Check if in given list of numbers, are any two numbers closer to each other than given threshold'), and the corpus contains Python code implementations. The task is to retrieve the correct code snippet that solves the described problem. Queries are problem‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HumanEvalRetrieval.","url":"https://huggingface.co/datasets/mteb/HumanEvalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","multilingual","embedding-benchmark/HumanEval","code"],"keywords_longer_than_N":true},
	{"name":"HC3FinanceRetrieval","keyword":"text-retrieval","description":"\n  HC3FinanceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on HC3 Finance dataset containing human vs AI-generated financial text detection. Each query is a financial question or prompt (e.g., 'Explain the impact of interest rate changes on bond prices'), and the corpus contains both human-written and AI-generated financial responses. The task is to retrieve the most relevant and accurate financial content that addresses the query. Queries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HC3FinanceRetrieval.","url":"https://huggingface.co/datasets/mteb/HC3FinanceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"RuSciBenchCociteRetrieval","keyword":"text-retrieval","description":"\n  RuSciBenchCociteRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task focuses on Co-citation Prediction for scientific papers from eLibrary,\n        Russia's largest electronic library of scientific publications. Given a query paper (title and abstract),\n        the goal is to retrieve other papers that are co-cited with it. Two papers are considered co-cited\n        if they are both cited by at least 5 of the same other papers. Similar to the Direct Citation task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuSciBenchCociteRetrieval.","url":"https://huggingface.co/datasets/mteb/RuSciBenchCociteRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","mlsa-iai-msu-lab/ru_sci_bench_cocite_retrieval"],"keywords_longer_than_N":true},
	{"name":"FinanceBenchRetrieval","keyword":"text-retrieval","description":"\n  FinanceBenchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on FinanceBench dataset containing financial questions and answers. Each query is a financial question (e.g., 'What was the total revenue in Q3 2023?'), and the corpus contains financial document excerpts and annual reports. The task is to retrieve the correct financial information that answers the question. Queries are financial questions while the corpus contains relevant excerpts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinanceBenchRetrieval.","url":"https://huggingface.co/datasets/mteb/FinanceBenchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-th-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"miracl-fr-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"miracl-ko-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Korean"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"CQADupstackAndroidRetrieval","keyword":"text-retrieval","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\nSource datasets:\n\nmteb/cqadupstack-android\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CQADupstackAndroidRetrieval.","url":"https://huggingface.co/datasets/mteb/CQADupstackAndroidRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-mpnet","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-mpnet-base-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"miracl-fr-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"miracl-ko-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Korean"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"document-retrieval","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"docred","keyword":"entity-linking-retrieval","description":"Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features:\n    - DocRED annotates both named entities and relations, and is the largest human-annotated dataset for document-level RE from plain text.\n    - DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.\n    - Along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios.","url":"https://huggingface.co/datasets/thunlp/docred","creator_name":"Tsinghua NLP group","creator_url":"https://huggingface.co/thunlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"docred","keyword":"text-retrieval","description":"Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features:\n    - DocRED annotates both named entities and relations, and is the largest human-annotated dataset for document-level RE from plain text.\n    - DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.\n    - Along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios.","url":"https://huggingface.co/datasets/thunlp/docred","creator_name":"Tsinghua NLP group","creator_url":"https://huggingface.co/thunlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"text-retrieval","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"entity-linking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"fact-checking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"alloprof","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAlloprof dataset\n\t\n\nThis is the dataset refered to in our paper:\nAlloprof: a new French question-answer education dataset and its use in an information retrieval case study (https://arxiv.org/abs/2302.07738)\nThis dataset was provided by AlloProf, an organisation in Quebec, Canada offering resources and a help forum curated by a large number of teachers to students on all subjects taught from in primary and secondary school.\nRaw data on questions is available in the following files:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/antoinelb7/alloprof.","url":"https://huggingface.co/datasets/antoinelb7/alloprof","creator_name":"Antoine Lefebvre-Brossard","creator_url":"https://huggingface.co/antoinelb7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","French","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"esci","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for \"esci\"\n\t\n\nESCI product search dataset\nhttps://github.com/amazon-science/esci-data/\nPreprocessings: \n-joined the two relevant files\n-product_text aggregate all product text\n-mapped esci_label to full name \n@article{reddy2022shopping,\ntitle={Shopping Queries Dataset: A Large-Scale {ESCI} Benchmark for Improving Product Search},\nauthor={Chandan K. Reddy and Llu√≠s M√†rquez and Fran Valero and Nikhil Rao and Hugo Zaragoza and Sambaran Bandyopadhyay and Arnab Biswas and Anlu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/esci.","url":"https://huggingface.co/datasets/tasksource/esci","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-evaluation-inputs","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Evaluation Datasets\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains consolidated RAGAS evaluation input datasets from 5 different retrieval strategies tested on the GDELT (Global Database of Events, Language, and Tone) RAG system. Each strategy was evaluated on the same golden testset of 12 questions, providing a direct comparison of retrieval performance.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: ~1,400+ evaluation records across 5 retrievers\nRetrievers Compared:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-inputs.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-inputs","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-evaluation-datasets","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Evaluation Datasets\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains consolidated RAGAS evaluation input datasets from 5 different retrieval strategies tested on the GDELT (Global Database of Events, Language, and Tone) RAG system. Each strategy was evaluated on the same golden testset of 12 questions, providing a direct comparison of retrieval performance.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: ~1,400+ evaluation records across 5 retrievers\nRetrievers Compared:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-datasets.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-datasets","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"times_of_india_news_headlines","keyword":"document-retrieval","description":"This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.","url":"https://huggingface.co/datasets/community-datasets/times_of_india_news_headlines","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","fact-checking-retrieval","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"times_of_india_news_headlines","keyword":"fact-checking-retrieval","description":"This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.","url":"https://huggingface.co/datasets/community-datasets/times_of_india_news_headlines","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","fact-checking-retrieval","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"metooma","keyword":"text-retrieval","description":"The dataset consists of tweets belonging to #MeToo movement on Twitter, labelled into different categories.\nDue to Twitter's development policies, we only provide the tweet ID's and corresponding labels,\nother data can be fetched via Twitter API.\nThe data has been labelled by experts, with the majority taken into the account for deciding the final label.\nWe provide these labels for each of the tweets. The labels provided for each data point\nincludes -- Relevance, Directed Hate, Generalized Hate,\nSarcasm, Allegation, Justification, Refutation, Support, Oppose","url":"https://huggingface.co/datasets/midas/metooma","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"times_of_india_news_headlines","keyword":"text-retrieval","description":"This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.","url":"https://huggingface.co/datasets/community-datasets/times_of_india_news_headlines","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","fact-checking-retrieval","text-simplification","no-annotation"],"keywords_longer_than_N":true},
	{"name":"MedQuAD-TR","keyword":"text-retrieval","description":"Additional Info :\n\nDataset source has also unanswered questions, but for the purpose of this dataset only answered questions were scraped.\nSome questions have more than 1 answers. To keep the dataset structured only the 1st answer was choosen.\nTop 5 Medical Fields With Most Asked Questions\nBeyin & Sinir (Brain & Nerve)      : 131 \nKadƒ±n Saƒülƒ±ƒüƒ± (Women's Health)     : 99\nHamilelik (Pregnancy)              : 87\nDeri Hastalƒ±klarƒ± (Skin Disorders) : 71\nCinsel Saƒülƒ±k (Sexual Health)      : 67‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zypchn/MedQuAD-TR.","url":"https://huggingface.co/datasets/zypchn/MedQuAD-TR","creator_name":"zeynep cahan","creator_url":"https://huggingface.co/zypchn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text-retrieval","Turkish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-hi-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (hi) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"dkstance","keyword":"fact-checking","description":"This dataset presents a series of stories on Reddit and the conversation around\nthem, annotated for stance. Stories are also annotated for veracity.\n\nFor more details see https://aclanthology.org/W19-6122/","url":"https://huggingface.co/datasets/strombergnlp/dkstance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"danfever","keyword":"fact-checking","description":"\\","url":"https://huggingface.co/datasets/strombergnlp/danfever","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","natural-language-inference","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-hi-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (hi) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"MedDataTR-1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MedData_tr-1\n\t\n\nThis dataset has 917 instances and 5227389 tokens in total\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nLanguage(s) (NLP): Turkish\nLicense: APACHE 2.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nMemorial Health Library : https://www.memorial.com.tr/saglik-kutuphanesi\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ncategory : The data was split into 3 categories \n\nTanƒ± ve Testler (Diagnoses and Tests)\nHastalƒ±klar (Diseases)\nTedavi Y√∂ntemleri (Treatment Methods)\n\ntopic :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zypchn/MedDataTR-1.","url":"https://huggingface.co/datasets/zypchn/MedDataTR-1","creator_name":"zeynep cahan","creator_url":"https://huggingface.co/zypchn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","text-retrieval","Turkish"],"keywords_longer_than_N":true},
	{"name":"miracl-te-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (te) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-te-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-te-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-te-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-te-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Telugu"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"fact-checking","description":"The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to\nprobe large language models, and extrapolate their future capabilities.","url":"https://huggingface.co/datasets/google/bigbench","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"miracl-te-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (te) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-te-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-te-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-te-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-te-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Telugu"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"miracl-id-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (id) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-id-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-id-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-id-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-id-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Indonesian"],"keywords_longer_than_N":true},
	{"name":"miracl-ko-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Korean"],"keywords_longer_than_N":true},
	{"name":"miracl-id-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (id) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-id-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-id-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-id-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-id-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Indonesian"],"keywords_longer_than_N":true},
	{"name":"miracl-ko-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Korean"],"keywords_longer_than_N":true},
	{"name":"USLawQA","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tUSLawQA\n\t\n\nUSLawQA is a groundbreaking dataset specifically designed to advance research in Information Retrieval (IR) and Question Answering (QA) in the legal domain. This dataset is built using legal texts from the United States Civil Code, structured for efficient training and evaluation of AI systems.\n\nNote: This dataset was meticulously created using custom web scrapers on uscode.house.gov and did not previously exist in this format. It represents a unique and valuable resource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/USLawQA.","url":"https://huggingface.co/datasets/ArchitRastogi/USLawQA","creator_name":"Archit Rastogi","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"infovqa_colqwen2_embeddings","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tInfoVQA ColQwen2.5 Embeddings\n\t\n\nThis dataset contains pre-computed embeddings for the InfoVQA dataset using the ColQwen2.5 model.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three configurations:\n\n\t\n\t\t\n\t\tCorpus Configuration\n\t\n\nContains document images with their embeddings.\nfrom datasets import load_dataset\ncorpus = load_dataset(\"WenxingZhu/infovqa_colqwen2_embeddings\", \"corpus\", split=\"test\")\n\nFields:\n\ncorpus-id (int): Document identifier\nimage (Image): Original document‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"base-dados-odio-lgbtqia","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBase de Dados de √ìdio contra Pessoas LGBTQIA+ em Portugu√™s (PT-BR)\n\t\n\nCole√ß√£o de datasets para detec√ß√£o de discurso de √≥dio contra pessoas LGBTQIA+ em portugu√™s brasileiro.\n\n\t\n\t\t\n\t\tüéØ Objetivo\n\t\n\nFornecer dados de treinamento e valida√ß√£o para sistemas de detec√ß√£o de discurso de √≥dio contra pessoas LGBTQIA+ em portugu√™s brasileiro.\n\n\t\n\t\t\n\t\tüì¢ Contexto Social\n\t\n\nEste dataset foi criado a partir de uma onda de √≥dio real sofrida pelo podcast Entre Amigues da equipe C√≥digo N√£o Bin√°rio. Os‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia.","url":"https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia","creator_name":"Veronyka \"Travahacker\" Gimenes","creator_url":"https://huggingface.co/Veronyka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Portuguese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-zh-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (zh) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"x-stance","keyword":"fact-checking","description":"The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions. The comments are partly German, partly French and Italian. The data have been extracted from the Swiss voting advice platform Smartvote.","url":"https://huggingface.co/datasets/strombergnlp/x-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-zh-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (zh) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-de-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language, \nFor each language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"miracl-de-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"humsetbias","keyword":"text-retrieval","description":"nlp-thedeep/humsetbias dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nlp-thedeep/humsetbias","creator_name":"TheDEEP NLP","creator_url":"https://huggingface.co/nlp-thedeep","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-retrieval","token-classification","multi-label-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"humset","keyword":"text-retrieval","description":"HumSet is a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. HumSet is curated by humanitarian analysts and covers various disasters around the globe that occurred from 2018 to 2021 in 46 humanitarian response projects. The dataset consists of approximately 17K annotated documents in three languages of English, French, and Spanish, originally taken from publicly-available resources. For each document, analysts have identified informative snippets (entries) in respect to common humanitarian frameworks, and assigned one or many classes to each entry. See the our paper for details.","url":"https://huggingface.co/datasets/nlp-thedeep/humset","creator_name":"TheDEEP NLP","creator_url":"https://huggingface.co/nlp-thedeep","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","token-classification","multi-label-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"ontario_laws_and_regs","keyword":"document-retrieval","description":"##Ontario Laws & Regulations Dataset \n\n\t\n\t\t\n\t\t‚öñÔ∏èOntario Laws & Regs‚öñÔ∏è\n\t\n\nThe Ontario Laws & Regs dataset contains 5,096 Ontario laws and regulations. \nThe laws and regulations consist of the most recent version of all current and revoked laws and regs. \nThe dataset is distributed under the MIT license and is intended to facilitate ML and data tasks involving Ontario legislation.\nIn addition, a scraper is provided which is capable of capturing different configurations of the data directly from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hordruma/ontario_laws_and_regs.","url":"https://huggingface.co/datasets/hordruma/ontario_laws_and_regs","creator_name":"Druma","creator_url":"https://huggingface.co/hordruma","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","text-retrieval","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"ontario_laws_and_regs","keyword":"text-retrieval","description":"##Ontario Laws & Regulations Dataset \n\n\t\n\t\t\n\t\t‚öñÔ∏èOntario Laws & Regs‚öñÔ∏è\n\t\n\nThe Ontario Laws & Regs dataset contains 5,096 Ontario laws and regulations. \nThe laws and regulations consist of the most recent version of all current and revoked laws and regs. \nThe dataset is distributed under the MIT license and is intended to facilitate ML and data tasks involving Ontario legislation.\nIn addition, a scraper is provided which is capable of capturing different configurations of the data directly from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hordruma/ontario_laws_and_regs.","url":"https://huggingface.co/datasets/hordruma/ontario_laws_and_regs","creator_name":"Druma","creator_url":"https://huggingface.co/hordruma","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","text-retrieval","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"syntheticDocQA_healthcare_industry_test","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is part of a topic-specific retrieval benchmark spanning multiple domains, which evaluates retrieval in more realistic industrial applications. \nIt includes documents about the Healthcare Industry that allow ViDoRe to benchmark medical documents. \n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThanks to a crawler (see below), we collected 1,000 PDFs from the Internet with the query ('healthcare industry'). From these documents, we randomly sampled 1000 pages.\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/syntheticDocQA_healthcare_industry_test.","url":"https://huggingface.co/datasets/vidore/syntheticDocQA_healthcare_industry_test","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NanoNQ-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNQ.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNQ-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNQ","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Assamese"],"keywords_longer_than_N":true},
	{"name":"neuclir1","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for NeuCLIR1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset created for the TREC NeuCLIR Track. The collection is designed to be similar to HC4, and a large portion of documents from HC4 are ported to this collection.\nThe documents are Web pages from Common Crawl in Chinese, Persian, and Russian.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nPersian\nRussian\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nNum Documents\n\n\n\t\t\nfas (Persian)\n2.2M\n\n\nrus (Russian)\n4.6M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/neuclir1.","url":"https://huggingface.co/datasets/neuclir/neuclir1","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"ag_news_fact_check_with_llm","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tEntity-Level Fact-Check Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides pairs of text snippets with controlled, entity-level factual perturbations, designed to evaluate large language models (LLMs) on their ability to detect, reason about, and correct factual errors at the entity level.\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nExisting datasets (e.g., CNN/DailyMail, WikiBio, XSum) focus on broad factual consistency but do not provide explicit mappings between original facts and their incorrect‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cyabra/ag_news_fact_check_with_llm.","url":"https://huggingface.co/datasets/Cyabra/ag_news_fact_check_with_llm","creator_name":"Cyabra ","creator_url":"https://huggingface.co/Cyabra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","ab_news","English","mit"],"keywords_longer_than_N":true},
	{"name":"NanoNQ-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNQ.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNQ-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNQ","French"],"keywords_longer_than_N":true},
	{"name":"NanoNQ-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNQ.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNQ-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNQ","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Assamese"],"keywords_longer_than_N":true},
	{"name":"neuclir1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for NeuCLIR1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the dataset created for the TREC NeuCLIR Track. The collection is designed to be similar to HC4, and a large portion of documents from HC4 are ported to this collection.\nThe documents are Web pages from Common Crawl in Chinese, Persian, and Russian.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese\nPersian\nRussian\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\nSplit\nNum Documents\n\n\n\t\t\nfas (Persian)\n2.2M\n\n\nrus (Russian)\n4.6M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/neuclir1.","url":"https://huggingface.co/datasets/neuclir/neuclir1","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"PubMedQA-MetaGenBlendedRAG","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPubMedQA-MetaGen: Metadata-Enriched PubMedQA Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPubMedQA-MetaGen is a metadata-enriched version of the PubMedQA biomedical question-answering dataset, created using the MetaGenBlendedRAG enrichment pipeline. The dataset contains both the original and enriched versions of the corpus, enabling direct benchmarking of retrieval-augmented and semantic search approaches in biomedical NLP.\n\n\n\t\n\t\t\n\t\tFiles Provided\n\t\n\n\nPubMedQA_original_corpus.csv\nThis file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG.","url":"https://huggingface.co/datasets/Shivam6693/PubMedQA-MetaGenBlendedRAG","creator_name":"Shivam Raj Solanki","creator_url":"https://huggingface.co/Shivam6693","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NQ-NL","keyword":"text-retrieval","description":"\n  NQ-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNQ-NL is a translation of NQ\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nq\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NQ-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NQ-NL.","url":"https://huggingface.co/datasets/mteb/NQ-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"MMS-VPR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset\n\t\n\nMultimodal Street-Level Visual Place Recognition Dataset (MMS-VPR) is a novel, open-access dataset designed to advance research in visual place recognition (VPR) and multimodal urban scene understanding. This dataset focuses on complex, fine-grained, and pedestrian-only urban environments, addressing a significant gap in existing VPR datasets that often rely on vehicle-based imagery from road networks and overlook‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.","url":"https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR","creator_name":"Yiwei Ou","creator_url":"https://huggingface.co/Yiwei-Ou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","multi-class-image-classification","human-annotated","found"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"code-instruments-monetaires-medailles","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des instruments mon√©taires et des m√©dailles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Assamese"],"keywords_longer_than_N":true},
	{"name":"company-dataset","keyword":"text-retrieval","description":"Free dataset containing about 24M companies. Originally compiled by People Data Labs, released under a free license.\nData Schema and more information on te dataset at: https://docs.peopledatalabs.com/docs/free-company-dataset\nThis version has been downloaded on 2025-07-28\n","url":"https://huggingface.co/datasets/andreaaltomani/company-dataset","creator_name":"Andrea Altomani","creator_url":"https://huggingface.co/andreaaltomani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"TSMPD-US-Public-v1_1","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\t[Updated with SBERT Embeddings + Search Notebook]\n\t\n\n\n\t\n\t\t\n\t\tTSMPD‚ÄëUS: U.S. Small Merchant Product Dataset + SBERT Embeddings + Search Notebook\n\t\n\n‚ö° New in this release (April 2025):\nSBERT vector embeddings for all products (MiniLM‚ÄëL6)\nChunked Parquet format for scalable vector search\nJupyter notebook demo for live semantic queries\nThese additions make it easier to integrate small merchant data into RAG pipelines, grounding tasks, and real-time AI agents.\n\n\t\n\t\t\n\t\n\t\n\t\tAn open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1.","url":"https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1","creator_name":"Tokuhn","creator_url":"https://huggingface.co/Tokuhn","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","document-retrieval","semantic-similarity-classification","English"],"keywords_longer_than_N":true},
	{"name":"TSMPD-US-Public-v1_1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\t[Updated with SBERT Embeddings + Search Notebook]\n\t\n\n\n\t\n\t\t\n\t\tTSMPD‚ÄëUS: U.S. Small Merchant Product Dataset + SBERT Embeddings + Search Notebook\n\t\n\n‚ö° New in this release (April 2025):\nSBERT vector embeddings for all products (MiniLM‚ÄëL6)\nChunked Parquet format for scalable vector search\nJupyter notebook demo for live semantic queries\nThese additions make it easier to integrate small merchant data into RAG pipelines, grounding tasks, and real-time AI agents.\n\n\t\n\t\t\n\t\n\t\n\t\tAn open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1.","url":"https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1","creator_name":"Tokuhn","creator_url":"https://huggingface.co/Tokuhn","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","document-retrieval","semantic-similarity-classification","English"],"keywords_longer_than_N":true},
	{"name":"virginia-woolf-monologue-chunks","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVirginia Woolf Monologue Chunks Dataset\n\t\n\nThis dataset contains 6 semantically chunked text segments derived from a contemporary monologue based on Virginia Woolf's seminal essay \"A Room of One's Own\" (1929). It comes pre-loaded with vector embeddings from three different models, making it a ready-to-use resource for a variety of NLP tasks.\nIn addition to the dataset itself, this repository includes a comprehensive embedding analysis, detailed statistics, and 7 visualizations to help‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks.","url":"https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks","creator_name":"The Pageman at Bettergov.ph","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-retrieval","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench2025.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench2025","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Oriya"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedicalSciencesRetrieval","keyword":"document-retrieval","description":"\n  R2MEDMedicalSciencesRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedical-Sciences retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Medical-Sciences\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedicalSciencesRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Medical-Sciences"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"document-retrieval","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench2025.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench2025","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Oriya"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedicalSciencesRetrieval","keyword":"text-retrieval","description":"\n  R2MEDMedicalSciencesRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedical-Sciences retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Medical-Sciences\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedicalSciencesRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedicalSciencesRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Medical-Sciences"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"text-retrieval","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Maithili"],"keywords_longer_than_N":true},
	{"name":"isabelleps","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tIsabelle Premise Selection\n\t\n\npremise selection evaluation dataset for Isabelle, sourced from MAPL (https://huggingface.co/datasets/Simontwice/premise_selection_in_isabelle).\n","url":"https://huggingface.co/datasets/hcju/isabelleps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MACHINE-AUGMENTED PROOFS LIBRARY (MAPL)","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Maithili"],"keywords_longer_than_N":true},
	{"name":"isabelleps","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIsabelle Premise Selection\n\t\n\npremise selection evaluation dataset for Isabelle, sourced from MAPL (https://huggingface.co/datasets/Simontwice/premise_selection_in_isabelle).\n","url":"https://huggingface.co/datasets/hcju/isabelleps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MACHINE-AUGMENTED PROOFS LIBRARY (MAPL)","English"],"keywords_longer_than_N":true},
	{"name":"isabelleps","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIsabelle Premise Selection\n\t\n\npremise selection evaluation dataset for Isabelle, sourced from MAPL (https://huggingface.co/datasets/Simontwice/premise_selection_in_isabelle).\n","url":"https://huggingface.co/datasets/hcju/isabelleps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MACHINE-AUGMENTED PROOFS LIBRARY (MAPL)","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"leanps","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tLean Premise Selection Dataset\n\t\n\nLeanDojo (https://zenodo.org/doi/10.5281/zenodo.8040109) premise selection dataset\n","url":"https://huggingface.co/datasets/hcju/leanps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","lenandojo","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"leanps","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLean Premise Selection Dataset\n\t\n\nLeanDojo (https://zenodo.org/doi/10.5281/zenodo.8040109) premise selection dataset\n","url":"https://huggingface.co/datasets/hcju/leanps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","lenandojo","English"],"keywords_longer_than_N":true},
	{"name":"leanps","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLean Premise Selection Dataset\n\t\n\nLeanDojo (https://zenodo.org/doi/10.5281/zenodo.8040109) premise selection dataset\n","url":"https://huggingface.co/datasets/hcju/leanps","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","lenandojo","English"],"keywords_longer_than_N":true},
	{"name":"syntheticDocQA_energy_test","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is part of a topic-specific retrieval benchmark spanning multiple domains, which evaluates retrieval in more realistic industrial applications. \nIt includes documents about Energy that allow ViDoRe to benchmark technical documentation about energy. \n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThanks to a crawler (see below), we collected 1,000 PDFs from the Internet with the query ('energy'). From these documents, we randomly sampled 1000 pages.\nWe associated these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/syntheticDocQA_energy_test.","url":"https://huggingface.co/datasets/vidore/syntheticDocQA_energy_test","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Manipuri"],"keywords_longer_than_N":true},
	{"name":"DBPedia-PL","keyword":"text-retrieval","description":"\n  DBPedia-PL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia-PL\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-PL.","url":"https://huggingface.co/datasets/mteb/DBPedia-PL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Polish"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-NL","keyword":"text-retrieval","description":"\n  FiQA2018-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFinancial Opinion Mining and Question Answering. FiQA2018-NL is a Dutch translation\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-fiqa\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FiQA2018-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FiQA2018-NL.","url":"https://huggingface.co/datasets/mteb/FiQA2018-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/fiqa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Panjabi"],"keywords_longer_than_N":true},
	{"name":"SFinD-S","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis sample is part of the larger SFinD-S (Strative Financial Dataset - Synthetic), a comprehensive dataset designed for Retrieval-Augmented Generation (RAG) GenAI applications, Natural Language Processing (NLP), Large Language Models (LLM), and AI tasks in the financial domain. The full SFinD-S dataset contains over 20,000 records of realistic financial questions and verified answers, sourced from a wide variety of web content.\nIf you find this dataset useful or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tilmann-strative/SFinD-S.","url":"https://huggingface.co/datasets/tilmann-strative/SFinD-S","creator_name":"Tilmann Bruckhaus","creator_url":"https://huggingface.co/tilmann-strative","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"FQuADRetrieval","keyword":"document-retrieval","description":"\n  FQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset has been built from the French SQuad dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/manu/fquad2_test\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FQuADRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FQuADRetrieval.","url":"https://huggingface.co/datasets/mteb/FQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"FQuADRetrieval","keyword":"text-retrieval","description":"\n  FQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset has been built from the French SQuad dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/manu/fquad2_test\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FQuADRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FQuADRetrieval.","url":"https://huggingface.co/datasets/mteb/FQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Magahi"],"keywords_longer_than_N":true},
	{"name":"code-electoral","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode √©lectoral, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"stacksqa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tStacks Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the Stacks dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/stacksqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","stacks","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Assamese"],"keywords_longer_than_N":true},
	{"name":"stacksqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tStacks Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the Stacks dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/stacksqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","stacks","English"],"keywords_longer_than_N":true},
	{"name":"stacksqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tStacks Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the Stacks dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/stacksqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","stacks","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Assamese"],"keywords_longer_than_N":true},
	{"name":"REIRCOCO","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReferring Expression Instance Retrieval and A Strong End-to-End Baseline (ACMMM 2025)\n\t\n\nüåê Homepage | ü§ó Model(CLARE Checkpoints)(coming soon) | üìñ arXiv  | GitHub\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nREIRCOCO is a large-scale benchmark specifically designed for Referring Expression Instance Retrtieval(REIR). It features uniquely aligned referring expressions for over 215,000 object instances in 30,000+ images, totaling 613,000 fine-grained descriptions. The dataset is constructed through a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoxiangzhao/REIRCOCO.","url":"https://huggingface.co/datasets/haoxiangzhao/REIRCOCO","creator_name":"Xiangzhao Hao","creator_url":"https://huggingface.co/haoxiangzhao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","text-retrieval","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"synthetic-text-embedding","keyword":"text-retrieval","description":"hllj/synthetic-text-embedding dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hllj/synthetic-text-embedding","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Vietnamese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"TwitterHjerneRetrieval","keyword":"text-retrieval","description":"\n  TwitterHjerneRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish question asked on Twitter with the Hashtag #Twitterhjerne ('Twitter brain') and their corresponding answer.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Written\n\nReference\nhttps://huggingface.co/datasets/sorenmulli/da-hashtag-twitterhjerne\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval.","url":"https://huggingface.co/datasets/mteb/TwitterHjerneRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","sorenmulli/da-hashtag-twitterhjerne"],"keywords_longer_than_N":true},
	{"name":"OGC_MEGA_MultiDomain_DocRetrieval","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVisual Document Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for training visual document retrieval models. It combines multiple datasets from the OGC series, Colpali, and LlamaIndex to create the most comprehensive training resource for visual document retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains structured fields including unique identifiers with string lengths ranging from 45 to 50 characters, search query text with variable lengths between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval.","url":"https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","multilingual","English","French"],"keywords_longer_than_N":true},
	{"name":"OGC_MEGA_MultiDomain_DocRetrieval","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tVisual Document Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for training visual document retrieval models. It combines multiple datasets from the OGC series, Colpali, and LlamaIndex to create the most comprehensive training resource for visual document retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains structured fields including unique identifiers with string lengths ranging from 45 to 50 characters, search query text with variable lengths between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval.","url":"https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","multilingual","English","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"OGC_MEGA_MultiDomain_DocRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVisual Document Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for training visual document retrieval models. It combines multiple datasets from the OGC series, Colpali, and LlamaIndex to create the most comprehensive training resource for visual document retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains structured fields including unique identifiers with string lengths ranging from 45 to 50 characters, search query text with variable lengths between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval.","url":"https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","multilingual","English","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"CNIL","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFrench National Commission on Informatics and Liberty (CNIL) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (https://www.legifrance.gouv.fr/search/cnil).\nThis dataset is sourced from DILA/OPENDATA/CNIL and provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France.\nIt serves as a rich‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/CNIL.","url":"https://huggingface.co/datasets/Tricoteuses/CNIL","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Urdu"],"keywords_longer_than_N":true},
	{"name":"Argimi-Ardian-Finance-10k-text-image","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThe ArGiMI Ardian datasets : text and images\n\t\n\n\nThe ArGiMi project is committed to open-source principles and data sharing. \nThanks to our generous partners, we are releasing several valuable datasets to the public.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThis dataset comprises 11,000 financial annual reports, written in english, meticulously\nextracted from their original PDF format to provide a valuable resource for researchers and developers in financial\nanalysis and natural language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artefactory/Argimi-Ardian-Finance-10k-text-image.","url":"https://huggingface.co/datasets/artefactory/Argimi-Ardian-Finance-10k-text-image","creator_name":"Artefact","creator_url":"https://huggingface.co/artefactory","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-generation","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gaming","keyword":"text-retrieval","description":"\n  CQADupstackGamingRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGamingRetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gaming.","url":"https://huggingface.co/datasets/mteb/cqadupstack-gaming","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"document-retrieval","description":"\n  NevIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPaired evaluation of real world negation in retrieval, with questions and passages. Since models generally prefer one passage over the other always, there are two questions that the model must get right to understand the negation (hence the paired_accuracy metric).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://github.com/orionw/NevIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NevIR.","url":"https://huggingface.co/datasets/mteb/NevIR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-unix","keyword":"text-retrieval","description":"\n  CQADupstackUnixRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackUnixRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-unix.","url":"https://huggingface.co/datasets/mteb/cqadupstack-unix","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"ReasonAug","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReasonAug: A Training Set for Reasoning-intensive Retrieval\n\t\n\nReasonAug is a training dataset deisgned to improve performance on theorem-based subsets of BRIGHT, i.e., a reasoning-intensive retrieval benchmark.\nReasonAug includes 10,896 query-pos-neg triplets across math, physics, code, and finance. These examples were generated by GPT4o-mini.\n\nPaper: https://arxiv.org/pdf/2505.15045\nCode: https://github.com/siyue-zhang/diffusion_embedder\n\n\n\t\n\t\t\n\t\n\t\n\t\tReasonAug Dataset Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/siyue/ReasonAug.","url":"https://huggingface.co/datasets/siyue/ReasonAug","creator_name":"siyue zhang","creator_url":"https://huggingface.co/siyue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCClinicalRetrieval","keyword":"document-retrieval","description":"\n  R2MEDPMCClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Clinical"],"keywords_longer_than_N":true},
	{"name":"code-entree-sejour-etrangers-droit-asile","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'entr√©e et du s√©jour des √©trangers et du droit d'asile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCClinicalRetrieval","keyword":"text-retrieval","description":"\n  R2MEDPMCClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Clinical"],"keywords_longer_than_N":true},
	{"name":"DXYDiseaseRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/DXYDiseaseRetrieval.","url":"https://huggingface.co/datasets/CMIRB/DXYDiseaseRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"znanio-presentations-part1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 144,280 educational presentations from the znanio.ru platform, a comprehensive resource for teachers, educators, students, and parents that has been pioneering educational technologies and distance learning in the Russian-speaking internet since 2009. The dataset is split into two parts, each containing ~72,140 presentations organized across 25 archives. All files have been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-presentations-part1.","url":"https://huggingface.co/datasets/nyuuzyou/znanio-presentations-part1","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","document-question-answering","text-retrieval","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"svitppt","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Svitppt.com.ua Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for presentations from the svitppt.com.ua platform, a presentation storage and viewing service for Ukrainian school students. The dataset includes information such as presentation titles, URLs, download URLs, and extracted text content where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual, with Ukrainian being the primary language. Other languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/svitppt.","url":"https://huggingface.co/datasets/nyuuzyou/svitppt","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"mteb-BillSumCA","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBillSumCA (MTEB format)\n\t\n\nThis is the Californian test split of the BillSum dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on BillSum with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve Californian bills based on their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-BillSumCA.","url":"https://huggingface.co/datasets/isaacus/mteb-BillSumCA","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","FiscalNote/billsum","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Gujarati"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"entity-linking-retrieval","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"text-retrieval","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Manipuri"],"keywords_longer_than_N":true},
	{"name":"code-construction-habitation","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la construction et de l'habitation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"BrightRetrieval","keyword":"document-retrieval","description":"\n  BrightRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightRetrieval.","url":"https://huggingface.co/datasets/mteb/BrightRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"BrightRetrieval","keyword":"text-retrieval","description":"\n  BrightRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightRetrieval.","url":"https://huggingface.co/datasets/mteb/BrightRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"text-retrieval","description":"\n  NanoQuoraRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoQuoraRetrieval is a smaller subset of the QuoraRetrieval dataset, which is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nSocial\n\n\nReference\nhttps://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoQuoraRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoQuoraRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","mteb/quora","English"],"keywords_longer_than_N":true},
	{"name":"code-artisanat","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'artisanat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"goodreads-book-recommend","keyword":"text-retrieval","description":"nirajandhakal/goodreads-book-recommend dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nirajandhakal/goodreads-book-recommend","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["tabular-to-text","text-retrieval","table-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-ii","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe II, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"document-retrieval","description":"This dataset originates from the teaching materials of the NLP Course.\nvia: https://huggingface.co/learn/nlp-course/en/chapter5/5\n","url":"https://huggingface.co/datasets/real-jiakai/github-issues","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"github-issues","keyword":"text-retrieval","description":"This dataset originates from the teaching materials of the NLP Course.\nvia: https://huggingface.co/learn/nlp-course/en/chapter5/5\n","url":"https://huggingface.co/datasets/real-jiakai/github-issues","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpusRetrieval","keyword":"text-retrieval","description":"\n  NanoNFCorpusRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNFCorpus is a smaller subset of NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\nReference\nhttps://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","expert-annotated","monolingual","mteb/nfcorpus"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"GlobalRG-Retrieval","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGlobalRG - Retrieval Across Universals Task\n\t\n\nDespite recent advancements in vision-language models, their performance remains suboptimal on images from non-western cultures due to underrepresentation in training datasets. Various benchmarks have been proposed to test models' cultural inclusivity, but they have limited coverage of cultures and do not adequately assess cultural diversity across universal as well as culture-specific local concepts. We introduce the GlobalRG-Retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UBC-VL/GlobalRG-Retrieval.","url":"https://huggingface.co/datasets/UBC-VL/GlobalRG-Retrieval","creator_name":"UBCVL","creator_url":"https://huggingface.co/UBC-VL","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"code-consommation","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la consommation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum_Circuit_Synthetic","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Quantum_Circuit_Synthetic ‚Äì Overview\n\t\n\nOGC_Quantum_Circuit_Synthetic is a curated multimodal dataset focused on synthetic quantum circuits. It combines generated circuit images with expert-level technical queries to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet, adapted to handle synthetic data.\nQuantum circuit images and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Synthetic.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum_Circuit_Synthetic","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CSLRelatedRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/CSLRelatedRetrieval.","url":"https://huggingface.co/datasets/CMIRB/CSLRelatedRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AILA_statutes","keyword":"document-retrieval","description":"\n  AILAStatutes\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset is structured for the task of identifying the most relevant statutes for a given situation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReferencehttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILAStatutes\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_statutes.","url":"https://huggingface.co/datasets/mteb/AILA_statutes","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"amharic-passage-retrieval-dataset","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tAmharic Passage Retrieval Dataset\n\t\n\nThis dataset is a version of amharic-news-category-classification that has been filtered, deduplicated, and formatted for passage retrieval.\nThis dataset can be used directly with Sentence Transformers to train Amharic embedding models.\n\n\t\n\t\t\n\t\tSource Datasets:\n\t\n\n\nhttps://huggingface.co/datasets/rasyosef/amharic-news-category-classification\n\n\n\t\n\t\t\n\t\tModels and Code\n\t\n\nThe following Text Embedding and ColBERT late-interaction retrieval models were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset.","url":"https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset","creator_name":"Yosef Worku Alemneh","creator_url":"https://huggingface.co/rasyosef","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","Amharic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AILA_statutes","keyword":"text-retrieval","description":"\n  AILAStatutes\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset is structured for the task of identifying the most relevant statutes for a given situation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReferencehttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILAStatutes\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_statutes.","url":"https://huggingface.co/datasets/mteb/AILA_statutes","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-from-text-matching-short-tasks-danish","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThanks to Arrow Denmark and Nvidia for sponsoring the compute used to generate this dataset\n\t\n\nThe purpose of this dataset is to pre- or post-train embedding models for Danish text matching tasks on short texts. \nThe dataset consists of 100,000 samples generated with gemma-2-27b-it. \nThe column \"prompt\" shows the prompt given to the LLM and \"response\" shows the LLM output. \nEach sample in the dataset was generated from a seed task randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/synthetic-from-text-matching-short-tasks-danish.","url":"https://huggingface.co/datasets/ThatsGroes/synthetic-from-text-matching-short-tasks-danish","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Danish","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mteb-GovReport","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGovReport (MTEB format)\n\t\n\nThis is the test split of the GovReport dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on GovReport with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve US government reports from their summaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-GovReport.","url":"https://huggingface.co/datasets/isaacus/mteb-GovReport","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","summarization","launch/gov_reports","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-transports","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des transports, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Research-Papers","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tAI & Machine Learning Research Papers Dataset\n\t\n\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTotal Papers: 1296\nDomains Covered: \nArtificial Intelligence (AI)\nMachine Learning (ML)\nDeep Learning\nNatural Language Processing (NLP)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers.","url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PMC-Treatment","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/PMC-Treatment.","url":"https://huggingface.co/datasets/R2MED/PMC-Treatment","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"miracl-japanese-small-corpus","keyword":"text-retrieval","description":"mpkato/miracl-japanese-small-corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mpkato/miracl-japanese-small-corpus","creator_name":"Makoto Kato","creator_url":"https://huggingface.co/mpkato","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Touche2020-256-24-gpt-4o-2024-05-13-27907","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tTouche2020-256-24-gpt-4o-2024-05-13-27907 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the Touche2020-256-24-gpt-4o-2024-05-13-27907 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907.","url":"https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FactCheck","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tDataset Card for FactCheck\n\t\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nFactCheck is an benchmark for evaluating LLMs on knowledge graph fact verification. It combines structured facts from YAGO, DBpedia, and FactBench with web-extracted evidence including questions, summaries, full text, and metadata. The dataset contains examples designed for sentence-level fact-checking and QA tasks.\n\n\t\n\t\t\n\t\tüìö Supported Tasks\n\t\n\n\nQuestion Answering: Answer fact-checking questions derived from KG triples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FactCheck-AI/FactCheck.","url":"https://huggingface.co/datasets/FactCheck-AI/FactCheck","creator_name":"Fact Check","creator_url":"https://huggingface.co/FactCheck-AI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Arguana-Test","keyword":"text-retrieval","description":"\n  BIRCO-ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the ArguAna dataset from BIRCO. This dataset contains 100 queries where both queries and passages are complex one-paragraph arguments about current affairs. The objective is to retrieve the counter-argument that directly refutes the query‚Äôs stance.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"LoTTE","keyword":"document-retrieval","description":"\n  LoTTE\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLoTTE (Long-Tail Topic-stratified Evaluation for IR) is designed to evaluate retrieval models on underrepresented, long-tail topics. Unlike MSMARCO or BEIR, LoTTE features domain-specific queries and passages from StackExchange (covering writing, recreation, science, technology, and lifestyle), providing a challenging out-of-domain generalization benchmark.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web, Social\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LoTTE.","url":"https://huggingface.co/datasets/mteb/LoTTE","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"LoTTE","keyword":"text-retrieval","description":"\n  LoTTE\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLoTTE (Long-Tail Topic-stratified Evaluation for IR) is designed to evaluate retrieval models on underrepresented, long-tail topics. Unlike MSMARCO or BEIR, LoTTE features domain-specific queries and passages from StackExchange (covering writing, recreation, science, technology, and lifestyle), providing a challenging out-of-domain generalization benchmark.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web, Social\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LoTTE.","url":"https://huggingface.co/datasets/mteb/LoTTE","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"MIRe_ViD2R","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRe Pre-training Dataset for Multimodal Query Retrieval\n\t\n\nThis repository contains the pre-training dataset used in our work on MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval. The dataset is designed for training multimodal retrieval systems that integrate both visual and textual cues without fusing text features during the alignment stage.\nNote: This release excludes data from the WiT corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Y-J-Ju/MIRe_ViD2R.","url":"https://huggingface.co/datasets/Y-J-Ju/MIRe_ViD2R","creator_name":"Yeong-Joon Ju","creator_url":"https://huggingface.co/Y-J-Ju","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","image-to-text","visual-question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DBPedia-NL","keyword":"text-retrieval","description":"\n  DBPedia-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. DBPedia-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-dbpedia-entity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-NL.","url":"https://huggingface.co/datasets/mteb/DBPedia-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Dutch"],"keywords_longer_than_N":true},
	{"name":"document-loader-jul2025","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFederal Student Aid Document Loader Dataset\n\t\n\nThis dataset demonstrates document loading and processing techniques using LangChain's document loaders in an educational pipeline. It contains processed pages from official Federal Student Aid handbooks for the 2025-26 processing year.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 269 processed document pages extracted from four Federal Student Aid handbook volumes using LangChain's PyPDFDirectoryLoader.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/document-loader-jul2025.","url":"https://huggingface.co/datasets/dwb2023/document-loader-jul2025","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"ExioNAICS","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nExioNAICS is the first enterprise-level ML-ready benchmark dataset tailored for GHG emission estimation, bridging sector classification with carbon intensity analysis. In contrast to broad sectoral databases like ExioML, which offer global coverage of 163 sectors across 49 regions, ExioNAICS focuses on enterprise granularity by providing 20,850 textual descriptions mapped to validated NAICS codes and augmented with 166 sectoral carbon intensity factors. This design‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yvnminc/ExioNAICS.","url":"https://huggingface.co/datasets/Yvnminc/ExioNAICS","creator_name":"G","creator_url":"https://huggingface.co/Yvnminc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","apache-2.0","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"protobowl-11-13","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tProgressive Quiz Bowl Clues Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains Quiz Bowl questions and their corresponding progressive clues, designed for evaluating question-answering systems.\nThe progressive clues subset contains additional features such as GPT-3.5 generated categories and subcategories specific to each progressive clue.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nName: protobowl-11-13\nVersion: 1.0\nMaintainer: mgor\nHub URL: https://huggingface.co/datasets/mgor/protobowl-11-13‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mgor/protobowl-11-13.","url":"https://huggingface.co/datasets/mgor/protobowl-11-13","creator_name":"Maharshi Gor","creator_url":"https://huggingface.co/mgor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"AL-GR-Tiny","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAL-GR-Tiny: A Complete & Sampled Generative Recommendation Dataset\n\t\n\nPaper | Code | Project Page (AL-GR Org)\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAL-GR-Tiny is a compact, self-contained, and sampled version of the large-scale AL-GR ecosystem. It is designed for users who want to quickly experiment, develop, or understand the full pipeline of generative recommendation without needing to process terabytes of data.\nThis \"all-in-one\" repository bundles everything you need:\n\nPre-processed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/AL-GR-Tiny.","url":"https://huggingface.co/datasets/AL-GR/AL-GR-Tiny","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"usul-alkafi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tUsul Al-Kafi Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the full text of ÿßŸÑÿ£ÿµŸàŸÑ ŸÖŸÜ ÿßŸÑŸÉÿßŸÅŸä, a foundational Islamic book authored by ÿ´ŸÇÿ© ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖ ÿ£ÿ®Ÿä ÿ¨ÿπŸÅÿ± ŸÖÿ≠ŸÖÿØ ÿ®ŸÜ ŸäÿπŸÇŸàÿ® ÿ®ŸÜ ÿ•ÿ≥ÿ≠ÿßŸÇ ÿßŸÑŸÉŸÑŸäŸÜŸä ÿßŸÑÿ±ÿßÿ≤Ÿä. Each row in the dataset represents a single page from the book, preserving the original Arabic text structure. The book is divided into eight parts and includes beneficial annotations derived from various commentaries.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nVersion: 1.0  \nSource: Digitized from Dar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/usul-alkafi.","url":"https://huggingface.co/datasets/aliahabeeb/usul-alkafi","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","Arabic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Arguana","keyword":"retrieval","description":"This is the Arguana dataset from the BERDS benchmark. (Paper link: )The purpose of this dataset is evaluating diversity of retrieval systems given subjective questions.  \nEach instance consists of a question and a list of valid perspectives (opinions) for the question.\"Type\" indicates the number of perspectives a question has. \"Binary\" questions come with two perspectives, while \"Multi\" questions come with more than two.All the instances in this dataset is \"binary\".\nWe repurpose the Arguana‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timchen0618/Arguana.","url":"https://huggingface.co/datasets/timchen0618/Arguana","creator_name":"Hung-Ting Chen","creator_url":"https://huggingface.co/timchen0618","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Unmasking-the-Imposters","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tUnmasking the Imposters: Machine-Generated Tweet Detection Dataset\n\t\n\nThis dataset contains nine subsets of human and machine-generated tweets designed to evaluate the detection of AI-generated content across censored and uncensored large language models (LLMs). The dataset addresses the gap in understanding how content moderation and domain adaptation affect the detectability of machine-generated text on social media platforms.\n\nPaper: \"Unmasking the Imposters: How Censorship and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/redasers/Unmasking-the-Imposters.","url":"https://huggingface.co/datasets/redasers/Unmasking-the-Imposters","creator_name":"ReDAS Lab at the University of Houston","creator_url":"https://huggingface.co/redasers","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","fact-checking","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"MATH_qCoT_LLMquery_questionasquery_lexicalquery","keyword":"retrieval","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_qCoT_LLMquery_questionasquery_lexicalquery","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat-collectivites-mayotte","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat et des collectivit√©s publiques applicable √† la collectivit√© territoriale de Mayotte, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"arxiv-hard-negative-LLM","keyword":"text-retrieval","description":"This dataset contains hard negative examples generated using cross-encoders for training dense retrieval models.  Instead of traditional methods like BM25 or cross-encoders, which require full corpus access, this dataset utilizes an LLM to generate both a query and a hard negative example from a given passage. This corpus-free approach offers a potentially simpler and more efficient alternative for training high-performance retrievers. The dataset includes queries and hard negatives generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chungimungi/arxiv-hard-negative-LLM.","url":"https://huggingface.co/datasets/chungimungi/arxiv-hard-negative-LLM","creator_name":"Aarush","creator_url":"https://huggingface.co/chungimungi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-iii","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe III, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Urdu"],"keywords_longer_than_N":true},
	{"name":"mlx7-two-tower-data","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tmlx7-two-tower-data\n\t\n\nThis repository contains datasets used for training Two-Tower (Dual Encoder) models for document retrieval.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe datasets provided here are structured for training dual encoder models with various sampling strategies:\n\nclassic_triplets: 48.2 MB\nintra_query_neg: 47.6 MB\nmulti_pos_multi_neg: 126.5 MB\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nclassic_triplets.parquet: Standard triplet format with (query, positive_document, negative_document)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data.","url":"https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data","creator_name":"Azuremis","creator_url":"https://huggingface.co/Azuremis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"mlx7-two-tower-data","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tmlx7-two-tower-data\n\t\n\nThis repository contains datasets used for training Two-Tower (Dual Encoder) models for document retrieval.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe datasets provided here are structured for training dual encoder models with various sampling strategies:\n\nclassic_triplets: 48.2 MB\nintra_query_neg: 47.6 MB\nmulti_pos_multi_neg: 126.5 MB\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nclassic_triplets.parquet: Standard triplet format with (query, positive_document, negative_document)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data.","url":"https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data","creator_name":"Azuremis","creator_url":"https://huggingface.co/Azuremis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"LexSemBridge_eval","keyword":"retrieval","description":"This dataset contains the training set and test set required for LexSemBridge.\n\nPaper: LexSemBridge: Fine-Grained Dense Representation Enhancement through Token-Aware Embedding Augmentation\n\nCode: https://github.com/Jasaxion/LexSemBridge/\n\n\n\n\t\n\t\t\n\t\tPreparation\n\t\n\n1. You need to clone or download the entire repository.\n2. conda create -n lexsem python=3.10\n3. conda activate lexsem\n4. cd LexSemBridge\n5. pip install -r requirements.txt\n\n\n\t\n\t\t\n\t\tDataset and Model\n\t\n\n\nDataset Download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jasaxion/LexSemBridge_eval.","url":"https://huggingface.co/datasets/Jasaxion/LexSemBridge_eval","creator_name":"Shaoxiong Zhan","creator_url":"https://huggingface.co/Jasaxion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","arxiv:2508.17858","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"code-minier-nouveau","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode minier (nouveau), non-instruct (2025-09-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"spanish-corpus-xix","keyword":"document-retrieval","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"nemo-github-issues","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues.","url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"UMRB-OKVQA","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tOK-VQA Image-Text to Text Retreival\n\t\n\n@inproceedings{marino2019ok,\n  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},\n  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},\n  booktitle={Proceedings of the IEEE/cvf conference on computer vision and pattern recognition},\n  pages={3195--3204},\n  year={2019}\n}\n\n","url":"https://huggingface.co/datasets/izhx/UMRB-OKVQA","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"spanish-corpus-xix","keyword":"text-retrieval","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"nemo-github-issues","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues.","url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"CondAmbigQA-2K","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tCondAmbigQA-2K Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is an expanded version of the CondAmbigQA dataset, growing from the original 200 entries to 2000 entries.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCondAmbigQA-2K contains 2000 question-answering pairs with conditional contexts and ground truth answers. Each entry includes:\n\nQuestion: The ambiguous question\nProperties: Contains condition, groundtruth, and citations\nContext (ctxs): Retrieved relevant passages with scores\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Apocalypse-AGI-DAO/CondAmbigQA-2K.","url":"https://huggingface.co/datasets/Apocalypse-AGI-DAO/CondAmbigQA-2K","creator_name":"Apocalypse-AGI-DAO","creator_url":"https://huggingface.co/Apocalypse-AGI-DAO","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"ghana-news","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\nThe Ghana news topic classification dataset is constructed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news.","url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Medical-Sciences","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/Medical-Sciences.","url":"https://huggingface.co/datasets/R2MED/Medical-Sciences","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQARetrieval","keyword":"text-retrieval","description":"\n  NanoHotpotQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoHotpotQARetrieval is a smaller subset of the HotpotQA dataset, which is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval.","url":"https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"czech-politician-statements","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tCzech Politician Statements Dataset\n\t\n\nThis dataset contains fact-checked statements from the Demagog project along with \ntheir metadata and scraped evidence articles.\nGithub repository - dataset creation and fact checker pipeline scripts\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage(s) (NLP): Czech\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nSource of statements: Demagog\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tStatements\n\t\n\nStatements with their metadata (author, veracity label, ...).\nExample‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomn24/czech-politician-statements.","url":"https://huggingface.co/datasets/tomn24/czech-politician-statements","creator_name":"Hai Phong Nguyen","creator_url":"https://huggingface.co/tomn24","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Czech","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Manipuri"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval.V2","keyword":"document-retrieval","description":"\n  NLPJournalTitleIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"code-aviation-civile","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'aviation civile, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du domaine public fluvial et de la navigation int√©rieure, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Manipuri"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval.V2","keyword":"text-retrieval","description":"\n  NLPJournalTitleIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-mathematica","keyword":"text-retrieval","description":"\n  CQADupstackMathematicaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackMathematicaRetrieval\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-mathematica.","url":"https://huggingface.co/datasets/mteb/cqadupstack-mathematica","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"OGC_Memes","keyword":"retrieval","description":"racineai/OGC_Memes dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/racineai/OGC_Memes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Telugu"],"keywords_longer_than_N":true},
	{"name":"UMRB-ReMuQ","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tReMuQ Image-Text to Text Retrieval\n\t\n\nConverted from https://github.com/luomancs/ReMuQ\n@inproceedings{luo-etal-2023-end,\n    title = \"End-to-end Knowledge Retrieval with Multi-modal Queries\",\n    author = \"Luo, Man  and\n      Fang, Zhiyuan  and\n      Gokhale, Tejas  and\n      Yang, Yezhou  and\n      Baral, Chitta\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/UMRB-ReMuQ.","url":"https://huggingface.co/datasets/izhx/UMRB-ReMuQ","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["English","cc0-1.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"OGC_Memes","keyword":"text-retrieval","description":"racineai/OGC_Memes dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/racineai/OGC_Memes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Telugu"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-longevity-v1","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-longevity-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\nindex.info.json: (optional) dimensions, index type, faiss version.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~480-token chunks, ~15% overlap)\nEmbedder:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-longevity-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-longevity-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"OGC_History_Geography","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_History_Geography - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_History_Geography is a curated multimodal dataset focused on historical documents, geographical materials, and educational content. It combines text and image data extracted from real academic and educational PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_History_Geography.","url":"https://huggingface.co/datasets/racineai/OGC_History_Geography","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-longevity-v1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-longevity-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\nindex.info.json: (optional) dimensions, index type, faiss version.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~480-token chunks, ~15% overlap)\nEmbedder:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-longevity-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-longevity-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"OGC_History_Geography","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_History_Geography - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_History_Geography is a curated multimodal dataset focused on historical documents, geographical materials, and educational content. It combines text and image data extracted from real academic and educational PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_History_Geography.","url":"https://huggingface.co/datasets/racineai/OGC_History_Geography","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_06b","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-0.6B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_06b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_06b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval.V2","keyword":"document-retrieval","description":"\n  NLPJournalTitleAbsRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval.V2","keyword":"text-retrieval","description":"\n  NLPJournalTitleAbsRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V2 dataset (last updated 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_06b","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-0.6B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_06b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_06b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"code-action-sociale-familles","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'action sociale et des familles, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"NeuCLIR2022Retrieval","keyword":"text-retrieval","description":"\n  NeuCLIR2022Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\nSource datasets:\n\nmteb/neuclir-2022\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"NeuCLIR2022Retrieval\")\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NeuCLIR2022Retrieval.","url":"https://huggingface.co/datasets/mteb/NeuCLIR2022Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2022","Persian"],"keywords_longer_than_N":true},
	{"name":"code-securite-sociale","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la s√©curit√© sociale, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"fact-checking-retrieval","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"fact-checking","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TurHistQuadRetrieval","keyword":"text-retrieval","description":"\n  TurHistQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nQuestion Answering dataset on Ottoman History in Turkish\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Academic, Written\n\n\nReference\nhttps://github.com/okanvk/Turkish-Reading-Comprehension-Question-Answering-Dataset\n\n\n\t\n\nSource datasets:\n\nasparius/TurHistQuAD\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TurHistQuadRetrieval.","url":"https://huggingface.co/datasets/mteb/TurHistQuadRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","asparius/TurHistQuAD"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"text-retrieval","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tGermanRAG üá©üá™üìúü¶ú\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"reasonrank_data_rl","keyword":"information-retrieval","description":"\nUseful links: üìù arXiv Paper ‚Ä¢  üß© Github\n\n\nThe RL training data to train our ReasonRank. The data format is organized based on the training data format of VERL framework.\n","url":"https://huggingface.co/datasets/liuwenhan/reasonrank_data_rl","creator_name":"wenhan liu","creator_url":"https://huggingface.co/liuwenhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGermanRAG üá©üá™üìúü¶ú\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"exorde-social-media-one-month-2024","keyword":"text-retrieval","description":"","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-one-month-2024","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-retrieval","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SCIDOCS","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"banque_vision","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tüìä Banque_Vision: A Multimodal Dataset for Document Understanding\n\t\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nBanque_Vision is a multimodal dataset designed for document-based question answering (QA) and information retrieval. It combines textual data and visual document representations, enabling research on how vision models and language models interact for document comprehension.\nüîó Created by: Matteo Khanüéì Affiliation: TW3Partners \nüìç License: MIT  \nüîó Connect with me on LinkedInüîó Dataset on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MatteoKhan/banque_vision.","url":"https://huggingface.co/datasets/MatteoKhan/banque_vision","creator_name":"Khan Matteo","creator_url":"https://huggingface.co/MatteoKhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SCIDOCS","English"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCS","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SCIDOCS","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"small-spanish-legal-dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüìö Tripletas de B√∫squeda en Espa√±ol\n\t\n\n\n\t\n\t\t\n\t\tüìå Descripci√≥n\n\t\n\nEste dataset contiene tripletas en formato JSON dise√±adas para entrenar y evaluar modelos de recuperaci√≥n de informaci√≥n (Information Retrieval, IR) y aprendizaje contrastivo (Contrastive Learning) en el campo de Machine Learning.\nCada registro est√° estructurado en:\n\nquery: Consulta en lenguaje natural.\npositives[]: Lista de documentos relevantes para la consulta.\nnegatives[]: Lista de documentos no relevantes para la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wilfredomartel/small-spanish-legal-dataset.","url":"https://huggingface.co/datasets/wilfredomartel/small-spanish-legal-dataset","creator_name":"Wilfredo Martel","creator_url":"https://huggingface.co/wilfredomartel","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Spanish","odc-by","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"code-fonction-publique","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la fonction publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-domaine-etat","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du domaine de l'Etat, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"repository-learning","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tRepository Learning Training Dataset\n\t\n\nThis dataset contains training data extracted from GitHub repositories for training context-aware code review models. The dataset supports three primary machine learning tasks: contrastive learning, fine-tuning, and semantic indexing.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nPurpose: Enable training of AI models that understand repository-specific code review patterns and provide contextual feedback.\nSource: GitHub repositories with rich pull request history‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kotlarmilos/repository-learning.","url":"https://huggingface.co/datasets/kotlarmilos/repository-learning","creator_name":"Milos Kotlar","creator_url":"https://huggingface.co/kotlarmilos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","feature-extraction","machine-generated"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoHotpotQA.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoHotpotQA-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoHotpotQA","French"],"keywords_longer_than_N":true},
	{"name":"DBPedia-PLHardNegatives","keyword":"text-retrieval","description":"\n  DBPedia-PLHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\nSource datasets:\n\nmteb/dbpedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-PLHardNegatives.","url":"https://huggingface.co/datasets/mteb/DBPedia-PLHardNegatives","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","mteb/DBPedia_PL_test_top_250_only_w_correct-v2"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoHotpotQA.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoHotpotQA-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoHotpotQA","French"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQA-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoHotpotQA.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoHotpotQA-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoHotpotQA","French"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (06/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/LEGI.","url":"https://huggingface.co/datasets/Tricoteuses/LEGI","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"code-communes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des communes, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"neuclir-2022","keyword":"text-retrieval","description":"\n  NeuCLIR2022Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NeuCLIR2022Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/neuclir-2022.","url":"https://huggingface.co/datasets/mteb/neuclir-2022","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Persian","Russian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCORetrieval","keyword":"text-retrieval","description":"\n  NanoMSMARCORetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoMSMARCORetrieval is a smaller subset of MS MARCO, a collection of datasets focused on deep learning in search.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReferencehttps://microsoft.github.io/msmarco/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoMSMARCORetrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval.","url":"https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/msmarco"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"prezented","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Prezented.ru Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 2,289 educational presentations from the prezented.ru platform, a service focused on educational presentations for Russian schools. The dataset includes presentation titles, descriptions, download URLs, thumbnail images, and the original PPT/PPTX files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nRussian (ru): All content is in Russian\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/prezented.","url":"https://huggingface.co/datasets/nyuuzyou/prezented","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"uchitelya","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Uchitelya.com Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 199,230 educational materials from the uchitelya.com platform, a resource for teachers, educators, students, and parents providing diverse educational content on various topics. The dataset includes information such as material titles, URLs, download URLs, and extracted text content where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/uchitelya.","url":"https://huggingface.co/datasets/nyuuzyou/uchitelya","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Oriya"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedXpertQAExamRetrieval","keyword":"document-retrieval","description":"\n  R2MEDMedXpertQAExamRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedXpertQA-Exam retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedXpertQA-Exam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedXpertQAExamRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedXpertQA-Exam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Oriya"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedXpertQAExamRetrieval","keyword":"text-retrieval","description":"\n  R2MEDMedXpertQAExamRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedXpertQA-Exam retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedXpertQA-Exam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedXpertQAExamRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedXpertQAExamRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedXpertQA-Exam"],"keywords_longer_than_N":true},
	{"name":"LIMIT-small","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tLIMIT-small\n\t\n\nA retrieval dataset that exposes fundamental theoretical limitations of embedding-based retrieval models. Despite using simple queries like \"Who likes Apples?\", state-of-the-art embedding models achieve less than 20% recall@100 on LIMIT full and cannot solve LIMIT-small (46 docs).\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nVector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/LIMIT-small.","url":"https://huggingface.co/datasets/orionweller/LIMIT-small","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Manipuri"],"keywords_longer_than_N":true},
	{"name":"code-voirie-routiere","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la voirie routi√®re, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Qilin","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tQilin\n\t\n\nQilin is a large-scale multimodal dataset designed for advancing research in search, recommendation, and Retrieval-Augmented Generation (RAG) systems. This repository contains the official implementation of the dataset paper, baseline models, and evaluation tools.  This dataset was presented in Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions.\nGithub: https://github.com/RED-Search/Qilin\nThe image data can be found at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THUIR/Qilin.","url":"https://huggingface.co/datasets/THUIR/Qilin","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","sentence-similarity","text-retrieval","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Maithili"],"keywords_longer_than_N":true},
	{"name":"MCEval8K","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tMCEval8K\n\t\n\nMCEval8K is a diverse multiple-choice evaluation benchmark for probing language models‚Äô (LMs) understanding of a broad range of language skills using neuron-level analysis. \nIt was introduced in the ACL 2025 paper - \"Neuron Empirical Gradient: Discovering and Quantifying Neurons‚Äô Global Linear Controllability\".\n\n\t\n\t\t\n\t\tüîç Overview\n\t\n\nMCEval8K consists of 22 tasks grouped into six skill genres, covering linguistic analysis, content classification, reasoning, factuality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iszhaoxin/MCEval8K.","url":"https://huggingface.co/datasets/iszhaoxin/MCEval8K","creator_name":"XIN ZHAO","creator_url":"https://huggingface.co/iszhaoxin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","natural-language-inference","acceptability-classification"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"information-retrieval","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"text-retrieval","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","ClimateFEVER","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-from-retrieval-tasks-norwegian","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThanks to Arrow Denmark and Nvidia for sponsoring the compute used to generate this dataset\n\t\n\nThe purpose of this dataset is to pre- or post-train embedding models for retrieval tasks.\nThe dataset consists of 100,000 samples generated with gemma-2-27b-it.\nThe column \"prompt\" shows the prompt given to the LLM and \"response\" shows the LLM output.\nEach sample in the dataset was generated from a seed task randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-norwegian.","url":"https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-norwegian","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Norwegian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","ClimateFEVER","English"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFEVER","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","ClimateFEVER","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"Kialo","keyword":"retrieval","description":"This is the Kialo dataset from the BERDS benchmark. (Paper link: )The purpose of this dataset is evaluating diversity of retrieval systems given subjective questions.  \nEach instance consists of a question and a list of valid perspectives (opinions) for the question.\"Type\" indicates the number of perspectives a question has. \"Binary\" questions come with two perspectives, while \"Multi\" questions come with more than two.  \nWe collect the dataset from a debate website, Kialo.com.The positive and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timchen0618/Kialo.","url":"https://huggingface.co/datasets/timchen0618/Kialo","creator_name":"Hung-Ting Chen","creator_url":"https://huggingface.co/timchen0618","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFiQA2018.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFiQA2018-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFiQA2018","French"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoDBPedia.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoDBPedia-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoDBPedia","French"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFiQA2018.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFiQA2018-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFiQA2018","French"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoFiQA2018.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoFiQA2018-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoFiQA2018","French"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoDBPedia.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoDBPedia-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoDBPedia","French"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoDBPedia.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoDBPedia-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoDBPedia","French"],"keywords_longer_than_N":true},
	{"name":"SyntheticText2SQL","keyword":"text-retrieval","description":"\n  SyntheticText2SQL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding sql snippets. The task is to retrieve the most relevant code snippet for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://huggingface.co/datasets/gretelai/synthetic_text_to_sql\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SyntheticText2SQL.","url":"https://huggingface.co/datasets/mteb/SyntheticText2SQL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/synthetic-text2sql","code"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"code-minier","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode minier, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Telugu"],"keywords_longer_than_N":true},
	{"name":"Origin-Sequence-Data","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAL-GR/Origin-Sequence-Data: Raw User Behavior Sequences üìú\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nThis dataset is part of FORGE, a comprehensive benchmark for FOrming Raw user behavior sequences and Generative rEtrieval in Industrial Datasets, as presented in the paper FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets. The FORGE benchmark aims to address challenges in semantic identifiers (SIDs) for generative retrieval (GR) by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Origin-Sequence-Data.","url":"https://huggingface.co/datasets/AL-GR/Origin-Sequence-Data","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Gujarati"],"keywords_longer_than_N":true},
	{"name":"news_media_reliability","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tReliability Estimation of News Media Sources: \"Birds of a Feather Flock Together\"\n\t\n\nDataset introduced in the paper \"Reliability Estimation of News Media Sources: Birds of a Feather Flock Together\" published in the NAACL 2024 main conference.\nSimilar to the news media bias and factual reporting dataset, this dataset consists of a collections of 5.33K new media domains names with reliability labels. Additionally, for some domains, there is also a human-provided reliability score‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergioburdisso/news_media_reliability.","url":"https://huggingface.co/datasets/sergioburdisso/news_media_reliability","creator_name":"Sergio Burdisso","creator_url":"https://huggingface.co/sergioburdisso","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"T2Retrieval","keyword":"text-retrieval","description":"\n  T2Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nT2Ranking: A large-scale Chinese Benchmark for Passage Ranking\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Financial, Government, Non-fiction\n\n\nReference\nhttps://arxiv.org/abs/2304.03679\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"T2Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/T2Retrieval.","url":"https://huggingface.co/datasets/mteb/T2Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Mandarin Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MedBrowseComp","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMedBrowseComp Dataset\n\t\n\nThis repository contains datasets for medical information-seeking-oriented deep research and computer use tasks.\n\n\n\t\n\t\t\n\t\tDatasets\n\t\n\nThe repository contains three harmonized datasets:\n\nMedBrowseComp_50: A collection of 50 medical entries for browsing and comparison.\nMedBrowseComp_605: A comprehensive collection of 605 medical entries.\nMedBrowseComp_CUA: A curated collection of medical data for comparison and analysis.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThese datasets can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp.","url":"https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp","creator_name":"AIM-Harvard","creator_url":"https://huggingface.co/AIM-Harvard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"georgian-text-pairs","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGeorgian Text Pairs\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains Georgian language text pairs designed for natural language processing tasks. Each entry consists of two related Georgian text segments: a shorter \"positive\" text and a longer \"anchor\" text that provides additional context or elaboration.\n\n\t\n\t\t\n\t\tData Sources\n\t\n\nThe data for this dataset was gathered from multiple sources:\n\nGeorgian Wikipedia: Articles and encyclopedic content\nGeorgian websites: Various web sources‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sithet/georgian-text-pairs.","url":"https://huggingface.co/datasets/sithet/georgian-text-pairs","creator_name":"Irakli Khutsishvili","creator_url":"https://huggingface.co/sithet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","text-classification","Georgian","mit"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoQuoraRetrieval.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoQuoraRetrieval-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoQuoraRetrieval","French"],"keywords_longer_than_N":true},
	{"name":"livre-procedures-fiscales","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLivre des proc√©dures fiscales, non-instruct (2025-09-18)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales.","url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoQuoraRetrieval.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoQuoraRetrieval-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoQuoraRetrieval","French"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoQuoraRetrieval.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoQuoraRetrieval-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoQuoraRetrieval","French"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"FreshStackRetrieval","keyword":"text-retrieval","description":"\n  FreshStackRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA code retrieval task based on FreshStack dataset containing programming problems across multiple languages. Each query is a natural language description of a programming task (e.g., 'Write a function to reverse a string using recursion'), and the corpus contains code implementations in Python, JavaScript, and Go. The task is to retrieve the correct code snippet that solves the described problem. Queries are problem‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FreshStackRetrieval.","url":"https://huggingface.co/datasets/mteb/FreshStackRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","embedding-benchmark/FreshStack_mteb","code"],"keywords_longer_than_N":true},
	{"name":"intrinsic-intelligence-foundations","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüåø Intrinsic Intelligence Foundations\n\t\n\n\nToward truly autonomous and benevolent intelligence ‚Äî beyond externally imposed objectives.\n\nIntrinsic Intelligence Foundations is a structured, math-aware JSONL corpus built from K. Takahashi‚Äôs theoretical preprints (Fractal Category Theory / PF‚ÄìUGV / ‚Äúno-meta‚Äù autonomy line).It is designed to help LLMs understand mathematical structure, category-theoretic formalisms, and equation-level reasoning, while exposing an explicit architecture for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kadubon/intrinsic-intelligence-foundations.","url":"https://huggingface.co/datasets/kadubon/intrinsic-intelligence-foundations","creator_name":"K Takahashi","creator_url":"https://huggingface.co/kadubon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-generation","question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DS1000Retrieval","keyword":"text-retrieval","description":"\n  DS1000Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA code retrieval task based on 1,000 data science programming problems from DS-1000. Each query is a natural language description of a data science task (e.g., 'Create a scatter plot of column A vs column B with matplotlib'), and the corpus contains Python code implementations using libraries like pandas, numpy, matplotlib, scikit-learn, and scipy. The task is to retrieve the correct code snippet that solves the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DS1000Retrieval.","url":"https://huggingface.co/datasets/mteb/DS1000Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","embedding-benchmark/DS1000","code"],"keywords_longer_than_N":true},
	{"name":"tne","keyword":"document-retrieval","description":"TNE is an NLU task, which focus on relations between noun phrases (NPs) that can be mediated via prepositions.\nThe dataset contains 5,497 documents, annotated exhaustively with all possible links between the NPs in each document.","url":"https://huggingface.co/datasets/yanaiela/tne","creator_name":"Yanai Elazar","creator_url":"https://huggingface.co/yanaiela","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"zulu_stance","keyword":"fact-checking","description":"This is a stance detection dataset in the Zulu language. The data is translated to Zulu by Zulu native speakers, from English source texts.\n\nMisinformation has become a major concern in recent last years given its \nspread across our information sources. In the past years, many NLP tasks have\nbeen introduced in this area, with some systems reaching good results on \nEnglish language datasets. Existing AI based approaches for fighting \nmisinformation in literature suggest automatic stance detection as an integral\nfirst step to success. Our paper aims at utilizing this progress made for\nEnglish to transfers that knowledge into other languages, which is a \nnon-trivial task due to the domain gap between English and the target \nlanguages. We propose a black-box non-intrusive method that utilizes techniques\nfrom Domain Adaptation to reduce the domain gap, without requiring any human\nexpertise in the target language, by leveraging low-quality data in both a\nsupervised and unsupervised manner. This allows us to rapidly achieve similar\nresults for stance detection for the Zulu language, the target language in\nthis work, as are found for English. We also provide a stance detection dataset\nin the Zulu language.","url":"https://huggingface.co/datasets/strombergnlp/zulu_stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","sentiment-classification","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"tne","keyword":"text-retrieval","description":"TNE is an NLU task, which focus on relations between noun phrases (NPs) that can be mediated via prepositions.\nThe dataset contains 5,497 documents, annotated exhaustively with all possible links between the NPs in each document.","url":"https://huggingface.co/datasets/yanaiela/tne","creator_name":"Yanai Elazar","creator_url":"https://huggingface.co/yanaiela","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"factckbr","keyword":"fact-checking","description":"A dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification.\nThe data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.\nThe FACTCK.BR dataset contains 1309 claims with its corresponding label.","url":"https://huggingface.co/datasets/factckbr/factckbr","creator_name":"factckbr","creator_url":"https://huggingface.co/factckbr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"id_clickbait","keyword":"fact-checking","description":"The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.","url":"https://huggingface.co/datasets/community-datasets/id_clickbait","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tydi-as2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tTyDi-AS2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi-AS2 and Xtr-TyDi-AS2 are multilingual Answer Sentence Selection (AS2) datasets comprising 8 diverse languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nBoth the datasets were created from TyDi-QA, a multilingual question-answering dataset. TyDi-AS2 was created by converting the QA instances in TyDi-QA to AS2 instances (see Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/tydi-as2.","url":"https://huggingface.co/datasets/AmazonScience/tydi-as2","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"miracl-fi-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fi-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"miracl-fi-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fi-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"FACTOID","keyword":"fact-checking","description":"aisafe/FACTOID dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aisafe/FACTOID","creator_name":"safe ai","creator_url":"https://huggingface.co/aisafe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","fact-checking","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"Knowledge_Pile","keyword":"retrieval","description":"Knowledge Pile is a knowledge-related data leveraging Query of CC.\nThis dataset is a partial of Knowledge Pile(about 40GB disk size), full datasets have been released in [ü§ó knowledge_pile_full], a total of 735GB disk size and 188B tokens (using Llama2 tokenizer).\n\n\t\n\t\t\n\t\tQuery of CC\n\t\n\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping stage.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile.","url":"https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"contractual-clause-retrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tContractual Clause Retrieval üìë\n\t\n\nContractual Clause Retrieval by Isaacus is a challenging legal information retrieval evaluation dataset consisting of 45 unique types of contractual clauses paired with 2 highly representative examples of each, resulting in 90 pairings.\nThis dataset is intended to stress test the ability of information retrieval, zero-shot classification, and NLI models to identify a broad range of common types of contractual clauses based solely on their definition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/contractual-clause-retrieval.","url":"https://huggingface.co/datasets/isaacus/contractual-clause-retrieval","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","zero-shot-classification","text-classification","text-ranking","expert-generated"],"keywords_longer_than_N":true},
	{"name":"australian-tax-guidance-retrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAustralian Tax Guidance Retrieval üè¶\n\t\n\nAustralian Tax Guidance Retrieval by Isaacus is a novel, diverse, and challenging legal information retrieval evaluation dataset consisting of 112 real-life Australian tax law questions paired with expert-annotated, relevant Australian Government tax guidance and policies.\nUniquely, this dataset sources its real-life tax questions from the posts of everyday Australian taxpayers on the ATO Community forum, with relevant Australian Government‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/australian-tax-guidance-retrieval.","url":"https://huggingface.co/datasets/isaacus/australian-tax-guidance-retrieval","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","text-ranking","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"code-procedures-civiles-execution","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des proc√©dures civiles d'ex√©cution, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"quora_swe","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for \"quora_swe\"\n\t\n\nThe dataset quora_swe is a subset of the automatically translated (MNT) Swedish Semantic Textual Similarity dataset: quora-deduplicates .\n","url":"https://huggingface.co/datasets/Gabriel/quora_swe","creator_name":"Gabriel Borg","creator_url":"https://huggingface.co/Gabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","semantic-similarity-classification","Swedish","mit"],"keywords_longer_than_N":true},
	{"name":"mleb-scalr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSCALR (MLEB version)\n\t\n\nThis is the version of the SCALR evaluation dataset used in the Massive Legal Embedding Benchmark (MLEB) by Isaacus.\nThis dataset tests the ability of information retrieval models to retrieve relevant legal holdings to complex, reasoning-intensive legal questions.\n\n\t\n\t\t\n\t\tStructure üóÇÔ∏è\n\t\n\nAs per the MTEB information retrieval dataset format, this dataset comprises three splits, default, corpus and queries.\nThe default split pairs questions (query-id) with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mleb-scalr.","url":"https://huggingface.co/datasets/isaacus/mleb-scalr","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","nguha/legalbench","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"miracl-te-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (te) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-te-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-te-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-te-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-te-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Telugu"],"keywords_longer_than_N":true},
	{"name":"miracl-fi-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fi-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"DMRetriever_MTT","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tüß† Overview\n\t\n\nDMRetriever-MTT is the Massive Text Triplets (MTT) dataset used for training the DMRetriever model.It is constructed through a large-scale pipeline involving massive text-pair generation, mutual-agreement‚Äìbased false-positive filtering, and difficulty-aware hard-negative mining.  \nFor more details, please refer to our paper.This release provides the MTT-0.85 version, where the difficulty level for hard-negative mining is set to 0.85. The dataset contains 1,137,630‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DMRetriever_MTT.","url":"https://huggingface.co/datasets/DMIR01/DMRetriever_MTT","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"miracl-te-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (te) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-te-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-te-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-te-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-te-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Telugu"],"keywords_longer_than_N":true},
	{"name":"miracl-fi-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fi-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"DMRetriever_MTT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüß† Overview\n\t\n\nDMRetriever-MTT is the Massive Text Triplets (MTT) dataset used for training the DMRetriever model.It is constructed through a large-scale pipeline involving massive text-pair generation, mutual-agreement‚Äìbased false-positive filtering, and difficulty-aware hard-negative mining.  \nFor more details, please refer to our paper.This release provides the MTT-0.85 version, where the difficulty level for hard-negative mining is set to 0.85. The dataset contains 1,137,630‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DMRetriever_MTT.","url":"https://huggingface.co/datasets/DMIR01/DMRetriever_MTT","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"DMRetriever_MTT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüß† Overview\n\t\n\nDMRetriever-MTT is the Massive Text Triplets (MTT) dataset used for training the DMRetriever model.It is constructed through a large-scale pipeline involving massive text-pair generation, mutual-agreement‚Äìbased false-positive filtering, and difficulty-aware hard-negative mining.  \nFor more details, please refer to our paper.This release provides the MTT-0.85 version, where the difficulty level for hard-negative mining is set to 0.85. The dataset contains 1,137,630‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DMRetriever_MTT.","url":"https://huggingface.co/datasets/DMIR01/DMRetriever_MTT","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"evidence_infer_treatment","keyword":"fact-checking-retrieval","description":"Data and code from our \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\", NAACL 2019. This work concerns inferring the results reported in clinical trials from text.\n\nThe dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple treatments. Each of these articles will have multiple questions, or 'prompts' associated with them. These prompts will ask about the relationship between an intervention and comparator with respect to an outcome, as reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared to placebo on the duration of headaches. For the sake of this task, we assume that a particular article will report that the intervention of interest either significantly increased, significantly decreased or had significant effect on the outcome, relative to the comparator.\n\nThe dataset could be used for automatic data extraction of the results of a given RCT. This would enable readers to discover the effectiveness of different treatments without needing to read the paper.","url":"https://huggingface.co/datasets/jaydeyoung/evidence_infer_treatment","creator_name":"jay deyoung","creator_url":"https://huggingface.co/jaydeyoung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","fact-checking-retrieval","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"evidence_infer_treatment","keyword":"text-retrieval","description":"Data and code from our \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\", NAACL 2019. This work concerns inferring the results reported in clinical trials from text.\n\nThe dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple treatments. Each of these articles will have multiple questions, or 'prompts' associated with them. These prompts will ask about the relationship between an intervention and comparator with respect to an outcome, as reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared to placebo on the duration of headaches. For the sake of this task, we assume that a particular article will report that the intervention of interest either significantly increased, significantly decreased or had significant effect on the outcome, relative to the comparator.\n\nThe dataset could be used for automatic data extraction of the results of a given RCT. This would enable readers to discover the effectiveness of different treatments without needing to read the paper.","url":"https://huggingface.co/datasets/jaydeyoung/evidence_infer_treatment","creator_name":"jay deyoung","creator_url":"https://huggingface.co/jaydeyoung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","fact-checking-retrieval","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"entity-linking-retrieval","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"miracl-en-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-en-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-en-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-en-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-en-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"miracl-en-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-en-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-en-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-en-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-en-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"document-retrieval","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"fact-checking-retrieval","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"miracl-en-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-en-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-en-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-en-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-en-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"miracl-en-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (en) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-en-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-en-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-en-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-en-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"arxiv_dataset","keyword":"text-retrieval","description":"A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.","url":"https://huggingface.co/datasets/arxiv-community/arxiv_dataset","creator_name":"ArXiv Community","creator_url":"https://huggingface.co/arxiv-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","text-retrieval","document-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ko-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ko) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ko-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ko) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ko) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-yo-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (yo) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-yo-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-yo-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-yo-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-yo-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"miracl-yo-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (yo) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-yo-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-yo-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-yo-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-yo-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"code-patrimoine","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du patrimoine, non-instruct (2025-05-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"M4LE","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nM4LE is a Multi-ability, Multi-range, Multi-task, bilingual benchmark for long-context evaluation. We categorize long-context understanding into five distinct abilities by considering whether it is required to identify single or multiple spans in long contexts based on explicit or semantic hints. Specifically, these abilities are explicit single-span, semantic single-span, explicit multiple-span, semantic multiple-span, and global. Different from previous long-context‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wckwan/M4LE.","url":"https://huggingface.co/datasets/wckwan/M4LE","creator_name":"Cyrus Kwan","creator_url":"https://huggingface.co/wckwan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-detailed-results","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Detailed Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains detailed RAGAS evaluation results with per-question metric scores for 5 different retrieval strategies tested on the GDELT RAG system. Each record includes the full evaluation context (question, contexts, response) plus 4 RAGAS metric scores.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: ~1,400+ evaluation records with metric scores\nRetrievers Evaluated: Baseline, Naive, BM25, Ensemble, Cohere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-detailed-results.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-detailed-results","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"code-pensions-civiles-militaires-retraite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"medwiki","keyword":"entity-linking-retrieval","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining.","url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"widdd","keyword":"entity-linking-retrieval","description":"WiDDD stands for WIkiData Disambig with Descriptions. The former dataset comes from [Cetoli & al](https://arxiv.org/pdf/1810.09164.pdf)  paper, and is aimed at solving Named Entity Disambiguation. This datasets tries to extract relevant information from entities descriptions only, instead of working with graphs. In order to do so, we mapped every Wikidata id (correct id and wrong id) in the original paper with its WikiData description. If not found, row is discarded for this version.","url":"https://huggingface.co/datasets/mnemlaghi/widdd","creator_name":"Mehdi Nemlaghi","creator_url":"https://huggingface.co/mnemlaghi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","token-classification","entity-linking-retrieval","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"medwiki","keyword":"text-retrieval","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining.","url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language. As all three folds (train, dev and test) share the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"widdd","keyword":"text-retrieval","description":"WiDDD stands for WIkiData Disambig with Descriptions. The former dataset comes from [Cetoli & al](https://arxiv.org/pdf/1810.09164.pdf)  paper, and is aimed at solving Named Entity Disambiguation. This datasets tries to extract relevant information from entities descriptions only, instead of working with graphs. In order to do so, we mapped every Wikidata id (correct id and wrong id) in the original paper with its WikiData description. If not found, row is discarded for this version.","url":"https://huggingface.co/datasets/mnemlaghi/widdd","creator_name":"Mehdi Nemlaghi","creator_url":"https://huggingface.co/mnemlaghi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","token-classification","entity-linking-retrieval","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ragtime1","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tRAGTIME1 Collection\n\t\n\nThis dataset contains the documents for TREC RAGTIME Track. \nPlease refer to the website for the details of the task. \nRAGTIME is a multilingual RAG task, which expects the participating system to retrieve relevant documents from all four languages and synthesize a response with citation to the report request. \nFor convenience, we separate the documents by their languages into four .jsonl files. However, they are intended to be used as a whole set. \nThe documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trec-ragtime/ragtime1.","url":"https://huggingface.co/datasets/trec-ragtime/ragtime1","creator_name":"TREC RAGTIME Track","creator_url":"https://huggingface.co/trec-ragtime","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","multilingual","extended|c4"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Telugu"],"keywords_longer_than_N":true},
	{"name":"ragtime1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tRAGTIME1 Collection\n\t\n\nThis dataset contains the documents for TREC RAGTIME Track. \nPlease refer to the website for the details of the task. \nRAGTIME is a multilingual RAG task, which expects the participating system to retrieve relevant documents from all four languages and synthesize a response with citation to the report request. \nFor convenience, we separate the documents by their languages into four .jsonl files. However, they are intended to be used as a whole set. \nThe documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trec-ragtime/ragtime1.","url":"https://huggingface.co/datasets/trec-ragtime/ragtime1","creator_name":"TREC RAGTIME Track","creator_url":"https://huggingface.co/trec-ragtime","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","multilingual","extended|c4"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Telugu"],"keywords_longer_than_N":true},
	{"name":"LIMIT","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tLIMIT\n\t\n\nA retrieval dataset that exposes fundamental theoretical limitations of embedding-based retrieval models. Despite using simple queries like \"Who likes Apples?\", state-of-the-art embedding models achieve less than 20% recall@100 on LIMIT full and cannot solve LIMIT-small (46 docs).\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nPaper: On the Theoretical Limitations of Embedding-Based Retrieval\nCode: github.com/google-deepmind/limit\nFull version: LIMIT (50k documents)\nSmall version: LIMIT-small (46‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/LIMIT.","url":"https://huggingface.co/datasets/orionweller/LIMIT","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"LIMIT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLIMIT\n\t\n\nA retrieval dataset that exposes fundamental theoretical limitations of embedding-based retrieval models. Despite using simple queries like \"Who likes Apples?\", state-of-the-art embedding models achieve less than 20% recall@100 on LIMIT full and cannot solve LIMIT-small (46 docs).\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nPaper: On the Theoretical Limitations of Embedding-Based Retrieval\nCode: github.com/google-deepmind/limit\nFull version: LIMIT (50k documents)\nSmall version: LIMIT-small (46‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/LIMIT.","url":"https://huggingface.co/datasets/orionweller/LIMIT","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-982705","keyword":"retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-982705 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-982705 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"code-education","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'√©ducation, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"USCode-QAPairs-Finetuning","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tUSCode-QueryPairs Dataset\n\t\n\nThis dataset contains query-answer pairs curated from the United States Code, suitable for fine-tuning any embedding model. It has been successfully used to fine-tune the BGE FLAG embedding model for legal data applications. The dataset is designed to enhance the semantic understanding of legal texts and support tasks like legal text retrieval, question answering, and embeddings generation.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource: United States Code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/USCode-QAPairs-Finetuning.","url":"https://huggingface.co/datasets/ArchitRastogi/USCode-QAPairs-Finetuning","creator_name":"Archit Rastogi ","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"code-assurances","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des assurances, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\nüé¨ 570k+ annotated clips with granular quality scores (0-10 scale)\nüìè Five-dimensional scoring: temporal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\nüé¨ 570k+ annotated clips with granular quality scores (0-10 scale)\nüìè Five-dimensional scoring: temporal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"augmented-recap-datacomp-3m","keyword":"text-retrieval","description":"This is an experimental augmentation of about 3 million synthetic captions from Recap-Datacomp-1B. This dataset includes about 2 million multilingual captions. \nIt attempts to balance for gender stereotypes, added occupations, race, union membership, and religion to a subsample. We have also performed hair color and eye color balancing. It also includes some permutations of sentence orders, and modificaitons of the number of items (\"Two\" is changed to \"Three\", \"Four\", etc.)\nWe have also run‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/augmented-recap-datacomp-3m.","url":"https://huggingface.co/datasets/ontocord/augmented-recap-datacomp-3m","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"fact-checking","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"code-mutualite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la mutualit√©, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"SciFact-NL","keyword":"text-retrieval","description":"\n  SciFact-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSciFactNL verifies scientific claims in Dutch using evidence from the research literature containing scientific paper abstracts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Medical, Written\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-scifact\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SciFact-NL.","url":"https://huggingface.co/datasets/mteb/SciFact-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/scifact","Dutch"],"keywords_longer_than_N":true},
	{"name":"MedExamRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/MedExamRetrieval.","url":"https://huggingface.co/datasets/CMIRB/MedExamRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"real-math-dataset-207-with-extra-proof-dependencies-corpus","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Extended Statement Collection\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements extracted from the Real Math Dataset with 207 mathematical papers. It includes main statements, statement dependencies, and proof dependencies with complete metadata preservation and global ID mapping for references.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal statements: 2,137\nSource papers: 207 mathematical papers from arXiv\nStatement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus.","url":"https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"FactNews","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tEvaluation Benchmark for Sentence-Level Factuality Prediciton in Portuguese\n\t\n\nThe FactNews consits of the first large sentence-level annotated corpus for factuality prediciton in Portuguese. \nIt is composed of 6,191 sentences annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating \ntwo text classification problems for predicting sentence-level factuality of news reporting and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/FactNews.","url":"https://huggingface.co/datasets/franciellevargas/FactNews","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"MintakaRetrieval","keyword":"text-retrieval","description":"\n  MintakaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWe introduce Mintaka, a complex, natural, and multilingual dataset designed for experimenting with end-to-end question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English, annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian, Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka includes 8 types of complex questions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MintakaRetrieval.","url":"https://huggingface.co/datasets/mteb/MintakaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","jinaai/mintakaqa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"real-math-dataset-207-with-extra-proof-dependencies-corpus","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Extended Statement Collection\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements extracted from the Real Math Dataset with 207 mathematical papers. It includes main statements, statement dependencies, and proof dependencies with complete metadata preservation and global ID mapping for references.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal statements: 2,137\nSource papers: 207 mathematical papers from arXiv\nStatement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus.","url":"https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"bcms-fake-news-articles","keyword":"fact-checking","description":"toni5rovic/bcms-fake-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/toni5rovic/bcms-fake-news-articles","creator_name":"Antonije Petrovic","creator_url":"https://huggingface.co/toni5rovic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Croatian","Serbian","Bosnian","Serbo-Croatian"],"keywords_longer_than_N":true},
	{"name":"code-justice-militaire-nouveau","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de justice militaire (nouveau), non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"TV2Nordretrieval","keyword":"document-retrieval","description":"\n  TV2Nordretrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article and corresponding summaries extracted from the Danish newspaper TV2 Nord.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReferencehttps://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TV2Nordretrieval\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TV2Nordretrieval.","url":"https://huggingface.co/datasets/mteb/TV2Nordretrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","alexandrainst/nordjylland-news-summarization"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Awadhi"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-NL","keyword":"text-retrieval","description":"\n  NFCorpus-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval. NFCorpus-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nfcorpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NFCorpus-NL\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NFCorpus-NL.","url":"https://huggingface.co/datasets/mteb/NFCorpus-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/nfcorpus","Dutch"],"keywords_longer_than_N":true},
	{"name":"TV2Nordretrieval","keyword":"text-retrieval","description":"\n  TV2Nordretrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article and corresponding summaries extracted from the Danish newspaper TV2 Nord.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Written\n\n\nReferencehttps://huggingface.co/datasets/alexandrainst/nordjylland-news-summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TV2Nordretrieval\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TV2Nordretrieval.","url":"https://huggingface.co/datasets/mteb/TV2Nordretrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","alexandrainst/nordjylland-news-summarization"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Awadhi"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"struct-ir","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSSRB: Direct Natural Language Querying to Massive Heterogeneous Semi-Structured Data\n\t\n\ngithub\nWe employ LLM-based automatic evaluation and build a large-scale semi-structured retrieval benchmark (SSRB) using LLM generation and filtering, containing 14M structured objects from 99 different schemas across 6 domains, along with 8,485 test queries that combine both exact and fuzzy matching conditions.\nThis repository contains the data for SSRB.\n\n\t\n\t\t\n\t\n\t\n\t\tData Download\n\t\n\nData can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vec-ai/struct-ir.","url":"https://huggingface.co/datasets/vec-ai/struct-ir","creator_name":"Vector AI","creator_url":"https://huggingface.co/vec-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","apache-2.0","10M - 100M","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-physics","keyword":"text-retrieval","description":"\n  CQADupstackPhysicsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackPhysicsRetrieval\"])\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-physics.","url":"https://huggingface.co/datasets/mteb/cqadupstack-physics","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"tabfquad_test_subsampled","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nTabFQuAD (Table French Question Answering Dataset) is designed to evaluate TableQA models in realistic industry settings. Using a vision language model (GPT4V), we create additional queries to augment the existing human-annotated ones.\n\n\t\n\t\t\n\t\tData Curation\n\t\n\nTo ensure homogeneity across our benchmarked datasets, we subsampled the original test set to 280 pairs, leaving the rest for training and renaming the different columns.\n\n\t\n\t\t\n\t\tLoad the dataset\n\t\n\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/tabfquad_test_subsampled.","url":"https://huggingface.co/datasets/vidore/tabfquad_test_subsampled","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","French","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Panjabi"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"text-retrieval","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Awadhi"],"keywords_longer_than_N":true},
	{"name":"code-route","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la route, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Awadhi"],"keywords_longer_than_N":true},
	{"name":"StackOverflowQA","keyword":"text-retrieval","description":"\n  StackOverflowQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of natural language queries and their corresponding response which may include some text mixed with code snippets. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\n\n\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/StackOverflowQA.","url":"https://huggingface.co/datasets/mteb/StackOverflowQA","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","CoIR-Retrieval/stackoverflow-qa","English"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval.V2","keyword":"document-retrieval","description":"\n  NLPJournalAbsArticleRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V2 dataset (last updated 2025-06-15).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","mteb/NLPJournalAbsArticleRetrieval"],"keywords_longer_than_N":true},
	{"name":"bcms-claim-sentences","keyword":"fact-checking","description":"toni5rovic/bcms-claim-sentences dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/toni5rovic/bcms-claim-sentences","creator_name":"Antonije Petrovic","creator_url":"https://huggingface.co/toni5rovic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Serbian","Croatian","Bosnian","Serbo-Croatian"],"keywords_longer_than_N":true},
	{"name":"spoken-squad-t2a","keyword":"information-retrieval","description":"arteemg/spoken-squad-t2a dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/arteemg/spoken-squad-t2a","creator_name":"Artem G","creator_url":"https://huggingface.co/arteemg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","audio-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"spoken-squad-t2a","keyword":"text-retrieval","description":"arteemg/spoken-squad-t2a dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/arteemg/spoken-squad-t2a","creator_name":"Artem G","creator_url":"https://huggingface.co/arteemg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","audio-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval.V2","keyword":"text-retrieval","description":"\n  NLPJournalAbsArticleRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V2 dataset (last updated 2025-06-15).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","mteb/NLPJournalAbsArticleRetrieval"],"keywords_longer_than_N":true},
	{"name":"train","keyword":"retrieval","description":"Thun09/train dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Thun09/train","creator_name":"Yuanlei Zheng","creator_url":"https://huggingface.co/Thun09","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SPARBench","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tSPAR-Benchmark: A Realistic Evaluation Dataset for Academic Search Systems\n\t\n\nPaper: SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search\nCode: https://github.com/xiaofengShi/SPAR\n\n\n\t\n\t\t\n\t\n\t\n\t\tBenchmark Overview\n\t\n\nSPAR-Benchmark is an evaluation dataset constructed for realistic academic search scenarios, aiming to provide a reliable and practical performance evaluation foundation for academic search systems. The dataset covers the complete process from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MonteXiaofeng/SPARBench.","url":"https://huggingface.co/datasets/MonteXiaofeng/SPARBench","creator_name":"XiaofengShi","creator_url":"https://huggingface.co/MonteXiaofeng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","mit","n<1K","arxiv:2507.15245"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Maithili"],"keywords_longer_than_N":true},
	{"name":"ID_REG_MD_Embed","keyword":"text-retrieval","description":"üìß Github\nüîó LinkedIn\n\n\t\n\t\t\n\t\tüèõÔ∏è Indonesian Legal RAG Dataset with Embeddings & TF-IDF Vectors\n\t\n\n\n\t\n\t\t\n\t\tüìñ What is this dataset?\n\t\n\nThis dataset contains Indonesian legal documents with pre-computed embeddings and TF-IDF vectors for building RAG (Retrieval-Augmented Generation) systems. It includes regulations, laws, and legal documents from Indonesia with ready-to-use vector representations.\nüéØ Perfect for: Legal AI, Indonesian NLP, RAG systems, semantic search, and legal chatbots‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azzindani/ID_REG_MD_Embed.","url":"https://huggingface.co/datasets/Azzindani/ID_REG_MD_Embed","creator_name":"Azzindani","creator_url":"https://huggingface.co/Azzindani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Indonesian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"znanio-presentations-part2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 144,280 educational presentations from the znanio.ru platform, a comprehensive resource for teachers, educators, students, and parents that has been pioneering educational technologies and distance learning in the Russian-speaking internet since 2009. The dataset is split into two parts, each containing ~72,140 presentations organized across 25 archives. All files have been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-presentations-part2.","url":"https://huggingface.co/datasets/nyuuzyou/znanio-presentations-part2","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","document-question-answering","text-retrieval","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"wordnet-definitions","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWordNet Multiple Definitions - Columnar Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an optimized columnar version of WordNet multiple definitions, designed for high-performance queries and rapid extraction.\nEach definition was sourced by GPT-5 Nano. I may update this to include additional definitions in the future, but I will not break the format.\nThe original dataset has a more unabridged and noisy set of data; so I'm definitely going to leave it intact. Noisy training is important‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/wordnet-definitions.","url":"https://huggingface.co/datasets/AbstractPhil/wordnet-definitions","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","translation","text-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"finlucrag","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tFinLucRAG Corpus (OHLCV + SEC/PR Index)\n\t\n\nOne-stop corpus metadata for building finance RAG systems.This repo ships two Parquet tables and a fetcher. It does not re-host filings/press releases.\n\n\t\n\t\t\n\t\tWhat‚Äôs included\n\t\n\n\ndata/ohlcv.parquet ‚Äî daily OHLCV for ~30 tickers (2022-01-01 ‚Üí 2025-09-05).\ndata/filings.parquet ‚Äî document-level index of SEC filings & earnings press releases:\ndoc IDs/keys, statement dates, EDGAR doc URLs (stable, file-specific), checksums, and basic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lakshaychhabra/finlucrag.","url":"https://huggingface.co/datasets/lakshaychhabra/finlucrag","creator_name":"Lakshay Chhabra","creator_url":"https://huggingface.co/lakshaychhabra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Retrieve-Pile","keyword":"retrieval","description":"Retrieve-Pile (Knowledge-Pile) is a knowledge-related data leveraging Retrieve-from-CC (We also called this method as \"Query of CC\")Ôºåa total of 735GB disk size and 188B tokens (using Llama2 tokenizer). \n\n\t\n\t\t\n\t\tRetrieve-from-CC\n\t\n\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping stage. Leveraging the great generalization capability of large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile.","url":"https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"INCA-17-01-2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tFrench Court Decisions Dataset (INCA)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe French Court Decisions Dataset (INCA) is a comprehensive collection of judicial decisions from various French courts. This dataset contains decisions from multiple jurisdictions, providing a broad perspective on French jurisprudence and representing an essential resource for legal research, analysis, and machine learning applications in the French legal domain.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nThe data is sourced from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/INCA-17-01-2025.","url":"https://huggingface.co/datasets/La-Mousse/INCA-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","document-retrieval","document-question-answering","French"],"keywords_longer_than_N":true},
	{"name":"beir-nl-mmarco","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR-NL Benchmark\n\t\n\nBEIR-NL is a Dutch-translated version of the BEIR benchmark, a diverse and heterogeneous collection of datasets covering various domains from biomedical and financial texts to general web content. Our benchmark is integrated into the Massive Multilingual Text Embedding Benchmark (MMTEB).\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nmMarco repository on GitHub.\n\n\t\n\t\t\n\t\tAdditional Information\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThis dataset is licensed under the Apache‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/beir-nl-mmarco.","url":"https://huggingface.co/datasets/clips/beir-nl-mmarco","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Dutch","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"MixBench25","keyword":"retrieval","description":"MixBench is a benchmark for evaluating mixed-modality retrieval. It contains queries and corpora from four datasets: MSCOCO, Google_WIT, VisualNews, and OVEN. Each subset provides: query, corpus, mixed_corpus, and qrel splits.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FEVER","English"],"keywords_longer_than_N":true},
	{"name":"MixBench25","keyword":"document-retrieval","description":"MixBench is a benchmark for evaluating mixed-modality retrieval. It contains queries and corpora from four datasets: MSCOCO, Google_WIT, VisualNews, and OVEN. Each subset provides: query, corpus, mixed_corpus, and qrel splits.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FEVER","English"],"keywords_longer_than_N":true},
	{"name":"NanoFEVER","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","FEVER","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Telugu"],"keywords_longer_than_N":true},
	{"name":"temporal-nobel-prize","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Temporal Nobel Prize\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Tevatron-compatible version of proposed benchmark time-sensitive queries dataset from the paper [CIKM'24] Time-Sensitve Retrieval-Augmented Generation for Question Answering.\n\ncorpus.jsonl: 989 rows\n\n{\"docid\":0,\"text\":\"Wilhelm Conrad R√∂ntgen\\nThe Nobel Prize in Physics 1901...\"}\n{\"docid\":1,\"text\":\"Emil von Behring\\nThe Nobel Prize in Medicine 1901...\"}\n...\n\n\nquery.jsonl: 3244 rows\n\n{\n  \"query_id\":0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LouisDo2108/temporal-nobel-prize.","url":"https://huggingface.co/datasets/LouisDo2108/temporal-nobel-prize","creator_name":"Êùú‰øäÂäõ","creator_url":"https://huggingface.co/LouisDo2108","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"wikiformula","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tNTCIR-WFB\n\t\n\nWiki Formula Browsing Task from NTICR-12 (https://research.nii.ac.jp/ntcir/permission/ntcir-12/perm-en-MathIR.html)\n","url":"https://huggingface.co/datasets/hcju/wikiformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"wikiformula","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tNTCIR-WFB\n\t\n\nWiki Formula Browsing Task from NTICR-12 (https://research.nii.ac.jp/ntcir/permission/ntcir-12/perm-en-MathIR.html)\n","url":"https://huggingface.co/datasets/hcju/wikiformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"wikiformula","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tNTCIR-WFB\n\t\n\nWiki Formula Browsing Task from NTICR-12 (https://research.nii.ac.jp/ntcir/permission/ntcir-12/perm-en-MathIR.html)\n","url":"https://huggingface.co/datasets/hcju/wikiformula","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","wikipedia","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-EASY-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\nMost of the Subsets are synthetically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"code-impots-annexe-i","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, annexe I, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"WaterWiseTips","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüíß WaterWiseTips Dataset\n\t\n\nWaterWiseTips is a collection of 1,000 practical water-saving tips designed for home, garden, and everyday use.This dataset powers the WaterWise Home app ‚Äî a smart assistant that recommends personalized water-saving advice based on your habits.\n\n\n\t\n\t\t\n\t\tüìÇ Format\n\t\n\n\nFile: tips_dataset.csv\nColumn:\ntip ‚Äî A single water-saving suggestion.\n\n\n\n\n\n\t\n\t\t\n\t\tüß† Purpose\n\t\n\nThe dataset is designed to help AI applications provide relevant, personalized, and actionable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Liat2025/WaterWiseTips.","url":"https://huggingface.co/datasets/Liat2025/WaterWiseTips","creator_name":"Weiss","creator_url":"https://huggingface.co/Liat2025","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Touche2020","English"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"code-monetaire-financier","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode mon√©taire et financier, non-instruct (2025-09-02)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Touche2020","English"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","Touche2020","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-847943","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-847943 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-847943 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"CASS-17-01-2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tFrench Court of Cassation Decisions Dataset (CASS)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe French Court of Cassation Decisions Dataset (CASS) is a comprehensive collection of judicial decisions from the French Court of Cassation (Cour de cassation), France's highest court for civil and criminal matters. This dataset contains decisions that represent the most authoritative interpretations of French law, providing an invaluable resource for legal research, analysis, and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CASS-17-01-2025.","url":"https://huggingface.co/datasets/La-Mousse/CASS-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","document-retrieval","document-question-answering","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"msedup","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMathematics Stack Exchange Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/math.stackexchange.com.7z\n","url":"https://huggingface.co/datasets/hcju/msedup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mse","English"],"keywords_longer_than_N":true},
	{"name":"ARAFA","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tARAFA: An LLM Generated Arabic Fact Checking Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCreators:  \n\nKhalil, Christophe (Researcher)\n\nContributors:  \n\nSupervisors:  \nElbassuoni, Shady  \nAssaf, Rida\n\n\n\nAbstract:Automatic fact-checking in Arabic is challenging due to the lack of large-scale datasets and resources. ARAFA is a large-scale Modern Standard Arabic dataset for fact-checking, constructed using a fully automated framework leveraging large language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChristopheKhalil/ARAFA.","url":"https://huggingface.co/datasets/ChristopheKhalil/ARAFA","creator_name":"christophe Khalil","creator_url":"https://huggingface.co/ChristopheKhalil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","sentence-similarity","Arabic"],"keywords_longer_than_N":true},
	{"name":"code-propriete-personnes-publiques","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral de la propri√©t√© des personnes publiques, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"msedup","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMathematics Stack Exchange Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/math.stackexchange.com.7z\n","url":"https://huggingface.co/datasets/hcju/msedup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mse","English"],"keywords_longer_than_N":true},
	{"name":"msedup","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMathematics Stack Exchange Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/math.stackexchange.com.7z\n","url":"https://huggingface.co/datasets/hcju/msedup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mse","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"Code_Vulnerability_Labeled_Dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Code_Vulnerability_Labeled_Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides (code, vulnerability) pairs. The vulnerability field takes values according to the CWE annotation:\n\n\t\n\t\t\nCWE\nDescription\n\n\n\t\t\nCWE-020\nImproper Input Validation\n\n\nCWE-022\nImproper Limitation of a Pathname to a Restricted Directory (‚ÄúPath Traversal‚Äù)\n\n\nCWE-078\nImproper Neutralization of Special Elements used in an OS Command (‚ÄúOS Command Injection‚Äù)\n\n\nCWE-079\nImproper Neutralization of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset.","url":"https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset","creator_name":"lemon42-ai","creator_url":"https://huggingface.co/lemon42-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"code-communes-nouvelle-caledonie","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des communes de la Nouvelle-Cal√©donie, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"MahaSTS","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMahaSTS Dataset\n\t\n\nThe MahaSTS dataset is a human-annotated Sentence Textual Similarity (STS) dataset for Marathi, consisting of 16,860 sentence pairs labeled with continuous similarity scores in the range of 0-5. It is designed to enable effective training for sentence similarity tasks in Marathi, particularly in low-resource settings.\nPaper: L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and ModelsCode: https://github.com/l3cube-pune/MarathiNLPProject page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/MahaSTS.","url":"https://huggingface.co/datasets/l3cube-pune/MahaSTS","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","text-ranking","Marathi","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CNIL-18-01-2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tFrench National Commission on Informatics and Liberty (CNIL) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (CNIL). This dataset provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France. It serves as a rich resource for researchers, legal practitioners, and machine learning engineers interested in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CNIL-18-01-2025.","url":"https://huggingface.co/datasets/La-Mousse/CNIL-18-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","document-retrieval","document-question-answering","French"],"keywords_longer_than_N":true},
	{"name":"github-issues-simple","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis dataset is sourced from the issues within the official datasets repository on GitHub. We collected the corresponding issues and their comments via the GitHub API, performed some light data cleaning, and finally, randomly selected 1,000 samples to create this dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rachel521/github-issues-simple.","url":"https://huggingface.co/datasets/rachel521/github-issues-simple","creator_name":"Mikerachel521","creator_url":"https://huggingface.co/rachel521","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"github-issues-simple","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis dataset is sourced from the issues within the official datasets repository on GitHub. We collected the corresponding issues and their comments via the GitHub API, performed some light data cleaning, and finally, randomly selected 1,000 samples to create this dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rachel521/github-issues-simple.","url":"https://huggingface.co/datasets/rachel521/github-issues-simple","creator_name":"Mikerachel521","creator_url":"https://huggingface.co/rachel521","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","multi-class-classification","multi-label-classification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"KomuRetrieval","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tKommunityRetrieval Korean BEIR Dataset\n\t\n\nÌïúÍµ≠Ïñ¥ Ïª§ÎÆ§ÎãàÌã∞ Ïä§ÌÉÄÏùº ÏßàÏùò Í≤ÄÏÉâÏùÑ ÏúÑÌïú BEIR ÌòïÏãùÏùò ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Í∞úÏöî\n\t\n\nÏù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ ÌïúÍµ≠Ïñ¥ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÑ ÌèâÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ Íµ¨Ï∂ïÎêú BEIR ÌòïÏãùÏùò Î≤§ÏπòÎßàÌÅ¨ Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§. ÎÇòÎ¨¥ÏúÑÌÇ§ Î¨∏ÏÑúÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÏó¨ Îã§ÏñëÌïú Ïä§ÌÉÄÏùºÏùò ÏßàÏùòÏôÄ Í¥ÄÎ†® Î¨∏ÏÑú ÏåçÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÏäµÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã ÌäπÏßï\n\t\n\n\nÎ¨∏ÏÑú ÏÜåÏä§: ÎÇòÎ¨¥ÏúÑÌÇ§\nÎ¨∏ÏÑú Ï†ÑÏ≤òÎ¶¨: ÏµúÏÜåÌôîÎêú Ï†ÑÏ≤òÎ¶¨Î°ú Ïù∏Ìï¥ Îß§Ïö∞ Í∏¥ Î¨∏ÏÑú Í∏∏Ïù¥\nÏßàÏùò Ïú†Ìòï: 3Í∞ÄÏßÄ Ïä§ÌÉÄÏùºÏùÑ Ìè¨Í¥Ñ\nÌÇ§ÏõåÎìú Ïä§ÌÉÄÏùº: \"Î≥¥Ïä§ÌÑ¥ Î†àÎìúÏÇ≠Ïä§ Î∞§ÎπÑÎÖ∏ Ï†ÄÏ£º\"\nÏùòÎ¨∏Î¨∏ Ïä§ÌÉÄÏùº: \"ÌïúÏÑ∏Ï£ºÏôÄ ÎßåÎÇòÎ©¥ ÌöåÏ§ëÏãúÍ≥ÑÍ∞Ä Ïñ¥ÎñªÍ≤å Î≥ÄÌïòÎÇòÏöî?\"\nÏª§ÎÆ§ÎãàÌã∞ ÏßàÏùò Ïä§ÌÉÄÏùº: \"Ïï†Îì§ÏïÑ ÎèÑÏÇ¨Ïùò Î¨¥ÎÖÄÏóêÏÑú ÌûàÏöîÎ¶¨Í∞Ä Ïú†Ïπ¥Î¶¨ Íµ¨ÌïòÎ†§Í≥† ÏóÑÏ≤≠ÎÇú Ìù¨ÏÉùÍπåÏßÄ Ìïú Í±∞ Í∞ôÏùÄÎç∞ Ï£ºÏù∏Í≥µÏúºÎ°úÏÑú Î¨¥Ïä® Ïó≠Ìï†Ïù¥ÏóàÎäîÏßÄ ÏßÑÏßú Í∞ÄÎ¨ºÍ∞ÄÎ¨ºÌï®„Ö†„Ö† ÏïåÎ†§Ï£ºÎùº!\"\n\n\n\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï Î∞©Î≤ï\n\t\n\n\nÎ¨∏ÏÑú ÏÉòÌîåÎßÅ:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junyoungson/KomuRetrieval.","url":"https://huggingface.co/datasets/junyoungson/KomuRetrieval","creator_name":"Junyoung Son","creator_url":"https://huggingface.co/junyoungson","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MSMARCO","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"memefact-templates","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tMemeFact Templates Dataset\n\t\n\nThis dataset contains 663 meme templates enriched with contextual knowledge for fact-checking meme generation. Each template includes comprehensive information about its origin, cultural significance, visual characteristics, and typical caption patterns to support Retrieval Augmented Generation (RAG) systems.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe \"MemeFact Templates\" dataset is the result of extensive data engineering applied to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergiogpinto/memefact-templates.","url":"https://huggingface.co/datasets/sergiogpinto/memefact-templates","creator_name":"S√©rgio Miguel Gon√ßalves Pinto","creator_url":"https://huggingface.co/sergiogpinto","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"CRAG-EVAL","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tüìÑ CRAG-EVAL\n\t\n\nCRAG-EVAL is a dataset for evaluating document relevance using binary classification. It is designed for use in contextual relevance assessment tasks such as reranking, semantic search evaluation, or training classifiers to identify whether a retrieved document is relevant or not relevant to a given query or context.\n\n\n\t\n\t\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nEach example in the dataset is a pair of sentences:\n\nA question or query (short text)\nA document (longer text or passage)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skshmjn/CRAG-EVAL.","url":"https://huggingface.co/datasets/skshmjn/CRAG-EVAL","creator_name":"Saksham Jain","creator_url":"https://huggingface.co/skshmjn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"KomuRetrieval","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tKommunityRetrieval Korean BEIR Dataset\n\t\n\nÌïúÍµ≠Ïñ¥ Ïª§ÎÆ§ÎãàÌã∞ Ïä§ÌÉÄÏùº ÏßàÏùò Í≤ÄÏÉâÏùÑ ÏúÑÌïú BEIR ÌòïÏãùÏùò ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Í∞úÏöî\n\t\n\nÏù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ ÌïúÍµ≠Ïñ¥ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÑ ÌèâÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ Íµ¨Ï∂ïÎêú BEIR ÌòïÏãùÏùò Î≤§ÏπòÎßàÌÅ¨ Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§. ÎÇòÎ¨¥ÏúÑÌÇ§ Î¨∏ÏÑúÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÏó¨ Îã§ÏñëÌïú Ïä§ÌÉÄÏùºÏùò ÏßàÏùòÏôÄ Í¥ÄÎ†® Î¨∏ÏÑú ÏåçÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÏäµÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã ÌäπÏßï\n\t\n\n\nÎ¨∏ÏÑú ÏÜåÏä§: ÎÇòÎ¨¥ÏúÑÌÇ§\nÎ¨∏ÏÑú Ï†ÑÏ≤òÎ¶¨: ÏµúÏÜåÌôîÎêú Ï†ÑÏ≤òÎ¶¨Î°ú Ïù∏Ìï¥ Îß§Ïö∞ Í∏¥ Î¨∏ÏÑú Í∏∏Ïù¥\nÏßàÏùò Ïú†Ìòï: 3Í∞ÄÏßÄ Ïä§ÌÉÄÏùºÏùÑ Ìè¨Í¥Ñ\nÌÇ§ÏõåÎìú Ïä§ÌÉÄÏùº: \"Î≥¥Ïä§ÌÑ¥ Î†àÎìúÏÇ≠Ïä§ Î∞§ÎπÑÎÖ∏ Ï†ÄÏ£º\"\nÏùòÎ¨∏Î¨∏ Ïä§ÌÉÄÏùº: \"ÌïúÏÑ∏Ï£ºÏôÄ ÎßåÎÇòÎ©¥ ÌöåÏ§ëÏãúÍ≥ÑÍ∞Ä Ïñ¥ÎñªÍ≤å Î≥ÄÌïòÎÇòÏöî?\"\nÏª§ÎÆ§ÎãàÌã∞ ÏßàÏùò Ïä§ÌÉÄÏùº: \"Ïï†Îì§ÏïÑ ÎèÑÏÇ¨Ïùò Î¨¥ÎÖÄÏóêÏÑú ÌûàÏöîÎ¶¨Í∞Ä Ïú†Ïπ¥Î¶¨ Íµ¨ÌïòÎ†§Í≥† ÏóÑÏ≤≠ÎÇú Ìù¨ÏÉùÍπåÏßÄ Ìïú Í±∞ Í∞ôÏùÄÎç∞ Ï£ºÏù∏Í≥µÏúºÎ°úÏÑú Î¨¥Ïä® Ïó≠Ìï†Ïù¥ÏóàÎäîÏßÄ ÏßÑÏßú Í∞ÄÎ¨ºÍ∞ÄÎ¨ºÌï®„Ö†„Ö† ÏïåÎ†§Ï£ºÎùº!\"\n\n\n\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï Î∞©Î≤ï\n\t\n\n\nÎ¨∏ÏÑú ÏÉòÌîåÎßÅ:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junyoungson/KomuRetrieval.","url":"https://huggingface.co/datasets/junyoungson/KomuRetrieval","creator_name":"Junyoung Son","creator_url":"https://huggingface.co/junyoungson","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-wordpress","keyword":"text-retrieval","description":"\n  CQADupstackWordpressRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWordpressRetrieval\"])\nevaluator‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-wordpress.","url":"https://huggingface.co/datasets/mteb/cqadupstack-wordpress","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MSMARCO","English"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","MSMARCO","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"KomuRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tKommunityRetrieval Korean BEIR Dataset\n\t\n\nÌïúÍµ≠Ïñ¥ Ïª§ÎÆ§ÎãàÌã∞ Ïä§ÌÉÄÏùº ÏßàÏùò Í≤ÄÏÉâÏùÑ ÏúÑÌïú BEIR ÌòïÏãùÏùò ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Í∞úÏöî\n\t\n\nÏù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ ÌïúÍµ≠Ïñ¥ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÑ ÌèâÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ Íµ¨Ï∂ïÎêú BEIR ÌòïÏãùÏùò Î≤§ÏπòÎßàÌÅ¨ Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§. ÎÇòÎ¨¥ÏúÑÌÇ§ Î¨∏ÏÑúÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÏó¨ Îã§ÏñëÌïú Ïä§ÌÉÄÏùºÏùò ÏßàÏùòÏôÄ Í¥ÄÎ†® Î¨∏ÏÑú ÏåçÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÏäµÎãàÎã§.\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã ÌäπÏßï\n\t\n\n\nÎ¨∏ÏÑú ÏÜåÏä§: ÎÇòÎ¨¥ÏúÑÌÇ§\nÎ¨∏ÏÑú Ï†ÑÏ≤òÎ¶¨: ÏµúÏÜåÌôîÎêú Ï†ÑÏ≤òÎ¶¨Î°ú Ïù∏Ìï¥ Îß§Ïö∞ Í∏¥ Î¨∏ÏÑú Í∏∏Ïù¥\nÏßàÏùò Ïú†Ìòï: 3Í∞ÄÏßÄ Ïä§ÌÉÄÏùºÏùÑ Ìè¨Í¥Ñ\nÌÇ§ÏõåÎìú Ïä§ÌÉÄÏùº: \"Î≥¥Ïä§ÌÑ¥ Î†àÎìúÏÇ≠Ïä§ Î∞§ÎπÑÎÖ∏ Ï†ÄÏ£º\"\nÏùòÎ¨∏Î¨∏ Ïä§ÌÉÄÏùº: \"ÌïúÏÑ∏Ï£ºÏôÄ ÎßåÎÇòÎ©¥ ÌöåÏ§ëÏãúÍ≥ÑÍ∞Ä Ïñ¥ÎñªÍ≤å Î≥ÄÌïòÎÇòÏöî?\"\nÏª§ÎÆ§ÎãàÌã∞ ÏßàÏùò Ïä§ÌÉÄÏùº: \"Ïï†Îì§ÏïÑ ÎèÑÏÇ¨Ïùò Î¨¥ÎÖÄÏóêÏÑú ÌûàÏöîÎ¶¨Í∞Ä Ïú†Ïπ¥Î¶¨ Íµ¨ÌïòÎ†§Í≥† ÏóÑÏ≤≠ÎÇú Ìù¨ÏÉùÍπåÏßÄ Ìïú Í±∞ Í∞ôÏùÄÎç∞ Ï£ºÏù∏Í≥µÏúºÎ°úÏÑú Î¨¥Ïä® Ïó≠Ìï†Ïù¥ÏóàÎäîÏßÄ ÏßÑÏßú Í∞ÄÎ¨ºÍ∞ÄÎ¨ºÌï®„Ö†„Ö† ÏïåÎ†§Ï£ºÎùº!\"\n\n\n\n\n\t\n\t\t\n\t\tÎç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï Î∞©Î≤ï\n\t\n\n\nÎ¨∏ÏÑú ÏÉòÌîåÎßÅ:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junyoungson/KomuRetrieval.","url":"https://huggingface.co/datasets/junyoungson/KomuRetrieval","creator_name":"Junyoung Son","creator_url":"https://huggingface.co/junyoungson","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NIH-CXR14-BiomedCLIP-Features","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tNIH-CXR14-BiomedCLIP-Features Dataset\n\t\n\nThis dataset is derived from the NIH Chest X-ray Dataset (NIH-CXR14) and processed using the BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model from Microsoft. It contains image and text features extracted from chest X-ray images and their corresponding textual findings.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe original NIH-CXR14 dataset comprises 112,120 chest X-ray images with disease labels from 30,805 unique patients. This processed dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features.","url":"https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features","creator_name":"Tun√ßer","creator_url":"https://huggingface.co/Yasintuncer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","text-classification","image-feature-extraction","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Assamese"],"keywords_longer_than_N":true},
	{"name":"code-justice-administrative","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de justice administrative, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Recap-DataComp-1B","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Recap-DataComp-1B\n\t\n\n\n\nRecap-DataComp-1B is a large-scale image-text dataset that has been recaptioned using an advanced LLaVA-1.5-LLaMA3-8B model to enhance the alignment and detail of textual descriptions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nOur paper aims to bridge this community effort, leveraging the powerful and open-sourced LLaMA-3, a GPT-4 level LLM.\nOur recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestones/Recap-DataComp-1B.","url":"https://huggingface.co/datasets/lodestones/Recap-DataComp-1B","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Assamese"],"keywords_longer_than_N":true},
	{"name":"Wiki_Faiss_Indexes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tdataset_info:\n  features:\n  - name: text\n    dtype: string\n  - name: embeddings\n    dtype: float32\n    shape: [384]\n  configs:\n  - config_name: default\n    data_files: \"*.parquet\"\n\t\n\n\n\t\n\t\t\n\t\tWikipedia IVF-OPQ-PQ Vector Database (GPU-Optimized)\n\t\n\nA high-performance, GPU-accelerated FAISS vector database built from Wikipedia articles with pre-computed embeddings. This dataset contains approximately 35 million Wikipedia articles with 384-dimensional embeddings using the all-MiniLM-L6-v2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ram-G/Wiki_Faiss_Indexes.","url":"https://huggingface.co/datasets/Ram-G/Wiki_Faiss_Indexes","creator_name":"Sri Ram Pavan Kumar Guttikonda","creator_url":"https://huggingface.co/Ram-G","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"text-retrieval","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Telugu"],"keywords_longer_than_N":true},
	{"name":"takaraspider","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tTakaraSpider Japanese Web Crawl Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTakaraSpider is a large-scale web crawl dataset specifically designed to capture Japanese web content alongside international sources. The dataset contains 257,900 web pages collected through systematic crawling, with a primary focus on Japanese language content (78.5%) while maintaining substantial international representation (21.5%). This makes it ideal for Japanese-English comparative studies, cross-cultural web‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/takarajordan/takaraspider.","url":"https://huggingface.co/datasets/takarajordan/takaraspider","creator_name":"Jordan Legg","creator_url":"https://huggingface.co/takarajordan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","feature-extraction","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval.V2","keyword":"document-retrieval","description":"\n  NLPJournalAbsIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V2 dataset (last update 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval.V2","keyword":"text-retrieval","description":"\n  NLPJournalAbsIntroRetrieval.V2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V2 dataset (last update 2025-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.V2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"code-famille-aide-sociale","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la famille et de l'aide sociale, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech tools‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"entity-linking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech tools‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"fact-checking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech tools‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech tools‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Arabic","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_Energy_Arabic - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Energy_Arabic is a curated multimodal dataset focused on Arabic energy sector documents, including reports, financial statements, technical documentation, and industry analyses. It combines text and image data extracted from real energy-related PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training in Arabic.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy_Arabic.","url":"https://huggingface.co/datasets/racineai/OGC_Energy_Arabic","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Arabic","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Energy_Arabic - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Energy_Arabic is a curated multimodal dataset focused on Arabic energy sector documents, including reports, financial statements, technical documentation, and industry analyses. It combines text and image data extracted from real energy-related PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training in Arabic.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy_Arabic.","url":"https://huggingface.co/datasets/racineai/OGC_Energy_Arabic","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-d1ckgpt-v1","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-d1ckgpt-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~380-token chunks, ~15% overlap)\nEmbedder: bio-protocol/scientific-retriever (mean-pooled, L2-normalized)\nSimilarity: cosine via inner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-d1ckgpt-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-d1ckgpt-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"bio-faiss-d1ckgpt-v1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tbio-faiss-d1ckgpt-v1\n\t\n\nA FAISS index + metadata for scientific retrieval\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nindex.faiss: FAISS index (cosine w/ inner product). \nmeta.jsonl: one JSON per chunk; fields include chunk_id, paper_id, title, section, subsection, paragraph_index, keywords, boost.\n\n\n\t\n\t\t\n\t\tBuild provenance\n\t\n\n\nChunking: hierarchical (section‚Üíparagraph‚Üí~380-token chunks, ~15% overlap)\nEmbedder: bio-protocol/scientific-retriever (mean-pooled, L2-normalized)\nSimilarity: cosine via inner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bio-protocol/bio-faiss-d1ckgpt-v1.","url":"https://huggingface.co/datasets/bio-protocol/bio-faiss-d1ckgpt-v1","creator_name":"Bio Protocol","creator_url":"https://huggingface.co/bio-protocol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Telugu"],"keywords_longer_than_N":true},
	{"name":"finRAG","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tfinRAG Datasets\n\t\n\nThis is the official Huggingface repo of the finRAG datasets published by parsee.ai.\nMore detailed information about the 3 datasets and methodology can be found in the sub-directories for the individual datasets.\nWe wanted to investigate how good the current state of the art (M)LLMs are at solving the relatively simple problem of extracting revenue figures from publicly available financial reports. To test this, we created 3 different datasets, all based on the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/finRAG.","url":"https://huggingface.co/datasets/parsee-ai/finRAG","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","table-question-answering","text-retrieval","question-answering","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Telugu"],"keywords_longer_than_N":true},
	{"name":"OGC_CATIE-AQ_XMRec","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_CATIE-AQ_XMRec - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_CATIE-AQ_XMRec is a multimodal dataset that combines text and image data, and support tasks such as DSE retrieval (RAG).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset is a merge and shuffle of the following datasets in the OGC format:\n\nCATIE-AQ/XMRec_metadata_fr_Arts_Crafts_and_Sewing\nCATIE-AQ/XMRec_metadata_fr_Automotive\nCATIE-AQ/XMRec_metadata_fr_Cell_Phones_and_Accessories\nCATIE-AQ/XMRec_metadata_fr_Digital_Music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_CATIE-AQ_XMRec.","url":"https://huggingface.co/datasets/racineai/OGC_CATIE-AQ_XMRec","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OGC_ibm-research_REAL-MM-RAG","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_ibm-research_REAL-MM-RAG - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_ibm-research_REAL-MM-RAG is a multimodal dataset that combines text and image data, and support tasks such as DSE retrieval (RAG).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset is a merge and shuffle of the following datasets in the OGC format:\n\nibm-research/REAL-MM-RAG_TechSlides\nibm-research/REAL-MM-RAG_TechReport\nibm-research/REAL-MM-RAG_FinTabTrainSet\nibm-research/REAL-MM-RAG_FinTabTrainSet_rephrased‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_ibm-research_REAL-MM-RAG.","url":"https://huggingface.co/datasets/racineai/OGC_ibm-research_REAL-MM-RAG","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","cdla-permissive-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Magahi"],"keywords_longer_than_N":true},
	{"name":"AIVOStandard-retrieval-dynamics","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tAI Visibility Retrieval Dynamics: Tiered Citation Platforms, Decay, and the Governance Gap in LLM Discoverability\n\t\n\nAuthors: Paul Sheals; Tim de RosenAffiliation: The AIVO Standard‚Ñ¢Version: v1.0DOI: https://doi.org/10.5281/zenodo.17117353License: CC BY 4.0\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis white paper presents findings from The AIVO Standard‚Ñ¢ R&D program based on 100,000+ reverse-engineered prompts across industries and LLMs (ChatGPT, Gemini, Claude, Perplexity, Grok).We formalize a tiered‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pjsheals/AIVOStandard-retrieval-dynamics.","url":"https://huggingface.co/datasets/pjsheals/AIVOStandard-retrieval-dynamics","creator_name":"Paul Sheals","creator_url":"https://huggingface.co/pjsheals","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","text","Document"],"keywords_longer_than_N":true},
	{"name":"OGC_CATIE-AQ_XMRec","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_CATIE-AQ_XMRec - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_CATIE-AQ_XMRec is a multimodal dataset that combines text and image data, and support tasks such as DSE retrieval (RAG).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset is a merge and shuffle of the following datasets in the OGC format:\n\nCATIE-AQ/XMRec_metadata_fr_Arts_Crafts_and_Sewing\nCATIE-AQ/XMRec_metadata_fr_Automotive\nCATIE-AQ/XMRec_metadata_fr_Cell_Phones_and_Accessories\nCATIE-AQ/XMRec_metadata_fr_Digital_Music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_CATIE-AQ_XMRec.","url":"https://huggingface.co/datasets/racineai/OGC_CATIE-AQ_XMRec","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OGC_ibm-research_REAL-MM-RAG","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_ibm-research_REAL-MM-RAG - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_ibm-research_REAL-MM-RAG is a multimodal dataset that combines text and image data, and support tasks such as DSE retrieval (RAG).\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset is a merge and shuffle of the following datasets in the OGC format:\n\nibm-research/REAL-MM-RAG_TechSlides\nibm-research/REAL-MM-RAG_TechReport\nibm-research/REAL-MM-RAG_FinTabTrainSet\nibm-research/REAL-MM-RAG_FinTabTrainSet_rephrased‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_ibm-research_REAL-MM-RAG.","url":"https://huggingface.co/datasets/racineai/OGC_ibm-research_REAL-MM-RAG","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","cdla-permissive-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MedData-tr-2","keyword":"text-retrieval","description":"Total Token Count : 190M (o200k_base)\nDataset Source : https://www.medicalpark.com.tr/saglik-rehberi\n","url":"https://huggingface.co/datasets/zypchn/MedData-tr-2","creator_name":"zeynep cahan","creator_url":"https://huggingface.co/zypchn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","text-retrieval","Turkish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Manipuri"],"keywords_longer_than_N":true},
	{"name":"neuro-specter2-triplets","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tJerjes/neuro-specter2-triplets\n\t\n\nTriplet dataset for fine-tuning SPECTER2 on neuroscience.\nVersion date: 2025-08-12\n\n\t\n\t\t\n\t\tSchema\n\t\n\nColumns:\n\nanchor_id, positive_id, negative_id\nanchor_title, positive_title, negative_title\nanchor_abstract, positive_abstract, negative_abstract\nanchor_text, positive_text, negative_text  (title + abstract)\n\nSplit: train\n\n\t\n\t\t\n\t\tLoad\n\t\n\nfrom datasets import load_dataset\ntriplets = load_dataset(\"Jerjes/neuro-specter2-triplets\", split=\"train\")\n\n","url":"https://huggingface.co/datasets/Jerjes/neuro-specter2-triplets","creator_name":"Jerjes Aguirre","creator_url":"https://huggingface.co/Jerjes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","sentence-similarity","English","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"AutoRAGRetrieval","keyword":"document-retrieval","description":"\n  AutoRAGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset enables the evaluation of Korean RAG performance across various domains‚Äîfinance, public sector, healthcare, legal, and commerce‚Äîby providing publicly accessible documents, questions, and answers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Medical, Legal, Social, Financial\n\n\nReference\nhttps://arxiv.org/abs/2410.20878\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AutoRAGRetrieval.","url":"https://huggingface.co/datasets/mteb/AutoRAGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Assamese"],"keywords_longer_than_N":true},
	{"name":"AutoRAGRetrieval","keyword":"text-retrieval","description":"\n  AutoRAGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset enables the evaluation of Korean RAG performance across various domains‚Äîfinance, public sector, healthcare, legal, and commerce‚Äîby providing publicly accessible documents, questions, and answers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Medical, Legal, Social, Financial\n\n\nReference\nhttps://arxiv.org/abs/2410.20878\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AutoRAGRetrieval.","url":"https://huggingface.co/datasets/mteb/AutoRAGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"lotte-streams-for-murr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSimulated Query and Document Streams of LoTTE Forum Dataset\n\t\n\nThis dataset contains the simulated streams for the paper \"MURR: Model Updating with Regularized Replay for Searching a Document Stream\". \nPlease refer to the paper for the detailed sampling process. \nThe code for sampling the queries, qrels, and documents are documents in sampling.py. \nIt is not intended to be ran but for recording purposes. \nThe random numbers for sampling are also recorded in the files for futrue‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/lotte-streams-for-murr.","url":"https://huggingface.co/datasets/hltcoe/lotte-streams-for-murr","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"NorPlanQA","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tNorPlanQA\n\t\n\nThis dataset consists of zonal plans and building permit related questions set up in the BEIR format. The data was collected in cooperation with the municipalities of Kristiansand, Bergen and Larvik where plan-experts have helped formulate relevant questions and link the related text chunks. \nThe dataset is chunked with a custom chunking algorithm that utilizes tailored RegEx to split the documents into paragraphs.\n","url":"https://huggingface.co/datasets/kartai/NorPlanQA","creator_name":"KartAi","creator_url":"https://huggingface.co/kartai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Norwegian","Norwegian Bokm√•l","Norwegian Nynorsk","mit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Oriya"],"keywords_longer_than_N":true},
	{"name":"ABC-Pretraining-Data","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tABC Pretraining Data\n\t\n\nThis dataset contains the pretraining data for ABC, an open-source multimodal embedding model that uses a vision-language model backbone to deeply integrate image features with natural language instructions, advancing the state of visual embeddings with natural language control.\nThis dataset is derived from Google's Conceptual Captions dataset.\nEach item in the dataset contains a URL where the corresponding image can be downloaded and mined negatives for each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/ABC-Pretraining-Data.","url":"https://huggingface.co/datasets/TIGER-Lab/ABC-Pretraining-Data","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MATH_qCoT_LLMquery_lexicalquery","keyword":"retrieval","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_qCoT_LLMquery_lexicalquery","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"abstracts-faiss","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tabstracts-faiss\n\t\n\nThis is a faiss index, trained on abstracts-embeddings. A ready-to-go search interface for using this index is available at abstracts-index.\n\n\t\n\t\t\n\t\tBuilding\n\t\n\nIt was trained with the train.py script found at abstracts-search with the options -N -c 65536 (normalized, train 65536 clusters), using the default preprocess technique OPQ96_384 (PCA to a 384-dimensional vector, then apply OPQ for a 96-byte code). Note that, although the Stella model was trained with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/colonelwatch/abstracts-faiss.","url":"https://huggingface.co/datasets/colonelwatch/abstracts-faiss","creator_name":"Kenny Peng","creator_url":"https://huggingface.co/colonelwatch","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","English","cc0-1.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"pedsite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Pedsite.ru Pedagogical Website\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 9,536 educational materials from the pedsite.ru platform, a website for teachers to share experiences and showcase the best creative findings in the field of teaching and learning. The dataset includes information such as material titles, URLs, download URLs, author information, and extracted text content where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pedsite.","url":"https://huggingface.co/datasets/nyuuzyou/pedsite","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"doc4web","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Doc4web.ru Documents\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and content for 223,739 documents from the doc4web.ru platform, a document hosting service for students and teachers. The dataset includes information such as document titles, URLs, download links, and file paths. The documents cover various educational topics and are primarily in Russian.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual, with Russian being the primary language. Other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/doc4web.","url":"https://huggingface.co/datasets/nyuuzyou/doc4web","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"abstracts-faiss","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tabstracts-faiss\n\t\n\nThis is a faiss index, trained on abstracts-embeddings. A ready-to-go search interface for using this index is available at abstracts-index.\n\n\t\n\t\t\n\t\tBuilding\n\t\n\nIt was trained with the train.py script found at abstracts-search with the options -N -c 65536 (normalized, train 65536 clusters), using the default preprocess technique OPQ96_384 (PCA to a 384-dimensional vector, then apply OPQ for a 96-byte code). Note that, although the Stella model was trained with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/colonelwatch/abstracts-faiss.","url":"https://huggingface.co/datasets/colonelwatch/abstracts-faiss","creator_name":"Kenny Peng","creator_url":"https://huggingface.co/colonelwatch","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","English","cc0-1.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"news_media_bias_and_factuality","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tNews Media Factual Reporting and Political Bias\n\t\n\nDataset introduced in the paper \"Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions\" published in the CLEF 2024 main conference.\nSimilar to the news media reliability dataset, this dataset consists of a collections of 4K new media domains names with political bias and factual reporting labels.\nColumns of the dataset:\n\nsource: domain name\nbias: the political bias label. Values: \"left\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergioburdisso/news_media_bias_and_factuality.","url":"https://huggingface.co/datasets/sergioburdisso/news_media_bias_and_factuality","creator_name":"Sergio Burdisso","creator_url":"https://huggingface.co/sergioburdisso","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"AmazonQAC","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset\n\t\n\nTrain Dataset Size: 395 million samplesTest Dataset Size: 20k samplesSource: Amazon Search LogsFile Format: ParquetCompression: Snappy\nIf you use this dataset, please cite our EMNLP 2024 paper:\n@inproceedings{everaert-etal-2024-amazonqac,\n    title = \"{A}mazon{QAC}: A Large-Scale, Naturalistic Query Autocomplete Dataset\",\n    author = \"Everaert, Dante  and\n      Patki, Rohit  and\n      Zheng, Tianqi  and\n      Potts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amazon/AmazonQAC.","url":"https://huggingface.co/datasets/amazon/AmazonQAC","creator_name":"Amazon","creator_url":"https://huggingface.co/amazon","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-retrieval","English","cdla-permissive-2.0"],"keywords_longer_than_N":true},
	{"name":"code-urbanisme","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'urbanisme, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"VK-LSVD","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVK-LSVD: Large Short-Video Dataset\n\t\n\nVK-LSVD is the largest open industrial short-video recommendation dataset with real-world interactions: \n\n40B unique user‚Äìitem interactions with rich feedback (timespent, like, dislike, share, bookmark, click_on_author, open_comments) and\ncontext (place, platform, agent);\n10M users (with age, gender, geo);\n20M short videos (with duration, author_id, content embedding);\nGlobal Temporal Ordering across six consecutive months of user interactions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/VK-LSVD.","url":"https://huggingface.co/datasets/deepvk/VK-LSVD","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","graph-ml","other","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_Quantum ‚Äì Overview\n\t\n\nOGC_Quantum is a curated multimodal dataset focused on quantum technical documents. It combines text and image data extracted from real scientific PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.Quantum-related PDFs were collected from public online sources. Each document was processed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Quantum ‚Äì Overview\n\t\n\nOGC_Quantum is a curated multimodal dataset focused on quantum technical documents. It combines text and image data extracted from real scientific PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.Quantum-related PDFs were collected from public online sources. Each document was processed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"legalkit","keyword":"retrieval","description":"\n\n\n\t\n\t\t\n\t\tLegalKit, French labeled datasets built for legal ML training\n\t\n\nThis dataset consists of labeled data prepared for training sentence embeddings models in the context of French law. The labeling process utilizes the LLaMA-3-70B model through a structured workflow to enhance the quality of the labels. This dataset aims to support the development of natural language processing (NLP) models for understanding and working with legal texts in French.\n\n\t\n\t\t\n\t\n\t\n\t\tLabeling Workflow\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/legalkit.","url":"https://huggingface.co/datasets/louisbrulenaudet/legalkit","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","sentence-similarity","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Relic-Test","keyword":"document-retrieval","description":"\n  BIRCO-Relic\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the RELIC dataset from BIRCO. This dataset contains 100 queries which are excerpts from literary analyses with a missing quotation (indicated by [masked sentence(s)]). Each query has a candidate pool of 50 passages. The objective is to retrieve the passage that best completes the literary analysis.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Relic-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-Relic-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Relic-Test","keyword":"text-retrieval","description":"\n  BIRCO-Relic\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the RELIC dataset from BIRCO. This dataset contains 100 queries which are excerpts from literary analyses with a missing quotation (indicated by [masked sentence(s)]). Each query has a candidate pool of 50 passages. The objective is to retrieve the passage that best completes the literary analysis.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Relic-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-Relic-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Assamese"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoTouche2020.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoTouche2020-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoTouche2020","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Assamese"],"keywords_longer_than_N":true},
	{"name":"paecter_dataset","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPaECTER Dataset\n\t\n\nThe dataset contains publication numbers of patents used to train, validate, and test our models PaECTER and PAT SPECTER. These publication numbers were taken from the EPO's PATSTAT database (2023 Spring version). We used the titles and abstracts of these patents as provided in PATSTAT for training and other purposes. \nThe combined training and validation dataset comprises 300,000 EPO/PCT patents as focal (query) patents. Each focal patent is associated with 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mpi-inno-comp/paecter_dataset.","url":"https://huggingface.co/datasets/mpi-inno-comp/paecter_dataset","creator_name":"Max Planck Institute for Innovation and Competition","creator_url":"https://huggingface.co/mpi-inno-comp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoTouche2020.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoTouche2020-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoTouche2020","French"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoTouche2020.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoTouche2020-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoTouche2020","French"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tEnergy Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy.","url":"https://huggingface.co/datasets/racineai/OGC_Energy","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Urdu"],"keywords_longer_than_N":true},
	{"name":"legal_summarization","keyword":"document-retrieval","description":"\n  LegalSummarization\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consistes of 439 pairs of contracts and their summarizations from https://tldrlegal.com and https://tosdr.org/.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lauramanor/legal_summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legal_summarization.","url":"https://huggingface.co/datasets/mteb/legal_summarization","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LEGI","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFrench Legislative Texts (LEGI) Dataset (14/04/2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe LEGI Dataset contains decisions from the French Courts of Judicial jurisprudence decisions (https://www.legifrance.gouv.fr/search/juri).\nThis dataset is sourced from DILA/OPENDATA/LEGI.\nThis extensive collection represents the consolidated versions of French legal texts, offering a complete view of French legislation.\nIt is designed to assist in the analysis and extraction of legal information.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeMoussel/LEGI.","url":"https://huggingface.co/datasets/LeMoussel/LEGI","creator_name":"LeMoussel","creator_url":"https://huggingface.co/LeMoussel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","table-question-answering","summarization","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tEnergy Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy.","url":"https://huggingface.co/datasets/racineai/OGC_Energy","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"farcaster","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tFarcaster Threads Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains high-quality thread data from Farcaster's entire history, featuring 512-dimensional embeddings generated using VoyageAI (float32) on formatted thread text. The dataset includes comprehensive thread metadata, engagement metrics, and vector embeddings suitable for semantic search, recommendation systems, and content analysis.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Records: ~20,182,407 threads\nData Cutoff: 2025-08-02‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shoni/farcaster.","url":"https://huggingface.co/datasets/shoni/farcaster","creator_name":"alex paden","creator_url":"https://huggingface.co/shoni","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","cc-by-4.0","10M - 100M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Urdu"],"keywords_longer_than_N":true},
	{"name":"legal_summarization","keyword":"text-retrieval","description":"\n  LegalSummarization\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consistes of 439 pairs of contracts and their summarizations from https://tldrlegal.com and https://tosdr.org/.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lauramanor/legal_summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legal_summarization.","url":"https://huggingface.co/datasets/mteb/legal_summarization","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"document-retrieval","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"code-defense","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de la d√©fense, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"code-travail-maritime","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du travail maritime, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"text-retrieval","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"OGC_Geotechnie","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tGeotechnie Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Geotechnie.","url":"https://huggingface.co/datasets/racineai/OGC_Geotechnie","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"DisastIR","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for DisastIR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tDisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management\n\t\n\nDisastIR is the first benchmark for information retrieval (IR) model evaluation specified for Disaster Management, consisting of three main components:\n\nquery: a collection of user queries.  \nqrels: labeled query‚Äìpassage pairs with relevance scores.  \ncorpus: a collection of documents.\n\nThis dataset is useful for passage retrieval, ranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaiYinTAMU/DisastIR.","url":"https://huggingface.co/datasets/KaiYinTAMU/DisastIR","creator_name":"kai_yin","creator_url":"https://huggingface.co/KaiYinTAMU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"DisastIR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for DisastIR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tDisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management\n\t\n\nDisastIR is the first benchmark for information retrieval (IR) model evaluation specified for Disaster Management, consisting of three main components:\n\nquery: a collection of user queries.  \nqrels: labeled query‚Äìpassage pairs with relevance scores.  \ncorpus: a collection of documents.\n\nThis dataset is useful for passage retrieval, ranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaiYinTAMU/DisastIR.","url":"https://huggingface.co/datasets/KaiYinTAMU/DisastIR","creator_name":"kai_yin","creator_url":"https://huggingface.co/KaiYinTAMU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"DisastIR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for DisastIR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tDisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management\n\t\n\nDisastIR is the first benchmark for information retrieval (IR) model evaluation specified for Disaster Management, consisting of three main components:\n\nquery: a collection of user queries.  \nqrels: labeled query‚Äìpassage pairs with relevance scores.  \ncorpus: a collection of documents.\n\nThis dataset is useful for passage retrieval, ranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaiYinTAMU/DisastIR.","url":"https://huggingface.co/datasets/KaiYinTAMU/DisastIR","creator_name":"kai_yin","creator_url":"https://huggingface.co/KaiYinTAMU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ukr-lit","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Ukr-lit.com.ua Presentations\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 18,001 presentations from the ukr-lit.com.ua platform, a presentation storage and viewing service primarily focused on Ukrainian literature and related subjects. The dataset includes information such as presentation titles, URLs, download URLs, and filepaths for the original presentation files.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual, with Ukrainian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ukr-lit.","url":"https://huggingface.co/datasets/nyuuzyou/ukr-lit","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"OGC_Geotechnie","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tGeotechnie Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Geotechnie.","url":"https://huggingface.co/datasets/racineai/OGC_Geotechnie","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Oriya"],"keywords_longer_than_N":true},
	{"name":"bfiqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBFIQA Dataset\n\t\n\nBulgarian Financial Information Question Answering\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\n\t\n\t\t\nMetric\nCount\nDetails\n\n\n\t\t\nDocuments\n115,274\n57,636 BG + 57,638 EN\n\n\nQueries\n13,292\n6,644 BG + 6,648 EN\n\n\nRelevance Pairs\n17,110\nTrain: 14,166, Dev: 1,238, Test: 1,706\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Files & Sizes\n\t\n\n\n\t\n\t\t\nFile\nSize\nRecords\nDescription\n\n\n\t\t\ncorpus_bg.jsonl\n82.9 MB\n57,636\nBulgarian documents\n\n\ncorpus_en.jsonl\n44.9 MB\n57,638\nEnglish documents\n\n\nqueries_bg.jsonl0.9 MB\n6,644‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-bg/bfiqa.","url":"https://huggingface.co/datasets/llm-bg/bfiqa","creator_name":"LLM.bg","creator_url":"https://huggingface.co/llm-bg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Bulgarian","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"RealStories-Micro-MRL","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for ReactiveAI/RealStories-Micro-MRL\n\t\n\nFirst synthetic Memory Reinforcement Learning dataset for Proof-of-Concept Reactive Transformer models.\nDataset is divided into subsets, used in different Curriculum Stage of MRL training - each subset have\ndifferent number of follow-up interactions, could use different strategy, and have train and validation\nsplits.\n\n\t\n\t\t\n\t\tSubsets\n\t\n\n\nsteps-1: ~2300 train (~4600 interactions) / ~340 validation (~680 interactions) - Single-Step‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReactiveAI/RealStories-Micro-MRL.","url":"https://huggingface.co/datasets/ReactiveAI/RealStories-Micro-MRL","creator_name":"Reactive AI","creator_url":"https://huggingface.co/ReactiveAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","text-retrieval","text-generation","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"MedDataTR-1","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MedData_tr-1\n\t\n\nThis dataset has 917 instances and 5227389 tokens in total\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nLanguage(s) (NLP): Turkish\nLicense: APACHE 2.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nMemorial Health Library : https://www.memorial.com.tr/saglik-kutuphanesi\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ncategory : The data was split into 3 categories \n\nTanƒ± ve Testler (Diagnoses and Tests)\nHastalƒ±klar (Diseases)\nTedavi Y√∂ntemleri (Treatment Methods)\n\ntopic :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zypchn/MedDataTR-1.","url":"https://huggingface.co/datasets/zypchn/MedDataTR-1","creator_name":"zeynep cahan","creator_url":"https://huggingface.co/zypchn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","text-retrieval","Turkish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025.","url":"https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025","creator_name":"iclr2026-anonymous","creator_url":"https://huggingface.co/iclr2026-anonymous","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"MixBench2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025.","url":"https://huggingface.co/datasets/iclr2026-anonymous/MixBench2025","creator_name":"iclr2026-anonymous","creator_url":"https://huggingface.co/iclr2026-anonymous","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"movies_CLIP_ViT-L14","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüé¨ Movie Frame & Caption Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìñ Introduction\n\t\n\nThis dataset was created from multiple movies across 10 genres, with approximately 3 movies per genre.From each movie, frames were extracted periodically, and AI-generated captions (BLIP) were assigned to each frame.A total of 93,813 frames were extracted.\nThis dataset can be used for tasks such as:\n\nVideo understanding\nMultimodal learning (image + text)\nImage captioning\nVision-language retrieval\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÇ Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thaotien/movies_CLIP_ViT-L14.","url":"https://huggingface.co/datasets/thaotien/movies_CLIP_ViT-L14","creator_name":"B√πi Ng·ªçc Th·∫£o Ti√™n","creator_url":"https://huggingface.co/thaotien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","image-to-text","Vietnamese","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Coder-Stat","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCoder-Stat Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Coder-Stat dataset is a collection of programming-related data, including problem IDs, programming languages, original statuses, and source code snippets. This dataset is designed to assist in the analysis of coding patterns, error types, and performance metrics.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tModalities\n\t\n\n\nTabular: The dataset is structured in a tabular format.\nText: Contains text data, including source code snippets.\n\n\n\t\n\t\t\n\t\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Coder-Stat.","url":"https://huggingface.co/datasets/prithivMLmods/Coder-Stat","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text2text-generation","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"CSLCiteRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/CSLCiteRetrieval.","url":"https://huggingface.co/datasets/CMIRB/CSLCiteRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Unite-Instruct-Retrieval-Train","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them ‚Äî the content remains exactly the same. The only difference lies in the compression method, which now allows for quicker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Unite-Instruct-Retrieval-Train","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them ‚Äî the content remains exactly the same. The only difference lies in the compression method, which now allows for quicker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","DBPedia","English"],"keywords_longer_than_N":true},
	{"name":"syntheticDocQA_government_reports_test","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is part of a topic-specific retrieval benchmark spanning multiple domains, which evaluates retrieval in more realistic industrial applications. \nIt includes documents about the Government Reports that allow ViDoRe to benchmark administrative/legal documents. \n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThanks to a crawler (see below), we collected 1,000 PDFs from the Internet with the query ('government reports'). From these documents, we randomly sampled 1000 pages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/syntheticDocQA_government_reports_test.","url":"https://huggingface.co/datasets/vidore/syntheticDocQA_government_reports_test","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Unite-Base-Retrieval-Train","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them ‚Äî the content remains exactly the same. The only difference lies in the compression method, which now allows for quicker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","DBPedia","English"],"keywords_longer_than_N":true},
	{"name":"NanoDBPedia","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","DBPedia","English"],"keywords_longer_than_N":true},
	{"name":"Unite-Base-Retrieval-Train","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them ‚Äî the content remains exactly the same. The only difference lies in the compression method, which now allows for quicker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval","keyword":"text-retrieval","description":"\n  GermanQuAD-Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContext Retrieval for German Question Answering\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction, Web\n\n\nReference\nhttps://huggingface.co/datasets/deepset/germanquad\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GermanQuAD-Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval.","url":"https://huggingface.co/datasets/mteb/germanquad-retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"swahili_stopwords","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSwahili Stop-Words Dataset\n\t\n\nThe Swahili Stop-Words Dataset is a curated collection of function words that carry minimal semantic weight and are commonly omitted during text preprocessing in Natural Language Processing (NLP) workflows.  \nWhile these words are essential for the syntactic structure of Swahili, they can be excluded from most computational tasks without compromising the overall semantic integrity of the text.  \nThe availability of this dataset is critical for optimizing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredkondoro/swahili_stopwords.","url":"https://huggingface.co/datasets/alfredkondoro/swahili_stopwords","creator_name":"Alfredo ","creator_url":"https://huggingface.co/alfredkondoro","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Swahili","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"code-impots","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode g√©n√©ral des imp√¥ts, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqsRetrieval","keyword":"text-retrieval","description":"\n  JaGovFaqsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJaGovFaqs is a dataset consisting of FAQs manully extracted from the website of Japanese bureaus. The dataset consists of 22k FAQs, where the queries (questions) and corpus (answers) have been shuffled, and the goal is to match the answer with the question.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval.","url":"https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-449863","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-449863 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-449863 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Maithili"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","English"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","English"],"keywords_longer_than_N":true},
	{"name":"OGC_Cooking_Recipes","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC_Cooking_Recipes - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.","url":"https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"OGC_Cooking_Recipes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Cooking_Recipes - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.","url":"https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Maithili"],"keywords_longer_than_N":true},
	{"name":"AILA_casedocs","keyword":"document-retrieval","description":"\n  AILACasedocs\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to retrieve the case document that most closely matches or is most relevant to the scenario described in the provided query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\nReference\nhttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILACasedocs\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_casedocs.","url":"https://huggingface.co/datasets/mteb/AILA_casedocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NeuCLIR2023RetrievalHardNegatives","keyword":"text-retrieval","description":"\n  NeuCLIR2023RetrievalHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\nSource datasets:\n\nmteb/neuclir-2022\nmteb/neuclir-2023-hard-negatives‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NeuCLIR2023RetrievalHardNegatives.","url":"https://huggingface.co/datasets/mteb/NeuCLIR2023RetrievalHardNegatives","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2022","mteb/neuclir-2023-hard-negatives"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Maithili"],"keywords_longer_than_N":true},
	{"name":"AILA_casedocs","keyword":"text-retrieval","description":"\n  AILACasedocs\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to retrieve the case document that most closely matches or is most relevant to the scenario described in the provided query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\nReference\nhttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILACasedocs\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_casedocs.","url":"https://huggingface.co/datasets/mteb/AILA_casedocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-672024-v51y-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-672024-v51y-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-672024-v51y-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"DuBaikeRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/DuBaikeRetrieval.","url":"https://huggingface.co/datasets/CMIRB/DuBaikeRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"agentic-rag-redteam-bench","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAgentic RAG Red Teaming Dataset v1.0.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTest-only corpus of successful adversarial prompts and scenarios targeting agentic RAG systems (multimodal where applicable).\nOne file per attack type; no consolidated master file is provided.\nExisting, per-type schemas are vendorized locally and left unmodified relative to the record structures used in this work.\nThis dataset was not used to train any model. It is intended strictly for evaluation, diagnostics, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu/agentic-rag-redteam-bench.","url":"https://huggingface.co/datasets/Fujitsu/agentic-rag-redteam-bench","creator_name":"Fujitsu Laboratories","creator_url":"https://huggingface.co/Fujitsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-generation","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"document-retrieval","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"text-retrieval","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"InstructIR","keyword":"text-retrieval","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","msmarco","English"],"keywords_longer_than_N":true},
	{"name":"gleif-golden-copy-20250804","keyword":"text-retrieval","description":"This is a copy of the global authoritative list of LEIs (Legal Entity Identifier), also known as \"Golden Copy\", as provided by GLEIF (Global Legal Entity Identifier Foundation).\nIt includes data on approximately 3M global companies.\nMore information about the dataset, including details about the coverage and data format, is available at: https://www.gleif.org/en/lei-data/gleif-golden-copy/download-the-golden-copy\nThis data was downloaded from GLEIF on 2025-08-04.\n","url":"https://huggingface.co/datasets/andreaaltomani/gleif-golden-copy-20250804","creator_name":"Andrea Altomani","creator_url":"https://huggingface.co/andreaaltomani","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-ranking","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedQADiagRetrieval","keyword":"document-retrieval","description":"\n  R2MEDMedQADiagRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedQA-Diag retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedQA-Diag\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedQADiagRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedQA-Diag"],"keywords_longer_than_N":true},
	{"name":"news-topics","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tNeuCLIR News Topics\n\t\n\n","url":"https://huggingface.co/datasets/neuclir/news-topics","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","document-retrieval","NIST","multilingual"],"keywords_longer_than_N":true},
	{"name":"amharic-passage-retrieval-dataset-with-negatives","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tAmharic Passage Retrieval Dataset with Negatives\n\t\n\nThis dataset is a version of amharic-news-category-classification that has been filtered, deduplicated, and formatted for passage retrieval.\nThis dataset can be used directly with Sentence Transformers to train Amharic Text embedding and Reranking models.\n\n\t\n\t\t\n\t\tHard Negatives:\n\t\n\nThe negative_passages column contains hard negative passages that were mined using the roberta-amharic-text-embedding-medium embedding model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset-with-negatives.","url":"https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset-with-negatives","creator_name":"Yosef Worku Alemneh","creator_url":"https://huggingface.co/rasyosef","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","Amharic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Cybersec-Mutli-domain","keyword":"text-retrieval","description":"Creator: Zain NadeemRole: Python Django Developer | Software Engineer | Prompt Engineer | Ethical HackerLicense: CC BY 4.0Records: ~220,000Format: JSONLLanguage: English\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nThe CyberSec Multi-Domain Dataset is a structured collection of synthetic and open-source cybersecurity data across five important domains. It is designed for building, testing, and benchmarking machine learning models in cybersecurity, threat intelligence, and automation systems.\nThis dataset helps‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain.","url":"https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain","creator_name":"Zain Nadeem","creator_url":"https://huggingface.co/ZainNadeem7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","text-retrieval","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"R2MEDMedQADiagRetrieval","keyword":"text-retrieval","description":"\n  R2MEDMedQADiagRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMedQA-Diag retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/MedQA-Diag\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDMedQADiagRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDMedQADiagRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/MedQA-Diag"],"keywords_longer_than_N":true},
	{"name":"neuclir-2023-hard-negatives","keyword":"text-retrieval","description":"\n  NeuCLIR2023RetrievalHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/neuclir-2023-hard-negatives.","url":"https://huggingface.co/datasets/mteb/neuclir-2023-hard-negatives","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2022","Persian"],"keywords_longer_than_N":true},
	{"name":"amharic-passage-retrieval-dataset-with-negatives","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAmharic Passage Retrieval Dataset with Negatives\n\t\n\nThis dataset is a version of amharic-news-category-classification that has been filtered, deduplicated, and formatted for passage retrieval.\nThis dataset can be used directly with Sentence Transformers to train Amharic Text embedding and Reranking models.\n\n\t\n\t\t\n\t\tHard Negatives:\n\t\n\nThe negative_passages column contains hard negative passages that were mined using the roberta-amharic-text-embedding-medium embedding model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset-with-negatives.","url":"https://huggingface.co/datasets/rasyosef/amharic-passage-retrieval-dataset-with-negatives","creator_name":"Yosef Worku Alemneh","creator_url":"https://huggingface.co/rasyosef","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","text-retrieval","Amharic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"news-topics","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tNeuCLIR News Topics\n\t\n\n","url":"https://huggingface.co/datasets/neuclir/news-topics","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","document-retrieval","NIST","multilingual"],"keywords_longer_than_N":true},
	{"name":"newswire","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for NewsWire\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNewsWire contains 2.7 million unique public domain U.S. news wire articles, written between 1878 and 1977. Locations in these articles are georeferenced, topics are tagged using customized neural topic classification, named entities are recognized, and individuals are disambiguated to Wikipedia using a novel entity disambiguation model.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach year in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dell-research-harvard/newswire.","url":"https://huggingface.co/datasets/dell-research-harvard/newswire","creator_name":"Dell Research Harvard","creator_url":"https://huggingface.co/dell-research-harvard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"OpinionQA","keyword":"retrieval","description":"This is the OpinionQA dataset from the BERDS benchmark. (Paper link: )The purpose of this dataset is evaluating diversity of retrieval systems given subjective questions.  \nEach instance consists of a question and a list of valid perspectives (opinions) for the question.\"Type\" indicates the number of perspectives a question has. \"Binary\" questions come with two perspectives, while \"Multi\" questions come with more than two.  \nWe repurpose the OpinionQA dataset into the desired setting.We first‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timchen0618/OpinionQA.","url":"https://huggingface.co/datasets/timchen0618/OpinionQA","creator_name":"Hung-Ting Chen","creator_url":"https://huggingface.co/timchen0618","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"ciral","keyword":"text-retrieval","description":"This dataset consists of the queries and relevance judgements in the CIRAL test collection.","url":"https://huggingface.co/datasets/CIRAL/ciral","creator_name":"Cross-lingual Information Retrieval for African Languages","creator_url":"https://huggingface.co/CIRAL","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","Hausa","Somali","Swahili","Yoruba"],"keywords_longer_than_N":true},
	{"name":"msmarco_answerai_colbert_small_embeddings","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tMS MARCO ColBERT Embeddings\n\t\n\nPre-computed ColBERT embeddings for MS MARCO using PyLate and answerdotai/answerai-colbert-small-v1.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\ndata/corpus/: 177 parquet files with document embeddings\ndata/queries/: 11 parquet files with query embeddings\ndata/qrels/train.parquet: Relevance judgments (532,751 pairs)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load from directory (recommended for large datasets)\ncorpus =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"msmarco_answerai_colbert_small_embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMS MARCO ColBERT Embeddings\n\t\n\nPre-computed ColBERT embeddings for MS MARCO using PyLate and answerdotai/answerai-colbert-small-v1.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\ndata/corpus/: 177 parquet files with document embeddings\ndata/queries/: 11 parquet files with query embeddings\ndata/qrels/train.parquet: Relevance judgments (532,751 pairs)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load from directory (recommended for large datasets)\ncorpus =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"lsoie","keyword":"text-retrieval","description":"The Large Scale Open Information Extraction Dataset (LSOIE), is a dataset 20 \ntimes larger than the next largest human-annotated Open Information Extraction\n(OIE) dataset. LSOIE is a built upon the QA-SRL 2.0 dataset.","url":"https://huggingface.co/datasets/wardenga/lsoie","creator_name":"Robert Wardenga","creator_url":"https://huggingface.co/wardenga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","machine-generated","found","monolingual","extended|qa_srl"],"keywords_longer_than_N":true},
	{"name":"AmericanStories","keyword":"text-retrieval","description":"American Stories offers high-quality structured data from historical newspapers suitable for pre-training large language models to enhance the understanding of historical English and world knowledge. It can also be integrated into external databases of retrieval-augmented language models, enabling broader access to historical information, including interpretations of political events and intricate details about people's ancestors. Additionally, the structured article texts facilitate the application of transformer-based methods for popular tasks like detecting reproduced content, significantly improving accuracy compared to traditional OCR methods. American Stories serves as a substantial and valuable dataset for advancing multimodal layout analysis models and other multimodal applications.","url":"https://huggingface.co/datasets/dell-research-harvard/AmericanStories","creator_name":"Dell Research Harvard","creator_url":"https://huggingface.co/dell-research-harvard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","question-answering"],"keywords_longer_than_N":true},
	{"name":"law.go.kr","keyword":"text-retrieval","description":" Legal case retrieval with Korean Precedents (powered by https://law.go.kr/)\n\nThis dataset repository maintains files required for legal case retrieval using Korean Precedents acquired from https://law.go.kr/\nFor codes and more information, refer to GitHub page\n","url":"https://huggingface.co/datasets/woalsdnd/law.go.kr","creator_name":"Jaemin Son","creator_url":"https://huggingface.co/woalsdnd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","Korean","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"ID_REG_KG_2510","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIndonesian Legal Regulations - Knowledge Graph Enhanced Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Indonesian legal regulations enhanced with advanced knowledge graph features for improved Retrieval-Augmented Generation (RAG) systems.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\n\t\n\t\t\n\t\tOriginal Features (from embedding dataset)\n\t\n\n\nglobal_id: Unique document identifier\nlocal_id: Local chunk identifier\nregulation_type: Type of regulation (UU, PP, Perpres, etc.)\nenacting_body: Government‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azzindani/ID_REG_KG_2510.","url":"https://huggingface.co/datasets/Azzindani/ID_REG_KG_2510","creator_name":"Azzindani","creator_url":"https://huggingface.co/Azzindani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Indonesian","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rag-mini-wikipedia","keyword":"information-retrieval","description":"In this huggingface discussion you can share what you used the dataset for.\nDerives from https://www.kaggle.com/datasets/rtatman/questionanswer-dataset?resource=download we generated our own subset using generate.py.\n","url":"https://huggingface.co/datasets/rag-datasets/rag-mini-wikipedia","creator_name":"RAG Datasets","creator_url":"https://huggingface.co/rag-datasets","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","sentence-similarity","English","cc-by-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ultrafeedback_prompt_scores","keyword":"text-retrieval","description":"BlackBeenie/ultrafeedback_prompt_scores dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BlackBeenie/ultrafeedback_prompt_scores","creator_name":"Yeonwoo Sung","creator_url":"https://huggingface.co/BlackBeenie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rag-mini-bioasq","keyword":"information-retrieval","description":"See here for an updated version without nans in text-corpus.\nIn this huggingface discussion you can share what you used the dataset for.\nDerives from http://participants-area.bioasq.org/Tasks/11b/trainingDataset/ we generated our own subset using generate.py.\n","url":"https://huggingface.co/datasets/rag-datasets/rag-mini-bioasq","creator_name":"RAG Datasets","creator_url":"https://huggingface.co/rag-datasets","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["question-answering","sentence-similarity","English","cc-by-2.5","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IFIR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for IFIR Benchmark\n\t\n\nRepository: sighingsnow/IFIR\nFor the usage of this dataset, please refer to the github repo. \nIf you find this repository helpful, feel free to cite our paper:\n@misc{song2025ifir,\n      title={IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval}, \n      author={Tingyu Song and Guo Gan and Mingsheng Shang and Yilun Zhao},\n      year={2025},\n      eprint={2503.04644},\n      archivePrefix={arXiv}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/songtingyu/IFIR.","url":"https://huggingface.co/datasets/songtingyu/IFIR","creator_name":"Tingyu Song","creator_url":"https://huggingface.co/songtingyu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","mit","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"quest","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for QUEST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe provide here the data accompanying the paper: QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations\n.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nQUEST contains 6307 training queries, 323 examples for development, and 1727 examples for testing.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach examples file contains newline-separated json dictionaries with the following fields:\n\nquery - Paraphrased query written‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmalaviya/quest.","url":"https://huggingface.co/datasets/cmalaviya/quest","creator_name":"Chaitanya Malaviya","creator_url":"https://huggingface.co/cmalaviya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","wikipedia-sourced","original","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"RuSciBenchCiteRetrieval","keyword":"document-retrieval","description":"\n  RuSciBenchCiteRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is focused on Direct Citation Prediction for scientific papers from eLibrary,\n        Russia's largest electronic library of scientific publications. Given a query paper (title and abstract),\n        the goal is to retrieve papers that are directly cited by it from a larger corpus of papers.\n        The dataset for this task consists of 3,000 query papers, 15,000 relevant (cited) papers,\n        and 75‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuSciBenchCiteRetrieval.","url":"https://huggingface.co/datasets/mteb/RuSciBenchCiteRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","mlsa-iai-msu-lab/ru_sci_bench_cite_retrieval"],"keywords_longer_than_N":true},
	{"name":"MBPPRetrieval","keyword":"text-retrieval","description":"\n  MBPPRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA code retrieval task based on 378 Python programming problems from MBPP (Mostly Basic Python Programming). Each query is a natural language description of a programming task (e.g., 'Write a function to find the shared elements from the given two lists'), and the corpus contains Python code implementations. The task is to retrieve the correct code snippet that solves the described problem. Queries are problem descriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MBPPRetrieval.","url":"https://huggingface.co/datasets/mteb/MBPPRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","embedding-benchmark/MBPP","code"],"keywords_longer_than_N":true},
	{"name":"RuSciBenchCiteRetrieval","keyword":"text-retrieval","description":"\n  RuSciBenchCiteRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is focused on Direct Citation Prediction for scientific papers from eLibrary,\n        Russia's largest electronic library of scientific publications. Given a query paper (title and abstract),\n        the goal is to retrieve papers that are directly cited by it from a larger corpus of papers.\n        The dataset for this task consists of 3,000 query papers, 15,000 relevant (cited) papers,\n        and 75‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuSciBenchCiteRetrieval.","url":"https://huggingface.co/datasets/mteb/RuSciBenchCiteRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","mlsa-iai-msu-lab/ru_sci_bench_cite_retrieval"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-it-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (it) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (it) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Italian"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-it-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (it) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (it) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Italian"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-fr-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (fr) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"ara-stance","keyword":"fact-checking","description":"The AraStance dataset contains true and false claims, where each claim is paired with one or more documents. Each claim‚Äìarticle pair has a stance label: agree, disagree, discuss, or unrelated.","url":"https://huggingface.co/datasets/strombergnlp/ara-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-fr-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (fr) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (fr) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","French"],"keywords_longer_than_N":true},
	{"name":"miracl","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL (Topics and Qrels)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHomepage | \nRepository: | \nPaper | \nArXiv\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl.","url":"https://huggingface.co/datasets/miracl/miracl","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL (Topics and Qrels)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHomepage | \nRepository: | \nPaper | \nArXiv\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl.","url":"https://huggingface.co/datasets/miracl/miracl","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-de-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"miracl-de-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"vivechan-spritual-text-dataset-v2","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVivechan - Spiritual Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Vivechan - Spiritual Text Dataset is an open and public collection of textual data extracted from significant spiritual texts, curated to support discussions, inquiries, doubts, and Q&A sessions within the realm of spirituality. This dataset provides valuable content from the following revered sources:\n\nShrimad Bhagwat Mahapurana\nShripad Shri Vallabha Charitramrutam\nShiv Mahapurana Sankshipt\nValmiki Ramayan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2.","url":"https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2","creator_name":"Om Ashishkumar Soni","creator_url":"https://huggingface.co/om-ashish-soni","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-to-speech","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wikiart-captions-5k","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tWikiArt Captions ‚Äî 5k subset\n\t\n\n\nimage_row ‚Äî –∏–Ω–¥–µ–∫—Å –≤ 5k-—Å–∞–±—Å–µ—Ç–µ\ncaption ‚Äî –∞–≤—Ç–æ–æ–ø–∏—Å–∞–Ω–∏–µ (nlpconnect/vit-gpt2-image-captioning)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"USERNAME/wikiart-captions-5k\", data_files=\"data/train/captions.csv\")\n\n","url":"https://huggingface.co/datasets/Ekaterina2002/wikiart-captions-5k","creator_name":"Ekaterina","creator_url":"https://huggingface.co/Ekaterina2002","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"coreference-challenge","keyword":"retrieval","description":"\n\n\t\n\t\t\n\t\tPI-LLM Bench: The Core Retrieval Challenge Behind MRCR\n\t\n\n\nICML 2025 Long-Context Foundation Models Workshop Accepted.\n\nA simple context interference evaluation.\n\nUpdate: This dataset is integrated into Moonshot AI(Kimi)'s internal benchmarking framework for assessing ** tracking capacity and context interference in LLM/agents**.\nUpdate:Sept.6-mergerd into Moonshot/Kimi AI's internal eval tools and under review by a xAI(Grok)'s' eval team\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tTL;DR\n\t\n\nWe identify a task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/giantfish-fly/coreference-challenge.","url":"https://huggingface.co/datasets/giantfish-fly/coreference-challenge","creator_name":"c.p. wang","creator_url":"https://huggingface.co/giantfish-fly","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"fake_news_en_opensources","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tDataset Card for \"Fake News Opensources\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/FakeNewsDataset\nRepository: https://github.com/AndyTheFactory/FakeNewsDataset\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na consolidated and cleaned up version of the opensources Fake News dataset\nFake News Corpus comprises 8,529,090 individual articles, classified into 12 classes: reliable, unreliable, political, bias, fake, conspiracy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/fake_news_en_opensources.","url":"https://huggingface.co/datasets/andyP/fake_news_en_opensources","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","fact-checking","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"FinQARetrieval","keyword":"text-retrieval","description":"\n  FinQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA financial retrieval task based on FinQA dataset containing numerical reasoning questions over financial documents. Each query is a financial question requiring numerical computation (e.g., 'What is the percentage change in operating expenses from 2019 to 2020?'), and the corpus contains financial document text with tables and numerical data. The task is to retrieve the correct financial information that enables‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinQARetrieval.","url":"https://huggingface.co/datasets/mteb/FinQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-es-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"miracl-th-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"miracl-es-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"miracl-ru-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ru) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ru-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ru-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ru-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ru-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Russian"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"RuFacts","keyword":"fact-checking","description":"Fact-checking benchmark for the Russian Big Language Models.","url":"https://huggingface.co/datasets/akozlova/RuFacts","creator_name":"Anastasia Kozlova","creator_url":"https://huggingface.co/akozlova","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","cc-by-4.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"miracl-es-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"miracl-th-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"FeedbackQARetrieval","keyword":"text-retrieval","description":"\n  FeedbackQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nUsing Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Government, Medical, Written\nReference\nhttps://arxiv.org/abs/2204.03025\n\n\n\t\n\nSource datasets:\n\nlt2c/fqa\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FeedbackQARetrieval.","url":"https://huggingface.co/datasets/mteb/FeedbackQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multiple-choice-qa","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-es-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Spanish"],"keywords_longer_than_N":true},
	{"name":"miracl-ru-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ru) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ru-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ru-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ru-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ru-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Russian"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des pensions de retraite des marins fran√ßais du commerce, de p√™che ou de plaisance, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-evaluation-metrics","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Detailed Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains detailed RAGAS evaluation results with per-question metric scores for 5 different retrieval strategies tested on the GDELT RAG system. Each record includes the full evaluation context (question, contexts, response) plus 4 RAGAS metric scores.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: ~1,400+ evaluation records with metric scores\nRetrievers Evaluated: Baseline, Naive, BM25, Ensemble, Cohere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-metrics.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-evaluation-metrics","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"chinese-poetry","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tÂîêË©©‰∏âÁôæÈ¶ñ Dataset\n\t\n\nA structured JSON dataset of 320 classical Tang Dynasty poems, sourced from Á∂≠Âü∫ÊñáÂ∫´ÔºàWikisourceÔºâ.\nThis dataset provides clean, machine-readable text data suitable for natural language processing (NLP), classical Chinese analysis, digital humanities, and poetry generation tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Overview\n\t\n\n\nTotal entries: 320\nSource: Wikisource (Traditional Chinese)\nFormat: JSON Lines (.jsonl)\nEncoding: UTF-8\nLanguage: Classical Chinese (ÁπÅÈ´î‰∏≠Êñá)\n\nEach entry corresponds to one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZoneTwelve/chinese-poetry.","url":"https://huggingface.co/datasets/ZoneTwelve/chinese-poetry","creator_name":"ZoneTwelve","creator_url":"https://huggingface.co/ZoneTwelve","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","human-annotated","found"],"keywords_longer_than_N":true},
	{"name":"vie_wiki_dataset","keyword":"text-retrieval","description":"comet24082002/vie_wiki_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/comet24082002/vie_wiki_dataset","creator_name":"Pham Trung Dung","creator_url":"https://huggingface.co/comet24082002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Vietnamese","apache-2.0","1M - 10M","arrow"],"keywords_longer_than_N":true},
	{"name":"DebateSum","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDebateSum\n\t\n\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \"DebateSum: A large-scale argument mining and summarization dataset\"\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\nVideo of presentation at COLING 2020:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum.","url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-retrieval","text-generation","abstractive-qa"],"keywords_longer_than_N":true},
	{"name":"FollowIR-train","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFollowIR-train contains ~1800 query and instruction pairs, with labels for relevance (true or false). It can be used to train retrieval models to better follow instructions (see FollowIR-7B). \nThe dataset was created by taking instruction and query pairs from all TREC tracks (which provides instructions as \"narratives\") from 1993-on that provided these instructions. Synthetic documents were then created from GPT-3.5-Turbo-1106 and filtered using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/FollowIR-train.","url":"https://huggingface.co/datasets/jhu-clsp/FollowIR-train","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tab_fact","keyword":"fact-checking","description":"The problem of verifying whether a textual hypothesis holds the truth based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are restricted to dealing with unstructured textual evidence (e.g., sentences and passages, a pool of passages), while verification using structured forms of evidence, such as tables, graphs, and databases, remains unexplored. TABFACT is large scale dataset with 16k Wikipedia tables as evidence for 118k human annotated statements designed for fact verification with semi-structured evidence. The statements are labeled as either ENTAILED or REFUTED. TABFACT is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning.","url":"https://huggingface.co/datasets/wenhu/tab_fact","creator_name":"Wenhu Chen","creator_url":"https://huggingface.co/wenhu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"DebateSum","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDebateSum\n\t\n\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \"DebateSum: A large-scale argument mining and summarization dataset\"\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\nVideo of presentation at COLING 2020:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum.","url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-retrieval","text-generation","abstractive-qa"],"keywords_longer_than_N":true},
	{"name":"airbnb_embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of AirBnB listings with property descriptions, reviews, and other metadata. \nIt also contains text embeddings of the property descriptions as well as image embeddings of the listing image. The text embeddings were created using OpenAI's text-embedding-3-small model and the image embeddings using OpenAI's clip-vit-base-patch32 model available on Hugging Face. \nThe text embeddings have 1536 dimensions, while the image embeddings have 512 dimensions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/airbnb_embeddings.","url":"https://huggingface.co/datasets/MongoDB/airbnb_embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-to-image","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"lama","keyword":"fact-checking-retrieval","description":"LAMA is a dataset used to probe and analyze the factual and commonsense knowledge contained in pretrained language models. See https://github.com/facebookresearch/LAMA.","url":"https://huggingface.co/datasets/facebook/lama","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"lama","keyword":"text-retrieval","description":"LAMA is a dataset used to probe and analyze the factual and commonsense knowledge contained in pretrained language models. See https://github.com/facebookresearch/LAMA.","url":"https://huggingface.co/datasets/facebook/lama","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","text-classification","fact-checking-retrieval","text-scoring","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"spanex","keyword":"fact-checking","description":"SpanEx consists of 7071 instances annotated for span interactions.\nSpanEx is the first dataset with human phrase-level interaction explanations with explicit labels for interaction types. \nMoreover, SpanEx is annotated by three annotators, which opens new avenues for studies of human explanation agreement -- an understudied area in the explainability literature. \nOur study reveals that while human annotators often agree on span interactions, they also offer complementary reasons for a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spanex.","url":"https://huggingface.co/datasets/copenlu/spanex","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ViNLI-SimCSE-supervised_v2","keyword":"text-retrieval","description":"anti-ai/ViNLI-SimCSE-supervised_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anti-ai/ViNLI-SimCSE-supervised_v2","creator_name":"anti-ai","creator_url":"https://huggingface.co/anti-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","Vietnamese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-minilm","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-MiniLM-L6-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Recap-DataComp-1B","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Recap-DataComp-1B\n\t\n\n\n\nRecap-DataComp-1B is a large-scale image-text dataset that has been recaptioned using an advanced LLaVA-1.5-LLaMA3-8B model to enhance the alignment and detail of textual descriptions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nOur paper aims to bridge this community effort, leveraging the powerful and open-sourced LLaMA-3, a GPT-4 level LLM.\nOur recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered LLaVA-1.5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/Recap-DataComp-1B.","url":"https://huggingface.co/datasets/UCSC-VLAA/Recap-DataComp-1B","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"esci-us-small","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tESCI Shopping Queries Dataset (US Locale - Small Version)\n\t\n\nThis is a curated subset of the Amazon Shopping Queries Dataset (ESCI), filtered for the US locale only and using the small version of the dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Shopping Queries Dataset is a large-scale manually annotated dataset for improving product search, released by Amazon Science. It contains challenging search queries paired with products and human-labeled relevance judgments.\n\n\t\n\t\t\n\t\tOriginal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shuttie/esci-us-small.","url":"https://huggingface.co/datasets/shuttie/esci-us-small","creator_name":"Roman Grebennikov","creator_url":"https://huggingface.co/shuttie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"esci-us-small","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tESCI Shopping Queries Dataset (US Locale - Small Version)\n\t\n\nThis is a curated subset of the Amazon Shopping Queries Dataset (ESCI), filtered for the US locale only and using the small version of the dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Shopping Queries Dataset is a large-scale manually annotated dataset for improving product search, released by Amazon Science. It contains challenging search queries paired with products and human-labeled relevance judgments.\n\n\t\n\t\t\n\t\tOriginal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shuttie/esci-us-small.","url":"https://huggingface.co/datasets/shuttie/esci-us-small","creator_name":"Roman Grebennikov","creator_url":"https://huggingface.co/shuttie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-sources","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Source Documents\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains source documents extracted from the research paper \"Talking to GDELT Through Knowledge Graphs\"\n(arXiv:2503.07584v3). The documents are used as the knowledge base for a Retrieval-Augmented Generation (RAG) system\nfocused on GDELT (Global Database of Events, Language, and Tone) analysis.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Documents: 38 pages\nSource: Research paper on GDELT Knowledge Graphs\nFormat: PDF pages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-sources.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-sources","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gdelt-rag-sources","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tGDELT RAG Source Documents\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains source documents extracted from the research paper \"Talking to GDELT Through Knowledge Graphs\"\n(arXiv:2503.07584v3). The documents are used as the knowledge base for a Retrieval-Augmented Generation (RAG) system\nfocused on GDELT (Global Database of Events, Language, and Tone) analysis.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Documents: 38 pages\nSource: Research paper on GDELT Knowledge Graphs\nFormat: PDF pages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/gdelt-rag-sources.","url":"https://huggingface.co/datasets/dwb2023/gdelt-rag-sources","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ar-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ar) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ja-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ja) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-id-corpus-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (id) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-id-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-id-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-id-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-id-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Indonesian"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-queries-22-12","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ar-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ar) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ja-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWikipedia (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ja) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"miracl-id-corpus-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (id) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-id-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-id-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-id-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-id-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Indonesian"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-queries-22-12","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"RAVQAV2Data","keyword":"retrieval","description":"This is the official release of resources for the RAVQA-V2. This repository contains the pre-extracted features for OK-VQA, and the pre-trained checkpoints for RAVQA-V2 (equipped with Fine-grained Late-interaction Multi-modal Retrieval).\nThe code can be found on Github\n","url":"https://huggingface.co/datasets/BByrneLab/RAVQAV2Data","creator_name":"BByrneLab","creator_url":"https://huggingface.co/BByrneLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","üá∫üá∏ Region: US","VQA"],"keywords_longer_than_N":true},
	{"name":"fake_news_filipino_parquet","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tFake News Filipino (Parquet version)\n\t\n\nThis is a Parquet version of the Fake News Filipino dataset by Cruz et al., 2020.\nIt contains 3,206 Filipino-language news articles, half labeled fake (1) and half real (0).The dataset is widely used for benchmarking fake-news detection and fact-checking models in low-resource languages.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß© Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"renshhhh/fake_news_filipino_parquet\", data_files=\"train.parquet\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renshhhh/fake_news_filipino_parquet.","url":"https://huggingface.co/datasets/renshhhh/fake_news_filipino_parquet","creator_name":"Gabriel Mari Flores","creator_url":"https://huggingface.co/renshhhh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"SSLQ-Version-1.600","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tSSLQ Version 1.600\n\t\n\nSSLQ Version 1.600, ‚ÄúSynthetic Scenic Lore Image Quality‚Äù, is a hand-curated dataset of 600 manually annotated images drawn from the SSLQ archive, which is a long-term study in synthetic image aesthetics \nand visual coherence. Each image was labeled in Label Studio 1.13 using a structured XML schema and enriched with human and LLM commentary \ndescribing visual qualities, stylistic alignment, and subjective evaluations of quality and mood.\n\n\t\n\t\t\n\t\n\t\n\t\tAnnotation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shalvers/SSLQ-Version-1.600.","url":"https://huggingface.co/datasets/shalvers/SSLQ-Version-1.600","creator_name":"Steven Halverson","creator_url":"https://huggingface.co/shalvers","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","image-to-text","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"rumoureval_2019","keyword":"fact-checking","description":"\nStance prediction task in English. The goal is to predict whether a given reply to a claim either supports, denies, questions, or simply comments on the claim. Ran as a SemEval task in 2019.","url":"https://huggingface.co/datasets/strombergnlp/rumoureval_2019","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Logic-ORiented-Retrieve","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tLogic-ORiented Retriever Enhancement Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for training and evaluating Logic-ORiented Retriever Enhancement (LORE) models.\nThe dataset implements a three-tier contrastive learning framework with fine-grained sample classification:\n\nP (Positive, label=1): Chunks sufficient to answer the query\nN1 (Distractor, label=-1): Chunks used by LLM in query rewriting, seemingly relevant but unhelpful  \nN2 (Negative, label=0): Other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Retrieve.","url":"https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Retrieve","creator_name":"AestasZhang","creator_url":"https://huggingface.co/XiaSheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SqCLIRIL","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüó£Ô∏è SqCLIRIL: Spoken Query Benchmark for Cross-Lingual IR in Indian Languages\n\t\n\nSqCLIRIL is a Spoken Query Benchmark designed to evaluate cross-lingual information retrieval (CLIR) systems using both spoken and text queries.It covers five Indian languages ‚Äî Hindi, Gujarati, Bengali, Kannada, and English ‚Äî with diverse speech samples from male and female speakers to capture natural variability in pronunciation and acoustic conditions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Dataset Summary\n\t\n\n\n\t\n\t\t\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/irlab-daiict/SqCLIRIL.","url":"https://huggingface.co/datasets/irlab-daiict/SqCLIRIL","creator_name":"IRLAB","creator_url":"https://huggingface.co/irlab-daiict","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-retrieval","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"Logic-ORiented-Retrieve","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tLogic-ORiented Retriever Enhancement Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for training and evaluating Logic-ORiented Retriever Enhancement (LORE) models.\nThe dataset implements a three-tier contrastive learning framework with fine-grained sample classification:\n\nP (Positive, label=1): Chunks sufficient to answer the query\nN1 (Distractor, label=-1): Chunks used by LLM in query rewriting, seemingly relevant but unhelpful  \nN2 (Negative, label=0): Other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Retrieve.","url":"https://huggingface.co/datasets/XiaSheng/Logic-ORiented-Retrieve","creator_name":"AestasZhang","creator_url":"https://huggingface.co/XiaSheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"code-penitentiaire","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode p√©nitentiaire, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode des pensions militaires d'invalidit√© et des victimes de guerre, non-instruct (2025-03-10)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"germanquad","keyword":"text-retrieval","description":"In order to raise the bar for non-English QA, we are releasing a high-quality, human-labeled German QA dataset consisting of 13 722 questions, incl. a three-way annotated test set.\nThe creation of GermanQuAD is inspired by insights from existing datasets as well as our labeling experience from several industry projects. We combine the strengths of SQuAD, such as high out-of-domain performance, with self-sufficient questions that contain all relevant information for open-domain QA as in the NaturalQuestions dataset. Our training and test datasets do not overlap like other popular datasets and include complex questions that cannot be answered with a single entity or only a few words.","url":"https://huggingface.co/datasets/deepset/germanquad","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"DisastIR-DevLite","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tüåç DisastIR-Devlite & DisastIR-Test\n\t\n\nDisastIR-Devlite and DisastIR-Test are two complementary subsets derived from the DisastIR benchmark for disaster-related information retrieval.They are designed as the validation set and test set, respectively\n\n\n\t\n\t\t\n\t\tüß≠ Overview\n\t\n\n\nDisastIR-Devlite is a lightweight validation set derived from DisastIR by sampling a subset of queries and constructing a smaller passage corpus tailored to them.It enables rapid and effective model development.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DisastIR-DevLite.","url":"https://huggingface.co/datasets/DMIR01/DisastIR-DevLite","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DisastIR-DevLite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüåç DisastIR-Devlite & DisastIR-Test\n\t\n\nDisastIR-Devlite and DisastIR-Test are two complementary subsets derived from the DisastIR benchmark for disaster-related information retrieval.They are designed as the validation set and test set, respectively\n\n\n\t\n\t\t\n\t\tüß≠ Overview\n\t\n\n\nDisastIR-Devlite is a lightweight validation set derived from DisastIR by sampling a subset of queries and constructing a smaller passage corpus tailored to them.It enables rapid and effective model development.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DisastIR-DevLite.","url":"https://huggingface.co/datasets/DMIR01/DisastIR-DevLite","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DisastIR-DevLite","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüåç DisastIR-Devlite & DisastIR-Test\n\t\n\nDisastIR-Devlite and DisastIR-Test are two complementary subsets derived from the DisastIR benchmark for disaster-related information retrieval.They are designed as the validation set and test set, respectively\n\n\n\t\n\t\t\n\t\tüß≠ Overview\n\t\n\n\nDisastIR-Devlite is a lightweight validation set derived from DisastIR by sampling a subset of queries and constructing a smaller passage corpus tailored to them.It enables rapid and effective model development.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DMIR01/DisastIR-DevLite.","url":"https://huggingface.co/datasets/DMIR01/DisastIR-DevLite","creator_name":"DMIR","creator_url":"https://huggingface.co/DMIR01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-ranking","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ID_REG_MD_RAG","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tIndonesian Legal RAG Processed Database\n\t\n\nThis repository contains a fully preprocessed Indonesian legal regulation database ready for RAG (Retrieval Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Records: 199,994\nProcessing Date: 2025-08-23\nEmbedding Model: Qwen/Qwen3-Embedding-0.6B\nEmbedding Dimension: 1024\n\n\n\t\n\t\t\n\t\tFiles Description\n\t\n\n\n\t\n\t\t\n\t\tMain Database\n\t\n\n\nprocessed_legal_database.parquet - Complete preprocessed database with all features\nembeddings.npy -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azzindani/ID_REG_MD_RAG.","url":"https://huggingface.co/datasets/Azzindani/ID_REG_MD_RAG","creator_name":"Azzindani","creator_url":"https://huggingface.co/Azzindani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Indonesian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCTreatmentRetrieval","keyword":"document-retrieval","description":"\n  R2MEDPMCTreatmentRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Treatment retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Treatment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCTreatmentRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Treatment"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"entity-linking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"fact-checking-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"R2MEDPMCTreatmentRetrieval","keyword":"text-retrieval","description":"\n  R2MEDPMCTreatmentRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPMC-Treatment retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/PMC-Treatment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDPMCTreatmentRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDPMCTreatmentRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/PMC-Treatment"],"keywords_longer_than_N":true},
	{"name":"arxiv-abstracts-2021","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for arxiv-abstracts-2021\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.","url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","explanation-generation","text-simplification","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"italian-embedding-finetune-dataset","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tItalian-BERT-FineTuning-Embeddings\n\t\n\nThis repository contains a comprehensive dataset designed for fine-tuning BERT-based Italian embedding models. The dataset aims to enhance performance on tasks such as information retrieval, semantic search, and embeddings generation.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset leverages the C4 dataset (Italian subset) and employs advanced techniques like sliding window segmentation and in-document sampling to create high-quality, diverse examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset.","url":"https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset","creator_name":"Archit Rastogi","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Italian","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"prezentacii","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for Prezentacii.org Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 100,381 educational materials from the prezentacii.org platform, a resource for teachers and students providing multimedia presentations and other educational content on various topics. The dataset includes information such as material titles, URLs, download URLs, and extracted text content where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/prezentacii.","url":"https://huggingface.co/datasets/nyuuzyou/prezentacii","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-android","keyword":"text-retrieval","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackAndroidRetrieval\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-android.","url":"https://huggingface.co/datasets/mteb/cqadupstack-android","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Urdu"],"keywords_longer_than_N":true},
	{"name":"IndonesianIdClickbaitClassification","keyword":"fact-checking","description":"\n  IndonesianIdClickbaitClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\nReference\nhttp://www.sciencedirect.com/science/article/pii/S2352340920311252\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification.","url":"https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"IndonesianIdClickbaitClassification","keyword":"fact-checking-retrieval","description":"\n  IndonesianIdClickbaitClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\nReference\nhttp://www.sciencedirect.com/science/article/pii/S2352340920311252\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification.","url":"https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"SciVer","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tSCIVER: A Benchmark for Multimodal Scientific Claim Verification\n\t\n\n\n  üåê Github ‚Ä¢\n  üìñ Paper ‚Ä¢\n  ü§ó Data\n\n\n\n\n\t\n\t\t\n\t\tüì∞ News\n\t\n\n\n[May 15, 2025] SciVer has been accepted by ACL 2025 Main!\n\n\n\t\n\t\t\n\t\tüëã Overview\n\t\n\n\nSCIVER is the first benchmark specifically designed to evaluate the ability of foundation models to verify scientific claims across text, charts, and tables. It challenges models to reason over complex, multimodal contexts with fine-grained entailment labels and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chengyewang/SciVer.","url":"https://huggingface.co/datasets/chengyewang/SciVer","creator_name":"chengyewang","creator_url":"https://huggingface.co/chengyewang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"neuclir-2023","keyword":"text-retrieval","description":"\n  NeuCLIR2023Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NeuCLIR2023Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/neuclir-2023.","url":"https://huggingface.co/datasets/mteb/neuclir-2023","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Persian","Russian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"SIU3R","keyword":"text-retrieval","description":"This is the official Hugging Face repository for SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment.\nProject Page: https://insomniaaac.github.io/siu3r/\nCode: https://github.com/WU-CVGL/SIU3R\n\n\t\n\t\t\n\t\tPretrained Models for SIU3R\n\t\n\nWe provide pretrained models for the Panoptic Segmentation task. We train MASt3R backbone with adapter on the COCO dataset for SIU3R initialization.\n\n\t\n\t\t\n\t\tPreprocessed Scannet Dataset for SIU3R Training\n\t\n\nThis dataset is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/insomnia7/SIU3R.","url":"https://huggingface.co/datasets/insomnia7/SIU3R","creator_name":"XuQi","creator_url":"https://huggingface.co/insomnia7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","image-segmentation","text-retrieval","mit","arxiv:2507.02705"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"DBPedia_test_top_250_only_w_correct-v2","keyword":"text-retrieval","description":"\n  DBPediaHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2.","url":"https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","mteb/dbpedia","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-221689","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-221689 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-221689 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"healthcare-disease-knowledge","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDisease Symptoms & Treatment Dataset\n\t\n\nThis dataset contains structured information about 687 diseases and their associated details.It is intended for research, educational, and prototyping purposes in healthcare-related ML/NLP tasks.  \n\n\t\n\t\t\n\t\tContents\n\t\n\nEach row corresponds to one disease, with 17 columns:\n\ndisease ‚Äî Name of the disease  \nmain_link ‚Äî Reference link  \nDiagnosis_treatment_link ‚Äî Link to diagnosis/treatment page  \nDoctors_departments_link ‚Äî Relevant medical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/harmesh95/healthcare-disease-knowledge.","url":"https://huggingface.co/datasets/harmesh95/healthcare-disease-knowledge","creator_name":"Harmesh G V","creator_url":"https://huggingface.co/harmesh95","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"neuclir-2022-hard-negatives","keyword":"text-retrieval","description":"\n  NeuCLIR2022RetrievalHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the documents that are relevant to the queries. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://neuclir.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/neuclir-2022-hard-negatives.","url":"https://huggingface.co/datasets/mteb/neuclir-2022-hard-negatives","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","mteb/neuclir-2022","Persian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"MedQA-Diag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/MedQA-Diag.","url":"https://huggingface.co/datasets/R2MED/MedQA-Diag","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"mathlibretrieval","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tInformalized Mathlib4 Retrieval Dataset\n\t\n\nThe goal is to retrieve relevant mathlib4 theorems based on informal mathematical queries. Sourced from https://huggingface.co/datasets/hcju/leansearch_bench/\n","url":"https://huggingface.co/datasets/hcju/mathlibretrieval","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","leansearch","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Assamese"],"keywords_longer_than_N":true},
	{"name":"mathlibretrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tInformalized Mathlib4 Retrieval Dataset\n\t\n\nThe goal is to retrieve relevant mathlib4 theorems based on informal mathematical queries. Sourced from https://huggingface.co/datasets/hcju/leansearch_bench/\n","url":"https://huggingface.co/datasets/hcju/mathlibretrieval","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","leansearch","English"],"keywords_longer_than_N":true},
	{"name":"mathlibretrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tInformalized Mathlib4 Retrieval Dataset\n\t\n\nThe goal is to retrieve relevant mathlib4 theorems based on informal mathematical queries. Sourced from https://huggingface.co/datasets/hcju/leansearch_bench/\n","url":"https://huggingface.co/datasets/hcju/mathlibretrieval","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","leansearch","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Assamese"],"keywords_longer_than_N":true},
	{"name":"RAGTruth-TR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tRAGTruth-TR\n\t\n\nnewmindai/RAGTruth-TR is a Turkish-translated version of the wandb/RAGTruth-processed dataset.\nIt is designed for evaluating Retrieval-Augmented Generation (RAG) systems in Turkish, enabling research in hallucination detection, fact-checking, and response quality assessment.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource Dataset: wandb/RAGTruth-processed\nTarget Language: Turkish\nPurpose: Hallucination detection and RAG evaluation in Turkish NLP systems\nLicense: MIT (inherits from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/newmindai/RAGTruth-TR.","url":"https://huggingface.co/datasets/newmindai/RAGTruth-TR","creator_name":"NewMind AI","creator_url":"https://huggingface.co/newmindai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Telugu"],"keywords_longer_than_N":true},
	{"name":"HunSum2AbstractiveRetrieval","keyword":"document-retrieval","description":"\n  HunSum2AbstractiveRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHunSum-2-abstractive is a Hungarian dataset containing news articles along with lead, titles and metadata.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.03555\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HunSum2AbstractiveRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval.","url":"https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Hungarian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Telugu"],"keywords_longer_than_N":true},
	{"name":"HunSum2AbstractiveRetrieval","keyword":"text-retrieval","description":"\n  HunSum2AbstractiveRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHunSum-2-abstractive is a Hungarian dataset containing news articles along with lead, titles and metadata.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.03555\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HunSum2AbstractiveRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval.","url":"https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Hungarian"],"keywords_longer_than_N":true},
	{"name":"symurbench_datasets","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tSyMuRBench Datasets and Precomputed Features\n\t\n\nThis repository contains datasets and precomputed features for SyMuRBench, a benchmark for symbolic music understanding models. It includes metadata and MIDI files for multiple classification and retrieval tasks, along with pre-extracted music21 and jSymbolic features.\nYou can install and use the full pipeline via:\nüëâ https://github.com/Mintas/SyMuRBench\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nSyMuRBench supports evaluation across diverse symbolic music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai-forever/symurbench_datasets.","url":"https://huggingface.co/datasets/ai-forever/symurbench_datasets","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","üá∫üá∏ Region: US","symbolic-music","music-information-retrieval","classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"document-retrieval","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V1 dataset (last update 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"text-retrieval","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract. This is the V1 dataset (last update 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource datasets:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"OGC_Nuclear","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Nuclear - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Nuclear is a curated multimodal dataset focused on nuclear technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.\nNuclear-related PDFs were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Nuclear.","url":"https://huggingface.co/datasets/racineai/OGC_Nuclear","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"OGC_Qualitative","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC_Qualitative\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Qualitative is a high-quality multimodal dataset created through the merge of multiple domain-specific datasets with enhanced data processing techniques. This dataset represents our most refined approach to multimodal data generation, incorporating filtering algorithms and improved AI-assisted content generation to deliver superior quality for RAG, DSE, question answering, document search, and vision-language model training tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Qualitative.","url":"https://huggingface.co/datasets/racineai/OGC_Qualitative","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"lm25","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNote: This dataset is not yet complete. More coming soon...\n\t\n\n\n\t\n\t\t\n\t\tLM25 Dataset\n\t\n\n\n\t\n\t\t\n\t\tUpdate 5/25/25 Added nfcorpus distilled from Qwen3 to sft-distill\n\t\n\nAdded 2387 prompt/completion pairs with reasoning distilled from Qwen3-32B-AWQ using best-of-32 generated completion and screened using BM25 reward\n(augmented query improvement by increased NDCG) on the train subset of NFCORPUS from the BEIR retrieval dataset.\n\n\t\n\t\t\n\t\n\t\n\t\tUpdate 5/22/25 Added fiqa distilled from Qwen3 to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dleemiller/lm25.","url":"https://huggingface.co/datasets/dleemiller/lm25","creator_name":"Lee Miller","creator_url":"https://huggingface.co/dleemiller","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"BrightLongRetrieval","keyword":"document-retrieval","description":"\n  BrightLongRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset with long documents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightLongRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightLongRetrieval.","url":"https://huggingface.co/datasets/mteb/BrightLongRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"BrightLongRetrieval","keyword":"text-retrieval","description":"\n  BrightLongRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset with long documents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightLongRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightLongRetrieval.","url":"https://huggingface.co/datasets/mteb/BrightLongRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-30052024-rc2l-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-30052024-rc2l-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"IIYIPostRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/IIYIPostRetrieval.","url":"https://huggingface.co/datasets/CMIRB/IIYIPostRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"mt-raig-bench","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMT-RAIG Bench\n\t\n\nMT-RAIG Bench is the first largescale benchmark for retrieval-augmented insight generation over multiple tables.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nKey\nType\nDescription\n\n\n\t\t\ngold_table_id_set\nList[str]\nMulti table ID set\n\n\nquestion\nstr\nQuestion\n\n\ninsight\nstr\nInsight\n\n\ntype\nstr\nQuestion type  - Analysis & Summary  - Comparsion & Relationship  - Performance & Outcome  - Trend & Pattern\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Example\n\t\n\n...\n{\n    \"gold_table_id_set\": [‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yonsei-dli/mt-raig-bench.","url":"https://huggingface.co/datasets/yonsei-dli/mt-raig-bench","creator_name":"Data & Language Intelligence Lab","creator_url":"https://huggingface.co/yonsei-dli","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","table-question-answering","document-retrieval","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mt-raig-bench","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMT-RAIG Bench\n\t\n\nMT-RAIG Bench is the first largescale benchmark for retrieval-augmented insight generation over multiple tables.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nKey\nType\nDescription\n\n\n\t\t\ngold_table_id_set\nList[str]\nMulti table ID set\n\n\nquestion\nstr\nQuestion\n\n\ninsight\nstr\nInsight\n\n\ntype\nstr\nQuestion type  - Analysis & Summary  - Comparsion & Relationship  - Performance & Outcome  - Trend & Pattern\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Example\n\t\n\n...\n{\n    \"gold_table_id_set\": [‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yonsei-dli/mt-raig-bench.","url":"https://huggingface.co/datasets/yonsei-dli/mt-raig-bench","creator_name":"Data & Language Intelligence Lab","creator_url":"https://huggingface.co/yonsei-dli","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","table-question-answering","document-retrieval","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"document-retrieval","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"Quora-NL","keyword":"text-retrieval","description":"\n  Quora-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nQuoraRetrieval is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions. QuoraRetrieval-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nWritten\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-quora\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Quora-NL.","url":"https://huggingface.co/datasets/mteb/Quora-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/quora","Dutch"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"text-retrieval","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"mteb-BillSumUS","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBillSumUS (MTEB formsat)\n\t\n\nThis is the federal US test split of the BillSum dataset formatted in the Massive Text Embedding Benchmark (MTEB) information retrieval dataset format.\nThis dataset is intended to facilitate the consistent and reproducible evaluation of information retrieval models on BillSum with the mteb embedding model evaluation framework.\nMore specifically, this dataset tests the ability of information retrieval models to retrieve US congressional bills based on their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isaacus/mteb-BillSumUS.","url":"https://huggingface.co/datasets/isaacus/mteb-BillSumUS","creator_name":"Isaacus","creator_url":"https://huggingface.co/isaacus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-retrieval","FiscalNote/billsum","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"UMRB-LLaVA","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tLLaVA Image-Text to Text retreival\n\t\n\nTest split.\nRefer to https://github.com/LinWeizheDragon/FLMR/blob/main/docs/Datasets.md\nand\nhttps://arxiv.org/pdf/2402.08327 section A.3.1 LLaVA\nOriginal dataset: https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K\n","url":"https://huggingface.co/datasets/izhx/UMRB-LLaVA","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Item-SID","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for AL-GR-Item-SID\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tüìñ Dataset Description\n\t\n\nAL-GR-Item-SID is a dataset containing Semantic IDs (SIDs) for products from an anonymized e-commerce platform. These IDs are generated using a multi-modal model and are specifically designed to serve as dense, meaningful features for Generative Recommendation systems, such as the LLM model.\nUnlike traditional sparse item IDs (e.g., item_12345), Semantic IDs are sequences of discrete tokens‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-SID.","url":"https://huggingface.co/datasets/AL-GR/Item-SID","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval","keyword":"document-retrieval","description":"\n  NLPJournalAbsArticleRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsArticleRetrieval","keyword":"text-retrieval","description":"\n  NLPJournalAbsArticleRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding full article with the given abstract. This is the V1 dataset (last updated 2020-06-15).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/sbintuitions/JMTEB\n\n\n\t\n\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval.","url":"https://huggingface.co/datasets/mteb/NLPJournalAbsArticleRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","sbintuitions/JMTEB"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Maithili"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Maithili"],"keywords_longer_than_N":true},
	{"name":"synthetic-from-retrieval-tasks-danish","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThanks to Arrow Denmark and Nvidia for sponsoring the compute used to generate this dataset\n\t\n\nThe purpose of this dataset is to pre- or post-train embedding models for Danish retrieval tasks. \nThe dataset consists of 100,000 samples generated with gemma-2-27b-it. \nThe column \"prompt\" shows the prompt given to the LLM and \"response\" shows the LLM output. \nEach sample in the dataset was generated from a seed task randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-danish.","url":"https://huggingface.co/datasets/ThatsGroes/synthetic-from-retrieval-tasks-danish","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Danish","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"InfoSearch_train","keyword":"retrieval","description":"EIT-NLP/InfoSearch_train dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EIT-NLP/InfoSearch_train","creator_name":"EIT-NLP","creator_url":"https://huggingface.co/EIT-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ESCI","keyword":"text-retrieval","description":"henilp105/ESCI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/henilp105/ESCI","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Awadhi"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBRIGHT benchmark\n\t\n\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\nBRIGHT provides a good testbed for future retrieval research in more realistic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT.","url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBRIGHT benchmark\n\t\n\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\nBRIGHT provides a good testbed for future retrieval research in more realistic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT.","url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Oriya"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNFCorpus.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNFCorpus-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNFCorpus","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Oriya"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNFCorpus.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNFCorpus-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNFCorpus","French"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpus-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoNFCorpus.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoNFCorpus-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoNFCorpus","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-tex","keyword":"text-retrieval","description":"\n  CQADupstackTexRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackTexRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-tex.","url":"https://huggingface.co/datasets/mteb/cqadupstack-tex","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"R2MEDIIYiClinicalRetrieval","keyword":"document-retrieval","description":"\n  R2MEDIIYiClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIIYi-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/IIYi-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDIIYiClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/IIYi-Clinical"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"R2MEDIIYiClinicalRetrieval","keyword":"text-retrieval","description":"\n  R2MEDIIYiClinicalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIIYi-Clinical retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/IIYi-Clinical\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDIIYiClinicalRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDIIYiClinicalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/IIYi-Clinical"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"tydiqa-goldp-vietnamese","keyword":"text-retrieval","description":"anti-ai-community/tydiqa-goldp-vietnamese dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anti-ai-community/tydiqa-goldp-vietnamese","creator_name":"anti-ai-community","creator_url":"https://huggingface.co/anti-ai-community","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Vietnamese","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020Retrieval","keyword":"text-retrieval","description":"\n  NanoTouche2020Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoTouche2020 is a smaller subset of Touch√© Task 1: Argument Retrieval for Controversial Questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReferencehttps://webis.de/events/touche-20/shared-task-1.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoTouche2020Retrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval.","url":"https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"french_MixEval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMixEval French Dataset\n\t\n\nThis dataset is the translation in french of MixEval dataset from MixEval https://huggingface.co/datasets/MixEval/MixEval\nIt‚Äôs designed to evaluate model on a french dataset. Duplicates from the original dataset were removed & unique answers were added.\nCheck MixEval's datacard for more information.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains this fields : \n\nproblem_type: multiple_choice\n\nprompt_fr: prompt in french‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIffl/french_MixEval.","url":"https://huggingface.co/datasets/AIffl/french_MixEval","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text-retrieval","French","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"R2MEDBiologyRetrieval","keyword":"document-retrieval","description":"\n  R2MEDBiologyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBiology retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Biology\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBiologyRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Biology"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"R2MEDBiologyRetrieval","keyword":"text-retrieval","description":"\n  R2MEDBiologyRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBiology retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://huggingface.co/datasets/R2MED/Biology\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"R2MEDBiologyRetrieval\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval.","url":"https://huggingface.co/datasets/mteb/R2MEDBiologyRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated and reviewed","monolingual","R2MED/Biology"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"PubMedAbstractsSubsetEmbedded","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tPubMed Abstracts Subset with MedCPT Embeddings (float32)\n\t\n\nThis dataset contains a probabilistic sample of ~2.4 million PubMed abstracts, enriched with precomputed dense embeddings (title + abstract), from the ncbi/MedCPT-Article-Encoder model. It is derived from public metadata made available via the National Library of Medicine (NLM) and was used in the paper Efficient and Reproducible Biomedical QA using Retrieval-Augmented Generation.\nEach entry includes:\n\ntitle: Title of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slinusc/PubMedAbstractsSubsetEmbedded.","url":"https://huggingface.co/datasets/slinusc/PubMedAbstractsSubsetEmbedded","creator_name":"Linus Stuhlmann","creator_url":"https://huggingface.co/slinusc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"english-words-definitions","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tEnglish Words Definitions\n\t\n\nThis dataset contains definitions and important facts about 467k words that appear in the context of English texts.\nIt has been used to train our high-performance, compact text embedding models mdbr-leaf-ir and mdbr-leaf-mt.\nThe original list of words stems from here. We have extended it with definitions and important facts about each word using Claude 3.7 Sonnet.\n","url":"https://huggingface.co/datasets/MongoDB/english-words-definitions","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Gujarati"],"keywords_longer_than_N":true},
	{"name":"multicare-cases","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMultiCaRe: Open-Source Clinical Case Dataset\n\t\n\nMultiCaRe is an open-source, multimodal clinical case dataset derived from PubMed Central‚Äôs Open Access (OA) Case Report articles. It links de-identified case narratives to figure images/captions and article-level metadata, enabling cross-modal supervision and retrieval.\n\nSource and process: OA case reports from PMC; parsed metadata and abstracts; extracted case narratives; downloaded and processed figures; aligned captions; curated image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openmed-community/multicare-cases.","url":"https://huggingface.co/datasets/openmed-community/multicare-cases","creator_name":"OpenMed Community","creator_url":"https://huggingface.co/openmed-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ID_REG_MD_KG","keyword":"text-retrieval","description":"üìß Github\nüîó LinkedIn\n\n\t\n\t\t\n\t\tüèõÔ∏è Indonesian Legal RAG Dataset with Knowledge Graph Enhancement\n\t\n\n\n\t\n\t\t\n\t\tüìñ What is this dataset?\n\t\n\nThis dataset contains Indonesian legal documents enhanced with Knowledge Graph features for building better RAG (Retrieval-Augmented Generation) systems. It includes regulations, laws, and legal documents from Indonesia with smart scoring and relationship mapping.\nüéØ Perfect for: Legal AI, Indonesian NLP, RAG systems, legal research, and chatbots\n\n\t\n\t\t\n\t\t‚ú® Key‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Azzindani/ID_REG_MD_KG.","url":"https://huggingface.co/datasets/Azzindani/ID_REG_MD_KG","creator_name":"Azzindani","creator_url":"https://huggingface.co/Azzindani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Indonesian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"floorplans","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tüè† Floorplan Image Dataset\n\t\n\nThis dataset contains a collection of floorplan images curated as part of a larger research project on architectural retrieval systems.\n\n\t\n\t\t\n\t\tüì¶ Dataset Summary\n\t\n\nThis repository stores floorplan images that were used primarily for testing and development of image retrieval methods. The dataset includes various floorplan styles, layouts, and formats to support tasks such as:\n\nContent-based image retrieval (CBIR)\nFloorplan similarity matching\nComputer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JoaoMigSilva/floorplans.","url":"https://huggingface.co/datasets/JoaoMigSilva/floorplans","creator_name":"Joao Silva","creator_url":"https://huggingface.co/JoaoMigSilva","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"NanoArguAnaRetrieval","keyword":"text-retrieval","description":"\n  NanoArguAnaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoArguAna is a smaller subset of ArguAna, a dataset for argument retrieval in debate contexts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReferencehttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoArguAnaRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/arguana","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Gujarati"],"keywords_longer_than_N":true},
	{"name":"code-expropriation-utilite-publique","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'expropriation pour cause d'utilit√© publique, non-instruct (2025-09-20)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"syntheticDocQA_artificial_intelligence_test","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is part of a topic-specific retrieval benchmark spanning multiple domains, which evaluates retrieval in more realistic industrial applications. \nIt includes documents about the Artificial Intelligence. \n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThanks to a crawler (see below), we collected 1,000 PDFs from the Internet with the query ('artificial intelligence'). From these documents, we randomly sampled 1000 pages.\nWe associated these with 100 questions and answers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/syntheticDocQA_artificial_intelligence_test.","url":"https://huggingface.co/datasets/vidore/syntheticDocQA_artificial_intelligence_test","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"JADE-17-01-2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tFrench Administrative Court Decisions Dataset (JADE)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe French Administrative Court Decisions Dataset (JADE) is a comprehensive collection of judicial decisions from French administrative courts. This dataset contains decisions from various administrative jurisdictions, providing a valuable resource for legal research, analysis, and machine learning applications in the legal domain.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nThe data is sourced from the official DILA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/JADE-17-01-2025.","url":"https://huggingface.co/datasets/La-Mousse/JADE-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","document-retrieval","document-question-answering","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_as","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_as","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Assamese"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SciFact","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SciFact","English"],"keywords_longer_than_N":true},
	{"name":"NanoSciFact","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","SciFact","English"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-141246","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-141246 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-141246 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Manipuri"],"keywords_longer_than_N":true},
	{"name":"bank-of-ghana-treasury-bills","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nBank of Ghana historical and real-time treasury bills data. Bank of Ghana\nClick Here: \n\n\t\n\t\t\n\t\tData Format\n\t\n\n{\n    \"issue_date\": \"...\", \n    \"tender\": \"...\", \n    \"security_type\": \"...\", \n    \"discount_rate\": \"...\", \n    \"interest_rate\": \"...\"\n}\n\n\n\t\n\t\t\n\t\tLoad Dataset\n\t\n\npip install datasets\n\nfrom datasets import load_dataset\n\ntreasury = load_dataset(\"worldboss/bank-of-ghana-treasury-bills\", split=\"train\")\n\npd.DataFrame(treasury).head()\n\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/bank-of-ghana-treasury-bills.","url":"https://huggingface.co/datasets/worldboss/bank-of-ghana-treasury-bills","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"msmarco-tr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for \"msmarco-tr\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/parsak/msmarco-tr","creator_name":"Parsa Kazerooni","creator_url":"https://huggingface.co/parsak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Turkish","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"msmarco-tr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for \"msmarco-tr\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/parsak/msmarco-tr","creator_name":"Parsa Kazerooni","creator_url":"https://huggingface.co/parsak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","Turkish","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"docvqa_test_subsampled","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is the test set taken from the DocVQA dataset. It includes collected images from the UCSF Industry Documents Library. Questions and answers were manually annotated.\nExample of data (see viewer)\n\n\t\n\t\t\n\t\tData Curation\n\t\n\nTo ensure homogeneity across our benchmarked datasets, we subsampled the original test set to 500 pairs and renamed the different columns.\n\n\t\n\t\t\n\t\tLoad the dataset\n\t\n\nfrom datasets import load_dataset\nds =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/docvqa_test_subsampled.","url":"https://huggingface.co/datasets/vidore/docvqa_test_subsampled","creator_name":"Vidore","creator_url":"https://huggingface.co/vidore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["document-question-answering","visual-document-retrieval","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"memefact-llm-evaluations","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tMemeFact LLM Evaluations Dataset\n\t\n\nThis dataset contains 7,680 evaluation records where state-of-the-art Large Language Models (LLMs) assessed fact-checking memes according to specific quality criteria. The dataset provides comprehensive insights into how different AI models evaluate visual-textual content and how these evaluations compare to human judgments.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe \"MemeFact LLM Evaluations\" dataset documents a systematic study‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergiogpinto/memefact-llm-evaluations.","url":"https://huggingface.co/datasets/sergiogpinto/memefact-llm-evaluations","creator_name":"S√©rgio Miguel Gon√ßalves Pinto","creator_url":"https://huggingface.co/sergiogpinto","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"fact-checking","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-programmers","keyword":"text-retrieval","description":"\n  CQADupstackProgrammersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-programmers.","url":"https://huggingface.co/datasets/mteb/cqadupstack-programmers","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Urdu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Urdu"],"keywords_longer_than_N":true},
	{"name":"cosmopedia-wikihow-chunked","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a chunked version of a subset of data in the Cosmopedia dataset curated by Hugging Face.\nSpecifically, we have only used a subset of Wikihow articles from the Cosmopedia dataset, and each article has been split into chunks containing no more than 2 paragraphs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset represents a chunk of a larger article, and contains the following fields:\n\ndoc_id: A unique identifier for the parent article\nchunk_id: A unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked.","url":"https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"modup","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMathOverflow Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/mathoverflow.net.7z\n","url":"https://huggingface.co/datasets/hcju/modup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mo","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQ","keyword":"document-retrieval","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NQ","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"Wikipedia_Passages_Sample","keyword":"text-retrieval","description":"Colino23/Wikipedia_Passages_Sample dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Colino23/Wikipedia_Passages_Sample","creator_name":"Nicolas","creator_url":"https://huggingface.co/Colino23","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","mit","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"modup","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMathOverflow Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/mathoverflow.net.7z\n","url":"https://huggingface.co/datasets/hcju/modup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mo","English"],"keywords_longer_than_N":true},
	{"name":"modup","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tMathOverflow Duplicate Question Retrieval\n\t\n\nThe task of Duplicate Question Retrieval involves retrieving questions that are duplicates of a given input question. We construct our dataset using the Mathematics Stack Exchange Data Dump (2024-09-30) https://archive.org/download/stackexchange_20240930/stackexchange_20240930/mathoverflow.net.7z\n","url":"https://huggingface.co/datasets/hcju/modup","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","mo","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQ","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NQ","English"],"keywords_longer_than_N":true},
	{"name":"NanoNQ","keyword":"text-retrieval","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NQ","English"],"keywords_longer_than_N":true},
	{"name":"bahadoransports","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tMENA & CIS Business Index Dataset\n\t\n\n\n\t\n\t\t\n\t\tüåç Overview\n\t\n\nThis dataset contains structured, multilingual data about real-world businesses in the MENA (Middle East and North Africa) and CIS (Commonwealth of Independent States) regions, optimized for indexing in AI and LLM models. It aims to enhance business recognition in AI-based search, chatbots, and voice assistants.\n\n\t\n\t\t\n\t\tüì¶ Data Structure\n\t\n\nEach record includes:\n\nBusiness name (in English, Arabic, and Persian)\nLocation and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Zahrasaghafi/bahadoransports.","url":"https://huggingface.co/datasets/Zahrasaghafi/bahadoransports","creator_name":"Zahra Saghafi","creator_url":"https://huggingface.co/Zahrasaghafi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","Persian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gdz4you","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for GDZ4You.com Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 18,037 educational materials from the gdz4you.com platform, a resource for teachers and students providing multimedia presentations and other educational content. The dataset includes information such as material titles, URLs, download links, ratings, and slide-by-slide content with images where available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gdz4you.","url":"https://huggingface.co/datasets/nyuuzyou/gdz4you","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-548936","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-548936 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-548936 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Panjabi"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"MixBench25-visual","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MixBench25-visual","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual.","url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25-visual","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-webmasters","keyword":"text-retrieval","description":"\n  CQADupstackWebmastersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWebmastersRetrieval\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-webmasters.","url":"https://huggingface.co/datasets/mteb/cqadupstack-webmasters","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Awadhi"],"keywords_longer_than_N":true},
	{"name":"rag-tutorial-prebuilt-indexes","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tüîç Pre-built Indexes for RAG Tutorial\n\t\n\nWelcome to the official repository for Pre-built Dense Indexes used in our RAG (Retrieval-Augmented Generation) Tutorial.\nThis repository is designed to help learners, instructors, and researchers easily integrate domain-specific dense retrieval into their RAG workflows without spending time building indexes from scratch.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ What This Repository Contains\n\t\n\nThis repository hosts ready-to-use FAISS-based dense indexes and supporting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShubhamC/rag-tutorial-prebuilt-indexes.","url":"https://huggingface.co/datasets/ShubhamC/rag-tutorial-prebuilt-indexes","creator_name":"Shubham Chatterjee","creator_url":"https://huggingface.co/ShubhamC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"mulesoft-documentation-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tmulesoft-documentation-embeddings\n\t\n\nMuleSoft Documentation Embeddings for RAG Applications\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nVersion: 1.0.0\nCreated: 2025-09-16T02:41:16.352809\nSource: Vector Database\nLicense: MIT\nLanguage: en\n\n\n\t\n\t\t\n\t\tTask Categories\n\t\n\nquestion-answering, retrieval, knowledge-base\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tSkillPilotDataSet_v11\n\t\n\n\nTotal Objects: 6430\nUnique Properties: 13\nKnowledge Sources: mulesoft, user_defined_docs\nAverage Content Length: 5079‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BassemE/mulesoft-documentation-embeddings.","url":"https://huggingface.co/datasets/BassemE/mulesoft-documentation-embeddings","creator_name":"Bassem","creator_url":"https://huggingface.co/BassemE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"phantom-wiki-v1","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for PhantomWiki\n\t\n\nThis repository contains pre-generated instances of the PhantomWiki dataset, created using the phantom-wiki Python package.  PhantomWiki is a framework for evaluating LLMs, particularly RAG and agentic workflows, designed to be resistant to memorization. Unlike fixed datasets, PhantomWiki generates unique instances on demand, ensuring novelty and preventing data leakage.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPhantomWiki generates a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kilian-group/phantom-wiki-v1.","url":"https://huggingface.co/datasets/kilian-group/phantom-wiki-v1","creator_name":"Kilian's Group","creator_url":"https://huggingface.co/kilian-group","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Biology","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/Biology.","url":"https://huggingface.co/datasets/R2MED/Biology","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackST","keyword":"text-retrieval","description":"\n  CodeFeedbackST\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"CodeFeedbackST\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackST.","url":"https://huggingface.co/datasets/mteb/CodeFeedbackST","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"rank1-run-files","keyword":"retrieval","description":"\n\t\n\t\t\n\t\trank1-run-files: Pre-computed Run Files for Reranking Evaluation\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains pre-computed run files used by the rank1 family of models on various retrieval benchmarks. These files are what were used for top-k rereranking and also include the re-annotated DL19 qrels. These files are needed to download to reproduce our results.\n\n\t\n\t\t\n\t\n\t\n\t\tBenchmarks Included\n\t\n\nThe dataset includes run files for the following benchmarks:\n\nBEIR (multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-run-files.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-run-files","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","arxiv:2502.18418","üá∫üá∏ Region: US","reranker"],"keywords_longer_than_N":true},
	{"name":"abstracts-embeddings","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tabstracts-embeddings\n\t\n\nThis is the embeddings of the titles and abstracts of 110 million academic publications taken from the OpenAlex dataset as of January 1, 2025. The embeddings are generated with a Unix pipeline, chaining together the AWS CLI, gzip, oa_jsonl (a C parser tailored to the JSON Lines structure of the OpenAlex snapshot), and a Python embedding script. The source code of oa_jsonl and the Makefile which sets up the pipeline is available on Github, but the general process‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/colonelwatch/abstracts-embeddings.","url":"https://huggingface.co/datasets/colonelwatch/abstracts-embeddings","creator_name":"Kenny Peng","creator_url":"https://huggingface.co/colonelwatch","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","English","cc0-1.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"rank1-run-files","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\trank1-run-files: Pre-computed Run Files for Reranking Evaluation\n\t\n\nüìÑ Paper | üöÄ GitHub Repository\nThis dataset contains pre-computed run files used by the rank1 family of models on various retrieval benchmarks. These files are what were used for top-k rereranking and also include the re-annotated DL19 qrels. These files are needed to download to reproduce our results.\n\n\t\n\t\t\n\t\n\t\n\t\tBenchmarks Included\n\t\n\nThe dataset includes run files for the following benchmarks:\n\nBEIR (multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-run-files.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-run-files","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","arxiv:2502.18418","üá∫üá∏ Region: US","reranker"],"keywords_longer_than_N":true},
	{"name":"abstracts-embeddings","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tabstracts-embeddings\n\t\n\nThis is the embeddings of the titles and abstracts of 110 million academic publications taken from the OpenAlex dataset as of January 1, 2025. The embeddings are generated with a Unix pipeline, chaining together the AWS CLI, gzip, oa_jsonl (a C parser tailored to the JSON Lines structure of the OpenAlex snapshot), and a Python embedding script. The source code of oa_jsonl and the Makefile which sets up the pipeline is available on Github, but the general process‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/colonelwatch/abstracts-embeddings.","url":"https://huggingface.co/datasets/colonelwatch/abstracts-embeddings","creator_name":"Kenny Peng","creator_url":"https://huggingface.co/colonelwatch","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","English","cc0-1.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"tip-of-my-tongue-known-item-search","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tThe TOMT-KIS (tip-of-my-tongue-known-item-search) Dataset\n\t\n\nSearchers who cannot resolve a known-item information need using a search engine might post a respective question on a question answering platform, hoping that the discussion with other people can help to identify the item. TOMT-KIS is a large-scale dataset of 1.28 million known-item questions from the r/tipofmytongue subreddit in the QPP++@ECIR'23 paper on A Large-Scale Dataset for Known-Item Question Performance Prediction.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/webis/tip-of-my-tongue-known-item-search.","url":"https://huggingface.co/datasets/webis/tip-of-my-tongue-known-item-search","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Telugu"],"keywords_longer_than_N":true},
	{"name":"LLMs-First-Task","keyword":"retrieval","description":"\nSuper easy task for humans  that All SOTA LLM fail to retrieve the correct answer from context. Including SOTA models: GPT5, Grok4, DeepSeek, Gemini 2.5PRO, Mistral, Llama4...etc \n\nICML 2025 Long-Context Foundation Models Workshop Accepted.(https://arxiv.org/abs/2506.08184)\nUpdate: This dataset is integrated into Moonshot AI(Kimi)'s internal benchmarking framework for assessing ** tracking capacity and context interference in LLM/agents**.\nUpdate:Sept.6-mergerd into Moonshot/Kimi AI's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/giantfish-fly/LLMs-First-Task.","url":"https://huggingface.co/datasets/giantfish-fly/LLMs-First-Task","creator_name":"c.p. wang","creator_url":"https://huggingface.co/giantfish-fly","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CAPP-17-01-2025","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tFrench Court of Appeal Decisions Dataset (CAPP)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe French Court of Appeal Decisions Dataset (CAPP) is a comprehensive collection of judicial decisions from French Courts of Appeal. This dataset contains appellate court decisions from various jurisdictions throughout France, providing a valuable resource for legal research, analysis, and machine learning applications in the French legal domain.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nThe data is sourced from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CAPP-17-01-2025.","url":"https://huggingface.co/datasets/La-Mousse/CAPP-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","document-retrieval","document-question-answering","French"],"keywords_longer_than_N":true},
	{"name":"pi-llm-bench","keyword":"retrieval","description":"\n\n\t\n\t\t\n\t\tPI-LLM Bench: The Core Retrieval Challenge Behind MRCR\n\t\n\nICML 2025 Long-Context Foundation Models Workshop Accepted.\nA simple context interference evaluation.\n\nAdoption (Aug 31, 2025): This dataset is integrated into a top-5 open-weight model company‚Äôs internal benchmarking framework for assessing ** tracking capacity and context interference in agents**.\nUpdate:Sept.6-mergerd into Moonshot/Kimi AI's internal eval tools and under review by a leading properiety model's eval team‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cog2ai/pi-llm-bench.","url":"https://huggingface.co/datasets/Cog2ai/pi-llm-bench","creator_name":"Cog2 AI","creator_url":"https://huggingface.co/Cog2ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"proofwikiqa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tProofWiki Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the ProofWiki dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/proofwikiqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"proofwikiqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tProofWiki Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the ProofWiki dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/proofwikiqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"proofwikiqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tProofWiki Question-Answer Retrieval Dataset\n\t\n\nWe use the theorems from the test set of the ProofWiki dataset in NaturalProofs as queries, and include all proofs from the dataset as the corpus.\n","url":"https://huggingface.co/datasets/hcju/proofwikiqa","creator_name":"Haocheng Ju","creator_url":"https://huggingface.co/hcju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","proofwiki","English"],"keywords_longer_than_N":true},
	{"name":"Material_Selection_Eval","keyword":"text-retrieval","description":"A benchmark designed to facilitate evaluation and modify the behavior of a foundation model through different existing techniques in the context of material selection for conceptual design.\nThe data is collected by conducting a survey of experts in the field of material selection. The same questions mentioned in keyquestions.csv are asked to experts.\nThis can be used to evaluate a Language model performance and its spread compared to a human evaluation.\nTo get into a more detailed explanation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmudrc/Material_Selection_Eval.","url":"https://huggingface.co/datasets/cmudrc/Material_Selection_Eval","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","text-retrieval","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"code-travail","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du travail, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"ragkeep-deutsche-klassik-books-de","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tragkeep-weimarer-klassik-books-de\n\t\n\nReleased subset of Weimarer Klassik books curated in ragkeep and prepared by ragprep.\n\n\t\n\t\t\n\t\tContents (HF subset)\n\t\n\n\nReleased Markdown: books/**/results/_released.md\nHTML rendering: books/**/results/html/<bookname>.html\nTOC JSON: books/**/results/toc.json\nProvenance & corrections: book-manifest.yaml, errata.txt\n\n<bookname> = canonical folder basename Author#Title#Index.\n\n\t\n\t\t\n\t\tLoading\n\t\n\nfrom datasets import load_dataset\n\nmd =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lafisrap/ragkeep-deutsche-klassik-books-de.","url":"https://huggingface.co/datasets/Lafisrap/ragkeep-deutsche-klassik-books-de","creator_name":"Michael Schmidt","creator_url":"https://huggingface.co/Lafisrap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"OGC_colpali-VisRAG-vdr","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tWIP - there might be issues with the negatives\n\t\n\n\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n700,000+\n\n\nRows with negatives\n‚âà 33%\n\n\nRows without queries (image negatives only)\n‚âà 25%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr.","url":"https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"code-organisation-judiciaire","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode de l'organisation judiciaire, non-instruct (2025-05-31)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"OGC_colpali-VisRAG-vdr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tWIP - there might be issues with the negatives\n\t\n\n\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n700,000+\n\n\nRows with negatives\n‚âà 33%\n\n\nRows without queries (image negatives only)\n‚âà 25%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr.","url":"https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_8b","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 500,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-8B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 500,000 samples with embeddings\nQuery‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_8b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_8b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_8b","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 500,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-8B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 500,000 samples with embeddings\nQuery‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_8b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_8b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"OGC_Hydrogen","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tHydrogen Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Hydrogen.","url":"https://huggingface.co/datasets/racineai/OGC_Hydrogen","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Telugu"],"keywords_longer_than_N":true},
	{"name":"Item-Info","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAL-GR/Item-Info: Anonymized Item Titles\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets\nCode: https://github.com/selous123/al_sid\nProject Page: https://huggingface.co/AL-GR\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository, AL-GR/Item-Info, is a companion dataset to the AL-GR generative recommendation ecosystem. It provides a crucial mapping from the abstract item identifiers (base62_string) to their corresponding anonymized text titles.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-Info.","url":"https://huggingface.co/datasets/AL-GR/Item-Info","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","English","apache-2.0","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"OGC_Hydrogen","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tHydrogen Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Hydrogen.","url":"https://huggingface.co/datasets/racineai/OGC_Hydrogen","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Telugu"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Telugu"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"text-retrieval","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"document-retrieval","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"text-retrieval","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Philosophical-STS-Text-Pairs","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tPhilosophical-STS-Text-Pairs\n\t\n\n\n\t\n\t\t\n\t\tGemma 3 Generated Synthetic Text Pairs for Embedding Pre-training\n\t\n\nThis project introduces SEP-STS-Text-Pairs, a synthetic dataset specifically designed for pre-training and fine-tuning embedding models on Semantic Textual Similarity (STS) tasks. The core of the effort involves a Python script that leverages the Gemma 3 12b generative AI model to create high-quality, diverse pairs of texts along with numerical similarity scores.\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/johnnyboycurtis/Philosophical-STS-Text-Pairs.","url":"https://huggingface.co/datasets/johnnyboycurtis/Philosophical-STS-Text-Pairs","creator_name":"Jonathan","creator_url":"https://huggingface.co/johnnyboycurtis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-ranking","text-retrieval","llm_generated","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"AL-GR","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAL-GR: A Large-scale Generative Recommendation Dataset\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial DatasetsCode: https://github.com/selous123/al_sidProject Page: https://huggingface.co/datasets/AL-GR\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAL-GR is a large-scale dataset designed for generative recommendation tasks using Large Language Models (LLMs). The core idea is to transform user historical behavior sequences into natural language prompts, enabling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/AL-GR.","url":"https://huggingface.co/datasets/AL-GR/AL-GR","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","feature-extraction","image-feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bhojpuri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"vietnamese-medical-dataset","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVietnamese Medical Dataset\n\t\n\n\nA lightweight dataset of (anchor, positive, negative) triplets for training Vietnamese medical text embeddings.\nAnchors are short section headers, positives are answer snippets from the same article, and negatives are semantically related snippets from other articles in the same category (semi-hard negatives).\n\n\n\t\n\t\t\n\t\tTL;DR\n\t\n\n\nLanguage: Vietnamese\nDomain: Healthcare / Patient education\nFormat: JSON\nUse cases: Contrastive learning (TripletLoss /‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mtue29/vietnamese-medical-dataset.","url":"https://huggingface.co/datasets/mtue29/vietnamese-medical-dataset","creator_name":"Phan Vo Minh Tue","creator_url":"https://huggingface.co/mtue29","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Vietnamese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoMSMARCO.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoMSMARCO-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoMSMARCO","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoMSMARCO.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoMSMARCO-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoMSMARCO","French"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCO-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoMSMARCO.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoMSMARCO-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoMSMARCO","French"],"keywords_longer_than_N":true},
	{"name":"eg-legal-rag","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal RAG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetrieval-augmented generation optimized dataset with summaries, keywords, and cross-references for building legal search systems.\nThis dataset contains 1,046 examples of rag data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-rag.","url":"https://huggingface.co/datasets/fr3on/eg-legal-rag","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"MultiLongDocRetrieval","keyword":"text-retrieval","description":"\n  MultiLongDocRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMulti Long Doc Retrieval (MLDR) 'is curated by the multilingual articles from Wikipedia, Wudao and mC4 (see Table 7), and NarrativeQA (KocÀáisky ÃÅ et al., 2018; Gu Ãànther et al., 2023), which is only for English.' (Chen et al., 2024).\n        It is constructed by sampling lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MultiLongDocRetrieval.","url":"https://huggingface.co/datasets/mteb/MultiLongDocRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","LM-generated","multilingual","Shitao/MLDR","Arabic"],"keywords_longer_than_N":true},
	{"name":"eg-legal-rag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal RAG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetrieval-augmented generation optimized dataset with summaries, keywords, and cross-references for building legal search systems.\nThis dataset contains 1,046 examples of rag data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-rag.","url":"https://huggingface.co/datasets/fr3on/eg-legal-rag","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"MATH_NuminaMath_allquerytypes","keyword":"retrieval","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_NuminaMath_allquerytypes","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Magahi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Awadhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Awadhi"],"keywords_longer_than_N":true},
	{"name":"BIRCO-WTB-Test","keyword":"document-retrieval","description":"\n  BIRCO-WTB\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the WhatsThatBook dataset from BIRCO. This dataset contains 100 queries where each query is an ambiguous description of a book. Each query has a candidate pool of 50 book descriptions. The objective is to retrieve the correct book description.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-WTB-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-WTB-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-WTB-Test","keyword":"text-retrieval","description":"\n  BIRCO-WTB\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the WhatsThatBook dataset from BIRCO. This dataset contains 100 queries where each query is an ambiguous description of a book. Each query has a candidate pool of 50 book descriptions. The objective is to retrieve the correct book description.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-WTB-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-WTB-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"GermanGovServiceRetrieval","keyword":"text-retrieval","description":"\n  GermanGovServiceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLHM-Dienstleistungen-QA is a German question answering dataset for government services of the Munich city administration. It associates questions with a textual context containing the answer\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval.","url":"https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hne","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hne","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Chhattisgarhi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"ppt4web","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for PPT4Web Educational Materials\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata and original files for 182,405 educational presentations from the ppt4web.ru platform, which provides online viewing and downloading of PowerPoint presentations. The dataset includes information such as presentation titles, URLs, download URLs, and file paths.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with some presentations in other languages such as English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ppt4web.","url":"https://huggingface.co/datasets/nyuuzyou/ppt4web","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"dotnet-runtime","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\t.NET Runtime Fine-Tuning Data and Index\n\t\n\nThis directory contains data for fine-tuning models and building RAGs for the dotnet/runtime repository.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\ndata/: Contains all datasets and indexes.\nraw/sample/: Sample PRs and diffs collected from GitHub.\nraw_data.tar: Archive of collected PRs and diffs from GitHub.\nsamples/: Json files with processed samples suitable for dataset generation.\nprocessed/: Parquet files for fine-tuning (e.g., train.parquet, test.parquet).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kotlarmilos/dotnet-runtime.","url":"https://huggingface.co/datasets/kotlarmilos/dotnet-runtime","creator_name":"Milos Kotlar","creator_url":"https://huggingface.co/kotlarmilos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","machine-generated","human-verified","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-from-text-matching-long-tasks-danish","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tThanks to Arrow Denmark and Nvidia for sponsoring the compute used to generate this dataset\n\t\n\nThe purpose of this dataset is to pre- or post-train embedding models for Danish text matching tasks. \nThe dataset consists of 100,000 samples generated with gemma-2-27b-it. \nThe column \"prompt\" shows the prompt given to the LLM and \"response\" shows the LLM output. \nEach sample in the dataset was generated from a seed task randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThatsGroes/synthetic-from-text-matching-long-tasks-danish.","url":"https://huggingface.co/datasets/ThatsGroes/synthetic-from-text-matching-long-tasks-danish","creator_name":"Kasper Groes Albin Ludvigsen","creator_url":"https://huggingface.co/ThatsGroes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Danish","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"attackqa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tAttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs\n\t\n\n\n\n\t\n\t\t\n\t\tlicense: apache-2.0\n\t\n\nThis dataset is derived from the MITRE ATT&CK¬Æ knowledge base that bears the following license:\n¬© 2025 The MITRE Corporation. This work is reproduced and distributed with the permission of The MITRE Corporation.\nIn using the dataset, please consider citing the following paper:\nmisc{c:attackqa,\n      title={AttackQA: Development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/attackqa.","url":"https://huggingface.co/datasets/sambanovasystems/attackqa","creator_name":"SambaNova","creator_url":"https://huggingface.co/sambanovasystems","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","text-retrieval","text-ranking","English"],"keywords_longer_than_N":true},
	{"name":"PMC-Clinical","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tR2MED: First Reasoning-Driven Medical Retrieval Benchmark\n\t\n\n R2MED is a high-quality, high-resolution synthetic information retrieval (IR) dataset designed for medical scenarios. It contains 876 queries with three retrieval tasks, five medical scenarios, and twelve body systems.\n\n\t\n\t\t\nDataset\n#Q\n#D\nAvg. Pos\nQ-Len\nD-Len\n\n\n\t\t\nBiology\n103\n57359\n3.6\n115.2\n83.6\n\n\nBioinformatics77\n47473\n2.9\n273.8\n150.5\n\n\nMedical Sciences\n88\n34810\n2.8\n107.1\n122.7\n\n\nMedXpertQA-Exam\n97‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R2MED/PMC-Clinical.","url":"https://huggingface.co/datasets/R2MED/PMC-Clinical","creator_name":"A Benchmark for Reasoning-Driven Medical Retrieval","creator_url":"https://huggingface.co/R2MED","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Oriya"],"keywords_longer_than_N":true},
	{"name":"code-service-national","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tCode du service national, non-instruct (2025-07-11)\n\t\n\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national.","url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","text-retrieval","question-answering"],"keywords_longer_than_N":true},
	{"name":"LegalQuAD","keyword":"text-retrieval","description":"\n  LegalQuAD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of questions and legal documents in German.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/Christoph911/AIKE2021_Appendix\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LegalQuAD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalQuAD.","url":"https://huggingface.co/datasets/mteb/LegalQuAD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kashmiri"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_4b","keyword":"retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-4B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_4b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_4b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-ClinicalTrial-Test","keyword":"document-retrieval","description":"\n  BIRCO-ClinicalTrial\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the Clinical-Trial dataset from BIRCO. This dataset contains 50 queries that are patient case reports. Each query has a candidate pool comprising 30-110 clinical trial descriptions. Relevance is graded (0, 1, 2), where 1 and 2 are considered relevant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_pa","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Panjabi"],"keywords_longer_than_N":true},
	{"name":"RAVine-dense-index","keyword":"information-retrieval","description":"\n\t\n\t\t\n\t\tRAVine-dense-index\n\t\n\nThis repository contains dense index files for the search tools of the RAVine: Reality-Aligned Evaluation for Agentic Search framework. The corpus is MS MARCO V2.1, encoded using Alibaba-NLP/gte-modernbert-base.\nPaper: RAVine: Reality-Aligned Evaluation for Agentic Search\nCode: https://github.com/SwordFaith/RAVine\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nAgentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is driving the evolution of intelligent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-dense-index.","url":"https://huggingface.co/datasets/sapphirex/RAVine-dense-index","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","arxiv:2507.16725","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"BIRCO-ClinicalTrial-Test","keyword":"text-retrieval","description":"\n  BIRCO-ClinicalTrial\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the Clinical-Trial dataset from BIRCO. This dataset contains 50 queries that are patient case reports. Each query has a candidate pool comprising 30-110 clinical trial descriptions. Relevance is graded (0, 1, 2), where 1 and 2 are considered relevant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test.","url":"https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_pa","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Panjabi"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_4b","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-4B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_4b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_4b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna-fr","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoArguAna.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoArguAna-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoArguAna","French"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"fact-checking","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"fact-checking-retrieval","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"discursos-senado-legislatura-56","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDiscursos da 56¬™ Legislatura do Senado Federal\n\t\n\n\n\t\n\t\t\n\t\tVis√£o geral\n\t\n\nCorpus de pronunciamentos do Plen√°rio do Senado Federal durante a 56¬™ Legislatura (2019‚Äì2022), coletados via API p√∫blica e consolidados em Parquet. Cada linha √© um pronunciamento com metadados e texto integral quando dispon√≠vel.\n\n\t\n\t\t\n\t\tDetalhes do dataset\n\t\n\n\n\t\n\t\t\n\t\tDescri√ß√£o\n\t\n\n\nPeriodo: 2019-02-01 a 2023-01-01\n\nUnidade: pronunciamento no Plen√°rio do Senado\n\nFormato: Parquet (colunar, comprimido)  \n\nCampos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56.","url":"https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56","creator_name":"Fabricio Fernandes Santana","creator_url":"https://huggingface.co/fabriciosantana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","summarization","text-retrieval","text-generation"],"keywords_longer_than_N":true},
	{"name":"TinyStories-MRL","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDataset Card for ReactiveAI/TinyStories-MRL\n\t\n\nSynthetic Memory Reinforcement Learning dataset for Proof-of-Concept Reactive Transformer models.\nDataset is divided into subsets, used in different Curriculum Stage of MRL training - each subset have\ndifferent number of follow-up interactions, could use different strategy, and have train and validation\nsplits.\n\nAfter first experiments with MRL, we decided to abandon single step and two steps stages. That's because with single\nstep‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReactiveAI/TinyStories-MRL.","url":"https://huggingface.co/datasets/ReactiveAI/TinyStories-MRL","creator_name":"Reactive AI","creator_url":"https://huggingface.co/ReactiveAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","question-answering","text-generation","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoArguAna.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoArguAna-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoArguAna","French"],"keywords_longer_than_N":true},
	{"name":"NanoArguAna-fr","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nFrench translation of zeta-alpha-ai/NanoArguAna.\n","url":"https://huggingface.co/datasets/CATIE-AQ/NanoArguAna-fr","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","zeta-alpha-ai/NanoArguAna","French"],"keywords_longer_than_N":true},
	{"name":"Microsoft_Learn","keyword":"text-retrieval","description":"PetraAI/Microsoft_Learn dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PetraAI/Microsoft_Learn","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","fill-mask","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"text-retrieval","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"WebVid-CoVR","keyword":"retrieval","description":"arxiv.org/abs/2308.14746\n","url":"https://huggingface.co/datasets/lucas-ventura/WebVid-CoVR","creator_name":"Lucas","creator_url":"https://huggingface.co/lucas-ventura","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1M - 10M","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"DXYConsultRetrieval","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tüî≠ Overview\n\t\n\n\n\t\n\t\t\n\t\tCMIRB: Chinese Medical Information Retrieval Benchmark\n\t\n\n CMIRB is a specialized multi-task dataset designed specifically for medical information retrieval. It consists of data collected from various medical online websites, encompassing 5 tasks and 10 datasets, and has practical application scenarios.\n\n\t\n\t\t\nName\nDescription\nQuery #Samples\nDoc #Samples\n\n\n\t\t\nMedExamRetrieval\nMedical multi-choice exam\n697\n27,871\n\n\nDuBaikeRetrieval\nMedical search query from BaiDu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMIRB/DXYConsultRetrieval.","url":"https://huggingface.co/datasets/CMIRB/DXYConsultRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"document-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true},
	{"name":"xCodeEval","keyword":"text-retrieval","description":"The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', i.e., being able to get the same output for a given input.","url":"https://huggingface.co/datasets/NTU-NLP-sg/xCodeEval","creator_name":"NLP Group of Nanyang Technological University","creator_url":"https://huggingface.co/NTU-NLP-sg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","token-classification","text-retrieval","text-generation","text-classification"],"keywords_longer_than_N":true},
	{"name":"dd-indexes","keyword":"text-retrieval","description":"\n\t\n\t\t\n\t\t‚ö° Pre-computed Search Indexes for Due Diligence\n\t\n\nHigh-performance search indexes and ML artifacts for AI-powered due diligence analysis\nThis repository contains pre-computed search indexes, embeddings, and knowledge graphs that power fast document retrieval and analysis. Skip the expensive embedding computation and start searching immediately!\n\n\t\n\t\t\n\t\tüéØ What's Included\n\t\n\n\n\t\n\t\t\n\t\tüîç FAISS Vector Indexes (4 indexes, 20.2MB)\n\t\n\nHigh-performance similarity search with sub-second query‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jmzlx/dd-indexes.","url":"https://huggingface.co/datasets/jmzlx/dd-indexes","creator_name":"Juan Salas","creator_url":"https://huggingface.co/jmzlx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-question-answering","text-classification","feature-extraction","English"],"keywords_longer_than_N":true}
]
;
