const data_for_modality_search = 
[
	{"name":"msmarco-10k","keyword":"search","description":"\n\t\n\t\t\n\t\tA 10K docs sample from MS MARCO\n\t\n\nThis is a sample dataset of random 10K rows from the MS MARCO dataset. This is used in Nixiesearch quickstart guide to save some time indexing a full MSMARCO with 8M documents.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nThis is a JSONL-formatted dataset with only two fields inside: id for document identifier and text for the actual text snippet.\n{\n  \"id\": \"0\",\n  \"text\": \"The presence of communication amid scientific minds was equally important to the success of the Manhattanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nixiesearch/msmarco-10k.","url":"https://huggingface.co/datasets/nixiesearch/msmarco-10k","creator_name":"Nixiesearch","creator_url":"https://huggingface.co/nixiesearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"code-search-net-ruby","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-ruby\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Ruby\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"synthetic-search-queries-ru","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Queries : Russian\n\t\n\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories for Russian language domain:\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous Integration/Continuousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru.","url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"synthetic-search-filters-ru-raw","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Filters Raw: Russian\n\t\n\nThis is the raw version of EmbeddingStudio/synthetic-search-filters-ru dataset for Russian language domain.\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\nArtificial Intelligence and Machine Learning, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environmentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw.","url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","Russian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"query-parsing-instructions-saiga","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Query Parsing Instruction for Saiga family\n\t\n\nThis is the version of EmbeddingStudio/synthetic-search-queries-ru dataset created the way to be aligned with Saiga-Mistral-7B instruction format.\n\n\t\n\t\t\n\t\tGeneration details\n\t\n\nWe used synthetically generated query parsing instructions:\n\nWe generated lists of possible filters for 72 company categories: \nRaw version of filters dataset\nSplit by representations\n\n\nSelect randomly up-to 150 possible combinations (1-3 filters inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga.","url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Embeddings__Ultimate_1Million_Movies_Dataset","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tDataset Card for Embedding Enriched The Ultimate 1Million Movies Dataset (TMDB + IMDb)\n\t\n\nThis dataset contains movie metadata from TMDB sourced from Kaggle, with an added layer of embeddings and token counts for semantic search and ML applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nA daily-updated snapshot taken in early 2025 of an existing movie metadata collection, sourced from TMDB Movies Dataset 2025 on Kaggle, enriched with 768-dimensionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Remsky/Embeddings__Ultimate_1Million_Movies_Dataset.","url":"https://huggingface.co/datasets/Remsky/Embeddings__Ultimate_1Million_Movies_Dataset","creator_name":"Jeremy Braun","creator_url":"https://huggingface.co/Remsky","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"modified-codesearchnet-code-summarization","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tModified CodeSearchNet (MCSN) Dataset\n\t\n\nThis dataset is a modification of the CodeSearchNet dataset from CodeXGLUE benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and repository contexts on summary quality.  The dataset includes modifications for evaluating at both function and repository levels.\nPaper: Code Summarization Beyond Function Level\nDataset Structure:\nThe dataset contains samples with the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization.","url":"https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"RAVine-logs","keyword":"search","description":"\n\t\n\t\t\n\t\tRAVine-logs\n\t\n\nThis repository contains the running logs of the experiments conducted in the paper RAVine: Reality-Aligned Evaluation for Agentic Search. These logs can be used for result reproduction or detailed case analysis of agentic LLMs with search performance.\nRAVine is a comprehensive evaluation system for agentic search, encompassing the web environment, benchmark datasets, and a novel evaluation method, serving as a full-process, reproducible, and goal-aligned evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-logs.","url":"https://huggingface.co/datasets/sapphirex/RAVine-logs","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","English","apache-2.0","arxiv:2507.16725","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ai-search-agent","keyword":"search","description":"\n\t\n\t\t\n\t\tAI Search Agent Agent Meta and Traffic Dataset in AI Agent Marketplace | AI Agent Directory | AI Agent Index from DeepNLP\n\t\n\nThis dataset is collected from AI Agent Marketplace Index and Directory at http://www.deepnlp.org, which contains AI Agents's meta information such as agent's name, website, description, as well as the monthly updated Web performance metrics, including Google,Bing average search ranking positions, Github Stars, Arxiv References, etc.\nThe dataset is helpful for AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeepNLP/ai-search-agent.","url":"https://huggingface.co/datasets/DeepNLP/ai-search-agent","creator_name":"DeepNLP","creator_url":"https://huggingface.co/DeepNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"amazon-esci-data","keyword":"search","description":"\n\t\n\t\t\n\t\tAmazon Shopping Queries Dataset\n\t\n\nDataset for improving product search, ranking and recommendations, featuring query-product pairs with detailed relevance labels.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe dataset contains search queries paired with up to 40 potentially relevant products, each labeled using the ESCI system:\n\nExact match: Products that perfectly match the customer's search intent (e.g., searching \"iPhone 13\" and finding \"Apple iPhone 13 128GB\")\nSubstitute product: Alternative productsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/milistu/amazon-esci-data.","url":"https://huggingface.co/datasets/milistu/amazon-esci-data","creator_name":"Milutin Studen","creator_url":"https://huggingface.co/milistu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","text-generation","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"askubuntu","keyword":"search","description":"\n\t\n\t\t\n\t\taskubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical Q&A search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"synthetic-search-filters-ru","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Filters\n\t\n\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories and for the Russian language domain:\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous Integration/Continuous Deployment, Creditâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru.","url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","Russian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-Doc-v1-Summaries","keyword":"search","description":"spacemanidol/MSMARCO-Doc-v1-Summaries dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/spacemanidol/MSMARCO-Doc-v1-Summaries","creator_name":"Daniel Campos","creator_url":"https://huggingface.co/spacemanidol","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-mpnet","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-mpnet-base-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"code-search-net-python","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-python\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nHomepage: None\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\nPaper: None\nLeaderboard: None\nPoint of Contact: @Nan-Do\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"langcache-sentencepairs-v1","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tRedis LangCache Sentence Pairs Dataset\n\t\n\n\n\nA large, consolidated collection of English sentence pairs for training and evaluating semantic similarity, retrieval, and re-ranking models. \nIt merges widely used benchmarks into a single schema with consistent fields and ready-made splits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nName: langcache-sentencepairs-v1\nSummary: Sentence-pair dataset created to fine-tune encoder-based embedding and re-ranking models. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/redis/langcache-sentencepairs-v1.","url":"https://huggingface.co/datasets/redis/langcache-sentencepairs-v1","creator_name":"Redis","creator_url":"https://huggingface.co/redis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","text-ranking","text-retrieval","English"],"keywords_longer_than_N":true},
	{"name":"gaia2","keyword":"search","description":"\n\t\n\t\t\n\t\tGaia2\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGaia2 is a benchmark dataset for evaluating AI agent capabilities in simulated environments. The dataset contains 800 scenarios that test agent performance in environments where time flows continuously and events occur dynamically.\nThe dataset evaluates seven core capabilities: Execution (multi-step planning and state changes), Search (information gathering and synthesis), Adaptability (dynamic response to environmentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meta-agents-research-environments/gaia2.","url":"https://huggingface.co/datasets/meta-agents-research-environments/gaia2","creator_name":"Meta Agents Research Environments","creator_url":"https://huggingface.co/meta-agents-research-environments","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","task-planning","dialogue-modeling","dialogue-generation","conversational"],"keywords_longer_than_N":true},
	{"name":"virginia-woolf-monologue-chunks","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tVirginia Woolf Monologue Chunks Dataset\n\t\n\nThis dataset contains 6 semantically chunked text segments derived from a contemporary monologue based on Virginia Woolf's seminal essay \"A Room of One's Own\" (1929). It comes pre-loaded with vector embeddings from three different models, making it a ready-to-use resource for a variety of NLP tasks.\nIn addition to the dataset itself, this repository includes a comprehensive embedding analysis, detailed statistics, and 7 visualizations to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks.","url":"https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks","creator_name":"The Pageman at Bettergov.ph","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-retrieval","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"query-parsing-instructions-falcon","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Query Parsing Instruction for Instruct Falcon family\n\t\n\nThis is the version of EmbeddingStudio/synthetic-search-queries dataset created the way to be aligned with Falcon-7B-Instruct instruction format.\n\n\t\n\t\t\n\t\tGeneration details\n\t\n\nWe used synthetically generated query parsing instructions:\n\nWe generated lists of possible filters for 63 customer categories: \nRaw version of filters dataset\nSplit by representations\n\n\nSelect randomly up-to 150 possible combinations (1-3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon.","url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"RAVine-mapper","keyword":"search","description":"\n\t\n\t\t\n\t\tRAVine-mapper\n\t\n\nThis repository contains the URL-to-document ID mapping files (RAVine-mapper), which are crucial for the implementation of the fetch tool within the RAVine: Reality-Aligned Evaluation for Agentic Search framework. This dataset is essential when utilizing RAVine for agentic search evaluations.\nRAVine (Reality-Aligned eValuation framework for agentic LLMs with search) is a comprehensive evaluation system designed for agentic search. It encompasses a web environmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-mapper.","url":"https://huggingface.co/datasets/sapphirex/RAVine-mapper","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","apache-2.0","arxiv:2507.16725","ðŸ‡ºðŸ‡¸ Region: US","agentic-llm"],"keywords_longer_than_N":true},
	{"name":"mlx7-two-tower-data","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tmlx7-two-tower-data\n\t\n\nThis repository contains datasets used for training Two-Tower (Dual Encoder) models for document retrieval.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe datasets provided here are structured for training dual encoder models with various sampling strategies:\n\nclassic_triplets: 48.2 MB\nintra_query_neg: 47.6 MB\nmulti_pos_multi_neg: 126.5 MB\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nclassic_triplets.parquet: Standard triplet format with (query, positive_document, negative_document)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data.","url":"https://huggingface.co/datasets/Azuremis/mlx7-two-tower-data","creator_name":"Azuremis","creator_url":"https://huggingface.co/Azuremis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"RAVine-qrels","keyword":"search","description":"\n\t\n\t\t\n\t\tRAVine-qrels\n\t\n\nThe qrels in this repo refer to the relevance labels in MS MARCO V2.1 corpus for the queries of the RAVine test set. We collected them from trec-2024-rag and converted them into jsonline formats.\nThis dataset is associated with the paper RAVine: Reality-Aligned Evaluation for Agentic Search.\nGithub: https://github.com/SwordFaith/RAVine\n\n\t\n\t\t\n\t\n\t\n\t\tRelated Datasets on Hugging Face\n\t\n\nThe RAVine project includes several other datasets available on Hugging Face:\n\nQueries &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-qrels.","url":"https://huggingface.co/datasets/sapphirex/RAVine-qrels","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"quora_swe","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tDataset Card for \"quora_swe\"\n\t\n\nThe dataset quora_swe is a subset of the automatically translated (MNT) Swedish Semantic Textual Similarity dataset: quora-deduplicates .\n","url":"https://huggingface.co/datasets/Gabriel/quora_swe","creator_name":"Gabriel Borg","creator_url":"https://huggingface.co/Gabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","semantic-similarity-classification","Swedish","mit"],"keywords_longer_than_N":true},
	{"name":"code-search-net-go","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-go\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Go\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the dataset asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"search-dataset","keyword":"search","description":"\n\t\n\t\t\n\t\tAI Search Providers Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Structure\n\t\n\nEach entry contains:\n\nid: Unique identifier for the QA pair\nquestion: The query text\nexpected_answer: The correct answer\ncategory: Topic category\narea: Broader area classification (News/Knowledge)\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Categories\n\t\n\nThe dataset covers various domains including:\n\nEntertainment\nSports\nTechnology\nGeneral News\nFinance\nArchitecture\nArts\nAstronomy\nAuto (Automotive)\nE-sports\nFashion\nFalse Premise\n\n\n\t\n\t\t\n\t\tðŸ“ˆâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junzhang1207/search-dataset.","url":"https://huggingface.co/datasets/junzhang1207/search-dataset","creator_name":"John","creator_url":"https://huggingface.co/junzhang1207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"synthetic-search-queries","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Queries\n\t\n\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories:\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores (Onlineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries.","url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"browsecomp-plus-corpus","keyword":"search","description":"\n\t\n\t\t\n\t\tBrowseComp-Plus\n\t\n\nProject Page | Paper | Code\nBrowseComp-Plus is a new benchmark for Deep-Research system, isolating the effect of the retriever and the LLM agent to enable fair, transparent comparisons of Deep-Research agents. The benchmark sources challenging, reasoning-intensive queries from OpenAI's BrowseComp. However, instead of searching the live web, BrowseComp-Plus evaluates against a fixed, curated corpus of ~100K web documents from the web. The corpus includes bothâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tevatron/browsecomp-plus-corpus.","url":"https://huggingface.co/datasets/Tevatron/browsecomp-plus-corpus","creator_name":"Tevatron","creator_url":"https://huggingface.co/Tevatron","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-653452","keyword":"search","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-653452 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-653452 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AmazonQAC","keyword":"search","description":"\n\t\n\t\t\n\t\tAmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset\n\t\n\nTrain Dataset Size: 395 million samplesTest Dataset Size: 20k samplesSource: Amazon Search LogsFile Format: ParquetCompression: Snappy\nIf you use this dataset, please cite our EMNLP 2024 paper:\n@inproceedings{everaert-etal-2024-amazonqac,\n    title = \"{A}mazon{QAC}: A Large-Scale, Naturalistic Query Autocomplete Dataset\",\n    author = \"Everaert, Dante  and\n      Patki, Rohit  and\n      Zheng, Tianqi  and\n      Pottsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amazon/AmazonQAC.","url":"https://huggingface.co/datasets/amazon/AmazonQAC","creator_name":"Amazon","creator_url":"https://huggingface.co/amazon","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-retrieval","English","cdla-permissive-2.0"],"keywords_longer_than_N":true},
	{"name":"local-emoji-search-gte","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tlocal emoji semantic search\n\t\n\nEmoji, their text descriptions and precomputed text embeddings with Alibaba-NLP/gte-large-en-v1.5 for use in emoji semantic search. \nThis work is largely inspired by the original emoji-semantic-search repo and aims to provide the data for fully local use, as the demo is not working as of a few days ago.\n\nThis repo only contains a precomputed embedding \"database\", equivalent to server/emoji-embeddings.jsonl.gz in the original repo, to be used as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/local-emoji-search-gte.","url":"https://huggingface.co/datasets/pszemraj/local-emoji-search-gte","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"code-search-net-javascript","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-javascript\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in JavaScript\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"code-search-net-php","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-php\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Php\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"code-search-net-java","keyword":"codesearchnet","description":"\n\t\n\t\t\n\t\tDataset Card for \"code-search-net-java\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset's comments are in English and the functions are coded in Java\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nTrain, test, validation labels are included in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java.","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-minilm","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-MiniLM-L6-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"italian-embedding-finetune-dataset","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tItalian-BERT-FineTuning-Embeddings\n\t\n\nThis repository contains a comprehensive dataset designed for fine-tuning BERT-based Italian embedding models. The dataset aims to enhance performance on tasks such as information retrieval, semantic search, and embeddings generation.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset leverages the C4 dataset (Italian subset) and employs advanced techniques like sliding window segmentation and in-document sampling to create high-quality, diverse examplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset.","url":"https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset","creator_name":"Archit Rastogi","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Italian","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-221689","keyword":"search","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-221689 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-221689 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-548936","keyword":"search","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-548936 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-548936 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"swift-mlx-Qwen3-Embedding-4B","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tðŸ” VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B - Embeddings Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nCe dataset contient des embeddings vectoriels gÃ©nÃ©rÃ©s par le systÃ¨me LocalRAG pour la recherche sÃ©mantique dans la documentation technique.\n\n\t\n\t\t\n\t\tðŸ“Š Statistiques\n\t\n\n\nFormat: SafeTensors\nVecteurs: 7,511\nDimension: 2560\nModÃ¨le d'embedding: Qwen/Qwen3-Embedding-4B\nType d'index: HNSW\nGÃ©nÃ©rÃ© le: 2025-08-22T14:04:16.932676\n\n\n\t\n\t\t\n\t\tðŸ“ Contenu\n\t\n\n\nembeddings.safetensors: Embeddings vectoriels auâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B.","url":"https://huggingface.co/datasets/VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B","creator_name":"GOURBIN","creator_url":"https://huggingface.co/VincentGOURBIN","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","embeddings","faiss","rag"],"keywords_longer_than_N":true},
	{"name":"synthetic-search-filters","keyword":"search-queries","description":"\n\t\n\t\t\n\t\tSynthetic Search Filters\n\t\n\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores (Online and Offline)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters.","url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"norwegian-nli-triplets-c","keyword":"search","description":"\n\t\n\t\t\n\t\tnorwegian-nli-triplets-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Keyword-based search engine for documents\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the norwegian-nli-triplets-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c.","url":"https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RAVine-dense-index","keyword":"search","description":"\n\t\n\t\t\n\t\tRAVine-dense-index\n\t\n\nThis repository contains dense index files for the search tools of the RAVine: Reality-Aligned Evaluation for Agentic Search framework. The corpus is MS MARCO V2.1, encoded using Alibaba-NLP/gte-modernbert-base.\nPaper: RAVine: Reality-Aligned Evaluation for Agentic Search\nCode: https://github.com/SwordFaith/RAVine\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nAgentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is driving the evolution of intelligentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-dense-index.","url":"https://huggingface.co/datasets/sapphirex/RAVine-dense-index","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","arxiv:2507.16725","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"query-expansion","keyword":"semantic-search","description":"\n\t\n\t\t\n\t\tQuery Expansion Dataset\n\t\n\nThis dataset is designed to train search query expansion models that can generate multiple semantic expansions for a given query.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThe goal of this dataset is to serve as input for training small language models (0.5B to 3B parameters) to act as query expander models in various search systems, including but not limited to Retrieval-Augmented Generation (RAG) systems.\nQuery expansion is a technique used to enhance search results by generatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/s-emanuilov/query-expansion.","url":"https://huggingface.co/datasets/s-emanuilov/query-expansion","creator_name":"Simeon Emanuilov","creator_url":"https://huggingface.co/s-emanuilov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true}
]
;
