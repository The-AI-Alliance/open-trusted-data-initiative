const data_for_modality_rag = 
[
	{"name":"germanrag","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGermanRAG üá©üá™üìúü¶ú\\n\\t\\n\\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\\nIn contrast to the original dataset the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag."},
	{"name":"germanrag","keyword":"retrieval-augmented-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGermanRAG üá©üá™üìúü¶ú\\n\\t\\n\\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\\nIn contrast to the original dataset the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag."},
	{"name":"BaldursGate3-Evaluation-Dataset","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stucksam/BaldursGate3-Evaluation-Dataset","creator_name":"Samuel","creator_url":"https://huggingface.co/stucksam","description":"stucksam/BaldursGate3-Evaluation-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"invoices-example","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parsee-ai/invoices-example","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInoices Sample Dataset\\n\\t\\n\\nThis is a sample dataset generated on app.parsee.ai for invoices. The goal was to evaluate different LLMs on this RAG task using the Parsee evaluation tools. A full study can be found here: https://github.com/parsee-ai/parsee-datasets/blob/main/datasets/invoices/parsee-loader/README.md\\nparsee-core version used: 0.1.3.11\\nThis dataset was created on the basis of 15 sample invoices (PDF files).\\nAll PDF files are publicly accessible on parsee.ai, to access‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/invoices-example."},
	{"name":"revenues-example","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parsee-ai/revenues-example","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRevenues Sample Dataset\\n\\t\\n\\nparsee-core version used: 0.1.3.14\\nThis dataset was created on the basis of 15 pages from annual/quarterly filings of major German stock-exchange listed companies (PDF files).\\nAll PDF files are publicly accessible on parsee.ai, to access them copy the \\\"source_identifier\\\" (first column) and paste it in this URL (replace '{SOURCE_IDENTIFIER}' with the actual identifier):\\nhttps://app.parsee.ai/documents/view/{SOURCE_IDENTIFIER}\\nSo for example:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/revenues-example."},
	{"name":"neural-bridge-rag-dataset-12000-google-translated","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated","creator_name":"pandora","creator_url":"https://huggingface.co/pandora-s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is a repository where I will slowly translate neural-bridge/rag-dataset-12000 into different languages with Google Translate.As RAG datasets are quite scarce, I felt that this could be useful for many who seek to add RAG capabilities to their models!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow?\\n\\t\\n\\nThere are no secrets; these are raw translations that might not be 100% reliable. I literally run the entire dataset through Google Translate overnight.I'm prioritizing \\\"quantity\\\" over \\\"quality\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated."},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"AI framework for improving LLM responses\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp."},
	{"name":"hotpotqa_sample_autorag","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gnekt/hotpotqa_sample_autorag","creator_name":"Christian Di Maio","creator_url":"https://huggingface.co/gnekt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tATTENTION\\n\\t\\n\\nUtilizing the full dataset corpus and associated questions with pay-for-use Large Language Models (LLMs) can result in substantial costs.\\n"},
	{"name":"hotpotqa_small_sample_autorag","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gnekt/hotpotqa_small_sample_autorag","creator_name":"Christian Di Maio","creator_url":"https://huggingface.co/gnekt","description":"gnekt/hotpotqa_small_sample_autorag dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"grouse","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/illuin/grouse","creator_name":"Illuin Technology","creator_url":"https://huggingface.co/illuin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GroUSE\\n\\t\\n\\nGroUSE (Grounded QA Unitary Scoring of Evaluators) is a dataset designed to assess the performance of Grounded QA evaluators. Its purpose is to evaluate whether an LLM, when used as a grounded QA evaluator, delivers the expected scores across six metrics when presented with both good and imperfect answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach sample is of the following form :\\n{\\n    \\\"references\\\": [\\n        \\\"[Content of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/illuin/grouse."},
	{"name":"German-RAG-SFT-Alpaca-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-SFT-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-SFT (Supervised Fine-Tuning) Alpaca-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe SFT Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-SFT-Alpaca-HESSIAN-AI."},
	{"name":"German-RAG-SFT-ShareGPT-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-SFT-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-SFT (Supervised Fine-Tuning) Share-GPT Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe SFT Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-SFT-ShareGPT-HESSIAN-AI."},
	{"name":"SFinD-S","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tilmann-strative/SFinD-S","creator_name":"Tilmann Bruckhaus","creator_url":"https://huggingface.co/tilmann-strative","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis sample is part of the larger SFinD-S (Strative Financial Dataset - Synthetic), a comprehensive dataset designed for Retrieval-Augmented Generation (RAG) GenAI applications, Natural Language Processing (NLP), Large Language Models (LLM), and AI tasks in the financial domain. The full SFinD-S dataset contains over 20,000 records of realistic financial questions and verified answers, sourced from a wide variety of web content.\\nIf you find this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tilmann-strative/SFinD-S."},
	{"name":"German-RAG-DPO-Alpaca-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-DPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-DPO Alpaca Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge graph where Question-Answer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-DPO-Alpaca-HESSIAN-AI."},
	{"name":"German-RAG-DPO-ShareGPT-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-DPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-DPO Share-GPT Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge graph where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-DPO-ShareGPT-HESSIAN-AI."},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets can be for this training step are derived from 2 different sources:\\n\\nSauerkrautLM Preference Datasets:\\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI."},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Version of The Finanical Rag Embedding Dataset\\n\\t\\n\\n\\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \\nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\\nThis dataset is the Arabic version of the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset."},
	{"name":"EvalRAGData","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AITeamVN/EvalRAGData","creator_name":"VietNamAI","creator_url":"https://huggingface.co/AITeamVN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card: Vietnamese RAG Benchmark\\n\\t\\n\\nM√¥ t·∫£ d·ªØ li·ªáu:\\nEvalRAGData l√† m·ªôt t·∫≠p d·ªØ li·ªáu g·ªìm 120 samples ƒë∆∞·ª£c t·∫°o th·ªß c√¥ng b·ªüi con ng∆∞·ªùi ƒë·ªÉ ƒë√°nh gi√° LLM cho kh·∫£ nƒÉng tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh (RAG). \\nT·∫≠p d·ªØ li·ªáu n√†y ƒë√°ng gi√° 3 kh·∫£ nƒÉng c·ªßa LLM:\\n\\nKh·∫£ nƒÉng ch·ªëng nhi·ªÅu: M√¥ h√¨nh tr√≠ch xu·∫•t th√¥ng tin h·ªØu √≠ch t·ª´ c√°c t√†i li·ªáu nhi·ªÖu. ( 1 positive + 4 negative ho·∫∑c 1 positive)\\nLo·∫°i b·ªè negative: M√¥ h√¨nh t·ª´ ch·ªëi tr·∫£ l·ªùi c√¢u h·ªèi khi ki·∫øn th·ª©c c·∫ßn thi·∫øt kh√¥ng c√≥ trong b·∫•t k·ª≥ t√†i li·ªáu n√†o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AITeamVN/EvalRAGData."},
	{"name":"Vietnamese-Function-Calling-Test","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test","creator_name":"phamhai","creator_url":"https://huggingface.co/phamhai","description":"Vietnamese Function Calling Benchmark\\n\\nRAG applications for Vietnamese chatbot systems are becoming increasingly popular. Many LLM models already support FC for Vietnamese, but there is no common and comprehensive benchmark yet. Today, I am releasing a benchmark for the Vietnamese Function Calling task. I hope this will serve as a standard for product teams to choose models in a reasonable and appropriate way.\\nDataset Details:\\n\\n\\nData size: 2899 single-turn funcation calling samples\\nDomains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test."},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI."},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-LLM-EASY-BENCHMARK\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\\nMost of the Subsets are synthetically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK."},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI."},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-LLM-HARD Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\\nThe subsets are derived from Synthetic generation inspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK."},
	{"name":"raghalu-open","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liveperson/raghalu-open","creator_name":"LivePerson Inc.","creator_url":"https://huggingface.co/liveperson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAGHalu Open Source Data\\n\\t\\n\\nThis dataset is the public data portion from the paper Two-tiered\\nEncoder-based Hallucination Detection for Retrieval-Augmented Generation\\nin the Wild by Ilana Zimmerman, Jadin Tredup, Ethan Selfridge, and\\nJoseph Bradley, accepted at EMNLP 2024\\n(Industry Track). The private brand data portion of the dataset is not\\nincluded.\\nNote that this dataset and the paper do not use the common hallucination\\nterms factuality and faithfulness as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liveperson/raghalu-open."},
	{"name":"Finance-Instruct-500k","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","description":"\\n\\t\\n\\t\\t\\n\\t\\tFinance-Instruct-500k Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\\nThe dataset includes content tailored for financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k."},
	{"name":"tldr","keyword":"retrieval augmented generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"rag-dataset-1200","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-dataset-1200","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval-Augmented Generation (RAG) Dataset 1200\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) Dataset 1200 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache licence 2.0.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-dataset-1200."},
	{"name":"russian-retrieval","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLNavigator/russian-retrieval","creator_name":"Alexandr Brut-Brulyako","creator_url":"https://huggingface.co/MLNavigator","description":"Based on Sberquad\\n\\nAnswer converted to human affordable answer.\\n\\nContext augmented with some pices of texts from wiki accordant to text on tematic and keywords.\\n\\nThis dataset cold be used for training retrieval LLM models or modificators for ability of LLM to retrieve target information from collection of tematic related texts.\\n\\nDataset has version with SOURCE data for generating answer with specifing source document for right answer. See file retrieval_dataset_src.jsonl\\n\\n\\nDataset consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLNavigator/russian-retrieval."},
	{"name":"rag-hallucination-dataset-1000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000 is an English dataset designed to reduce the hallucination in RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHallucination in large language models (LLMs) refers to the generation of incorrect, nonsensical, or unrelated text that does not stem from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000."},
	{"name":"rag-dataset-12000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-dataset-12000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval-Augmented Generation (RAG) Dataset 12000\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) Dataset 12000 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-dataset-12000."},
	{"name":"rag-full-20000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-full-20000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval-Augmented Generation (RAG) Full 20000\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) Full 20000 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-full-20000."},
	{"name":"rag_instruct_benchmark_tester","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG-Instruct-Benchmark-Tester\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is an updated benchmarking test dataset for \\\"retrieval augmented generation\\\" (RAG) use cases in the enterprise, especially for financial services, and legal.  This test dataset includes 200 questions with context passages pulled from common 'retrieval scenarios', e.g., financial news, earnings releases,\\ncontracts, invoices, technical articles, general news and short texts.  \\nThe questions are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester."},
	{"name":"rag_instruct_benchmark_tester","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG-Instruct-Benchmark-Tester\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is an updated benchmarking test dataset for \\\"retrieval augmented generation\\\" (RAG) use cases in the enterprise, especially for financial services, and legal.  This test dataset includes 200 questions with context passages pulled from common 'retrieval scenarios', e.g., financial news, earnings releases,\\ncontracts, invoices, technical articles, general news and short texts.  \\nThe questions are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester."},
	{"name":"tech-news-embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/tech-news-embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nHackerNoon curated the internet's most cited 7M+ tech company news articles and blog posts about the 3k+ most valuable tech companies in 2022 and 2023. \\nTo further enhance the dataset's utility, a new embedding field and vector embedding for every datapoint have been added using the OpenAI EMBEDDING_MODEL = \\\"text-embedding-3-small\\\", with an EMBEDDING_DIMENSION of 256. \\nNotably, this extension with vector embeddings only contains a portion of the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/tech-news-embeddings."},
	{"name":"cosmopedia-wikihow-chunked","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a chunked version of a subset of data in the Cosmopedia dataset curated by Hugging Face.\\nSpecifically, we have only used a subset of Wikihow articles from the Cosmopedia dataset, and each article has been split into chunks containing no more than 2 paragraphs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record in the dataset represents a chunk of a larger article, and contains the following fields:\\n\\ndoc_id: A unique identifier for the parent article\\nchunk_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked."},
	{"name":"airbnb_embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/airbnb_embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset consists of AirBnB listings with property descriptions, reviews, and other metadata. \\nIt also contains text embeddings of the property descriptions as well as image embeddings of the listing image. The text embeddings were created using OpenAI's text-embedding-3-small model and the image embeddings using OpenAI's clip-vit-base-patch32 model available on Hugging Face. \\nThe text embeddings have 1536 dimensions, while the image embeddings have 512 dimensions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/airbnb_embeddings."},
	{"name":"RAG-v1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/RAG-v1","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-RAG-v1\\n\\t\\n\\nGlaive-RAG-v1 is a dataset with ~50k samples built using the Glaive platform, for finetuning models for RAG use cases. \\nEach row has:\\n\\nList of documents for context\\nQuestion\\nAnswer Mode\\nAnswer\\n\\nThe answer mode is to define if the model should output only grounded responses or if it should combine it's internal information as well.\\nThe answers have Cited documents at the beginning and also <co: 1> tags in the text to mark citations.\\nTo report any problems or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/glaiveai/RAG-v1."},
	{"name":"indonesia-law-qa-embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biznetgio/indonesia-law-qa-embeddings","creator_name":"Biznet Gio Nusantara","creator_url":"https://huggingface.co/biznetgio","description":"biznetgio/indonesia-law-qa-embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"frames-benchmark","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/frames-benchmark","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFRAMES: Factuality, Retrieval, And reasoning MEasurement Set\\n\\t\\n\\nFRAMES is a comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.\\nOur paper with details and experiments is available on arXiv: https://arxiv.org/abs/2409.12941.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n824 challenging multi-hop questions requiring information from 2-15 Wikipedia articles\\nQuestions span diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/frames-benchmark."},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets can be for this training step are derived from 3 different sources:\\n\\nSauerkrautLM Preference Datasets:\\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI."},
	{"name":"RAG-v1-ruen","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MexIvanov/RAG-v1-ruen","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A version of the glaiveai/RAG-v1 dataset extended with machine translation to Russian language for multilingual retrieval-augmented generation tasks.\\nReleased under the same license as the original dataset, provided as is with research intent (but not limited), use/read at your own risk.\\n"},
	{"name":"RAG-RewardBench","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench","creator_name":"Zhuoran Jin","creator_url":"https://huggingface.co/jinzhuoran","description":"This repository contains the data presented in RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment.\\nCode: https://github.com/jinzhuoran/RAG-RewardBench/\\n"},
	{"name":"RAG-RewardBench","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench","creator_name":"Zhuoran Jin","creator_url":"https://huggingface.co/jinzhuoran","description":"This repository contains the data presented in RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment.\\nCode: https://github.com/jinzhuoran/RAG-RewardBench/\\n"},
	{"name":"RAG-Instruct","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nRAG-Instruct is a RAG dataset designed to comprehensively enhance LLM RAG capabilities, synthesized using GPT-4o. This dataset is based on the Wikipedia corpus and This dataset is based on the Wikipedia corpus and offers the advantages of query-document scenario diversity and task diversity.\\nThe RAG-Instruct dataset can significantly enhance the RAG ability of LLMs and make remarkable improvements in RAG performance across various tasks.\\n\\n\\t\\n\\t\\t\\nModel\\nWQA (acc)\\nPQA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct."},
	{"name":"docprompting-conala","keyword":"retrieval augmented generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"rag_instruct_test_dataset2_financial_0.1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG-Instruct-Financial-Test-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a test dataset for \\\"retrieval augmented generation\\\" (RAG) use cases, especially for financial data extraction and analysis, including a series of questions relating to tabular financial data and common-sense math operations (small increments, decrements, sorting and ordering as well as recognizing when information is not included in a particular source).  This test dataset includes 100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1."},
	{"name":"rag_instruct_test_dataset2_financial_0.1","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG-Instruct-Financial-Test-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a test dataset for \\\"retrieval augmented generation\\\" (RAG) use cases, especially for financial data extraction and analysis, including a series of questions relating to tabular financial data and common-sense math operations (small increments, decrements, sorting and ordering as well as recognizing when information is not included in a particular source).  This test dataset includes 100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1."},
	{"name":"preguntas-respuestas-RAG","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hythyt/preguntas-respuestas-RAG","creator_name":"hyt","creator_url":"https://huggingface.co/hythyt","description":"hythyt/preguntas-respuestas-RAG dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Finance-Instruct-500k","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/Finance-Instruct-500k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tFinance-Instruct-500k Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\\nThe dataset includes content tailored for financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/Finance-Instruct-500k."},
	{"name":"CardBench","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jerry999/CardBench","creator_name":"Jiarui Liu","creator_url":"https://huggingface.co/Jerry999","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAutomatic Generation of Model and Data Cards: A Step Towards Responsible AI\\n\\t\\n\\nThe work has been accepted to NAACL 2024 Oral.\\nAbstract: In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-written model and data cards. We propose an automated generation approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jerry999/CardBench."},
	{"name":"nitibench","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VISAI-AI/nitibench","creator_name":"VISAI AI","creator_url":"https://huggingface.co/VISAI-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\tüë©üèª‚Äç‚öñÔ∏è NitiBench: A Thai Legal Benchmark for RAG\\n\\t\\n\\n[üìÑ Technical Report] | [üë®‚Äçüíª Github Repository]\\nThis dataset provides the test data for evaluating LLM frameworks, such as RAG or LCLM. The benchmark consists of two datasets:\\n\\nNitiBench-CCL\\nNitiBench-Tax\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüèõÔ∏è NitiBench-CCL\\n\\t\\n\\nDerived from the WangchanX-Legal-ThaiCCL-RAG Dataset, our version includes an additional preprocessing step in which we separate the reasoning process from the final answer. The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VISAI-AI/nitibench."},
	{"name":"enstrag_dataset","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Maxenceleguery/enstrag_dataset","creator_name":"Maxence Legu√©ry","creator_url":"https://huggingface.co/Maxenceleguery","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Maxenceleguery/enstrag_dataset."}
]
;
