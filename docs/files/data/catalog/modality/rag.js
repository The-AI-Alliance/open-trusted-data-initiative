const data_for_modality_rag = 
[
	{"name":"Finetune-RAG","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pints-ai/Finetune-RAG","creator_name":"Pints AI","creator_url":"https://huggingface.co/pints-ai","description":"\n\t\n\t\t\n\t\tFinetune-RAG Dataset\n\t\n\nThis dataset is part of the Finetune-RAG project, which aims to tackle hallucination in retrieval-augmented LLMs. It consists of synthetically curated and processed RAG documents that can be utilised for LLM fine-tuning.\nEach line in the finetunerag_dataset.jsonl file is a JSON object:\n{\n  \"content\": \"<correct content chunk retrieved>\",\n  \"filename\": \"<original document filename>\",\n  \"fictitious_filename1\":\"<filename of fake doc 1>\",\n  \"fictitious_content1\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pints-ai/Finetune-RAG.","first_N":5,"first_N_keywords":["text-generation","question-answering","machine-generated","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"pile-of-law-bm25","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/pile-of-law-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/pile-of-law-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"pile-of-law-bm25","keyword":"retrieval-augmented-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/pile-of-law-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/pile-of-law-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"pstuts_rag_qa","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mbudisic/pstuts_rag_qa","creator_name":"Marko Budisic","creator_url":"https://huggingface.co/mbudisic","description":"\n\t\n\t\t\n\t\tüìä PsTuts-RAG Q&A Dataset\n\t\n\nThis dataset contains question-answer pairs generated using RAGAS \nfrom Photoshop tutorial video transcripts published in PsTuts-VQA Dataset. \nIt's designed for training and evaluating RAG (Retrieval-Augmented Generation) systems focused on Photoshop tutorials.\n\n\t\n\t\t\n\t\n\t\n\t\tüìù Dataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset contains 100 question-answer pairs related to Photoshop usage, generated from video transcripts using RAGAS's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mbudisic/pstuts_rag_qa.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"barexam-qa-bm25","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/barexam-qa-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/barexam-qa-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"barexam-qa-bm25","keyword":"retrieval-augmented-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/barexam-qa-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/barexam-qa-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"Rhodes_Island","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DimitrisRode/Rhodes_Island","creator_name":"Dimitris papakonstantis","creator_url":"https://huggingface.co/DimitrisRode","description":"\n\t\n\t\t\n\t\tRhodes Island Knowledge Base\n\t\n\nA structured, up-to-date Q&A and reference dataset about Rhodes Island (Rhodos), Greece, optimized for retrieval-augmented generation and fine-tuning of language models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset aggregates detailed information on:\n\nHistory, culture & heritage  \nMajor & hidden attractions (villages, monasteries, beaches)  \nAccommodation (hotels, guesthouses, agrotourism)  \nPractical tables (pharmacies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DimitrisRode/Rhodes_Island.","first_N":5,"first_N_keywords":["English","mit","üá∫üá∏ Region: US","travel","rhodes"],"keywords_longer_than_N":true},
	{"name":"lme-mc10","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Percena/lme-mc10","creator_name":"Percena","creator_url":"https://huggingface.co/Percena","description":"\n\t\n\t\t\n\t\tLME‚ÄëMC10 ¬∑ LongMemEval(s)¬†Multiple‚ÄëChoice¬†10\n\t\n\nLME‚ÄëMC10 is a 500‚Äëitem multiple‚Äëchoice benchmark derived from LongMemEval(s).Each item probes one of LongMemEval‚Äôs five long‚Äëterm memory abilities, but is reformatted into a 10‚Äëoption MC task for straightforward automated evaluation (plain accuracy, balanced accuracy, etc.). \n\nInformation Extraction¬†(IE)\nMulti-Session Reasoning¬†(MR)\nKnowledge Updates¬†(KU)\nTemporal Reasoning¬†(TR)\nAbstention¬†(ABS)\n\nThe original AI‚Äëjudge rubric is removed;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Percena/lme-mc10.","first_N":5,"first_N_keywords":["question-answering","expert-generated","machine-generated","xiaowu0162/longmemeval","English"],"keywords_longer_than_N":true},
	{"name":"kindred-ecommerce-merchant-deals-dataset","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset","creator_name":"Kindred Soul Ltd","creator_url":"https://huggingface.co/kindred-soul-ltd","description":"\n\t\n\t\t\n\t\tKindred E-commerce Merchant Deals Dataset\n\t\n\nAI-ready catalogue of deals and offers for global retail brands.Structured in CSV and JSONL, validated against JSON Schema.\nTrain-ready catalogue of promotions, ready for RAG, embeddings, or classic search.\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\n    \n        File\n        Rows\n        Description\n    \n        \n            data/csv/brands.csv or data/jsonl/brands.jsonl\n            ~90K\n            E-Commerce Merchant metadata, Logo URL, and domains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","cc-by-4.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"kindred-ecommerce-merchant-deals-dataset","keyword":"retrieval-augmented-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset","creator_name":"Kindred Soul Ltd","creator_url":"https://huggingface.co/kindred-soul-ltd","description":"\n\t\n\t\t\n\t\tKindred E-commerce Merchant Deals Dataset\n\t\n\nAI-ready catalogue of deals and offers for global retail brands.Structured in CSV and JSONL, validated against JSON Schema.\nTrain-ready catalogue of promotions, ready for RAG, embeddings, or classic search.\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\n    \n        File\n        Rows\n        Description\n    \n        \n            data/csv/brands.csv or data/jsonl/brands.jsonl\n            ~90K\n            E-Commerce Merchant metadata, Logo URL, and domains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kindred-soul-ltd/kindred-ecommerce-merchant-deals-dataset.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","English","cc-by-4.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"rag-hallucination-dataset-1000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\n\t\n\t\t\n\t\tRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000\n\t\n\nRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000 is an English dataset designed to reduce the hallucination in RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nHallucination in large language models (LLMs) refers to the generation of incorrect, nonsensical, or unrelated text that does not stem from an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"BaldursGate3-Evaluation-Dataset","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stucksam/BaldursGate3-Evaluation-Dataset","creator_name":"Samuel","creator_url":"https://huggingface.co/stucksam","description":"stucksam/BaldursGate3-Evaluation-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"rag_instruct_test_dataset2_financial_0.1","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\n\t\n\t\t\n\t\tDataset Card for RAG-Instruct-Financial-Test-Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a test dataset for \"retrieval augmented generation\" (RAG) use cases, especially for financial data extraction and analysis, including a series of questions relating to tabular financial data and common-sense math operations (small increments, decrements, sorting and ordering as well as recognizing when information is not included in a particular source).  This test dataset includes 100 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"rag_instruct_test_dataset2_financial_0.1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\n\t\n\t\t\n\t\tDataset Card for RAG-Instruct-Financial-Test-Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a test dataset for \"retrieval augmented generation\" (RAG) use cases, especially for financial data extraction and analysis, including a series of questions relating to tabular financial data and common-sense math operations (small increments, decrements, sorting and ordering as well as recognizing when information is not included in a particular source).  This test dataset includes 100 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_test_dataset2_financial_0.1.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"rag_instruct_benchmark_tester","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\n\t\n\t\t\n\t\tDataset Card for RAG-Instruct-Benchmark-Tester\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is an updated benchmarking test dataset for \"retrieval augmented generation\" (RAG) use cases in the enterprise, especially for financial services, and legal.  This test dataset includes 200 questions with context passages pulled from common 'retrieval scenarios', e.g., financial news, earnings releases,\ncontracts, invoices, technical articles, general news and short texts.  \nThe questions are segmented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"rag_instruct_benchmark_tester","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester","creator_name":"llmware","creator_url":"https://huggingface.co/llmware","description":"\n\t\n\t\t\n\t\tDataset Card for RAG-Instruct-Benchmark-Tester\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is an updated benchmarking test dataset for \"retrieval augmented generation\" (RAG) use cases in the enterprise, especially for financial services, and legal.  This test dataset includes 200 questions with context passages pulled from common 'retrieval scenarios', e.g., financial news, earnings releases,\ncontracts, invoices, technical articles, general news and short texts.  \nThe questions are segmented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llmware/rag_instruct_benchmark_tester.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"tech-news-embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/tech-news-embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nHackerNoon curated the internet's most cited 7M+ tech company news articles and blog posts about the 3k+ most valuable tech companies in 2022 and 2023. \nTo further enhance the dataset's utility, a new embedding field and vector embedding for every datapoint have been added using the OpenAI EMBEDDING_MODEL = \"text-embedding-3-small\", with an EMBEDDING_DIMENSION of 256. \nNotably, this extension with vector embeddings only contains a portion of the original dataset, 1576528‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/tech-news-embeddings.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"preguntas-respuestas-RAG","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hythyt/preguntas-respuestas-RAG","creator_name":"hyt","creator_url":"https://huggingface.co/hythyt","description":"hythyt/preguntas-respuestas-RAG dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Spanish","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"russian-retrieval","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLNavigator/russian-retrieval","creator_name":"Alexandr Brut-Brulyako","creator_url":"https://huggingface.co/MLNavigator","description":"Based on Sberquad\n\nAnswer converted to human affordable answer.\n\nContext augmented with some pices of texts from wiki accordant to text on tematic and keywords.\n\nThis dataset cold be used for training retrieval LLM models or modificators for ability of LLM to retrieve target information from collection of tematic related texts.\n\nDataset has version with SOURCE data for generating answer with specifing source document for right answer. See file retrieval_dataset_src.jsonl\n\n\nDataset consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLNavigator/russian-retrieval.","first_N":5,"first_N_keywords":["question-answering","Russian","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"rag-dataset-12000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-dataset-12000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\n\t\n\t\t\n\t\tRetrieval-Augmented Generation (RAG) Dataset 12000\n\t\n\nRetrieval-Augmented Generation (RAG) Dataset 12000 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach significantly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-dataset-12000.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"rag-full-20000","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-full-20000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\n\t\n\t\t\n\t\tRetrieval-Augmented Generation (RAG) Full 20000\n\t\n\nRetrieval-Augmented Generation (RAG) Full 20000 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach significantly boosts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-full-20000.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Finance-Instruct-500k","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k.","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"frames-benchmark","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/frames-benchmark","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tFRAMES: Factuality, Retrieval, And reasoning MEasurement Set\n\t\n\nFRAMES is a comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.\nOur paper with details and experiments is available on arXiv: https://arxiv.org/abs/2409.12941.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n824 challenging multi-hop questions requiring information from 2-15 Wikipedia articles\nQuestions span diverse topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/frames-benchmark.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"docprompting-conala","keyword":"retrieval augmented generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tldr","keyword":"retrieval augmented generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"rag-dataset-1200","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-dataset-1200","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\n\t\n\t\t\n\t\tRetrieval-Augmented Generation (RAG) Dataset 1200\n\t\n\nRetrieval-Augmented Generation (RAG) Dataset 1200 is an English dataset designed for RAG-optimized models, built by Neural Bridge AI, and released under Apache licence 2.0.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRetrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach significantly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-dataset-1200.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"raghalu-open","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liveperson/raghalu-open","creator_name":"LivePerson Inc.","creator_url":"https://huggingface.co/liveperson","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for RAGHalu Open Source Data\n\t\n\nThis dataset is the public data portion from the paper Two-tiered\nEncoder-based Hallucination Detection for Retrieval-Augmented Generation\nin the Wild by Ilana Zimmerman, Jadin Tredup, Ethan Selfridge, and\nJoseph Bradley, accepted at EMNLP 2024\n(Industry Track). The private brand data portion of the dataset is not\nincluded.\nNote that this dataset and the paper do not use the common hallucination\nterms factuality and faithfulness as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liveperson/raghalu-open.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-sa-4.0","10K<n<100K","arxiv:2311.05232"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"RAG-v1-ruen","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MexIvanov/RAG-v1-ruen","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A version of the glaiveai/RAG-v1 dataset extended with machine translation to Russian language for multilingual retrieval-augmented generation tasks.\nReleased under the same license as the original dataset, provided as is with research intent (but not limited), use/read at your own risk.\n","first_N":5,"first_N_keywords":["English","Russian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Vietnamese-Function-Calling-Test","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test","creator_name":"phamhai","creator_url":"https://huggingface.co/phamhai","description":"Vietnamese Function Calling Benchmark\n\nRAG applications for Vietnamese chatbot systems are becoming increasingly popular. Many LLM models already support FC for Vietnamese, but there is no common and comprehensive benchmark yet. Today, I am releasing a benchmark for the Vietnamese Function Calling task. I hope this will serve as a standard for product teams to choose models in a reasonable and appropriate way.\nDataset Details:\n\n\nData size: 2899 single-turn funcation calling samples\nDomains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test.","first_N":5,"first_N_keywords":["Vietnamese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"CardBench","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jerry999/CardBench","creator_name":"Jiarui Liu","creator_url":"https://huggingface.co/Jerry999","description":"\n\t\n\t\t\n\t\tAutomatic Generation of Model and Data Cards: A Step Towards Responsible AI\n\t\n\nThe work has been accepted to NAACL 2024 Oral.\nAbstract: In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-written model and data cards. We propose an automated generation approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jerry999/CardBench.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ToolLinkOS","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eliaslumer/ToolLinkOS","creator_name":"Elias Lumer","creator_url":"https://huggingface.co/eliaslumer","description":"\n\t\n\t\t\n\t\tGraph RAG-Tool Fusion\n\t\n\nThis repository accompanies the research paper Graph RAG-Tool Fusion and ToolLinkOS dataset. In the paper, we introduce Graph RAG-Tool Fusion (advanced tool retrieval approach) and the ToolLinkOS dataset, a collection of 573 fictional tools with an average of 6.3 dependencies each, spanning over 15 industries.\n\nRecent developments in retrieval-augmented generation (RAG) for selecting relevant tools from a tool knowledge base enable LLM agents to scale their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eliaslumer/ToolLinkOS.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"hotpotqa_small_sample_autorag","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gnekt/hotpotqa_small_sample_autorag","creator_name":"Christian Di Maio","creator_url":"https://huggingface.co/gnekt","description":"gnekt/hotpotqa_small_sample_autorag dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI framework for improving LLM responses\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RAG-v1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/RAG-v1","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\n\t\n\t\t\n\t\tGlaive-RAG-v1\n\t\n\nGlaive-RAG-v1 is a dataset with ~50k samples built using the Glaive platform, for finetuning models for RAG use cases. \nEach row has:\n\nList of documents for context\nQuestion\nAnswer Mode\nAnswer\n\nThe answer mode is to define if the model should output only grounded responses or if it should combine it's internal information as well.\nThe answers have Cited documents at the beginning and also <co: 1> tags in the text to mark citations.\nTo report any problems or suggestions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/glaiveai/RAG-v1.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"grouse","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/illuin/grouse","creator_name":"Illuin Technology","creator_url":"https://huggingface.co/illuin","description":"\n\t\n\t\t\n\t\tDataset Card for GroUSE\n\t\n\nGroUSE (Grounded QA Unitary Scoring of Evaluators) is a dataset designed to assess the performance of Grounded QA evaluators. Its purpose is to evaluate whether an LLM, when used as a grounded QA evaluator, delivers the expected scores across six metrics when presented with both good and imperfect answers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEach sample is of the following form :\n{\n    \"references\": [\n        \"[Content of the 1st‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/illuin/grouse.","first_N":5,"first_N_keywords":["expert-generated","monolingual","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"RAG-Instruct","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nRAG-Instruct is a RAG dataset designed to comprehensively enhance LLM RAG capabilities, synthesized using GPT-4o. This dataset is based on the Wikipedia corpus and This dataset is based on the Wikipedia corpus and offers the advantages of query-document scenario diversity and task diversity.\nThe RAG-Instruct dataset can significantly enhance the RAG ability of LLMs and make remarkable improvements in RAG performance across various tasks.\n\n\t\n\t\t\nModel\nWQA (acc)\nPQA (acc)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-SFT-Alpaca-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-SFT-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-SFT (Supervised Fine-Tuning) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe SFT Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-SFT-Alpaca-HESSIAN-AI.","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\n\t\n\t\t\n\t\tArabic Version of The Finanical Rag Embedding Dataset\n\t\n\n\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\nThis dataset is the Arabic version of the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-EASY-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\nMost of the Subsets are synthetically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK.","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"EvalRAGData","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AITeamVN/EvalRAGData","creator_name":"VietNamAI","creator_url":"https://huggingface.co/AITeamVN","description":"\n\t\n\t\t\n\t\tDataset Card: Vietnamese RAG Benchmark\n\t\n\nM√¥ t·∫£ d·ªØ li·ªáu:\nEvalRAGData l√† m·ªôt t·∫≠p d·ªØ li·ªáu g·ªìm 120 samples ƒë∆∞·ª£c t·∫°o th·ªß c√¥ng b·ªüi con ng∆∞·ªùi ƒë·ªÉ ƒë√°nh gi√° LLM cho kh·∫£ nƒÉng tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh (RAG). \nT·∫≠p d·ªØ li·ªáu n√†y ƒë√°ng gi√° 3 kh·∫£ nƒÉng c·ªßa LLM:\n\nKh·∫£ nƒÉng ch·ªëng nhi·ªÅu: M√¥ h√¨nh tr√≠ch xu·∫•t th√¥ng tin h·ªØu √≠ch t·ª´ c√°c t√†i li·ªáu nhi·ªÖu. ( 1 positive + 4 negative ho·∫∑c 1 positive)\nLo·∫°i b·ªè negative: M√¥ h√¨nh t·ª´ ch·ªëi tr·∫£ l·ªùi c√¢u h·ªèi khi ki·∫øn th·ª©c c·∫ßn thi·∫øt kh√¥ng c√≥ trong b·∫•t k·ª≥ t√†i li·ªáu n√†o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AITeamVN/EvalRAGData.","first_N":5,"first_N_keywords":["Vietnamese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","summarization","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"RAG-RewardBench","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench","creator_name":"Zhuoran Jin","creator_url":"https://huggingface.co/jinzhuoran","description":"This repository contains the data presented in RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment.\nCode: https://github.com/jinzhuoran/RAG-RewardBench/\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"RAG-RewardBench","keyword":"retrieval-augmented-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench","creator_name":"Zhuoran Jin","creator_url":"https://huggingface.co/jinzhuoran","description":"This repository contains the data presented in RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment.\nCode: https://github.com/jinzhuoran/RAG-RewardBench/\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"SFinD-S","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tilmann-strative/SFinD-S","creator_name":"Tilmann Bruckhaus","creator_url":"https://huggingface.co/tilmann-strative","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis sample is part of the larger SFinD-S (Strative Financial Dataset - Synthetic), a comprehensive dataset designed for Retrieval-Augmented Generation (RAG) GenAI applications, Natural Language Processing (NLP), Large Language Models (LLM), and AI tasks in the financial domain. The full SFinD-S dataset contains over 20,000 records of realistic financial questions and verified answers, sourced from a wide variety of web content.\nIf you find this dataset useful or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tilmann-strative/SFinD-S.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"indonesia-law-qa-embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biznetgio/indonesia-law-qa-embeddings","creator_name":"Biznet Gio Nusantara","creator_url":"https://huggingface.co/biznetgio","description":"biznetgio/indonesia-law-qa-embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-retrieval","Indonesian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-DPO-Alpaca-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-DPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-DPO Alpaca Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge graph where Question-Answer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-DPO-Alpaca-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","German","cc-by-sa-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"German-RAG-DPO-ShareGPT-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-DPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-DPO Share-GPT Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge graph where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-DPO-ShareGPT-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","German","cc-by-sa-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-SFT-ShareGPT-HESSIAN-AI","keyword":"rag","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avemio/German-RAG-SFT-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\n\t\n\t\t\n\t\tGerman-RAG-SFT (Supervised Fine-Tuning) Share-GPT Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe SFT Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. Most tasks were developed using synthetically enhanced data derived from the German Wikipedia, accessed through Cohere's dataset (wikipedia-22-12-de-embeddings). The data is structured in a training knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-SFT-ShareGPT-HESSIAN-AI.","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"cosmopedia-wikihow-chunked","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a chunked version of a subset of data in the Cosmopedia dataset curated by Hugging Face.\nSpecifically, we have only used a subset of Wikihow articles from the Cosmopedia dataset, and each article has been split into chunks containing no more than 2 paragraphs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset represents a chunk of a larger article, and contains the following fields:\n\ndoc_id: A unique identifier for the parent article\nchunk_id: A unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"airbnb_embeddings","keyword":"retrieval augmented generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/airbnb_embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of AirBnB listings with property descriptions, reviews, and other metadata. \nIt also contains text embeddings of the property descriptions as well as image embeddings of the listing image. The text embeddings were created using OpenAI's text-embedding-3-small model and the image embeddings using OpenAI's clip-vit-base-patch32 model available on Hugging Face. \nThe text embeddings have 1536 dimensions, while the image embeddings have 512 dimensions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/airbnb_embeddings.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-to-image","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"invoices-example","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parsee-ai/invoices-example","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","description":"\n\t\n\t\t\n\t\tInoices Sample Dataset\n\t\n\nThis is a sample dataset generated on app.parsee.ai for invoices. The goal was to evaluate different LLMs on this RAG task using the Parsee evaluation tools. A full study can be found here: https://github.com/parsee-ai/parsee-datasets/blob/main/datasets/invoices/parsee-loader/README.md\nparsee-core version used: 0.1.3.11\nThis dataset was created on the basis of 15 sample invoices (PDF files).\nAll PDF files are publicly accessible on parsee.ai, to access them‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/invoices-example.","first_N":5,"first_N_keywords":["question-answering","English","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"revenues-example","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parsee-ai/revenues-example","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","description":"\n\t\n\t\t\n\t\tRevenues Sample Dataset\n\t\n\nparsee-core version used: 0.1.3.14\nThis dataset was created on the basis of 15 pages from annual/quarterly filings of major German stock-exchange listed companies (PDF files).\nAll PDF files are publicly accessible on parsee.ai, to access them copy the \"source_identifier\" (first column) and paste it in this URL (replace '{SOURCE_IDENTIFIER}' with the actual identifier):\nhttps://app.parsee.ai/documents/view/{SOURCE_IDENTIFIER}\nSo for example:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/revenues-example.","first_N":5,"first_N_keywords":["table-question-answering","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\n\t\n\t\t\n\t\tGermanRAG üá©üá™üìúü¶ú\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"retrieval-augmented-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\n\t\n\t\t\n\t\tGermanRAG üá©üá™üìúü¶ú\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"neural-bridge-rag-dataset-12000-google-translated","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated","creator_name":"pandora","creator_url":"https://huggingface.co/pandora-s","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a repository where I will slowly translate neural-bridge/rag-dataset-12000 into different languages with Google Translate.As RAG datasets are quite scarce, I felt that this could be useful for many who seek to add RAG capabilities to their models!\n\n\t\n\t\t\n\t\tHow?\n\t\n\nThere are no secrets; these are raw translations that might not be 100% reliable. I literally run the entire dataset through Google Translate overnight.I'm prioritizing \"quantity\" over \"quality\" here. As‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated.","first_N":5,"first_N_keywords":["French","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"hotpotqa_sample_autorag","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gnekt/hotpotqa_sample_autorag","creator_name":"Christian Di Maio","creator_url":"https://huggingface.co/gnekt","description":"\n\t\n\t\t\n\t\tATTENTION\n\t\n\nUtilizing the full dataset corpus and associated questions with pay-for-use Large Language Models (LLMs) can result in substantial costs.\n","first_N":5,"first_N_keywords":["question-answering","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"RAGPPI_Atomics","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Youngseung/RAGPPI_Atomics","creator_name":"Jeon","creator_url":"https://huggingface.co/Youngseung","description":"\n\t\n\t\t\n\t\tRAG Benchmark for Protein-Protein Interactions (RAGPPI)\n\t\n\n\n\t\n\t\t\n\t\tüìä Overview\n\t\n\nRetrieving expected therapeutic impacts in protein-protein interactions (PPIs) is crucial in drug development, enabling researchers to prioritize promising targets and improve success rates. While Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) frameworks accelerate discovery, no benchmark exists for identifying therapeutic impacts in PPIs.\nRAGPPI is the first factual QA benchmark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Youngseung/RAGPPI_Atomics.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"housing-qa-bm25","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/housing-qa-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/housing-qa-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"housing-qa-bm25","keyword":"retrieval-augmented-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoorangyee/housing-qa-bm25","creator_name":"Minhu, Park","creator_url":"https://huggingface.co/hoorangyee","description":"\n\t\n\t\t\n\t\tLRAGE: Legal Retrieval Augmented Generation Evaluation Tool\n\t\n\nLRAGE (Legal Retrieval Augmented Generation Evaluation) is an open-source toolkit designed to evaluate Large Language Models (LLMs) in a Retrieval-Augmented Generation (RAG) setting, specifically tailored for the legal domain.  \nThis repository facilitates evaluating LLM performance on legal tasks without cumbersome engineering overhead.\nCode: https://github.com/hoorangyee/LRAGE\nFor more details, please refer to the LRAGE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoorangyee/housing-qa-bm25.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","arxiv:2504.01840"],"keywords_longer_than_N":true},
	{"name":"MNLP_M2_rag_documents","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smikulas/MNLP_M2_rag_documents","creator_name":"Szabina H.","creator_url":"https://huggingface.co/smikulas","description":"\n\t\n\t\t\n\t\tMNLP_M2_rag_documents\n\t\n\nThis is a sample set of documents for use in Retrieval-Augmented Generation (RAG) evaluation.\n","first_N":5,"first_N_keywords":["English","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"medimaven-qa-data","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dranreb1660/medimaven-qa-data","creator_name":"Bernard Kyei-Mensah","creator_url":"https://huggingface.co/dranreb1660","description":"\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tü©∫ MediMaven-QA v1.0\n\t\n\nMediMaven-QA is a chunk-level, citation-preserving medical question-answer corpus purpose-built for Retrieval-Augmented Generation (RAG).It bridges everyday lay-symptom narratives with trustworthy clinical content from curated web sources.\n\n\t\n\t\n\t\n\t\tüì¶ Dataset Contents\n\t\n\n\n\t\n\t\t\nConfig¬†(name)\nRows\nWhat it holds\nTypical use-case\n\n\n\t\t\nchunks\n70 243\n400-token, sentence-aware context windows with rich metadata (id, url, title, section, source, n_token, text)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dranreb1660/medimaven-qa-data.","first_N":5,"first_N_keywords":["machine-generated","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"NoiserBench","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinyang23/NoiserBench","creator_name":"Jinyang Wu","creator_url":"https://huggingface.co/Jinyang23","description":"\n\t\n\t\t\n\t\tDataset Card for NoiserBench\n\t\n\nThis dataset card describes NoiserBench, a comprehensive evaluation framework for analyzing the role of noise in Retrieval-Augmented Generation (RAG) systems with Large Language Models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNoiserBench is a comprehensive benchmark designed to evaluate how different types of noise affect Large Language Models in Retrieval-Augmented Generation scenarios. The benchmark encompasses multiple datasets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jinyang23/NoiserBench.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"NoiserBench","keyword":"retrieval-augmented-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinyang23/NoiserBench","creator_name":"Jinyang Wu","creator_url":"https://huggingface.co/Jinyang23","description":"\n\t\n\t\t\n\t\tDataset Card for NoiserBench\n\t\n\nThis dataset card describes NoiserBench, a comprehensive evaluation framework for analyzing the role of noise in Retrieval-Augmented Generation (RAG) systems with Large Language Models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNoiserBench is a comprehensive benchmark designed to evaluate how different types of noise affect Large Language Models in Retrieval-Augmented Generation scenarios. The benchmark encompasses multiple datasets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jinyang23/NoiserBench.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"documents-prevenia","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PrevenIA/documents-prevenia","creator_name":"prevenIA","creator_url":"https://huggingface.co/PrevenIA","description":"Documents used by the RAG component of the prevenIA chatbot to answer questions about suicide. \n","first_N":5,"first_N_keywords":["Spanish","mit","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Finance-Instruct-500k","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/Finance-Instruct-500k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/Finance-Instruct-500k.","first_N":5,"first_N_keywords":["apache-2.0","üá∫üá∏ Region: US","finance","fine-tuning","conversational-ai"],"keywords_longer_than_N":true},
	{"name":"enstrag_dataset","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Maxenceleguery/enstrag_dataset","creator_name":"Maxence Legu√©ry","creator_url":"https://huggingface.co/Maxenceleguery","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Maxenceleguery/enstrag_dataset.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ragtime1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/trec-ragtime/ragtime1","creator_name":"TREC RAGTIME Track","creator_url":"https://huggingface.co/trec-ragtime","description":"\n\t\n\t\t\n\t\tRAGTIME1 Collection\n\t\n\nThis dataset contains the documents for TREC RAGTIME Track. \nPlease refer to the website for the details of the task. \nRAGTIME is a multilingual RAG task, which expects the participating system to retrieve relevant documents from all four languages and synthesize a response with citation to the report request. \nFor convenience, we separate the documents by their languages into four .jsonl files. However, they are intended to be used as a whole set. \nThe documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trec-ragtime/ragtime1.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","multilingual","extended|c4"],"keywords_longer_than_N":true},
	{"name":"nitibench","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VISAI-AI/nitibench","creator_name":"VISAI AI","creator_url":"https://huggingface.co/VISAI-AI","description":"\n\t\n\t\t\n\t\tüë©üèª‚Äç‚öñÔ∏è NitiBench: A Thai Legal Benchmark for RAG\n\t\n\n[üìÑ Technical Report] | [üë®‚Äçüíª Github Repository]\nThis dataset provides the test data for evaluating LLM frameworks, such as RAG or LCLM. The benchmark consists of two datasets:\n\nNitiBench-CCL\nNitiBench-Tax\n\n\n\t\n\t\t\n\t\n\t\n\t\tüèõÔ∏è NitiBench-CCL\n\t\n\nDerived from the WangchanX-Legal-ThaiCCL-RAG Dataset, our version includes an additional preprocessing step in which we separate the reasoning process from the final answer. The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VISAI-AI/nitibench.","first_N":5,"first_N_keywords":["sentence-similarity","text-generation","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Finance","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mcube030/Finance","creator_name":"Mcube","creator_url":"https://huggingface.co/Mcube030","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mcube030/Finance.","first_N":5,"first_N_keywords":["apache-2.0","üá∫üá∏ Region: US","finance","fine-tuning","conversational-ai"],"keywords_longer_than_N":true},
	{"name":"rag-tutorial-prebuilt-indexes","keyword":"rag","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShubhamC/rag-tutorial-prebuilt-indexes","creator_name":"Shubham Chatterjee","creator_url":"https://huggingface.co/ShubhamC","description":"\n\t\n\t\t\n\t\tüîç Pre-built Indexes for RAG Tutorial\n\t\n\nWelcome to the official repository for Pre-built Dense Indexes used in our RAG (Retrieval-Augmented Generation) Tutorial.\nThis repository is designed to help learners, instructors, and researchers easily integrate domain-specific dense retrieval into their RAG workflows without spending time building indexes from scratch.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ What This Repository Contains\n\t\n\nThis repository hosts ready-to-use FAISS-based dense indexes and supporting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShubhamC/rag-tutorial-prebuilt-indexes.","first_N":5,"first_N_keywords":["English","mit","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"memefact-templates","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sergiogpinto/memefact-templates","creator_name":"S√©rgio Miguel Gon√ßalves Pinto","creator_url":"https://huggingface.co/sergiogpinto","description":"\n\t\n\t\t\n\t\tMemeFact Templates Dataset\n\t\n\nThis dataset contains 663 meme templates enriched with contextual knowledge for fact-checking meme generation. Each template includes comprehensive information about its origin, cultural significance, visual characteristics, and typical caption patterns to support Retrieval Augmented Generation (RAG) systems.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe \"MemeFact Templates\" dataset is the result of extensive data engineering applied to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sergiogpinto/memefact-templates.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"RAG_dataset_V1","keyword":"rag","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ibokajordan/RAG_dataset_V1","creator_name":"ibrahim √∂zkal","creator_url":"https://huggingface.co/ibokajordan","description":"ibokajordan/RAG_dataset_V1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Turkish","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"RAGPPI","keyword":"rag","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Youngseung/RAGPPI","creator_name":"Jeon","creator_url":"https://huggingface.co/Youngseung","description":"\n\t\n\t\t\n\t\tRAG Benchmark for Protein-Protein Interactions (RAGPPI)\n\t\n\n\n\t\n\t\t\n\t\tüìä Overview\n\t\n\nRetrieving expected therapeutic impacts in protein-protein interactions (PPIs) is crucial in drug development, enabling researchers to prioritize promising targets and improve success rates. While Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) frameworks accelerate discovery, no benchmark exists for identifying therapeutic impacts in PPIs.\nRAGPPI is the first factual QA benchmark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Youngseung/RAGPPI.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true}
]
;
